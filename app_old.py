import streamlit as st
import datetime
import base64

# Set page config must be the first Streamlit command
st.set_page_config(layout="wide", page_title="Amazon Advertising Dashboard", page_icon="assets/hand_logo.png")



import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import numpy as np
import json
import os
import re
import glob
import time
import io
import math
import calendar
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict
from io import StringIO
from urllib.parse import quote
from typing import Dict, List, Tuple, Optional, Any, Union, Set
from sklearn.linear_model import LinearRegression
from PIL import Image
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
import uuid
import functools
from insights import generate_insights
from contextlib import contextmanager

# --- Enhanced Campaign Filtering Function ---
def phrase_match(value, filter_value):
    """Enhanced phrase matching for campaign names with pipe separators"""
    if not isinstance(value, str):
        return False
    pattern = re.escape(filter_value)
    # Match as a whole phrase (preceded/followed by |, start/end, or whitespace)
    regex = rf"(^|[|\s]){pattern}([|\s]|$)"
    return re.search(regex, value, re.IGNORECASE) is not None or value.strip().lower() == filter_value.strip().lower()



# --- Performance Monitoring Utilities ---
@contextmanager
def performance_timer(operation_name):
    """Context manager to time operations and log performance metrics."""
    start_time = time.time()
    try:
        yield
    finally:
        elapsed_time = time.time() - start_time
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append(f"[PERFORMANCE] {operation_name}: {elapsed_time:.3f} seconds")

def performance_monitor(func):
    """Decorator to monitor function performance."""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        with performance_timer(f"{func.__name__}"):
            return func(*args, **kwargs)
    return wrapper

# --- Helper Functions for Expandable/Downloadable Sections ---
def create_expandable_section(title, key=None):
    """
    Creates an expandable section with a title and expand/collapse button.
    
    Args:
        title: The title of the section
        key: Optional unique key for the section (will be generated if not provided)
        
    Returns:
        is_expanded: Boolean indicating if the section is expanded
        section_key: The unique key for the section
    """
    if key is None:
        # Generate a unique key if none provided
        key = f"section_{str(uuid.uuid4())[:8]}"
        
    # Initialize session state for this section if it doesn't exist
    if f"expanded_{key}" not in st.session_state:
        st.session_state[f"expanded_{key}"] = False
    
    # Create a container for the header with title and button
    col1, col2 = st.columns([0.85, 0.15])
    
    with col1:
        st.markdown(f"#### {title}")
    
    with col2:
        if st.session_state[f"expanded_{key}"]:
            if st.button("Collapse", key=f"collapse_btn_{key}"):
                st.session_state[f"expanded_{key}"] = False
                st.rerun()
        else:
            if st.button("Expand", key=f"expand_btn_{key}"):
                st.session_state[f"expanded_{key}"] = True
                st.rerun()
    
    return st.session_state[f"expanded_{key}"], key

def get_table_download_link(df, filename, button_text="Download Data"):
    """
    Generates a link to download the dataframe as a CSV file.
    
    Args:
        df: Pandas DataFrame to download
        filename: Name of the file to download
        button_text: Text to display on the download button
        
    Returns:
        None (displays the download button directly)
    """
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}.csv" class="download-button">{button_text}</a>'
    st.markdown(href, unsafe_allow_html=True)

def get_figure_download_link(fig, filename, button_text="Download Chart"):
    """
    Generates a link to download a Plotly figure as an HTML file.
    
    Args:
        fig: Plotly figure to download
        filename: Name of the file to download
        button_text: Text to display on the download button
        
    Returns:
        None (displays the download button directly)
    """
    buffer = io.StringIO()
    fig.write_html(buffer)
    html_bytes = buffer.getvalue().encode()
    b64 = base64.b64encode(html_bytes).decode()
    href = f'<a href="data:text/html;base64,{b64}" download="{filename}.html" class="download-button">{button_text}</a>'
    st.markdown(href, unsafe_allow_html=True)

def expandable_dataframe(df, title, column_config=None, use_styling_func=None, styling_args=None):
    """
    Creates an expandable section containing a dataframe with download option.
    
    Args:
        df: Pandas DataFrame to display
        title: Title of the section
        column_config: Optional column configuration for st.dataframe
        use_styling_func: Optional styling function to apply (e.g., style_acos)
        styling_args: Optional arguments to pass to the styling function
        
    Returns:
        None
    """
    is_expanded, section_key = create_expandable_section(title)
    
    if is_expanded:
        # Create a container for the dataframe and download button
        col1, col2 = st.columns([0.85, 0.15])
        
        with col2:
            # Add download button
            get_table_download_link(df, f"{title.lower().replace(' ', '_')}")
        
        # Display the dataframe with appropriate styling
        if use_styling_func and callable(use_styling_func):
            if styling_args:
                use_styling_func(df, **styling_args)
            else:
                use_styling_func(df)
        else:
            st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True)

def expandable_chart(fig, title):
    """
    Creates an expandable section containing a Plotly chart with download option.
    
    Args:
        fig: Plotly figure to display
        title: Title of the section
        
    Returns:
        None
    """
    is_expanded, section_key = create_expandable_section(title)
    
    if is_expanded:
        # Create a container for the chart and download button
        col1, col2 = st.columns([0.85, 0.15])
        
        with col2:
            # Add download button
            get_figure_download_link(fig, f"{title.lower().replace(' ', '_')}")
        
        # Display the chart
        st.plotly_chart(fig, use_container_width=True, config={'responsive': True})

# Add CSS for enhanced UI components
st.markdown("""
<style>
/* Download buttons */
.download-button {
    display: inline-block;
    padding: 0.5em 1em;
    background-color: #4CAF50;
    color: white;
    text-align: center;
    text-decoration: none;
    font-size: 14px;
    border-radius: 4px;
    cursor: pointer;
    transition: background-color 0.3s;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
.download-button:hover {
    background-color: #45a049;
    box-shadow: 0 4px 8px rgba(0,0,0,0.15);
}

/* Enhanced section headers */
.main-section-header {
    font-size: 1.5em;
    font-weight: bold;
    color: #1f77b4;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
}

/* Improved metrics display */
.metric-container {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #1f77b4;
    margin: 0.5rem 0;
}

/* Warning and info boxes */
.warning-box {
    background-color: #fff3cd;
    border: 1px solid #ffeaa7;
    border-radius: 4px;
    padding: 1rem;
    margin: 1rem 0;
}

.info-box {
    background-color: #d1ecf1;
    border: 1px solid #b8daff;
    border-radius: 4px;
    padding: 1rem;
    margin: 1rem 0;
}

/* Enhanced table styling */
.dataframe {
    font-size: 0.9em;
}

/* Progress indicators */
.progress-text {
    font-size: 0.8em;
    color: #666;
    font-style: italic;
}
</style>
""", unsafe_allow_html=True)

# Global color gradient functions for styling tables
def color_gradient_blue(val, min_val, max_val, scale_max=75):
    # Blue gradient: from dark gray (#23272f) to blue (#2563eb)
    if pd.isnull(val):
        return ''
    # Scale from 0% to scale_max% (default: 75%)
    norm = min(max(val, 0), scale_max) / scale_max
    norm = norm ** 0.5  # sqrt scaling for more visual spread
    r = int(35 + (37-35)*norm)
    g = int(39 + (99-39)*norm)
    b = int(47 + (235-47)*norm)
    return f'background-color: rgb({r},{g},{b}); color: #fff;'

def color_gradient_green(val, min_val, max_val, scale_max=75):
    # Green gradient: from dark gray (#23272f) to deep green (#15803d)
    if pd.isnull(val):
        return ''
    # Scale from 0% to scale_max% (default: 75%)
    norm = min(max(val, 0), scale_max) / scale_max
    norm = norm ** 0.5  # sqrt scaling for more visual spread
    r = int(35 + (21-35)*norm)    # 35 to 21
    g = int(39 + (128-39)*norm)   # 39 to 128
    b = int(47 + (61-47)*norm)    # 47 to 61
    return f'background-color: rgb({r},{g},{b}); color: #fff;'

# Helper function to apply ACoS styling to a specific column
# This function was removed as part of removing ACoS coloring based on user goals
def apply_acos_styling(styled_df, numeric_df, acos_column, target, use_avg_fallback=False):
    # Function removed - returning unstyled dataframe
    return styled_df

# --- Helper Functions ---
def show_loading_spinner(message="Loading data..."):
    """Display a consistent loading spinner with the given message.
    
    Args:
        message: Text to display next to the spinner
    
    Returns:
        A Streamlit spinner context manager that can be used in a with statement
    """
    return st.spinner(message)

# --- Ensure session state keys are initialized ---
if 'current_page' not in st.session_state:
    st.session_state.current_page = "home"  # Set default page
    
# --- Cache Management Functions ---
def clear_caches():
    """Clear all st.cache_data caches to force data refresh"""
    st.cache_data.clear()
    if 'debug_messages' in st.session_state:
        st.session_state.debug_messages.append("[INFO] All data caches cleared")
        
if 'cache_initialized' not in st.session_state:
    st.session_state.cache_initialized = True
    # Initialize cache timestamp to track when data was last refreshed
    st.session_state.last_cache_refresh = datetime.now()

# Global ACoS styling functions moved to top level
def clean_acos(val):
    if pd.isnull(val):
        return 0.0
    try:
        # Remove any CSS, percent, commas, whitespace, and newlines
        if isinstance(val, str):
            val = val.replace('\n', '').replace('\r', '')
            val = val.split(';')[0]
            val = val.replace('%', '').replace(',', '').strip()
        return float(val)
    except (ValueError, TypeError, AttributeError):
        # If conversion fails, return 0
        return 0.0

# Helper function to safely convert values to numeric, handling both string and numeric inputs
def safe_convert_to_numeric(series):
    if series.dtype == 'object':
        return pd.to_numeric(series.str.replace('[$,]', '', regex=True), errors='coerce')
    else:
        return pd.to_numeric(series, errors='coerce')

def calculate_acos_range_distribution(df, num_ranges=5):
    """
    Calculate the distribution of targets across different ACoS ranges.
    
    Args:
        df: DataFrame containing targeting data with 'ACoS', 'Spend', and sales columns
        num_ranges: Number of ACoS ranges to create (default: 5)
        
    Returns:
        DataFrame with ACoS ranges, count of targets, spend, and sales in each range
    """
    if df.empty or 'ACoS' not in df.columns or 'Spend' not in df.columns:
        return pd.DataFrame(columns=['ACoS Range', 'Number of Targets', '% of Total Spend', '% of Total Ad Sales', 'Spend', 'Ad Sales'])
    
    # Clean and convert ACoS values to numeric
    df = df.copy()
    df['ACoS_numeric'] = df['ACoS'].apply(lambda x: clean_acos(x))
    df['Spend_numeric'] = df['Spend'].replace('[\$,]', '', regex=True).astype(float)
    
    # Determine which sales column to use
    sales_col = None
    if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and 'Sponsored Display' in str(df.get('Campaign Type', '')):
        sales_col = 'Sales (Views & Clicks)' if 'Sales (Views & Clicks)' in df.columns else 'Ad Sales'
    else:
        sales_col = 'Ad Sales' if 'Ad Sales' in df.columns else 'Sales'
    
    if sales_col not in df.columns:
        # If no sales column is found, add a placeholder
        df[sales_col] = 0
    
    df['Sales_numeric'] = df[sales_col].replace('[\$,]', '', regex=True).astype(float)
    
    # Initialize results dictionary
    results = []
    total_spend = df['Spend_numeric'].sum()
    total_sales = df['Sales_numeric'].sum()
    
    # Create No Sales row data (will add at the end)
    no_sales_df = df[df['Sales_numeric'] == 0]
    no_sales_count = len(no_sales_df)
    no_sales_spend = no_sales_df['Spend_numeric'].sum()
    no_sales_spend_percentage = (no_sales_spend / total_spend * 100) if total_spend > 0 else 0
    
    # Get data with sales for dynamic range calculation
    df_with_sales = df[df['Sales_numeric'] > 0]
    
    if len(df_with_sales) == 0:
        # If there are no targets with sales, return just the No Sales row
        results_df = pd.DataFrame(results)
    else:
        # Calculate dynamic ranges based on the data
        # Always have 0% as the lower bound of the first range and 100%+ as the last range
        
        # Get ACoS values for targets with sales
        acos_values = df_with_sales['ACoS_numeric'].dropna()
        
        # Check if we have ACoS goals in the client config to help inform our ranges
        has_acos_goal = False
        acos_goal = None
        if 'client_config' in st.session_state and st.session_state.client_config:
            goals = st.session_state.client_config.get('goals', {})
            if goals:
                # Check for branded, non-branded, or account-wide goals
                acos_goal = goals.get('branded_acos') or goals.get('non_branded_acos') or goals.get('account_wide_acos')
                if acos_goal is not None:
                    try:
                        acos_goal = float(acos_goal)
                        has_acos_goal = True
                    except (ValueError, TypeError):
                        has_acos_goal = False
        
        # Determine the upper bound for dynamic ranges
        max_for_ranges = min(100, acos_values.quantile(0.95)) if len(acos_values) > 0 else 100
        
        # Create dynamic ranges (plus the 100%+ range) based on user selection
        if has_acos_goal and 0 < acos_goal < 100:
            # If we have an ACoS goal, create ranges centered around it
            # Half of ranges below the goal, one goal range, and half of ranges above the goal
            
            # Calculate how many ranges should be below and above the goal
            ranges_per_side = num_ranges // 2
            
            # Determine range size based on the goal
            range_size_below = acos_goal / (ranges_per_side + 1)  # +1 for the goal range
            range_size_above = (max_for_ranges - acos_goal) / (ranges_per_side + 1)  # +1 for the goal range
            
            # Create ranges dynamically
            ranges = []
            
            # First range always starts at 0
            lower_bound = 0
            
            # Create ranges below the goal
            for i in range(ranges_per_side):
                upper_bound = acos_goal - (ranges_per_side - i) * range_size_below
                ranges.append((lower_bound, upper_bound))
                lower_bound = upper_bound
            
            # Add the goal range
            ranges.append((lower_bound, acos_goal + range_size_above))
            lower_bound = acos_goal + range_size_above
            
            # Create ranges above the goal
            for i in range(ranges_per_side - 1):
                upper_bound = acos_goal + (i + 2) * range_size_above
                ranges.append((lower_bound, upper_bound))
                lower_bound = upper_bound
            
            # Add the range up to 100%
            ranges.append((lower_bound, 100))
            
            # Always add the 100%+ range
            ranges.append((100, float('inf')))
            
            # Create range labels without decimals
            range_labels = []
            for i, (lower, upper) in enumerate(ranges):
                if i == 0:
                    # First range is always 0-X%
                    range_labels.append(f"0-{int(upper)}%")
                elif upper == float('inf'):
                    # Last range is always 100%+
                    range_labels.append("100%+")
                elif upper == 100:
                    # Range ending at 100%
                    range_labels.append(f"{int(lower)}-100%")
                else:
                    # All other ranges
                    range_labels.append(f"{int(lower)}-{int(upper)}%")
        else:
            # If no goal, create evenly distributed ranges
            step = max_for_ranges / num_ranges  # num_ranges plus the 100%+ range
            
            ranges = []
            for i in range(num_ranges):
                if i == 0:
                    # First range always starts at 0
                    ranges.append((0, step))
                elif i == num_ranges - 1:
                    # Last range before 100%+
                    ranges.append((i * step, 100))
                else:
                    # Middle ranges
                    ranges.append((i * step, (i + 1) * step))
            
            # Always add the 100%+ range
            ranges.append((100, float('inf')))
            
            # Create range labels without decimals
            range_labels = []
            for i, (lower, upper) in enumerate(ranges):
                if i == 0:
                    # First range is always 0-X%
                    range_labels.append(f"0-{int(upper)}%")
                elif upper == float('inf'):
                    # Last range is always 100%+
                    range_labels.append("100%+")
                elif upper == 100:
                    # Range ending at 100%
                    range_labels.append(f"{int(lower)}-100%")
                else:
                    # All other ranges
                    range_labels.append(f"{int(lower)}-{int(upper)}%")
        
        # Calculate counts and spend for each range, excluding those with no sales
        for i, (lower, upper) in enumerate(ranges):
            range_df = df_with_sales[(df_with_sales['ACoS_numeric'] >= lower) & (df_with_sales['ACoS_numeric'] < upper)] if upper != float('inf') else df_with_sales[df_with_sales['ACoS_numeric'] >= lower]
            count = len(range_df)
            spend = range_df['Spend_numeric'].sum()
            sales = range_df['Sales_numeric'].sum()
            spend_percentage = (spend / total_spend * 100) if total_spend > 0 else 0
            sales_percentage = (sales / total_sales * 100) if total_sales > 0 else 0
            
            results.append({
                'ACoS Range': range_labels[i],
                'Number of Targets': count,
                'Spend': spend,
                '% of Total Spend': spend_percentage,
                'Ad Sales': sales,
                '% of Total Ad Sales': sales_percentage
            })
        
        # Now add the No Sales row at the end
        results.append({
            'ACoS Range': 'No Sales',
            'Number of Targets': no_sales_count,
            'Spend': no_sales_spend,
            '% of Total Spend': no_sales_spend_percentage,
            'Ad Sales': 0,
            '% of Total Ad Sales': 0
        })
        
        # Convert to DataFrame
        results_df = pd.DataFrame(results)
    
    # Format the columns
    results_df['Number of Targets'] = results_df['Number of Targets'].apply(lambda x: f"{x:,}" if x >= 1000 else str(x))
    results_df['Spend'] = results_df['Spend'].apply(lambda x: f"${x:,.2f}")
    results_df['Ad Sales'] = results_df['Ad Sales'].apply(lambda x: f"${x:,.2f}")
    results_df['% of Total Spend'] = results_df['% of Total Spend'].apply(lambda x: f"{x:.2f}%")
    results_df['% of Total Ad Sales'] = results_df['% of Total Ad Sales'].apply(lambda x: f"{x:.2f}%")
    
    # Reorder columns
    results_df = results_df[['ACoS Range', 'Number of Targets', '% of Total Spend', '% of Total Ad Sales', 'Spend', 'Ad Sales']]
    
    # Add debug information
    if 'debug_messages' in st.session_state:
        st.session_state.debug_messages.append(f"[ACoS Distribution] Generated {len(results_df)-1} dynamic ACoS ranges plus 'No Sales' row with {num_ranges} user-selected ranges")
    
    return results_df

# This function was removed as part of removing ACoS coloring based on user goals
def get_acos_color(acos, target_acos):
    # Function removed - returning empty style
    return ''

def style_acos(df, target_acos=None, column_config=None, use_avg_as_fallback=False, title=None, use_expander=False):
    """Display a DataFrame. ACoS coloring has been removed.
    
    Args:
        df: DataFrame to display
        target_acos: Parameter kept for backward compatibility but no longer used
        column_config: Optional column configuration for st.dataframe
        use_avg_as_fallback: Parameter kept for backward compatibility but no longer used
        title: Optional title for expandable section
        use_expander: Whether to use expandable section
    """
    try:
        if df.empty:
            st.session_state.debug_messages.append("[style_acos debug] DataFrame is empty.")
            if use_expander and title:
                is_expanded, section_key = create_expandable_section(title)
                if is_expanded:
                    col1, col2 = st.columns([0.85, 0.15])
                    with col2:
                        get_table_download_link(df, f"{title.lower().replace(' ', '_')}")
                    return st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True) if column_config else st.dataframe(df, use_container_width=True, hide_index=True)
            else:
                return st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True) if column_config else st.dataframe(df, use_container_width=True, hide_index=True)
        
        # Make a copy to avoid modifying the original
        df = df.copy()
        
        # Display the dataframe without ACoS styling
        if use_expander and title:
            is_expanded, section_key = create_expandable_section(title)
            if is_expanded:
                # Create a container for the dataframe and download button
                col1, col2 = st.columns([0.85, 0.15])
                with col2:
                    # Add download button
                    get_table_download_link(df, f"{title.lower().replace(' ', '_')}")
                
                # Display the dataframe without styling
                return st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True) if column_config else st.dataframe(df, use_container_width=True, hide_index=True)
        else:
            return st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True) if column_config else st.dataframe(df, use_container_width=True, hide_index=True)
    except Exception as e:
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append(f"[style_acos debug] Exception in style_acos: {e}")
        if use_expander and title:
            is_expanded, section_key = create_expandable_section(title)
            if is_expanded:
                col1, col2 = st.columns([0.85, 0.15])
                with col2:
                    get_table_download_link(df, f"{title.lower().replace(' ', '_')}")
                return st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True) if column_config else st.dataframe(df, use_container_width=True, hide_index=True)
        else:
            return st.dataframe(df, use_container_width=True, column_config=column_config, hide_index=True) if column_config else st.dataframe(df, use_container_width=True, hide_index=True)


# --- Helper Functions for Consistent ACoS Range Distribution ---

def get_consistent_acos_ranges(all_dataframes, num_ranges):
    """Calculate consistent ACoS ranges based on combined data from all dataframes."""
    combined_data = []
    for df in all_dataframes:
        if not df.empty and 'ACoS' in df.columns:
            df_copy = df.copy()
            df_copy['ACoS_numeric'] = df_copy['ACoS'].apply(lambda x: clean_acos(x))
            # Get sales column
            sales_col = 'Ad Sales' if 'Ad Sales' in df_copy.columns else 'Sales'
            if sales_col in df_copy.columns:
                df_copy['Sales_numeric'] = df_copy[sales_col].replace('[\$,]', '', regex=True).astype(float)
                combined_data.append(df_copy[df_copy['Sales_numeric'] > 0])
    
    if not combined_data:
        return None, None
    
    combined_df = pd.concat(combined_data, ignore_index=True)
    if combined_df.empty:
        return None, None
    
    acos_values = combined_df['ACoS_numeric'].dropna()
    if len(acos_values) == 0:
        return None, None
    
    # Simple evenly distributed ranges for consistency
    max_acos = min(100, acos_values.quantile(0.95))
    step = max_acos / num_ranges
    
    ranges = []
    for i in range(num_ranges):
        if i == 0:
            ranges.append((0, step))
        elif i == num_ranges - 1:
            ranges.append((i * step, 100))
        else:
            ranges.append((i * step, (i + 1) * step))
    ranges.append((100, float('inf')))  # 100%+ range
    
    # Create labels
    labels = []
    for lower, upper in ranges:
        if upper == float('inf'):
            labels.append("100%+")
        elif upper == 100:
            labels.append(f"{int(lower)}-100%")
        else:
            labels.append(f"{int(lower)}-{int(upper)}%")
    
    return ranges, labels

def calculate_acos_distribution_with_ranges(df, ranges, labels):
    """Calculate distribution using predefined ranges."""
    if df.empty or not ranges or not labels:
        return pd.DataFrame()
    
    df = df.copy()
    df['ACoS_numeric'] = df['ACoS'].apply(lambda x: clean_acos(x))
    df['Spend_numeric'] = df['Spend'].replace('[\$,]', '', regex=True).astype(float)
    
    # Determine which sales column to use
    sales_col = None
    if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and 'Sponsored Display' in str(df.get('Campaign Type', '')):
        sales_col = 'Sales (Views & Clicks)' if 'Sales (Views & Clicks)' in df.columns else 'Ad Sales'
    else:
        sales_col = 'Ad Sales' if 'Ad Sales' in df.columns else 'Sales'
    
    if sales_col not in df.columns:
        df[sales_col] = 0
    
    df['Sales_numeric'] = df[sales_col].replace('[\$,]', '', regex=True).astype(float)
    
    # Initialize results
    results = []
    total_spend = df['Spend_numeric'].sum()
    total_sales = df['Sales_numeric'].sum()
    
    # Calculate for each range
    df_with_sales = df[df['Sales_numeric'] > 0]
    for i, (lower, upper) in enumerate(ranges):
        if upper == float('inf'):
            range_df = df_with_sales[df_with_sales['ACoS_numeric'] >= lower]
        else:
            range_df = df_with_sales[(df_with_sales['ACoS_numeric'] >= lower) & (df_with_sales['ACoS_numeric'] < upper)]
        
        count = len(range_df)
        spend = range_df['Spend_numeric'].sum()
        sales = range_df['Sales_numeric'].sum()
        spend_percentage = (spend / total_spend * 100) if total_spend > 0 else 0
        sales_percentage = (sales / total_sales * 100) if total_sales > 0 else 0
        
        results.append({
            'ACoS Range': labels[i],
            'Number of Targets': count,
            'Spend': spend,
            '% of Total Spend': spend_percentage,
            'Ad Sales': sales,
            '% of Total Ad Sales': sales_percentage
        })
    
    # Add No Sales row
    no_sales_df = df[df['Sales_numeric'] == 0]
    no_sales_count = len(no_sales_df)
    no_sales_spend = no_sales_df['Spend_numeric'].sum()
    no_sales_spend_percentage = (no_sales_spend / total_spend * 100) if total_spend > 0 else 0
    
    results.append({
        'ACoS Range': 'No Sales',
        'Number of Targets': no_sales_count,
        'Spend': no_sales_spend,
        '% of Total Spend': no_sales_spend_percentage,
        'Ad Sales': 0,
        '% of Total Ad Sales': 0
    })
    
    # Convert to DataFrame and format
    results_df = pd.DataFrame(results)
    results_df['Number of Targets'] = results_df['Number of Targets'].apply(lambda x: f"{x:,}" if x >= 1000 else str(x))
    results_df['Spend'] = results_df['Spend'].apply(lambda x: f"${x:,.2f}")
    results_df['Ad Sales'] = results_df['Ad Sales'].apply(lambda x: f"${x:,.2f}")
    results_df['% of Total Spend'] = results_df['% of Total Spend'].apply(lambda x: f"{x:.2f}%")
    results_df['% of Total Ad Sales'] = results_df['% of Total Ad Sales'].apply(lambda x: f"{x:.2f}%")
    
    return results_df

# --- End Helper Functions for Consistent ACoS Range Distribution ---

# Constants
CLIENT_CONFIG_DIR = 'clients'

# --- Client Management Functions ---

@st.cache_data(ttl=300)  # Cache for 5 minutes
def get_existing_clients():
    """Returns a list of client names from the config directory."""
    if not os.path.exists(CLIENT_CONFIG_DIR):
        os.makedirs(CLIENT_CONFIG_DIR)
    return [f.replace('.json', '') for f in os.listdir(CLIENT_CONFIG_DIR) if f.endswith('.json')]

@st.cache_data(ttl=300)  # Cache for 5 minutes
def load_client_config(client_name):
    """Loads the configuration for a given client."""
    filepath = os.path.join(CLIENT_CONFIG_DIR, f"{client_name}.json")
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r') as f:
                return json.load(f)
        except json.JSONDecodeError:
            st.error(f"Error reading configuration file for {client_name}. It might be corrupted.")
            return None
    return None # Or raise error

def get_campaigns_from_bulk_file(bulk_data):
    """Extracts unique campaign names and types from the bulk file data."""
    campaign_data = {}
    campaign_type_map = {
        'Sponsored Products Campaigns': 'Sponsored Products',
        'Sponsored Brands Campaigns': 'Sponsored Brands',
        'Sponsored Display Campaigns': 'Sponsored Display'
    }
    
    for sheet_name, df in bulk_data.items():
        if sheet_name in campaign_type_map:
            campaign_type = campaign_type_map[sheet_name]
            
            if 'Campaign Name' in df.columns and 'State' in df.columns and 'Entity' in df.columns:
                all_campaigns = df[df['Entity'] == 'Campaign']
                for _, row in all_campaigns.drop_duplicates(subset=['Campaign Name']).iterrows():
                    campaign_name = row['Campaign Name']
                    if campaign_name not in campaign_data:
                        campaign_data[campaign_name] = campaign_type
    return campaign_data

def save_client_config(client_name, config_data):
    """Saves the configuration for a given client."""
    if not os.path.exists(CLIENT_CONFIG_DIR):
        os.makedirs(CLIENT_CONFIG_DIR)
    filepath = os.path.join(CLIENT_CONFIG_DIR, f"{client_name}.json")
    with open(filepath, 'w') as f:
        json.dump(config_data, f, indent=4)
    
    # Set a flag to indicate settings have been updated
    # This will trigger a refresh of the Advertising Audit page
    st.session_state.settings_updated = True

# --- Data Processing Functions ---

@st.cache_data(ttl=3600)  # Cache for 1 hour
def extract_asins_from_sales_report(sales_df):
    """
    Extracts ASINs and their titles from a sales report DataFrame.
    Returns a dictionary mapping ASINs to their titles.
    """
    if sales_df is None or sales_df.empty:
        st.session_state.debug_messages.append("Cannot extract ASINs: Sales report is empty")
        return {}
    
    # Check for ASIN columns with different possible names
    asin_column = None
    possible_asin_columns = ['ASIN', '(Child) ASIN', 'child asin', 'asin', '(Parent) ASIN', 'parent asin', 'sku']
    
    for col_name in possible_asin_columns:
        if col_name in sales_df.columns:
            asin_column = col_name
            st.session_state.debug_messages.append(f"Found ASIN column: {asin_column}")
            break
    
    # Also check for case-insensitive matches
    if asin_column is None:
        for col in sales_df.columns:
            col_lower = str(col).lower().strip()
            if any(name.lower() in col_lower for name in possible_asin_columns):
                asin_column = col
                st.session_state.debug_messages.append(f"Found case-insensitive ASIN column match: {asin_column}")
                break
    
    if asin_column is None:
        st.session_state.debug_messages.append("Cannot extract ASINs: No ASIN column found in sales report")
        st.session_state.debug_messages.append(f"Available columns: {list(sales_df.columns)}")
        return {}
    
    asin_title_map = {}
    standard_asin_pattern = re.compile(r'(B[0-9A-Z]{9})', re.IGNORECASE)
    
    # Ensure we have a Title column
    title_column = None
    possible_title_columns = ['Title', 'Product Title', 'title', 'product name', 'item name']
    
    for col_name in possible_title_columns:
        if col_name in sales_df.columns:
            title_column = col_name
            break
    
    # Also check for case-insensitive matches
    if title_column is None:
        for col in sales_df.columns:
            col_lower = str(col).lower().strip()
            if any(name.lower() in col_lower for name in possible_title_columns):
                title_column = col
                break
    
    if title_column is None:
        # Create a placeholder title column
        sales_df['Title'] = 'Title not available'
        title_column = 'Title'
    
    # Process each row to extract ASINs and titles
    for _, row in sales_df.iterrows():
        asin = str(row[asin_column]).strip()
        
        # Skip invalid ASINs
        if not asin or pd.isna(asin) or asin.lower() == 'nan' or asin == '':
            continue
            
        # First try to extract standard ASINs using regex pattern
        asin_matches = standard_asin_pattern.findall(asin)
        if asin_matches:
            asin = asin_matches[0].upper()  # Standardize to uppercase
        else:
            # If it doesn't match the standard pattern but has non-empty content, keep it as is
            # This will capture non-standard ASINs that still have valid sales data
            asin = asin.upper()  # Just standardize to uppercase
            st.session_state.debug_messages.append(f"Found non-standard ASIN format: {asin}")
        
        # Get the title
        title = str(row[title_column]).strip()
        if pd.isna(title) or title.lower() == 'nan' or title == '':
            title = 'Title not available'
            
        asin_title_map[asin] = title
    
    st.session_state.debug_messages.append(f"Extracted {len(asin_title_map)} ASINs with titles from sales report")
    return asin_title_map

@st.cache_data(ttl=3600, show_spinner="Processing sales report...")  # Cache for 1 hour
def process_sales_report(uploaded_file):
    """
    Reads an SC or VC sales report (CSV or XLSX) and extracts relevant sales data.
    Simplified version with maximum compatibility for different file formats.
    Handles Vendor Central reports with metadata row at the top.
    """
    try:
        # Step 1: Detect if this is a Vendor Central report with metadata row
        file_name = uploaded_file.name
        uploaded_file.seek(0)
        
        # Read the first few lines to check for header
        header_row_index = 0  # Default to first row
        
        if file_name.endswith('.csv'):
            # Read first 10 rows to check for header
            try:
                preview_df = pd.read_csv(uploaded_file, header=None, nrows=10, encoding='utf-8')
            except UnicodeDecodeError:
                uploaded_file.seek(0)
                preview_df = pd.read_csv(uploaded_file, header=None, nrows=10, encoding='latin1')
        elif file_name.endswith('.xlsx'):
            preview_df = pd.read_excel(uploaded_file, header=None, nrows=10)
        else:
            return None  # Unsupported file format
        
        # Check for metadata row (first row contains equals signs or specific Vendor Central patterns)
        if len(preview_df) > 0:
            first_row_str = ' '.join([str(x) for x in preview_df.iloc[0].values if pd.notna(x)])
            # Check for equals signs (general metadata indicator) or specific VC patterns
            if '=' in first_row_str or 'Program=' in first_row_str or 'Distributor View=' in first_row_str:
                header_row_index = 1  # Skip the metadata row
                st.session_state.debug_messages.append(f"Detected metadata row with equals sign or VC pattern, using row {header_row_index} as header")
        
        # Step 2: Read the file with the correct header row
        uploaded_file.seek(0)
        
        if file_name.endswith('.csv'):
            # Try a few common encodings for CSV files
            for encoding in ['utf-8', 'latin1', 'ISO-8859-1']:
                try:
                    df = pd.read_csv(uploaded_file, header=header_row_index, encoding=encoding)
                    if not df.empty:
                        break
                except Exception as e:
                    st.session_state.debug_messages.append(f"Error with encoding {encoding}: {str(e)}")
                    uploaded_file.seek(0)
                    continue
        elif file_name.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file, header=header_row_index)
        else:
            return None  # Unsupported file format
            
        if df is None or df.empty:
            st.session_state.debug_messages.append("File loaded but DataFrame is empty")
            return None
        
        # Step 3: Basic data cleaning
        df = df.dropna(how='all')  # Drop rows that are all NaN
        
        # Debug output to help troubleshoot
        original_columns = list(df.columns)
        st.session_state.debug_messages.append(f"Available columns after loading: {original_columns}")
        
        # Step 4: Create standardized DataFrame with proper column mapping
        standardized_df = pd.DataFrame()
        
        # NEW APPROACH: Preserve all original sales columns without generic mapping
        
        # Standard column mappings for non-sales columns
        column_mappings = {
            'ASIN': ['ASIN', '(Child) ASIN', 'asin', 'child asin'],  # Removed Parent ASIN from child ASIN mapping
            'Parent ASIN': ['(Parent) ASIN', 'Parent ASIN', 'parent asin'],  # Separate mapping for Parent ASIN
            'Title': ['Title', 'Product Title', 'title', 'product name', 'item name'],
            'Sessions': ['Sessions', 'Sessions - Total', 'Glance Views', 'Page Views', 'sessions', 'sessions - total', 'glance views', 'page views', 'traffic', 'views'],
            'Orders': ['Ordered Units', 'Shipped Units', 'Units Sold', 'units', 'orders', 'quantity']
        }
        
        # Identify ALL sales columns in the original data
        potential_sales_patterns = [
            'Ordered Revenue', 'Shipped Revenue', 'Ordered Product Sales', 
            'Shipped Product Sales', 'Product Sales', 'Gross Product Sales', 
            'Shipped COGS', 'Total Sales', 'Net Sales', 'Revenue'
        ]
        
        found_sales_columns = []
        for col in original_columns:
            # Check for exact matches first
            if col in potential_sales_patterns:
                found_sales_columns.append(col)
            # Then check for partial matches (case insensitive)
            else:
                col_lower = str(col).lower().strip()
                for pattern in potential_sales_patterns:
                    if pattern.lower() in col_lower and 'sales' in col_lower or 'revenue' in col_lower:
                        found_sales_columns.append(col)
                        break
        
        st.session_state.debug_messages.append(f"Found {len(found_sales_columns)} sales columns: {found_sales_columns}")
        
        # Map standard columns (ASIN, Parent ASIN, Title, Sessions, Orders)
        for std_col, possible_names in column_mappings.items():
            # First try exact matches for ASIN column
            if std_col == 'ASIN':
                # Try exact matches first (case-sensitive)
                for exact_name in ['ASIN', '(Child) ASIN']:
                    if exact_name in original_columns:
                        standardized_df[std_col] = df[exact_name].astype(str)
                        st.session_state.debug_messages.append(f"Found exact match for {exact_name}")
                        break
                # If we found an exact match, continue to next standard column
                if 'ASIN' in standardized_df.columns:
                    continue
            
            # Handle Parent ASIN column separately
            elif std_col == 'Parent ASIN':
                # Try exact matches first (case-sensitive)
                for exact_name in ['(Parent) ASIN', 'Parent ASIN']:
                    if exact_name in original_columns:
                        standardized_df[std_col] = df[exact_name].astype(str)
                        st.session_state.debug_messages.append(f"Found exact match for Parent ASIN: {exact_name}")
                        break
                # If we found an exact match, continue to next standard column
                if 'Parent ASIN' in standardized_df.columns:
                    continue
            
            # Fall back to partial/case-insensitive matching for non-sales columns
            for col in original_columns:
                col_lower = str(col).lower().strip()
                if any(name.lower() in col_lower for name in possible_names):
                    # Found a matching column
                    if std_col in ['Sessions', 'Orders']:
                        # Clean and convert numeric columns
                        values = df[col].astype(str).str.replace(r'[$,£€]', '', regex=True)
                        standardized_df[std_col] = pd.to_numeric(values, errors='coerce').fillna(0)
                    else:
                        # String columns
                        standardized_df[std_col] = df[col].astype(str)
                    
                    st.session_state.debug_messages.append(f"Mapped {col} to {std_col}")
                    break
        
        # Add ALL sales columns with their original names
        for sales_col in found_sales_columns:
            if sales_col in df.columns:
                # Clean and convert numeric columns
                values = df[sales_col].astype(str).str.replace(r'[$,£€]', '', regex=True)
                standardized_df[sales_col] = pd.to_numeric(values, errors='coerce').fillna(0)
                st.session_state.debug_messages.append(f"Preserved original sales column: {sales_col}")
        
        # Check if we found the essential columns
        if 'ASIN' not in standardized_df.columns:
            st.session_state.debug_messages.append("ASIN column not found in the report")
            return None
            
        # If no title column found, use ASIN as title
        if 'Title' not in standardized_df.columns:
            standardized_df['Title'] = standardized_df['ASIN']
            
        # If no sales columns found, add a placeholder Total Sales column
        if not found_sales_columns:
            standardized_df['Total Sales'] = 0.0
            st.session_state.debug_messages.append("No sales columns found, adding placeholder Total Sales column")
            found_sales_columns = ['Total Sales']
        
        # Step 5: Clean up and return the standardized DataFrame
        # Remove any rows with missing or invalid ASINs
        standardized_df = standardized_df.dropna(subset=['ASIN'])
        standardized_df = standardized_df[standardized_df['ASIN'].str.strip() != '']
        
        # Aggregate by ASIN (in case there are duplicates)
        agg_dict = {
            'Title': 'first',
        }
        
        # Add Parent ASIN to aggregation if it exists
        if 'Parent ASIN' in standardized_df.columns:
            agg_dict['Parent ASIN'] = 'first'
        
        # Add all sales columns to aggregation
        for sales_col in found_sales_columns:
            if sales_col in standardized_df.columns:
                agg_dict[sales_col] = 'sum'
        
        if 'Sessions' in standardized_df.columns:
            agg_dict['Sessions'] = 'sum'
        if 'Orders' in standardized_df.columns:
            agg_dict['Orders'] = 'sum'
            
        result_df = standardized_df.groupby('ASIN', as_index=False).agg(agg_dict)
        
        # Ensure we have at least one row
        if len(result_df) > 0:
            st.session_state.debug_messages.append(f"Successfully processed sales report with {len(result_df)} unique ASINs")
            return result_df
        else:
            st.session_state.debug_messages.append("No valid data rows found after processing")
            return None
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        st.session_state.debug_messages.append(f"Error processing sales report: {str(e)}")
        st.session_state.debug_messages.append(f"Error details: {error_details}")
        return None



@st.cache_data(ttl=3600, show_spinner="Processing bulk advertising data...")  # Cache for 1 hour
def process_bulk_data(uploaded_file):
    """
    Reads all sheets from the bulk advertising file, cleans data,
    and returns a dictionary of DataFrames.
    """
    bulk_data = {}
    # These are the primary campaign sheets we'll use for campaign analysis
    campaign_sheets = [
        'Sponsored Products Campaigns',
        'Sponsored Brands Campaigns',
        'Sponsored Display Campaigns', 
        'SB Multi Ad Group Campaigns',  # Added SB Multi Ad Group Campaigns as a relevant sheet
    ]

    numeric_cols_pattern = [
        'Impressions', 'Clicks', 'Spend', 'Orders', 'Total Sales', 'Sales', 'ROAS',
        'Cost Per Click (CPC)', 'Click-Thru Rate (CTR)',
        '7 Day Total Orders (#)', '7 Day Total Sales', 'Sales (Views & Clicks)'
    ]
    
    # Define the sheets that require campaign-level filtering
    campaign_sheets_to_filter = [
        'Sponsored Products Campaigns',
        'Sponsored Brands Campaigns',
        'Sponsored Display Campaigns',
        'SB Multi Ad Group Campaigns'  # Added SB Multi Ad Group Campaigns to filtering list
    ]

    try:
        # Use a more efficient approach to read Excel
        xls = pd.ExcelFile(uploaded_file)
        
        # Helper function to find actual sheet name case-insensitively
        def find_actual_sheet_name(target_name):
            """Find the actual sheet name by case-insensitive matching."""
            target_lower = target_name.lower()
            for sheet_name in all_sheet_names:
                if sheet_name.lower() == target_lower:
                    return sheet_name
            return None
        
        # Helper function to find actual sheet name case-insensitively
        def find_actual_sheet_name(target_name):
            """Find the actual sheet name by case-insensitive matching."""
            target_lower = target_name.lower()
            for sheet_name in all_sheet_names:
                if sheet_name.lower() == target_lower:
                    return sheet_name
            return None
        
        # Get all the sheets available in the file
        all_sheet_names = xls.sheet_names

        # Find actual sheet names case-insensitively for later use
        sp_sheet = find_actual_sheet_name('Sponsored Products Campaigns')
        sb_multi_sheet = find_actual_sheet_name('SB Multi Ad Group Campaigns')
        sb_standard_sheet = find_actual_sheet_name('Sponsored Brands Campaigns')
        sd_sheet = find_actual_sheet_name('Sponsored Display Campaigns')
        st.session_state.debug_messages.append(f"[Bulk File Processing] Found {len(all_sheet_names)} sheets in bulk file: {', '.join(all_sheet_names)}")
        
        # Check if we have both SB sheet types
        has_sb_multi = any(sheet.lower() == 'sb multi ad group campaigns' for sheet in all_sheet_names)
        has_sb_standard = any(sheet.lower() == 'sponsored brands campaigns' for sheet in all_sheet_names)
        
        # Log what we found for debugging
        if has_sb_multi:
            st.session_state.debug_messages.append("Found 'SB Multi Ad Group Campaigns' sheet - will use this for Sponsored Brands data")
        if has_sb_standard:
            if has_sb_multi:
                st.session_state.debug_messages.append("Also found 'Sponsored Brands Campaigns' sheet - will be ignored in favor of Multi Ad Group data")
            else:
                st.session_state.debug_messages.append("Found 'Sponsored Brands Campaigns' sheet")
        
        # Process ALL sheets in the file to ensure we don't miss any data
        # This is important for search term data which might be in non-standard sheets
        for sheet_name in all_sheet_names:
            # Skip sheets containing 'RAS' or 'Portfolio' in their names
            if 'RAS' in sheet_name or 'Portfolio' in sheet_name:
                st.session_state.debug_messages.append(f"Skipping sheet: {sheet_name} (contains 'RAS' or 'Portfolio')")
                continue
                
            st.session_state.debug_messages.append(f"Processing sheet: {sheet_name}")
            try:
                # Read the sheet
                df = pd.read_excel(xls, sheet_name=sheet_name)
                
                # Skip empty sheets
                if df.empty:
                    st.session_state.debug_messages.append(f"Sheet {sheet_name} is empty, skipping")
                    continue
                    
                # Store the sheet data in our dictionary
                bulk_data[sheet_name] = df
                st.session_state.debug_messages.append(f"Added sheet {sheet_name} to bulk_data dictionary ({len(df)} rows, {len(df.columns)} columns)")
            except Exception as e:
                st.session_state.debug_messages.append(f"Error processing sheet {sheet_name}: {str(e)}")
                continue
        
        # Now process the primary campaign sheets with additional cleaning
        campaign_sheet_list = []
        
        # Add the campaign sheets in the order we want to process them

        
        if sp_sheet:

        
            campaign_sheet_list.append(sp_sheet)
            
        # For Sponsored Brands, prioritize Multi Ad Group if available

            
        if has_sb_multi and sb_multi_sheet:

            
            campaign_sheet_list.append(sb_multi_sheet)

            
        elif has_sb_standard and sb_standard_sheet:

            
            campaign_sheet_list.append(sb_standard_sheet)
            
        if sd_sheet:

            
            campaign_sheet_list.append(sd_sheet)
        
        # Apply additional processing to campaign sheets
        for sheet_name in campaign_sheet_list:
            st.session_state.debug_messages.append(f"Applying campaign processing to sheet: {sheet_name}") # Debug
            try:
                # We already loaded the sheet in the first pass, so get it from bulk_data
                if sheet_name in bulk_data:
                    df = bulk_data[sheet_name].copy()
                else:
                    st.session_state.debug_messages.append(f"Sheet {sheet_name} not found in bulk_data, skipping campaign processing")
                    continue

                # Ensure required numeric columns exist and handle potential errors
                for col_pattern in numeric_cols_pattern:
                    if col_pattern in df.columns:
                        df[col_pattern] = pd.to_numeric(df[col_pattern], errors='coerce').fillna(0)
                
                # Convert column names to strings
                df.columns = df.columns.astype(str)
                
                # Rename columns for consistency
                column_renames = {}
                # Do not rename 'Sales' to 'Total Sales' as these are different metrics
                # 'Sales' in bulk file refers to ad-attributed sales
                # 'Total Sales' should only come from the sales report
                if 'Campaign' in df.columns and 'Campaign Name' not in df.columns:
                    column_renames['Campaign'] = 'Campaign Name'
                
                if column_renames:
                    df = df.rename(columns=column_renames)
                
                # Add campaign type efficiently
                if 'Sponsored Product' in sheet_name:
                    campaign_type = 'SP'
                elif 'Sponsored Brand' in sheet_name or sheet_name.lower() == 'sb multi ad group campaigns':
                    campaign_type = 'SB'
                elif 'Sponsored Display' in sheet_name:
                    campaign_type = 'SD'
                else:
                    campaign_type = 'Unknown'
                
                df['Campaign Type'] = campaign_type
                
                # Store processed data
                # For Multi Ad Group, store it under the standard Sponsored Brands key
                if sheet_name.lower() == 'sb multi ad group campaigns':
                    sheet_key = 'Sponsored Brands Campaigns'
                    st.session_state.debug_messages.append(f"Storing 'SB Multi Ad Group Campaigns' data as 'Sponsored Brands Campaigns'")
                    # Update the data in our dictionary
                    bulk_data[sheet_key] = df
                    # Keep the original sheet as well for search term detection
                    st.session_state.debug_messages.append(f"Keeping original 'SB Multi Ad Group Campaigns' sheet for search term detection")
                else:
                    # Update the existing data in our dictionary using normalized keys

                    # This ensures case-insensitive access to data

                    if sp_sheet and sheet_name == sp_sheet:

                        bulk_data['Sponsored Products Campaigns'] = df

                    elif sb_standard_sheet and sheet_name == sb_standard_sheet:

                        bulk_data['Sponsored Brands Campaigns'] = df  

                    elif sd_sheet and sheet_name == sd_sheet:

                        bulk_data['Sponsored Display Campaigns'] = df

                    else:

                        bulk_data[sheet_name] = df
                
                st.session_state.debug_messages.append(f"Applied campaign processing to {sheet_name}: {len(df)} rows")
                
            except Exception as e:
                st.session_state.debug_messages.append(f"Error applying campaign processing to sheet '{sheet_name}': {str(e)}")
        
        if not bulk_data:
            st.warning("No data could be processed from any sheets.")
            return None
        
        st.session_state.debug_messages.append(f"Successfully processed {len(bulk_data)} sheets from bulk file")
        return bulk_data
        
    except Exception as e:
        st.error(f"Error processing bulk file: {str(e)}")
        return None

@st.cache_data(ttl=3600, show_spinner="Processing companion ASIN data...")  # Cache for 1 hour
def process_companion_asin_data(uploaded_file):
    """
    Processes companion ASIN export CSV file and converts it to bulk data format.
    """
    try:
        # Read the CSV file
        df = pd.read_csv(uploaded_file)
        st.session_state.debug_messages.append(f"[Companion ASIN] Loaded CSV with {len(df)} rows and {len(df.columns)} columns")
        
        if df.empty:
            st.warning("Companion ASIN file is empty.")
            return None
            
        # Map companion columns to bulk data format
        column_mapping = {
            'campaign_name': 'Campaign Name',
            'asin': 'ASIN',
            'impressions': 'Impressions',
            'clicks': 'Clicks',
            'spend': 'Spend',
            'sales': 'Sales',
            'orders': 'Orders',
            'cpc': 'Cost Per Click (CPC)',
            'ctr': 'Click-Thru Rate (CTR)',
            'acos': 'ACoS',
            'roas': 'ROAS',
            'kind': 'Campaign Type Raw',
            'campaign_targeting_type': 'Targeting Type',
            'ad_group_name': 'Ad Group Name',
            'campaign_id': 'Campaign ID'
        }
        
        # Rename columns
        df_mapped = df.rename(columns=column_mapping)
        
        # Map campaign types
        campaign_type_mapping = {'sp': 'SP', 'sb': 'SB', 'sd': 'SD'}
        df_mapped['Campaign Type'] = df_mapped['Campaign Type Raw'].map(campaign_type_mapping)
        
        # Add Entity column based on ASIN presence (for targeting analysis)
        df_mapped['Entity'] = 'Product Ad'  # ASIN data represents product ads, not targeting
        df_mapped['Product Targeting Expression'] = df_mapped['ASIN']  # Use ASIN as targeting expression
        
        # Add Product column to identify the ad type
        df_mapped['Product'] = df_mapped['Campaign Type'].map({
            'SP': 'Sponsored Products',
            'SB': 'Sponsored Brands', 
            'SD': 'Sponsored Display'
        })
        
        # Add State column (assume enabled for companion data)
        df_mapped['State'] = 'enabled'
        
        # Ensure numeric columns are properly formatted
        numeric_cols = ['Impressions', 'Clicks', 'Spend', 'Sales', 'Orders', 'Cost Per Click (CPC)', 'Click-Thru Rate (CTR)', 'ACoS', 'ROAS']
        for col in numeric_cols:
            if col in df_mapped.columns:
                df_mapped[col] = pd.to_numeric(df_mapped[col], errors='coerce').fillna(0)
        
        # Convert percentage columns
        if 'Click-Thru Rate (CTR)' in df_mapped.columns:
            df_mapped['Click-Thru Rate (CTR)'] = df_mapped['Click-Thru Rate (CTR)'] * 100  # Convert to percentage
        if 'ACoS' in df_mapped.columns:
            df_mapped['ACoS'] = df_mapped['ACoS'] * 100  # Convert to percentage
            
        # Split data by campaign type to create separate sheets
        bulk_data = {}
        
        for campaign_type in ['SP', 'SB', 'SD']:
            type_df = df_mapped[df_mapped['Campaign Type'] == campaign_type].copy()
            if not type_df.empty:
                if campaign_type == 'SP':
                    asin_sheet_name = 'Sponsored Products ASIN Data'
                elif campaign_type == 'SB':
                    asin_sheet_name = 'Sponsored Brands ASIN Data'
                else:  # SD
                    asin_sheet_name = 'Sponsored Display ASIN Data'
                
                # Create ASIN data sheet for Product Analysis
                bulk_data[asin_sheet_name] = type_df
                st.session_state.debug_messages.append(f"[Companion ASIN] Created {asin_sheet_name} with {len(type_df)} ASIN rows")
        
        st.session_state.debug_messages.append(f"[Companion ASIN] Successfully processed companion ASIN data into {len(bulk_data)} sheets")
        return bulk_data
        
    except Exception as e:
        st.error(f"Error processing companion ASIN file: {str(e)}")
        st.session_state.debug_messages.append(f"[Companion ASIN] Error: {str(e)}")
        return None

@st.cache_data(ttl=3600, show_spinner="Processing companion search term data...")  # Cache for 1 hour
def process_companion_search_term_data(uploaded_file):
    """
    Processes companion Search Term export CSV file and converts it to bulk data format.
    """
    try:
        # Read the CSV file
        df = pd.read_csv(uploaded_file)
        st.session_state.debug_messages.append(f"[Companion Search Term] Loaded CSV with {len(df)} rows and {len(df.columns)} columns")
        
        if df.empty:
            st.warning("Companion Search Term file is empty.")
            return None
            
        # Map companion columns to bulk data format
        column_mapping = {
            'campaign_name': 'Campaign Name',
            'query': 'Customer Search Term',
            'target': 'Keyword Text',
            'match_type': 'Match Type',
            'impressions': 'Impressions',
            'clicks': 'Clicks',
            'spend': 'Spend',
            'sales': 'Sales',
            'orders': 'Orders',
            'cpc': 'Cost Per Click (CPC)',
            'ctr': 'Click-Thru Rate (CTR)',
            'acos': 'ACoS',
            'roas': 'ROAS',
            'kind': 'Campaign Type Raw',
            'campaign_targeting_type': 'Targeting Type',
            'ad_group_name': 'Ad Group Name',
            'campaign_id': 'Campaign ID',
            'keyword_id': 'Keyword ID'
        }
        
        # Rename columns
        df_mapped = df.rename(columns=column_mapping)
        
        # Universal text cleaning function for search terms and other text fields
        def clean_text_field(text):
            """Clean text fields by handling Unicode escape sequences and other encoding issues."""
            if pd.isna(text) or text == '':
                return text
            
            text = str(text)
            
            try:
                # Handle Unicode escape sequences (like \u0027 for apostrophe)
                import codecs
                text = codecs.decode(text, 'unicode_escape')
                
                # Handle common JSON escape sequences
                text = text.replace('\\"', '"')  # Escaped quotes
                text = text.replace('\\/', '/')   # Escaped forward slash
                text = text.replace('\\\\', '\\') # Escaped backslash
                
                # Remove any remaining backslash artifacts
                import re
                text = re.sub(r'\\u[0-9a-fA-F]{4}', lambda m: chr(int(m.group(0)[2:], 16)), text)
                
                # Clean up any remaining escape sequences
                text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')
                
                # Normalize whitespace
                text = ' '.join(text.split())
                
            except Exception as e:
                # If cleaning fails, return the original text
                st.session_state.debug_messages.append(f"[Text Cleaning] Warning: Could not clean text '{text[:50]}...': {str(e)}")
                pass
            
            return text
        
        # Apply text cleaning to search term and target columns
        if 'Customer Search Term' in df_mapped.columns:
            df_mapped['Customer Search Term'] = df_mapped['Customer Search Term'].apply(clean_text_field)
            st.session_state.debug_messages.append("[Companion Search Term] Applied text cleaning to Customer Search Term column")
        
        if 'Keyword Text' in df_mapped.columns:
            df_mapped['Keyword Text'] = df_mapped['Keyword Text'].apply(clean_text_field)
            st.session_state.debug_messages.append("[Companion Search Term] Applied text cleaning to Keyword Text column")
        
        # Map campaign types
        campaign_type_mapping = {'sp': 'SP', 'sb': 'SB', 'sd': 'SD'}
        df_mapped['Campaign Type'] = df_mapped['Campaign Type Raw'].map(campaign_type_mapping)
        
        # Handle target column translation and entity determination
        def process_target_and_entity(row):
            targeting_type = str(row.get('Targeting Type', '')).lower()
            match_type = str(row.get('Match Type', '')).lower()
            target_value = str(row.get('target', '')).lower()
            
            # Debug logging for auto targeting detection
            if targeting_type == 'auto':
                st.session_state.debug_messages.append(f"[Companion] Found auto targeting: targeting_type='{targeting_type}', match_type='{match_type}'")
            
            # Handle special target values first
            if target_value == 'asincategorysameAs':
                return 'Product Targeting', 'Category Target', 'Category Target'
            elif target_value == 'asinexpandedfrom':
                return 'Product Targeting', 'ASIN Expanded', 'Product Targeting'
            elif target_value == 'asinsameas':
                return 'Product Targeting', 'ASIN Target', 'Product Targeting'
            # Check if it's auto targeting (from campaign_targeting_type column)
            elif targeting_type == 'auto':
                return 'Product Targeting', row.get('Keyword Text', ''), 'Auto'
            # Check if it's keyword targeting (broad, exact, phrase)
            elif match_type in ['broad', 'exact', 'phrase']:
                # Capitalize the match type for proper display
                capitalized_match_type = row.get('Match Type', '').title()
                return 'Keyword', row.get('Keyword Text', ''), capitalized_match_type
            # Check if it's explicitly product targeting
            elif match_type == 'target' or targeting_type == 'manual' and target_value:
                return 'Product Targeting', row.get('Keyword Text', ''), 'Product Targeting'
            else:
                # Default to keyword for anything else (preserves original match type)
                return 'Keyword', row.get('Keyword Text', ''), row.get('Match Type', '')
        
        # Apply the function to get entity, targeting expression, and match type
        df_mapped[['Entity', 'Targeting Expression', 'Match Type']] = df_mapped.apply(
            lambda row: pd.Series(process_target_and_entity(row)), axis=1
        )
        
        # Add Target column for compatibility with targeting performance display
        df_mapped['Target'] = df_mapped['Targeting Expression']
        
        # Add Target Type column based on Entity
        df_mapped['Target Type'] = df_mapped['Entity'].apply(
            lambda x: 'Keyword' if x == 'Keyword' else 'Product Targeting'
        )
        
        # Add State column (assume enabled for companion data)
        df_mapped['State'] = 'enabled'
        
        # Add Product column to identify the ad type
        df_mapped['Product'] = df_mapped['Campaign Type'].map({
            'SP': 'Sponsored Products',
            'SB': 'Sponsored Brands', 
            'SD': 'Sponsored Display'
        })
        

        
        # Ensure numeric columns are properly formatted
        numeric_cols = ['Impressions', 'Clicks', 'Spend', 'Sales', 'Orders', 'Cost Per Click (CPC)', 'Click-Thru Rate (CTR)', 'ACoS', 'ROAS']
        for col in numeric_cols:
            if col in df_mapped.columns:
                df_mapped[col] = pd.to_numeric(df_mapped[col], errors='coerce').fillna(0)
        
        # Convert percentage columns
        if 'Click-Thru Rate (CTR)' in df_mapped.columns:
            df_mapped['Click-Thru Rate (CTR)'] = df_mapped['Click-Thru Rate (CTR)'] * 100  # Convert to percentage
        if 'ACoS' in df_mapped.columns:
            df_mapped['ACoS'] = df_mapped['ACoS'] * 100  # Convert to percentage
            
        # Create both search term sheets and campaign sheets by campaign type
        bulk_data = {}
        
        for campaign_type in ['SP', 'SB', 'SD']:
            type_df = df_mapped[df_mapped['Campaign Type'] == campaign_type].copy()
            if not type_df.empty:
                # Create search term sheet
                if campaign_type == 'SP':
                    search_sheet_name = 'Sponsored Products Search Term Report'
                    campaign_sheet_name = 'Sponsored Products Campaigns'
                elif campaign_type == 'SB':
                    search_sheet_name = 'Sponsored Brands Search Term Report'
                    campaign_sheet_name = 'Sponsored Brands Campaigns'
                else:  # SD
                    search_sheet_name = 'Sponsored Display Search Term Report'
                    campaign_sheet_name = 'Sponsored Display Campaigns'
                
                # Add search term sheet
                bulk_data[search_sheet_name] = type_df
                
                # Create campaign-level aggregation for overview metrics
                campaign_agg = type_df.groupby('Campaign Name').agg({
                    'Impressions': 'sum',
                    'Clicks': 'sum',
                    'Spend': 'sum',
                    'Sales': 'sum',
                    'Orders': 'sum'
                }).reset_index()
                
                # Add required columns for campaign sheet
                campaign_agg['Entity'] = 'Campaign'
                campaign_agg['State'] = 'enabled'
                campaign_agg['Product'] = type_df['Product'].iloc[0] if not type_df.empty else ''
                campaign_agg['Campaign Type'] = campaign_type
                
                # Calculate derived metrics
                campaign_agg['Cost Per Click (CPC)'] = campaign_agg['Spend'] / campaign_agg['Clicks'].replace(0, 1)
                campaign_agg['Click-Thru Rate (CTR)'] = (campaign_agg['Clicks'] / campaign_agg['Impressions'].replace(0, 1)) * 100
                campaign_agg['ACoS'] = (campaign_agg['Spend'] / campaign_agg['Sales'].replace(0, 1)) * 100
                campaign_agg['ROAS'] = campaign_agg['Sales'] / campaign_agg['Spend'].replace(0, 1)
                
                bulk_data[campaign_sheet_name] = campaign_agg
                st.session_state.debug_messages.append(f"[Companion Search Term] Created {search_sheet_name} with {len(type_df)} rows and {campaign_sheet_name} with {len(campaign_agg)} campaigns")
        
        st.session_state.debug_messages.append(f"[Companion Search Term] Successfully processed companion search term data into {len(bulk_data)} sheets")
        return bulk_data
        
    except Exception as e:
        st.error(f"Error processing companion search term file: {str(e)}")
        st.session_state.debug_messages.append(f"[Companion Search Term] Error: {str(e)}")
        return None

@st.cache_data(ttl=3600, show_spinner="Processing companion targeting data...")  # Cache for 1 hour
def process_companion_targeting_data(uploaded_file):
    """
    Processes companion Targeting export CSV file and converts it to bulk data format.
    This replaces Search Term report data when targets are being looked at instead of search terms.
    Includes Sponsored Display ad type data that wasn't in Search Term exports.
    
    Key features:
    - Maps targeting export columns to standard bulk data format
    - Handles different expression types (negativeexact, asinsameas, etc.)
    - Creates Campaign sheets for targeting performance analysis
    - Includes Sponsored Display data missing from Search Term exports
    - Takes priority over Search Term data for targeting analysis
    """
    try:
        # Read the CSV file
        df = pd.read_csv(uploaded_file)
        st.session_state.debug_messages.append(f"[Companion Targeting] Loaded CSV with {len(df)} rows and {len(df.columns)} columns")
        
        if df.empty:
            st.warning("Companion Targeting file is empty.")
            return None
            
        # First, let's determine which sales/orders columns are available
        available_cols = df.columns.tolist()
        st.session_state.debug_messages.append(f"[Companion Targeting] Available columns: {available_cols}")
        
        # Map companion columns to bulk data format based on companion_targeting.csv structure
        column_mapping = {
            'campaign_name': 'Campaign Name',
            'text': 'Keyword Text',  # The 'text' column contains the targeting text
            'match_type': 'Match Type',
            'impressions': 'Impressions',
            'clicks': 'Clicks',
            'spend': 'Spend',
            'cpc': 'Cost Per Click (CPC)',
            'ctr': 'Click-Thru Rate (CTR)',
            'acos': 'ACoS',
            'roas': 'ROAS',
            'kind': 'Campaign Type Raw',
            'campaign_targeting_type': 'Targeting Type',
            'ad_group_name': 'Ad Group Name',
            'campaign_id': 'Campaign ID',
            'id': 'Keyword ID',
            'expression_type': 'Expression Type'
        }
        
        # Dynamically map sales and orders columns based on what's available
        # Priority: attributed_sales_14d > sales > attributed_sales_7d
        if 'attributed_sales_14d' in available_cols:
            column_mapping['attributed_sales_14d'] = 'Sales'
        elif 'sales' in available_cols:
            column_mapping['sales'] = 'Sales'
        elif 'attributed_sales_7d' in available_cols:
            column_mapping['attributed_sales_7d'] = 'Sales'
            
        # Priority: attributed_conversions_14d > orders > attributed_conversions_7d
        if 'attributed_conversions_14d' in available_cols:
            column_mapping['attributed_conversions_14d'] = 'Orders'
        elif 'orders' in available_cols:
            column_mapping['orders'] = 'Orders'
        elif 'attributed_conversions_7d' in available_cols:
            column_mapping['attributed_conversions_7d'] = 'Orders'
        
        # Rename columns
        df_mapped = df.rename(columns=column_mapping)
        
        # Universal text cleaning function for targeting text and other text fields
        def clean_text_field(text):
            """Clean text fields by handling Unicode escape sequences and other encoding issues."""
            if pd.isna(text) or text == '':
                return text
            
            text = str(text)
            
            try:
                # Handle Unicode escape sequences (like \u0027 for apostrophe)
                import codecs
                text = codecs.decode(text, 'unicode_escape')
                
                # Handle common JSON escape sequences
                text = text.replace('\\"', '"')  # Escaped quotes
                text = text.replace('\\/', '/')   # Escaped forward slash
                text = text.replace('\\\\', '\\') # Escaped backslash
                
                # Remove any remaining backslash artifacts
                import re
                text = re.sub(r'\\u[0-9a-fA-F]{4}', lambda m: chr(int(m.group(0)[2:], 16)), text)
                
                # Clean up any remaining escape sequences
                text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')
                
                # Normalize whitespace
                text = ' '.join(text.split())
                
            except Exception as e:
                # If cleaning fails, return the original text
                st.session_state.debug_messages.append(f"[Text Cleaning] Warning: Could not clean text '{text[:50]}...': {str(e)}")
                pass
            
            return text
        
        # Apply text cleaning to targeting text column
        if 'Keyword Text' in df_mapped.columns:
            df_mapped['Keyword Text'] = df_mapped['Keyword Text'].apply(clean_text_field)
            st.session_state.debug_messages.append("[Companion Targeting] Applied text cleaning to Keyword Text column")
        
        # Map campaign types
        campaign_type_mapping = {'sp': 'SP', 'sb': 'SB', 'sd': 'SD'}
        df_mapped['Campaign Type'] = df_mapped['Campaign Type Raw'].map(campaign_type_mapping)
        
        # Handle target column translation and entity determination
        def process_target_and_entity(row):
            targeting_type = str(row.get('Targeting Type', '')).lower()
            match_type = str(row.get('Match Type', '')).lower()
            expression_type = str(row.get('Expression Type', '')).lower()
            target_value = str(row.get('Keyword Text', ''))
            campaign_name = str(row.get('Campaign Name', '')).lower()
            kind = str(row.get('Campaign Type Raw', '')).lower()
            campaign_targeting_type = str(row.get('campaign_targeting_type', '')).lower()
            
            # Handle auto targeting based on campaign_targeting_type column
            if campaign_targeting_type == 'auto':
                # Check for specific auto target types based on target value content
                target_value_lower = target_value.lower()
                
                if 'asinsubstituterelated' in target_value_lower:
                    clean_target = 'Auto - Substitute'
                elif 'querybroadrelmatches' in target_value_lower:
                    clean_target = 'Auto - Loose Match'
                elif 'queryhighrelmatches' in target_value_lower:
                    clean_target = 'Auto - Close Match'
                elif 'asinaccessoryrelated' in target_value_lower:
                    clean_target = 'Auto - Compliments'
                else:
                    # Check if the auto target contains an ASIN and format it
                    import re
                    asin_match = re.search(r'B0[A-Z0-9]{8}', target_value.upper())
                    if asin_match:
                        asin = asin_match.group(0)
                        clean_target = f'ASIN={asin}'
                    else:
                        # Generic auto targeting
                        clean_target = target_value if target_value else 'Auto Targeting'
                
                return 'Product Targeting', clean_target, 'Auto'

            # Special handling for Sponsored Display (SD) targeting
            if kind == 'sd' and target_value:
                import re
                import json
                
                try:
                    # Handle remarketing targets (views/purchases)
                    if 'views' in target_value.lower() or 'purchases' in target_value.lower():
                        # Extract the type (views or purchases) and lookback days
                        remarketing_type = 'Views' if 'views' in target_value.lower() else 'Purchases'
                        
                        # Try to extract lookback days using regex
                        # Look for patterns like "value\":\"7\", "value\":\"14\", etc.
                        days_match = re.search(r'"value":\s*"(\d+)"', target_value)
                        if days_match:
                            days = days_match.group(1)
                            clean_target = f"{remarketing_type} Remarketing - {days}d"
                        else:
                            # Fallback: look for standalone numbers at the end
                            days_match = re.search(r'(\d+)', target_value)
                            if days_match:
                                days = days_match.group(1)
                                clean_target = f"{remarketing_type} Remarketing - {days}d"
                            else:
                                clean_target = f"{remarketing_type} Remarketing"
                        
                        # Determine match type based on campaign name
                        if 'brand' in campaign_name:
                            match_type_result = 'Remarketing - Branded'
                        else:
                            match_type_result = 'Remarketing - Competitor'
                        
                        return 'Product Targeting', clean_target, match_type_result
                    
                    # Handle ASIN targeting (starts with B0 and is 10 chars)
                    asin_match = re.search(r'B0[A-Z0-9]{8}', target_value.upper())
                    if asin_match:
                        asin = asin_match.group(0)
                        clean_target = f"ASIN = {asin}"
                        return 'Product Targeting', clean_target, 'Product Target'
                    
                    # Handle category targeting
                    if 'asincategorysameAs'.lower() in target_value.lower() or 'similarProduct'.lower() in target_value.lower():
                        clean_target = 'SD Category Target'
                        return 'Product Targeting', clean_target, 'Category Targeting'
                        
                except Exception as e:
                    # If JSON parsing or regex fails, fall through to default handling
                    st.session_state.debug_messages.append(f"[SD Targeting] Error processing SD target '{target_value[:50]}...': {str(e)}")
            
            # Default handling for non-SD or non-special cases
            target_value_lower = target_value.lower()
            
            # Handle special expression types and targeting types
            if expression_type == 'negativeexact' or expression_type == 'negativephrase' or expression_type == 'negativebroad':
                # Handle negative keywords
                return 'Keyword', target_value, match_type.title()
            elif targeting_type == 'auto':
                # Auto targeting
                return 'Product Targeting', target_value, 'Auto'
            elif match_type in ['broad', 'exact', 'phrase']:
                # Regular keyword targeting
                return 'Keyword', target_value, match_type.title()
            elif match_type == 'target' or expression_type == 'asinsameas' or expression_type == 'asincategorysameAs':
                # Product targeting
                return 'Product Targeting', target_value, 'Product Target'
            else:
                # Default to keyword for unknown cases
                return 'Keyword', target_value, row.get('Match Type', '').title()
        
        # Apply target processing to each row
        targeting_results = df_mapped.apply(process_target_and_entity, axis=1, result_type='expand')
        df_mapped['Entity'] = targeting_results[0]
        df_mapped['Product Targeting Expression'] = targeting_results[1]  # For compatibility with existing analysis
        df_mapped['Match Type'] = targeting_results[2]
        
        # For product targeting, also set Targeting Expression for SD compatibility
        product_targeting_mask = df_mapped['Entity'] == 'Product Targeting'
        df_mapped.loc[product_targeting_mask, 'Targeting Expression'] = df_mapped.loc[product_targeting_mask, 'Product Targeting Expression']
        
        # For keywords, set the Keyword Text column properly for targeting analysis
        keyword_mask = df_mapped['Entity'] == 'Keyword'
        df_mapped.loc[keyword_mask, 'Keyword Text'] = df_mapped.loc[keyword_mask, 'Product Targeting Expression']
        
        # Add State column (assume enabled for companion data)
        df_mapped['State'] = 'enabled'
        
        # Add Product column to identify the ad type
        df_mapped['Product'] = df_mapped['Campaign Type'].map({
            'SP': 'Sponsored Products',
            'SB': 'Sponsored Brands', 
            'SD': 'Sponsored Display'
        })
        
        # Ensure numeric columns are properly formatted
        numeric_cols = ['Impressions', 'Clicks', 'Spend', 'Sales', 'Orders', 'Cost Per Click (CPC)', 'Click-Thru Rate (CTR)', 'ACoS', 'ROAS']
        for col in numeric_cols:
            if col in df_mapped.columns:
                df_mapped[col] = pd.to_numeric(df_mapped[col], errors='coerce').fillna(0)
        
        # Convert percentage columns
        if 'Click-Thru Rate (CTR)' in df_mapped.columns:
            df_mapped['Click-Thru Rate (CTR)'] = df_mapped['Click-Thru Rate (CTR)'] * 100  # Convert to percentage
        if 'ACoS' in df_mapped.columns:
            df_mapped['ACoS'] = df_mapped['ACoS'] * 100  # Convert to percentage
            
        # Create campaign sheets by campaign type (these will be used by targeting performance)
        bulk_data = {}
        
        for campaign_type in ['SP', 'SB', 'SD']:
            type_df = df_mapped[df_mapped['Campaign Type'] == campaign_type].copy()
            if not type_df.empty:
                if campaign_type == 'SP':
                    sheet_name = 'Sponsored Products Campaigns'
                elif campaign_type == 'SB':
                    sheet_name = 'Sponsored Brands Campaigns'
                else:  # SD
                    sheet_name = 'Sponsored Display Campaigns'
                
                bulk_data[sheet_name] = type_df
                st.session_state.debug_messages.append(f"[Companion Targeting] Created {sheet_name} with {len(type_df)} rows")
        
        st.session_state.debug_messages.append(f"[Companion Targeting] Successfully processed companion targeting data into {len(bulk_data)} sheets")
        return bulk_data
        
    except Exception as e:
        st.error(f"Error processing companion targeting file: {str(e)}")
        st.session_state.debug_messages.append(f"[Companion Targeting] Error: {str(e)}")
        return None

@st.cache_data(ttl=3600, show_spinner="Processing companion data...")  # Cache for 1 hour
def process_companion_data(asin_file, search_term_file, targeting_file=None):
    """
    Combines companion ASIN, Search Term, and Targeting data into a unified bulk data structure.
    The Targeting Export replaces Search Term data for targeting analysis and includes Sponsored Display data.
    """
    try:
        combined_bulk_data = {}
        asin_data = None
        search_term_data = None
        targeting_data = None
        
        # Process ASIN data
        if asin_file is not None:
            asin_data = process_companion_asin_data(asin_file)
            if asin_data:
                combined_bulk_data.update(asin_data)
                st.session_state.debug_messages.append(f"[Companion Combined] Added ASIN data: {list(asin_data.keys())}")
        
        # Process Targeting data (this has priority over Search Term data for targeting analysis)
        if targeting_file is not None:
            targeting_data = process_companion_targeting_data(targeting_file)
            if targeting_data:
                # Targeting data creates Campaign sheets which take priority for targeting performance analysis
                combined_bulk_data.update(targeting_data)
                st.session_state.debug_messages.append(f"[Companion Combined] Added Targeting data: {list(targeting_data.keys())}")
        
        # Process Search Term data (only add if targeting data not provided, or add search term reports)
        if search_term_file is not None:
            search_term_data = process_companion_search_term_data(search_term_file)
            if search_term_data:
                if targeting_data:
                    # If we have targeting data, only add Search Term reports, not campaign sheets
                    # since targeting data provides better campaign targeting information
                    for sheet_name, data in search_term_data.items():
                        if 'Search Term' in sheet_name and 'Campaigns' not in sheet_name:
                            combined_bulk_data[sheet_name] = data
                            st.session_state.debug_messages.append(f"[Companion Combined] Added Search Term report: {sheet_name}")
                else:
                    # No targeting data, use search term data for campaigns
                    # If we have both ASIN and Search Term data, prioritize Search Term data for campaigns
                    if asin_data:
                        # Clear any campaign sheets from ASIN data since Search Term data should handle campaigns
                        for sheet_name in ['Sponsored Products Campaigns', 'Sponsored Brands Campaigns', 'Sponsored Display Campaigns']:
                            if sheet_name in combined_bulk_data:
                                del combined_bulk_data[sheet_name]
                                st.session_state.debug_messages.append(f"[Companion Combined] Removed ASIN campaign data for {sheet_name}")
                        
                        # Add all search term data (both search term reports and campaign sheets)
                        combined_bulk_data.update(search_term_data)
                        st.session_state.debug_messages.append(f"[Companion Combined] Added all Search Term data: {list(search_term_data.keys())}")
                    else:
                        # Only search term data, add everything
                        combined_bulk_data.update(search_term_data)
                        st.session_state.debug_messages.append(f"[Companion Combined] Added Search Term data only: {list(search_term_data.keys())}")
        
        # If we only have ASIN data and no search term or targeting data, create campaign aggregation
        if asin_data and not search_term_data and not targeting_data:
            st.session_state.debug_messages.append("[Companion Combined] Only ASIN data provided, creating campaign aggregation")
            # We need to create campaign sheets from ASIN data since search term processing won't do it
            for campaign_type in ['SP', 'SB', 'SD']:
                if campaign_type == 'SP':
                    campaign_sheet_name = 'Sponsored Products Campaigns'
                elif campaign_type == 'SB':
                    campaign_sheet_name = 'Sponsored Brands Campaigns'
                else:  # SD
                    campaign_sheet_name = 'Sponsored Display Campaigns'
                
                # Find ASIN data for this campaign type (it would be in the combined_bulk_data already)
                # We need to aggregate from any existing data
                # For now, create empty campaign sheets since ASIN data alone doesn't provide campaign-level aggregation
                campaign_df = pd.DataFrame(columns=['Campaign Name', 'Entity', 'State', 'Product', 'Campaign Type', 
                                                  'Impressions', 'Clicks', 'Spend', 'Sales', 'Orders',
                                                  'Cost Per Click (CPC)', 'Click-Thru Rate (CTR)', 'ACoS', 'ROAS'])
                combined_bulk_data[campaign_sheet_name] = campaign_df
                st.session_state.debug_messages.append(f"[Companion Combined] Created empty {campaign_sheet_name} for ASIN-only data")
        
        if not combined_bulk_data:
            st.warning("No data could be processed from companion files.")
            return None
            
        # Mark this as companion data for UI purposes
        st.session_state.is_companion_data = True
        
        st.session_state.debug_messages.append(f"[Companion Combined] Successfully combined companion data with {len(combined_bulk_data)} sheets")
        return combined_bulk_data
        
    except Exception as e:
        st.error(f"Error processing companion data: {str(e)}")
        st.session_state.debug_messages.append(f"[Companion Combined] Error: {str(e)}")
        return None

@st.cache_data(ttl=3600, show_spinner="Classifying campaigns...")  # Cache for 1 hour
def classify_branded_campaigns(bulk_data, client_settings):
    """Classify campaigns as branded or non-branded based on targeting.
    Uses the global sales attribution choice from session state.
    
    Args:
        bulk_data: Dictionary of DataFrames from uploaded reports
        client_settings: Dictionary containing 'Branded Terms' and 'Branded ASINs'
        
    Returns:
        Dictionary with 'Branded' and 'Non-Branded' DataFrames for each campaign type
    """
    classified = {
        'Sponsored Products': {'Branded': [], 'Non-Branded': []},
        'Sponsored Brands': {'Branded': [], 'Non-Branded': []},
        'Sponsored Display': {'Branded': [], 'Non-Branded': []}
    }
    
    branded_terms = client_settings.get('Branded Terms', [])
    branded_asins = client_settings.get('Branded ASINs', [])
    st.session_state.debug_messages.append(f"Classifying with Branded Terms: {branded_terms}") # Log branded terms
    
    campaign_sheets = [
        'Sponsored Products Campaigns',
        'Sponsored Brands Campaigns',
        'Sponsored Display Campaigns'
    ]
    
    for sheet_name in campaign_sheets:
        if sheet_name not in bulk_data:
            st.session_state.debug_messages.append(f"Campaign sheet {sheet_name} not found in bulk data. Skipping classification.")
            continue
            
        df = bulk_data[sheet_name]
        # Ensure 'Entity' and 'Spend' columns exist and handle potential errors
        if 'Entity' not in df.columns:
             st.session_state.debug_messages.append(f"'{sheet_name}' is missing 'Entity' column. Skipping classification for this sheet.")
             continue
        if 'Spend' not in df.columns:
             st.session_state.debug_messages.append(f"'{sheet_name}' is missing 'Spend' column. Spend calculations might be inaccurate.")
             # Optionally add a Spend column with 0 if missing, or handle differently
             df['Spend'] = 0 
             
        # Determine which sales column to use based on global attribution choice
        if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and 'Sponsored Display' in sheet_name:
            sales_patterns = ['Sales (Views & Clicks)', 'Total Sales (Views & Clicks)', 'Sales', 'Total Sales']
            orders_patterns = ['Orders (Views & Clicks)', 'Orders', 'Total Orders']
            st.session_state.debug_messages.append(f"Classification: Using (Views & Clicks) attribution for {sheet_name}")
        else:
            sales_patterns = ['Sales', 'Total Sales', 'Sales (Views & Clicks)']
            orders_patterns = ['Orders', 'Total Orders', 'Orders (Views & Clicks)']
            
        # Find the appropriate sales column
        sales_col = None
        for pattern in sales_patterns:
            if pattern in df.columns:
                sales_col = pattern
                st.session_state.debug_messages.append(f"Classification: Using '{sales_col}' for sales in {sheet_name}")
                break
                
        # If sales column not found, add a placeholder
        if sales_col is None:
            st.session_state.debug_messages.append(f"Warning: No sales column found in {sheet_name}. Adding placeholder.")
            df['Sales'] = 0
            sales_col = 'Sales'

        # Filter for rows where Entity is 'Keyword' or 'Product Targeting'
        targets_df = df[df['Entity'].isin(['Keyword', 'Product Targeting'])]
        st.session_state.debug_messages.append(f"Processing {len(targets_df)} targeting rows in {sheet_name}")

        for index, row in targets_df.iterrows(): # Use index for better logging
            is_branded = False # Default
            classification_reason = "No matching criteria"
            # Safely get spend, convert to numeric, handle errors by coercing to NaN, then fill NaN with 0
            spend_val = row.get('Spend', 0)
            row_spend = pd.to_numeric(spend_val, errors='coerce')
            if pd.isna(row_spend):
                row_spend = 0 # Replace NaN with 0

            # Keyword targeting check
            if pd.notna(row.get('Keyword Text')):
                keyword = str(row['Keyword Text']).lower()
                match_found = False
                for brand_term in branded_terms:
                    # Ensure brand_term is not None or empty before checking
                    if brand_term and isinstance(brand_term, str) and brand_term.lower() in keyword:
                        is_branded = True
                        match_found = True
                        classification_reason = f"Keyword '{keyword}' matched term '{brand_term}'"
                        break # Stop checking terms once a match is found
                if not match_found:
                     classification_reason = f"Keyword '{keyword}' did not match any branded terms."
                # Log keyword check result regardless of match
                st.session_state.debug_messages.append(f"  Row Index: {index}, Type: Keyword, Target: '{keyword}', Spend: {row_spend:.2f}, IsBranded: {is_branded}, Reason: {classification_reason}")

            # Product targeting check
            elif pd.notna(row.get('Product Targeting Expression') or row.get('Targeting Expression')):
                 target_expr_val = row.get('Product Targeting Expression') or row.get('Targeting Expression')
                 target_expr = str(target_expr_val) # Ensure string conversion
                 # Ensure asin is not None or empty before checking
                 asin_match_found = any(asin and isinstance(asin, str) and asin in target_expr for asin in branded_asins)
                 expanded_present = 'expanded' in target_expr.lower()
                 exact_product_present = 'exact-product' in target_expr.lower()
                  
                 # Check if this is a Sponsored Display campaign
                 is_sponsored_display = 'Sponsored Display' in sheet_name
                  
                 # Special case for Sponsored Display with exact-product targeting
                 if is_sponsored_display and exact_product_present:
                     is_branded = True
                     classification_reason = f"Target '{target_expr}' contains 'exact-product' in Sponsored Display campaign (Branded)"
                 elif asin_match_found and not expanded_present:
                     is_branded = True
                     classification_reason = f"Target '{target_expr}' matched a branded ASIN and not 'expanded'"
                 elif asin_match_found and expanded_present:
                      classification_reason = f"Target '{target_expr}' matched ASIN but contained 'expanded' (Non-Branded)"
                      is_branded = False # Explicitly set to False
                 elif not asin_match_found:
                      classification_reason = f"Target '{target_expr}' did not match any branded ASINs."
                      is_branded = False # Explicitly set to False
                 else: # Should not happen based on logic, but good fallback
                      classification_reason = f"Target '{target_expr}' - unusual case"
                      is_branded = False # Default to Non-Branded
                 # Log product target check result
                 st.session_state.debug_messages.append(f"  Row Index: {index}, Type: Product Target, Target: '{target_expr}', Spend: {row_spend:.2f}, IsBranded: {is_branded}, Reason: {classification_reason}")

            else:
                # Row has a Bid but neither Keyword nor Product Target? Log this edge case.
                classification_reason = "Row has Bid but no Keyword/Product Target text"
                st.session_state.debug_messages.append(f"  Row Index: {index}, Type: Unknown/No Target, Spend: {row_spend:.2f}, IsBranded: {is_branded}, Reason: {classification_reason}")
                is_branded = False # Default to Non-Branded if unclear

            campaign_type = sheet_name.replace(' Campaigns', '')
            key = 'Branded' if is_branded else 'Non-Branded'
            # Make sure the row being appended has the numeric spend
            row_copy = row.copy()
            row_copy['Spend'] = row_spend
            classified[campaign_type][key].append(row_copy)
    
    # Convert lists to DataFrames
    for campaign_type in classified:
        for brand_type in classified[campaign_type]: # 'Branded' or 'Non-Branded'
            rows = classified[campaign_type][brand_type]
            # Check if we have any data to convert
            if not rows:
                st.session_state.debug_messages.append(f"  No data for {brand_type} in {campaign_type}. Creating empty DataFrame.")
                classified[campaign_type][brand_type] = pd.DataFrame()
                continue
            
            # Convert list of rows to DataFrame
            df = pd.DataFrame(rows)
            classified[campaign_type][brand_type] = df
            
            st.session_state.debug_messages.append(f"  Processing {brand_type} ({len(df)} rows) for {campaign_type}")

            # Aggregate Spend
            current_spend = 0.0
            if 'Spend' in df.columns:
                 # Ensure conversion to numeric, coercing errors, and filling NaN before sum
                 numeric_spend = pd.to_numeric(df['Spend'], errors='coerce').fillna(0)
                 current_spend = numeric_spend.sum()
                 st.session_state.debug_messages.append(f"    Adding {current_spend:.2f} Spend to {brand_type} (Total: {current_spend:.2f})")
            else:
                 st.session_state.debug_messages.append(f"    '{'Spend'}' column missing in {brand_type} {campaign_type} DataFrame. Spend not added.")

            # Aggregate Sales
            current_sales = 0.0
            if 'Sales' in df.columns:
                numeric_sales = pd.to_numeric(df['Sales'], errors='coerce').fillna(0)
                current_sales = numeric_sales.sum()
                st.session_state.debug_messages.append(f"    Adding {current_sales:.2f} Sales to {brand_type} (Total: {current_sales:.2f})")
            else:
                 st.session_state.debug_messages.append(f"    '{'Sales'}' column missing. Sales not added.")

            # Aggregate Impressions
            current_impressions = 0.0
            if 'Impressions' in df.columns:
                numeric_impressions = pd.to_numeric(df['Impressions'], errors='coerce').fillna(0)
                current_impressions = numeric_impressions.sum()
                st.session_state.debug_messages.append(f"    Adding {current_impressions:.0f} Impressions to {brand_type} (Total: {current_impressions:.0f})")
            else:
                 st.session_state.debug_messages.append(f"    '{'Impressions'}' column missing. Impressions not added.")

            # Aggregate Clicks
            current_clicks = 0.0
            if 'Clicks' in df.columns:
                numeric_clicks = pd.to_numeric(df['Clicks'], errors='coerce').fillna(0)
                current_clicks = numeric_clicks.sum()
                st.session_state.debug_messages.append(f"    Adding {current_clicks:.0f} Clicks to {brand_type} (Total: {current_clicks:.0f})")
            else:
                 st.session_state.debug_messages.append(f"    '{'Clicks'}' column missing. Clicks not added.")

    return classified

@st.cache_data(ttl=3600, show_spinner="Calculating KPIs...")  # Cache for 1 hour
def calculate_branded_kpis(classified_campaigns):
    """Calculate KPIs for branded vs non-branded campaigns.
    
    Args:
        classified_campaigns: Output from classify_branded_campaigns()
        
    Returns:
        Dictionary of KPIs for branded and non-branded campaigns
    """
    kpis = {
        'branded': {
            'Total Spend': 0,
            'Total Ad Sales': 0,
            'ACoS': 0,
            'ROAS': 0,
            'CPC': 0,
            'CVR': 0,
            'CTR': 0,
            'Total Impressions': 0,
            'Total Clicks': 0,
            'AOV': 0,
            'CPA': 0,
            'Total Orders': 0
        },
        'non_branded': {
            'Total Spend': 0,
            'Total Ad Sales': 0,
            'ACoS': 0,
            'ROAS': 0,
            'CPC': 0,
            'CVR': 0,
            'CTR': 0,
            'Total Impressions': 0,
            'Total Clicks': 0,
            'AOV': 0,
            'CPA': 0,
            'Total Orders': 0
        }
    }
    
    # Track the last DataFrame for each brand type for CVR/AOV calculations
    last_df = {'Branded': None, 'Non-Branded': None}
    
    for campaign_type in classified_campaigns:
        for brand_type in classified_campaigns[campaign_type]:
            df = classified_campaigns[campaign_type][brand_type]
            if not isinstance(df, pd.DataFrame) or df.empty:
                continue
                
            # Store the last non-empty DataFrame for each brand type
            last_df[brand_type] = df
                
            # Map the brand_type to the lowercase key used in kpis
            kpi_key = 'branded' if brand_type == 'Branded' else 'non_branded'
                
            # Ensure numeric conversion for all metrics
            if 'Spend' in df.columns:
                kpis[kpi_key]['Total Spend'] += pd.to_numeric(df['Spend'], errors='coerce').fillna(0).sum()
            if 'Sales' in df.columns:
                kpis[kpi_key]['Total Ad Sales'] += pd.to_numeric(df['Sales'], errors='coerce').fillna(0).sum()
            if 'Impressions' in df.columns:
                kpis[kpi_key]['Total Impressions'] += pd.to_numeric(df['Impressions'], errors='coerce').fillna(0).sum()
            if 'Clicks' in df.columns:
                kpis[kpi_key]['Total Clicks'] += pd.to_numeric(df['Clicks'], errors='coerce').fillna(0).sum()
            if 'Orders' in df.columns:
                kpis[kpi_key]['Total Orders'] += pd.to_numeric(df['Orders'], errors='coerce').fillna(0).sum()
    
    # Calculate derived metrics
    for brand_type in kpis:
        if kpis[brand_type]['Total Spend'] > 0:
            kpis[brand_type]['ACoS'] = (kpis[brand_type]['Total Spend'] / kpis[brand_type]['Total Ad Sales']) * 100 \
                if kpis[brand_type]['Total Ad Sales'] > 0 else 0
            kpis[brand_type]['ROAS'] = kpis[brand_type]['Total Ad Sales'] / kpis[brand_type]['Total Spend'] \
                if kpis[brand_type]['Total Spend'] > 0 else 0
            kpis[brand_type]['CPC'] = kpis[brand_type]['Total Spend'] / kpis[brand_type]['Total Clicks'] \
                if kpis[brand_type]['Total Clicks'] > 0 else 0
            kpis[brand_type]['CPA'] = kpis[brand_type]['Total Spend'] / (kpis[brand_type]['Total Clicks'] * kpis[brand_type]['CVR'] / 100) \
                if kpis[brand_type]['Total Clicks'] > 0 and kpis[brand_type]['CVR'] > 0 else 0
        
        if kpis[brand_type]['Total Impressions'] > 0:
            kpis[brand_type]['CTR'] = (kpis[brand_type]['Total Clicks'] / kpis[brand_type]['Total Impressions']) * 100
            
        # Calculate CVR and AOV based on Total Orders
        if kpis[brand_type]['Total Clicks'] > 0:
            kpis[brand_type]['CVR'] = (kpis[brand_type]['Total Orders'] / kpis[brand_type]['Total Clicks']) * 100 \
                if kpis[brand_type]['Total Orders'] > 0 else 0
            kpis[brand_type]['AOV'] = kpis[brand_type]['Total Ad Sales'] / kpis[brand_type]['Total Orders'] \
                if kpis[brand_type]['Total Orders'] > 0 else 0
    
    return kpis

@st.cache_data(ttl=3600, show_spinner="Analyzing targeting performance...", hash_funcs={"_thread.RLock": lambda _: None})  # Cache for 1 hour
def get_targeting_performance_data(bulk_data, client_config):
    # Include the Sales Attribution choice in the cache key
    import re  # Import re module at the top of the function
    sd_attribution = st.session_state.get('sd_attribution_choice', 'Sales')
    st.session_state.debug_messages.append(f"Using Sales Attribution model: {sd_attribution} for targeting performance data")
    # Function description moved to a comment to prevent it from showing as a tooltip
    # Processes bulk data to calculate KPIs per target, classified as branded or non-branded.
    # Handles keyword and product targeting from SP, SB, and SD campaigns.
    # Uses the global sales attribution choice from session state.
    st.session_state.debug_messages.append(f"Starting targeting performance analysis v8") # Debug version

    if bulk_data is None or client_config is None:
        st.session_state.debug_messages.append("Targeting analysis skipped: Missing bulk data or client config.")
        return pd.DataFrame(), pd.DataFrame()

    # --- Configuration Extraction ---
    # Safely extract branded terms (lowercase)
    branded_terms = [str(term).strip().lower() for term in client_config.get('branded_keywords', []) if str(term).strip()] if client_config.get('branded_keywords') else []

    # Safely extract branded ASINs (uppercase) from the correct source: branded_asins_data
    branded_asins_data = client_config.get('branded_asins_data', {})
    branded_asins = {str(asin).strip().upper() for asin in branded_asins_data.keys() if str(asin).strip()} # Use a set for faster lookups
    
    # Extract campaign product groups for filtering
    campaign_product_groups = {}
    if 'campaign_tags_data' in client_config:
        for campaign_name, campaign_info in client_config.get('campaign_tags_data', {}).items():
            product_group = campaign_info.get('tag_1', '') or 'Untagged Group'
            if product_group:
                # Store campaign names as uppercased, trimmed keys for robust lookup
                campaign_product_groups[str(campaign_name).strip().upper()] = product_group

    st.session_state.debug_messages.append(f"Found {len(branded_terms)} branded terms: {list(branded_terms)[:5]}...")
    st.session_state.debug_messages.append(f"Found {len(branded_asins)} branded ASINs from 'branded_asins_data': {list(branded_asins)[:5]}...")
    st.session_state.debug_messages.append(f"Found {len(campaign_product_groups)} campaigns with product groups")

    # --- Data Collection ---
    collected_targets = []
    
    # Determine which sheets to use for targeting data
    # Priority: Campaign sheets (from Targeting Export or bulk data) > Search Term Report sheets
    
    # Check if we have Campaign sheets available (from Targeting Export or bulk data)
    campaign_sheets_available = any(
        sheet_name in bulk_data and not bulk_data[sheet_name].empty 
        for sheet_name in [
            'Sponsored Products Campaigns',
            'Sponsored Brands Campaigns',
            'Sponsored Display Campaigns'
        ]
    )
    
    if campaign_sheets_available:
        # Use Campaign sheets - these have priority for targeting analysis
        targeting_sheets = [
            'Sponsored Products Campaigns',
            'Sponsored Brands Campaigns',
            'Sponsored Display Campaigns'
        ]
        st.session_state.debug_messages.append("Using Campaign sheets for targeting analysis (from Targeting Export or bulk data)")
    else:
        # Fall back to Search Term Report sheets for companion data without Targeting Export
        targeting_sheets = [
            'Sponsored Products Search Term Report',
            'Sponsored Brands Search Term Report', 
            'Sponsored Display Search Term Report'
        ]
        st.session_state.debug_messages.append("Using Search Term Report sheets for targeting analysis (fallback for companion data without Targeting Export)")

    # Precompile ASIN regex for efficiency
    asin_regex = re.compile(r'(B[0-9A-Z]{9})')

    for sheet_name in targeting_sheets:
        if sheet_name not in bulk_data or bulk_data[sheet_name].empty:
            st.session_state.debug_messages.append(f"Skipping sheet: {sheet_name} (Not found or empty)")
            continue

        df = bulk_data[sheet_name]
        st.session_state.debug_messages.append(f"Processing sheet: {sheet_name} with {len(df)} rows")

        # Dynamically find column names (case-insensitive)
        def find_col(potential_names):
            for name in potential_names:
                col = next((c for c in df.columns if c.strip().lower() == name.lower()), None)
                if col:
                    return col
            return None

        entity_col = find_col(['Entity'])
        # Column mapping depends on whether we're using Campaign sheets or Search Term Reports
        if campaign_sheets_available:
            # Using Campaign sheets (from Targeting Export or bulk data)
            keyword_text_col = find_col(['Keyword Text', 'Keyword'])
            product_targeting_col_sp_sb = find_col(['Product Targeting Expression', 'Keyword Text'])
            targeting_expression_col_sd = find_col(['Targeting Expression', 'Keyword Text', 'Product Targeting Expression'])
        else:
            # Using Search Term Reports (fallback for companion data without Targeting Export)
            keyword_text_col = find_col(['Keyword Text', 'Customer Search Term'])
            product_targeting_col_sp_sb = find_col(['Targeting Expression', 'Product Targeting Expression'])
            targeting_expression_col_sd = find_col(['Targeting Expression'])
        state_col = find_col(['State'])
        campaign_col = find_col(['Campaign Name (Informational Only)', 'Campaign Name', 'Campaign']) # Prioritize informational
        adgroup_col = find_col(['Ad Group Name', 'Ad Group'])
        bid_col = find_col(['Bid', 'Max Bid'])
        match_type_col = find_col(['Match Type']) # Add Match Type column
        spend_col = find_col(['Spend', 'Cost'])
        # Use global sales attribution choice to determine which sales column to prioritize
        if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and 'Sponsored Display' in sheet_name:
            sales_patterns = ['Sales (Views & Clicks)', 'Total Sales (Views & Clicks)', 'Sales', 'Total Sales', '14 Day Total Sales', '7 Day Total Sales']
            orders_patterns = ['Orders (Views & Clicks)', 'Orders', 'Total Orders', '14 Day Total Orders (#)', '7 Day Total Orders (#)']
        else:
            sales_patterns = ['Sales', 'Total Sales', '14 Day Total Sales', '7 Day Total Sales', 'Sales (Views & Clicks)']
            orders_patterns = ['Orders', '14 Day Total Orders (#)', '7 Day Total Orders (#)', 'Orders (Views & Clicks)']
            
        st.session_state.debug_messages.append(f"Targeting: Using sales patterns for {sheet_name}: {sales_patterns[:2]}...")
        sales_col = find_col(sales_patterns)
        orders_col = find_col(orders_patterns)
        impressions_col = find_col(['Impressions'])
        clicks_col = find_col(['Clicks'])

        # Essential columns check - Ad Group not required for Sponsored Brands
        required_cols = [entity_col, state_col, campaign_col]
        # Only require Ad Group for non-Sponsored Brands campaigns
        if 'Sponsored Brands' not in sheet_name and not adgroup_col:
            required_cols.append(adgroup_col)
            
        if not all(required_cols):
            missing = []
            for name, col_var in [('Entity', entity_col), ('State', state_col), ('Campaign', campaign_col)]:
                if not col_var:
                    missing.append(name)
            # Only include Ad Group in missing columns for non-Sponsored Brands
            if 'Sponsored Brands' not in sheet_name and not adgroup_col:
                missing.append('Ad Group')
                
            st.session_state.debug_messages.append(f"Error: Missing essential columns {missing} in {sheet_name}")
            continue

        # Filter for relevant entities (case-insensitive) and status
        # Expand valid entities to include variations seen in different campaign types
        valid_entities = ['keyword', 'product targeting', 'product target', 'contextual targeting', 'audience targeting']
        try:
            # Make filtering more robust to different casing and potential NaNs
            entity_mask = df[entity_col].fillna('').astype(str).str.strip().str.lower().apply(
                lambda x: any(entity in x for entity in valid_entities)
            )
            st.session_state.debug_messages.append(f"Entity types found in {sheet_name}: {df[entity_col].fillna('').astype(str).str.strip().str.lower().unique().tolist()}")
            # Remove state filtering - include all data regardless of state
            df_filtered = df[entity_mask]
        except KeyError as e:
             st.session_state.debug_messages.append(f"Error applying filters in {sheet_name}: Missing column {e}")
             continue
        st.session_state.debug_messages.append(f"Filtered to {len(df_filtered)} 'Keyword' or 'Product Targeting' rows in {sheet_name}")
        st.session_state.debug_messages.append(f"Filtered to {len(df_filtered)} 'Keyword' or 'Product Targeting' rows in {sheet_name}")

        # Process each relevant row
        for _, row in df_filtered.iterrows():
            entity_type = str(row[entity_col]).strip().lower()
            target_str = None
            classification = 'Non-Branded' # Default
            classification_reason = "Default - No specific match"

            # --- Extract Target String ---
            # Handle keyword targeting
            if 'keyword' in entity_type and keyword_text_col and pd.notna(row[keyword_text_col]):
                target_str = str(row[keyword_text_col]).strip()
                entity_type = 'keyword'  # Normalize entity type
            # Handle product targeting (including variations)
            elif any(target_type in entity_type for target_type in ['product targeting', 'targeting', 'contextual targeting', 'audience targeting', 'product', 'asin', 'category']):
                # For Campaign sheets (from companion targeting), prioritize cleaned target names
                if campaign_sheets_available:
                    # First check for cleaned target names in Keyword Text (which contains cleaned targets from companion processing)
                    if keyword_text_col and pd.notna(row[keyword_text_col]):
                        potential_target = str(row[keyword_text_col]).strip()
                        # Use this if it's not raw JSON
                        if not (potential_target.startswith('[{') and potential_target.endswith('}]')):
                            target_str = potential_target
                    
                    # If we still don't have a clean target, try Product Targeting Expression
                    if not target_str and product_targeting_col_sp_sb and pd.notna(row[product_targeting_col_sp_sb]):
                        target_str = str(row[product_targeting_col_sp_sb]).strip()
                        # If this looks like raw JSON, try other columns for cleaned names
                        if target_str.startswith('[{') and target_str.endswith('}]'):
                            if targeting_expression_col_sd and pd.notna(row[targeting_expression_col_sd]):
                                alt_target = str(row[targeting_expression_col_sd]).strip()
                                if not (alt_target.startswith('[{') and alt_target.endswith('}]')):
                                    target_str = alt_target
                    
                    # If still no clean target, try Targeting Expression
                    if not target_str and targeting_expression_col_sd and pd.notna(row[targeting_expression_col_sd]):
                        target_str = str(row[targeting_expression_col_sd]).strip()
                else:
                    # For Search Term Reports, use the original logic
                    if product_targeting_col_sp_sb and pd.notna(row[product_targeting_col_sp_sb]):
                        target_str = str(row[product_targeting_col_sp_sb]).strip()
                    elif targeting_expression_col_sd and pd.notna(row[targeting_expression_col_sd]):
                        target_str = str(row[targeting_expression_col_sd]).strip()
                
                # Fallback options if we still have raw JSON or no target_str
                if not target_str or (target_str.startswith('[{') and target_str.endswith('}]')):
                    # For SD campaigns, also check Targeting ID as a fallback
                    if 'Targeting ID' in df.columns and pd.notna(row.get('Targeting ID')):
                        target_str = str(row.get('Targeting ID')).strip()
                    # Check for ASIN column as a fallback for product targeting
                    elif 'ASIN' in df.columns and pd.notna(row.get('ASIN')):
                        target_str = str(row.get('ASIN')).strip()
                    # Check for Target ID column as a fallback
                    elif 'Target ID' in df.columns and pd.notna(row.get('Target ID')):
                        target_str = str(row.get('Target ID')).strip()
                    # Special handling for Sponsored Brands auto-tagging using Creative ASINs
                    elif 'Sponsored Brands' in sheet_name and 'Creative ASINs' in df.columns and pd.notna(row.get('Creative ASINs')):
                        creative_asins = [asin.strip().upper() for asin in str(row.get('Creative ASINs')).split(',') if asin.strip()]
                        if creative_asins:
                            # If all ASINs are branded, classify as branded
                            if set(creative_asins).issubset(branded_asins):
                                is_branded = True
                                classification_reason = f"All Creative ASINs ({creative_asins}) are branded. Classified as Branded."
                            else:
                                is_branded = False
                                classification_reason = f"Not all Creative ASINs ({creative_asins}) are branded. Classified as Non-Branded."
                            target_str = ','.join(creative_asins) # For traceability
                # Normalize entity type for consistent processing
                entity_type = 'product targeting'

            if not target_str:
                # st.session_state.debug_messages.append(f"Skipping row: Could not extract target string for entity '{entity_type}'")
                continue # Skip if no target string could be extracted

            # --- Universal Auto Targeting Cleanup ---
            # Apply the same cleanup logic as in search term data
            original_target = target_str
            campaign_name = str(row.get(campaign_col, '')).strip() if pd.notna(row.get(campaign_col)) else ''
            
            # Detect campaign type from campaign name or sheet name
            campaign_type = 'SP'  # Default
            if 'SB' in campaign_name.upper() or 'SPONSORED BRAND' in campaign_name.upper() or 'Sponsored Brands' in sheet_name:
                campaign_type = 'SB'
            elif 'SD' in campaign_name.upper() or 'SPONSORED DISPLAY' in campaign_name.upper() or 'Sponsored Display' in sheet_name:
                campaign_type = 'SD'
            
            # Handle JSON format targeting expressions first
            if target_str.startswith('[{') and target_str.endswith('}]'):
                try:
                    import json
                    parsed = json.loads(target_str)
                    if isinstance(parsed, list) and len(parsed) > 0 and isinstance(parsed[0], dict):
                        target_type = parsed[0].get('type', '')
                        target_value = parsed[0].get('value', '')
                        
                        # Auto targeting cleanup
                        if target_type in ['queryBroadRelMatches', 'queryHighRelMatches', 'asinSubstituteRelated', 'asinAccessoryRelated']:
                            if target_type == 'queryBroadRelMatches':
                                target_str = 'Auto - Loose Match'
                            elif target_type == 'queryHighRelMatches':
                                target_str = 'Auto - Close Match'
                            elif target_type == 'asinSubstituteRelated':
                                target_str = 'Auto - Substitute'
                            elif target_type == 'asinAccessoryRelated':
                                target_str = 'Auto - Compliments'
                        
                        # ASIN targeting cleanup
                        elif target_type == 'asinSameAs' and target_value:
                            if 'expanded' in target_str.lower():
                                target_str = f'ASIN-Expanded = {target_value}'
                            else:
                                target_str = f'ASIN = {target_value}'
                        
                        # Category targeting cleanup
                        elif target_type == 'asinCategorySameAs' and target_value:
                            target_str = f'{campaign_type} Category Targeting'
                        
                        # Other JSON types - extract value if available
                        elif target_value:
                            target_str = target_value
                            
                except Exception as e:
                    # If JSON parsing fails, continue with original logic
                    st.session_state.debug_messages.append(f"[Targeting Performance] JSON parsing failed for target: {target_str[:50]}... Error: {e}")
                    pass
            
            # Handle non-JSON format targeting expressions
            else:
                # Auto targeting cleanup for simple strings
                if target_str in ['queryBroadRelMatches', 'queryHighRelMatches', 'asinSubstituteRelated', 'asinAccessoryRelated']:
                    if target_str == 'queryBroadRelMatches':
                        target_str = 'Auto - Loose Match'
                    elif target_str == 'queryHighRelMatches':
                        target_str = 'Auto - Close Match'
                    elif target_str == 'asinSubstituteRelated':
                        target_str = 'Auto - Substitute'
                    elif target_str == 'asinAccessoryRelated':
                        target_str = 'Auto - Compliments'
                
                # ASIN detection and formatting for non-JSON format
                elif 'asinSameAs' in target_str or 'asinsameas' in target_str.lower():
                    asin_pattern = re.compile(r'B0[A-Z0-9]{8}', re.IGNORECASE)  # Case-insensitive ASIN pattern
                    asin_match = asin_pattern.search(target_str)
                    
                    if asin_match:
                        asin = asin_match.group().upper()  # Convert to uppercase for consistency
                        if 'expanded' in target_str.lower():
                            target_str = f'ASIN-Expanded = {asin}'
                        else:
                            target_str = f'ASIN = {asin}'
                    else:
                        # Enhanced fallback - try to extract any ASIN-like pattern
                        # Look for patterns like b0xxxxxxxx (10 chars starting with b0)
                        fallback_pattern = re.compile(r'b0[a-z0-9]{8}', re.IGNORECASE)
                        fallback_match = fallback_pattern.search(target_str)
                        
                        if fallback_match:
                            asin = fallback_match.group().upper()
                            if 'expanded' in target_str.lower():
                                target_str = f'ASIN-Expanded = {asin}'
                            else:
                                target_str = f'ASIN = {asin}'
                        else:
                            # Final fallback if no ASIN found
                            if 'expanded' in target_str.lower():
                                target_str = 'ASIN-Expanded Target'
                            else:
                                target_str = 'ASIN Target'
                
                # Category targeting (campaign-specific)
                elif 'category=' in target_str.lower() or 'categorysameas' in target_str.lower():
                    target_str = f'{campaign_type} Category Targeting'
            
            # SD-specific remarketing logic (applies to both JSON and non-JSON)
            if campaign_type == 'SD':
                if 'views' in target_str.lower() or 'purchases' in target_str.lower():
                    # Extract lookback days if present
                    days_match = re.search(r'(\d+)', target_str)
                    if days_match:
                        days = days_match.group(1)
                        if 'views' in target_str.lower():
                            target_str = f'Views Remarketing - {days}d'
                        elif 'purchases' in target_str.lower():
                            target_str = f'Purchases Remarketing - {days}d'
                    else:
                        if 'views' in target_str.lower():
                            target_str = 'Views Remarketing'
                        elif 'purchases' in target_str.lower():
                            target_str = 'Purchases Remarketing'
            
            # Log cleanup if target was changed
            if target_str != original_target:
                st.session_state.debug_messages.append(f"[Targeting Performance] Cleaned target: '{original_target}' → '{target_str}'")

            # --- Classification Logic ---
            target_lower = target_str.lower() # For keyword matching
            is_branded = False # Reset for each target
                            
            if entity_type == 'keyword':
                # Exact match check first for branded terms
                if target_lower in branded_terms:
                    is_branded = True
                    classification_reason = f"Keyword '{target_str}' exactly matched a branded term."
                else:
                    # Check if any branded term is a substring (e.g., "brand shoe" contains "brand")
                    if any(term in target_lower for term in branded_terms):
                         is_branded = True
                         classification_reason = f"Keyword '{target_str}' contained a branded term."
                    else:
                         classification_reason = f"Keyword '{target_str}' did not match any branded terms."

            elif entity_type == 'product targeting':
                # --- SPECIAL CASE FOR EXACT-PRODUCT TARGETING IN SD ---
                # Check if this is a Sponsored Display campaign with exact-product targeting
                is_sponsored_display = 'Sponsored Display' in sheet_name
                target_lower = target_str.lower()
                contains_exact_product = 'exact-product' in target_lower or 'exact-product' in original_target.lower()
                
                if is_sponsored_display and contains_exact_product:
                    is_branded = True
                    classification_reason = f"Target '{target_str}' contains 'exact-product' in Sponsored Display campaign (Branded)"
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f"[Targeting Performance] HIGHEST PRIORITY: Classified '{target_str}' as BRANDED due to exact-product")
                # --- ENHANCED AUTO TARGET LOGIC FOR SP ---
                elif sheet_name == 'Sponsored Products Campaigns':
                    # Check for Auto targeting patterns
                    target_lower = target_str.strip().lower()
                    
                    # Direct auto targeting terms
                    if target_lower in {'loose-match', 'close-match', 'complements', 'substitutes', 'auto - loose match', 'auto - close match', 'auto - substitute', 'auto - compliments'}:
                        entity_type = 'auto targeting'
                        match_type = 'Auto'
                        classification_reason = f"Target '{target_str}' matched Auto term for SP. Classified as 'Auto' target."
                    
                    # Check for auto targeting patterns in target expressions
                    elif any(pattern in target_lower for pattern in ['querybroadrelmatches', 'queryhighrelmatches', 'asinsubstituterelated', 'asinaccessoryrelated']):
                        entity_type = 'auto targeting'
                        match_type = 'Auto'
                        classification_reason = f"Target '{target_str}' contains Auto targeting pattern for SP. Classified as 'Auto' target."
                    
                    # Check for targeting type column with 'auto' value
                    elif 'Targeting Type' in df.columns and pd.notna(row.get('Targeting Type')) and str(row.get('Targeting Type')).strip().lower() == 'auto':
                        entity_type = 'auto targeting'
                        match_type = 'Auto'
                        classification_reason = f"Target '{target_str}' has Targeting Type 'Auto' for SP. Classified as 'Auto' target."
                # Continue with normal product targeting logic if not exact-product
                else:
                    found_asins = set(asin_regex.findall(target_str.upper())) # Use set for uniqueness

                    if found_asins:
                        # Check if ALL found ASINs are in the defined branded ASIN list
                        if found_asins.issubset(branded_asins):
                             # Check for 'expanded' non-branded)
                            if 'expanded' in target_lower:
                                is_branded = False
                                classification_reason = f"Target '{target_str}' contained only branded ASIN(s) {found_asins} but also 'expanded'."
                            else:
                                is_branded = True
                                classification_reason = f"Target '{target_str}' contained ONLY branded ASIN(s): {found_asins}"
                        else:
                            # If the target contains *any* non-branded ASIN, classify as Non-Branded
                            non_branded_found = found_asins - branded_asins
                            branded_found = found_asins.intersection(branded_asins)
                            is_branded = False # Explicitly non-branded
                            classification_reason = f"Target '{target_str}' contained non-branded ASIN(s): {non_branded_found}."
                            if branded_found:
                                classification_reason += f" (Also contained branded: {branded_found})"

                    else:
                        # If the target string doesn't contain any recognizable ASINs
                        # Check if it contains any branded *terms* as a fallback (e.g., targeting categories)
                        if any(term in target_lower for term in branded_terms):
                            is_branded = True
                            classification_reason = f"Product Target '{target_str}' (no ASINs found) contained a branded term."
                        else:
                            classification_reason = f"Product Target '{target_str}' contained no recognizable ASINs or branded terms."

            # --- COMPANION EXPORTS SPECIAL LOGIC ---
            # For Companion Exports, apply additional classification rules
            if st.session_state.get('is_companion_data', False):
                # Rule 1: "Remarketing - Branded" Match Type should be considered Branded
                if match_type_col and pd.notna(row.get(match_type_col)):
                    current_match_type = str(row.get(match_type_col)).strip()
                    if current_match_type == 'Remarketing - Branded':
                        is_branded = True
                        classification_reason = f"Companion Export: Match Type '{current_match_type}' classified as Branded"
                        st.session_state.debug_messages.append(f"[Companion Export] Classified '{target_str}' as BRANDED due to Match Type 'Remarketing - Branded'")
                
                # Rule 2: Check ASIN targets against Branded ASINs for both Targeting and Search Term Performance
                # This applies to both Target column (Targeting Performance) and Search Term column (Search Term Performance)
                asin_pattern_companion = re.compile(r'(B[0-9A-Z]{9})', re.IGNORECASE)
                
                # Check Target column for ASINs
                target_asins = set(asin_pattern_companion.findall(target_str.upper()))
                if target_asins:
                    # Check if any of the ASINs found are branded
                    branded_asins_found = target_asins.intersection(branded_asins)
                    if branded_asins_found:
                        is_branded = True
                        classification_reason = f"Companion Export: Target '{target_str}' contains branded ASIN(s): {branded_asins_found}"
                        st.session_state.debug_messages.append(f"[Companion Export] Classified '{target_str}' as BRANDED due to branded ASIN(s): {branded_asins_found}")

            # --- Universal ASIN Classification Safety Check ---
            # Final check to ensure any target containing ONLY branded ASINs is classified as Branded
            if not is_branded:  # Only apply if not already branded
                all_asins_in_target = set(asin_regex.findall(target_str.upper()))
                if all_asins_in_target and all_asins_in_target.issubset(branded_asins) and 'expanded' not in target_str.lower():
                    is_branded = True
                    classification_reason = f'Safety Check: Target {target_str} contains ONLY branded ASIN(s): {all_asins_in_target}'
                    st.session_state.debug_messages.append(f'[Universal ASIN Safety Check] Reclassified {target_str} as BRANDED')

            classification = 'Branded' if is_branded else 'Non-Branded' 

            # --- Data Extraction ---
            try:
                # Extract metrics, handling potential missing columns and non-numeric data
                spend = pd.to_numeric(row.get(spend_col, 0), errors='coerce') or 0
                sales = pd.to_numeric(row.get(sales_col, 0), errors='coerce') or 0
                orders = pd.to_numeric(row.get(orders_col, 0), errors='coerce') or 0
                impressions = pd.to_numeric(row.get(impressions_col, 0), errors='coerce') or 0
                clicks = pd.to_numeric(row.get(clicks_col, 0), errors='coerce') or 0

                # Calculate KPIs
                if sales > 0:
                    acos = (spend / sales) * 100
                else:
                    acos = 0
                roas = sales / spend if spend > 0 else 0
                cpc = spend / clicks if clicks > 0 else 0
                ctr = (clicks / impressions) * 100 if impressions > 0 else 0
                cvr = (orders / clicks) * 100 if clicks > 0 else 0
                aov = sales / orders if orders > 0 else 0
                cpa = spend / orders if orders > 0 else 0 # Cost Per Acquisition/Order

                # Get match type - enhanced logic for better detection
                if entity_type == 'keyword' and match_type_col and pd.notna(row.get(match_type_col)):
                    match_type = str(row.get(match_type_col)).strip()
                    # Skip negative keywords
                    if 'negative' in match_type.lower():
                        continue
                # Enhanced Auto targeting detection
                elif entity_type == 'auto targeting':
                    match_type = 'Auto'
                # For companion data, check if we have a Match Type column with 'Auto' value
                elif match_type_col and pd.notna(row.get(match_type_col)):
                    provided_match_type = str(row.get(match_type_col)).strip()
                    if provided_match_type == 'Auto':
                        match_type = 'Auto'
                        entity_type = 'auto targeting'  # Update entity type as well
                    elif provided_match_type in ['Remarketing - Branded', 'Remarketing - Competitor']:
                        match_type = provided_match_type
                    else:
                        match_type = provided_match_type
                elif sheet_name == 'Sponsored Display Campaigns':
                    # Use Match Type column if available (from companion targeting processing)
                    if match_type_col and pd.notna(row.get(match_type_col)):
                        match_type = str(row.get(match_type_col)).strip()
                    else:
                        # Default for SD if no match type available
                        match_type = 'Product Target'
                else:
                    # Check if product targeting contains 'category' for special classification
                    if entity_type == 'product targeting' and target_str and 'category' in target_str.lower():
                        match_type = 'Category Targeting'
                    else:
                        # Roll up all other product targeting types to 'Product Target' for consistency
                        match_type = 'Product Target' 
                
                # Handle Ad Group differently for Sponsored Brands
                ad_group_value = 'N/A'
                if adgroup_col and pd.notna(row.get(adgroup_col)):
                    ad_group_value = row.get(adgroup_col)
                elif 'Sponsored Brands' in sheet_name:
                    ad_group_value = 'SB Campaign'
                    
                # Get campaign name for product group lookup
                campaign_name = row.get(campaign_col, 'N/A')
                # Get product group for this campaign (case-insensitive, whitespace-trimmed lookup)
                # Only populate Product Group if there are actually product groups defined in Campaign Tagging
                product_group = ''
                if campaign_product_groups:  # Only if there are product groups defined
                    campaign_name_upper = str(campaign_name).strip().upper()
                    product_group = campaign_product_groups.get(campaign_name_upper, '')
                
                # Debug match type assignment
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f"[Match Type Debug] Target: '{target_str}' | Entity: '{entity_type}' | Match Type: '{match_type}' | Sheet: '{sheet_name}'")
                
                
                # Fix Target Type for Sponsored Display remarketing campaigns
                target_type_to_use = entity_type.title()
                
                # Check if this is a Sponsored Display campaign - use Targeting Expression to determine type
                if sheet_name == 'Sponsored Display Campaigns' and entity_type == 'product targeting':
                    # Get the targeting expression to determine if it's remarketing or product targeting
                    targeting_expression = ''
                    if targeting_expression_col_sd and pd.notna(row.get(targeting_expression_col_sd)):
                        targeting_expression = str(row.get(targeting_expression_col_sd, '')).lower()
                    
                    # First, check if it's category targeting (highest priority)
                    is_category_targeting = ('category' in targeting_expression or 
                                           'category' in target_str.lower() or
                                           'asinCategorySameAs' in str(row.get(targeting_expression_col_sd, '')))
                    
                    if is_category_targeting:
                        # It's category targeting
                        target_type_to_use = 'Product Targeting'
                        match_type = 'Category Targeting'
                        st.session_state.debug_messages.append(f"[Targeting Performance] Category targeting: '{target_str}' (Expression: {targeting_expression[:50]})")
                        
                    else:
                        # Check if it's remarketing (contains 'views' or 'purchases')
                        is_remarketing = 'views' in targeting_expression or 'purchases' in targeting_expression
                        
                        if is_remarketing:
                            # Check if it's category-based remarketing (contains both remarketing and category)
                            is_category_remarketing = 'category' in targeting_expression
                            
                            if is_category_remarketing:
                                # Category-based remarketing - extract lookback period and create descriptive target name
                                lookback_match = re.search(r'lookback=(\d+)', targeting_expression)
                                lookback_days = lookback_match.group(1) if lookback_match else '30'  # default to 30 if not found
                                
                                if 'views' in targeting_expression:
                                    target_str = f'Views Remarketing - {lookback_days}d'
                                else:  # purchases
                                    target_str = f'Purchases Remarketing - {lookback_days}d'
                                
                                # Category-based remarketing is always competitor
                                target_type_to_use = 'Remarketing - Competitor'
                                match_type = 'Remarketing - Competitor'
                                st.session_state.debug_messages.append(f"[Targeting Performance] Category remarketing: Updated target to '{target_str}' (Expression: {targeting_expression[:50]})")
                            else:
                                # Product-based remarketing - determine if branded or competitor based on expression content
                                if 'exact-product' in targeting_expression:
                                    target_type_to_use = 'Remarketing - Branded'
                                    match_type = 'Remarketing - Branded'
                                elif 'similar-product' in targeting_expression:
                                    target_type_to_use = 'Remarketing - Competitor'
                                    match_type = 'Remarketing - Competitor'
                                else:
                                    # Fallback to branded classification if no specific product type found
                                    if is_branded:
                                        target_type_to_use = 'Remarketing - Branded'
                                        match_type = 'Remarketing - Branded'
                                    else:
                                        target_type_to_use = 'Remarketing - Competitor'
                                        match_type = 'Remarketing - Competitor'
                                st.session_state.debug_messages.append(f"[Targeting Performance] Product remarketing: Updated Target Type and Match Type for '{target_str}' to '{target_type_to_use}' (Expression: {targeting_expression[:50]})")
                        else:
                            # It's product targeting - determine branded/non-branded
                            if 'similar-product' in targeting_expression:
                                # Similar product is always non-branded
                                is_branded = False
                                classification = 'Non-Branded'
                                classification_reason = 'Similar-product targeting is classified as Non-Branded'
                            elif 'exact-product' in targeting_expression:
                                # Exact product is branded, but we still check ASINs if available
                                is_branded = True
                                classification = 'Branded'
                                classification_reason = 'Exact-product targeting is classified as Branded'
                            # For other product targeting, classification remains as determined by ASIN check
                            match_type = 'Product Target'
                            st.session_state.debug_messages.append(f"[Targeting Performance] Product targeting: '{target_str}' classified as {classification} (Expression: {targeting_expression[:50]})")
                
                collected_targets.append({
                    'Campaign': campaign_name,
                    'Ad Group': ad_group_value,
                    'Product Group': product_group,
                    'Target Type': target_type_to_use,
                    'Target': target_str,
                    'Match Type': match_type,  # Use the match type as determined above
                    'Classification': classification,
                    'Classification Reason': classification_reason, # Added for debugging
                    'Spend': spend,
                    'Ad Sales': sales,
                    'Orders': orders,
                    'Impressions': impressions,
                    'Clicks': clicks,
                    'ACoS': round(acos, 2),
                    'ROAS': roas,
                    'CPC': cpc,
                    'CTR': ctr,
                    'CVR': cvr,
                    'AOV': aov,
                    'CPA': cpa,
                    'Bid': pd.to_numeric(row.get(bid_col, 0), errors='coerce') or 0, # Add Bid
                    'Sheet Source': sheet_name # Added for debugging
                })
            except Exception as e:
                 st.session_state.debug_messages.append(f"Error processing row data in {sheet_name} for target '{target_str}': {e}")

    # Process the collected targets
    targets_df = pd.DataFrame(collected_targets)
    
    if targets_df.empty:
        st.session_state.debug_messages.append("No targeting data found after processing.")
        return pd.DataFrame(), pd.DataFrame()
        
    # Log the distribution of target types for debugging
    if 'Target Type' in targets_df.columns:
        target_type_counts = targets_df['Target Type'].value_counts().to_dict()
        st.session_state.debug_messages.append(f"Target type distribution: {target_type_counts}")
    
    if 'Match Type' in targets_df.columns:
        match_type_counts = targets_df['Match Type'].value_counts().to_dict()
        st.session_state.debug_messages.append(f"Match type distribution: {match_type_counts}")
    
    # Ensure we're using 'Ad Sales' as the standard column name
    # But keep 'Sales' for backward compatibility with other functions
    if 'Sales' in targets_df.columns and 'Ad Sales' not in targets_df.columns:
        targets_df['Ad Sales'] = targets_df['Sales']
    elif 'Ad Sales' in targets_df.columns and 'Sales' not in targets_df.columns:
        targets_df['Sales'] = targets_df['Ad Sales']
        
    # Split into branded and non-branded
    branded_targets_df = targets_df[targets_df['Classification'] == 'Branded'].copy()
    non_branded_targets_df = targets_df[targets_df['Classification'] == 'Non-Branded'].copy()

    # Debug: Show total and sample rows
    st.session_state.debug_messages.append(
        f"[Targeting Classification] Total targets: {len(targets_df)}, Branded: {len(branded_targets_df)}, Non-Branded: {len(non_branded_targets_df)}"
    )

    if not non_branded_targets_df.empty:
        sample_cols = [col for col in ['Campaign','Target','Match Type','Spend','Ad Sales','ACoS'] if col in non_branded_targets_df.columns]
        if sample_cols:
            st.session_state.debug_messages.append(
                f"[Non-Branded Sample Rows] {non_branded_targets_df[sample_cols].head(10).to_dict(orient='records')}"
            )
        else:
            st.session_state.debug_messages.append("[Non-Branded Sample Rows] No sample columns available in non_branded_targets_df.")
    else:
        st.session_state.debug_messages.append("[Non-Branded Sample Rows] No non-branded rows found.")

    return branded_targets_df, non_branded_targets_df

@st.cache_data(ttl=3600, show_spinner="Processing data...", hash_funcs={"_thread.RLock": lambda _: None})  # Cache for 1 hour
def get_search_term_data(bulk_data, client_config=None):
    # Include the Sales Attribution choice in the cache key
    sd_attribution = st.session_state.get('sd_attribution_choice', 'Sales')
    st.session_state.debug_messages.append(f"Using Sales Attribution model: {sd_attribution} for search term data")
    # Function description moved to a comment to prevent it from showing as a tooltip
    # Extracts and processes search term data from bulk advertising files.
    # Handles both Sponsored Products and Sponsored Brands search terms.
    # Classifies search terms as Branded or Non-Branded based on client configuration.
    if not bulk_data or not isinstance(bulk_data, dict):
        return pd.DataFrame()
        
    st.session_state.debug_messages.append(f"Starting Search Term Performance")
    
    # Initialize an empty list to store search term data
    search_term_data = []
    
    # Get targeting data to match with search terms
    targeting_data = None
    # Check if we have both branded and non-branded targeting data in session state
    if 'branded_targets_df' in st.session_state and 'non_branded_targets_df' in st.session_state:
        branded_df = st.session_state.branded_targets_df
        non_branded_df = st.session_state.non_branded_targets_df
        if not branded_df.empty or not non_branded_df.empty:
            targeting_data = pd.concat([branded_df, non_branded_df], ignore_index=True)
            st.session_state.debug_messages.append(f"[Search Term Performance] Loaded targeting data: {len(targeting_data)} rows")
    
    # Extract campaign product groups for filtering
    campaign_product_groups = {}
    if client_config and 'campaign_tags_data' in client_config:
        for campaign_name, campaign_info in client_config.get('campaign_tags_data', {}).items():
            product_group = campaign_info.get('tag_1', '') or 'Untagged Group'
            if product_group:
                campaign_product_groups[campaign_name.upper()] = product_group
        st.session_state.debug_messages.append(f"[Search Term Performance] Found {len(campaign_product_groups)} campaigns with product groups")
    
    # Check each sheet in the bulk file for search term data
    for sheet_name, df in bulk_data.items():
        if not isinstance(df, pd.DataFrame) or df.empty:
            continue
            
        # Look for Search Term column (case insensitive)
        # Check for both 'Search Term' and 'Customer Search Term'
        search_term_col = None
        for col in df.columns:
            if col.lower() == 'search term' or col.lower() == 'customer search term':
                search_term_col = col
                st.session_state.debug_messages.append(f"[Search Term Performance] Found column: {col}")
                break
        
        # Look for Campaign Name column (case insensitive) - prioritize informational name over ID
        campaign_col = None
        # First, try to find 'Campaign Name (Informational Only)' specifically
        for col in df.columns:
            if col.lower() == 'campaign name (informational only)':
                campaign_col = col
                st.session_state.debug_messages.append(f"[Search Term Performance] Found informational campaign column: {col}")
                break
                
        # If not found, try 'Campaign Name'
        if not campaign_col:
            for col in df.columns:
                if col.lower() == 'campaign name':
                    campaign_col = col
                    st.session_state.debug_messages.append(f"[Search Term Performance] Found campaign name column: {col}")
                    break
                    
        # Last resort, use 'Campaign' column
        if not campaign_col:
            for col in df.columns:
                if col.lower() == 'campaign':
                    campaign_col = col
                    st.session_state.debug_messages.append(f"[Search Term Performance] Found campaign column: {col}")
                    break
        
        # Debug available columns
        st.session_state.debug_messages.append(f"[Search Term Performance] Available columns: {', '.join(df.columns)}")
                
        if search_term_col is None:
            continue
            
        st.session_state.debug_messages.append(f"Found search term data in sheet: {sheet_name}")
        
        # Identify campaign type (Sponsored Products or Sponsored Brands)
        campaign_type = None
        if 'Product' in df.columns:
            # Get unique values in the Product column
            product_values = df['Product'].unique()
            for product in product_values:
                if isinstance(product, str):
                    if 'sponsored products' in product.lower():
                        campaign_type = 'Sponsored Products'
                        break
                    elif 'sponsored brands' in product.lower():
                        campaign_type = 'Sponsored Brands'
                        break
        
        # If campaign type couldn't be determined from Product column, try to infer from sheet name
        if campaign_type is None:
            if 'product' in sheet_name.lower() or 'sp' in sheet_name.lower():
                campaign_type = 'Sponsored Products'
            elif 'brand' in sheet_name.lower() or 'sb' in sheet_name.lower():
                campaign_type = 'Sponsored Brands'
            else:
                campaign_type = 'Unknown'
                
        st.session_state.debug_messages.append(f"Campaign type for sheet {sheet_name}: {campaign_type}")
        
        # Create a copy of the dataframe with only the columns we need
        search_df = df.copy()
        
        # Add campaign type column if not already present
        if 'Campaign Type' not in search_df.columns:
            search_df['Campaign Type'] = campaign_type
            
        # Ensure required columns exist
        required_cols = ['Campaign', search_term_col, 'Target', 'Match Type', 'Impressions', 'Clicks', 'Spend', 'Orders', 'Sales']
        for col in required_cols:
            if col not in search_df.columns:
                search_df[col] = None
                
        # If we found a campaign column in the original data, use it to populate the Campaign column
        if campaign_col and campaign_col != 'Campaign':
            # Make sure to handle any NaN or empty values
            search_df['Campaign'] = df[campaign_col].fillna('')
            # Replace empty strings with None so we can detect them later
            search_df.loc[search_df['Campaign'] == '', 'Campaign'] = None
            st.session_state.debug_messages.append(f"[Search Term Performance] Populated Campaign column from {campaign_col}, found {search_df['Campaign'].notna().sum()} non-empty values")
                
        # Rename the search term column to a standard name
        search_df = search_df.rename(columns={search_term_col: 'Search Term'})
        
        # Helper function to safely convert values to float
        def safe_convert_to_float(val):
            if pd.isna(val):
                return 0.0
            try:
                # Remove any non-numeric characters except decimal point
                return float(str(val).replace('$', '').replace(',', '').replace('%', ''))
            except:
                return 0.0
                
        # Calculate metrics if possible
        if 'Clicks' in search_df.columns and 'Spend' in search_df.columns and search_df['Clicks'].sum() > 0:
            # Apply safe conversion to ensure numeric values
            spend_values = search_df['Spend'].apply(safe_convert_to_float)
            clicks_values = search_df['Clicks'].apply(safe_convert_to_float)
            search_df['CPC'] = spend_values / clicks_values.replace(0, float('nan'))
            # Replace NaN with 0
            search_df['CPC'] = search_df['CPC'].fillna(0)
        else:
            search_df['CPC'] = 0
            
        # Determine which sales column to use based on attribution choice
        sales_col = None
        if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and campaign_type == 'Sponsored Display':
            sales_col = 'Sales (Views & Clicks)' if 'Sales (Views & Clicks)' in search_df.columns else 'Sales'
        else:
            sales_col = 'Sales' if 'Sales' in search_df.columns else None
            
        # If we have a valid sales column, calculate ACoS and CVR
        if sales_col and 'Spend' in search_df.columns:
            # Create Ad Sales column for consistency with targeting performance
            search_df['Ad Sales'] = search_df[sales_col]
            
            # Apply safe conversion to numeric values
            spend_values = search_df['Spend'].apply(safe_convert_to_float)
            sales_values = search_df['Ad Sales'].apply(safe_convert_to_float)
            
            # Calculate ACoS
            search_df['ACoS'] = (spend_values / sales_values.replace(0, float('nan')) * 100).fillna(0)
            # Format ACoS as percentage with 2 decimal places
            search_df['ACoS'] = search_df['ACoS'].apply(lambda x: round(float(x), 2) if pd.notnull(x) else 0)
            
            # Calculate CVR (Conversion Rate)
            orders_values = search_df['Orders'].apply(safe_convert_to_float)
            clicks_values = search_df['Clicks'].apply(safe_convert_to_float)
            search_df['CVR'] = (orders_values / clicks_values.replace(0, float('nan')) * 100).fillna(0)
            # Format CVR as percentage with 2 decimal places
            search_df['CVR'] = search_df['CVR'].apply(lambda x: round(float(x), 2) if pd.notnull(x) else 0)
            
            # Calculate CTR (Click-Through Rate)
            clicks_values = search_df['Clicks'].apply(safe_convert_to_float)
            impressions_values = search_df['Impressions'].apply(safe_convert_to_float)
            search_df['CTR'] = (clicks_values / impressions_values.replace(0, float('nan')) * 100).fillna(0)
            # Format CTR as percentage with 2 decimal places
            search_df['CTR'] = search_df['CTR'].apply(lambda x: round(float(x), 2) if pd.notnull(x) else 0)
            
            # Calculate ROAS
            sales_values = search_df['Ad Sales'].apply(safe_convert_to_float)
            spend_values = search_df['Spend'].apply(safe_convert_to_float)
            search_df['ROAS'] = (sales_values / spend_values.replace(0, float('nan'))).fillna(0)
            # Format ROAS with 2 decimal places
            search_df['ROAS'] = search_df['ROAS'].apply(lambda x: round(float(x), 2) if pd.notnull(x) else 0)
            
            # Calculate AOV (Average Order Value)
            sales_values = search_df['Ad Sales'].apply(safe_convert_to_float)
            orders_values = search_df['Orders'].apply(safe_convert_to_float)
            search_df['AOV'] = (sales_values / orders_values.replace(0, float('nan'))).fillna(0)
            # Format AOV with 2 decimal places
            search_df['AOV'] = search_df['AOV'].apply(lambda x: round(float(x), 2) if pd.notnull(x) else 0)
            
            # Format CPC with 2 decimal places
            if 'CPC' in search_df.columns:
                search_df['CPC'] = search_df['CPC'].apply(lambda x: round(float(x), 2) if pd.notnull(x) else 0)
                
            # Ensure all numeric columns are properly formatted
            for col in ['Spend', 'Ad Sales', 'Orders', 'Impressions', 'Clicks']:
                if col in search_df.columns:
                    search_df[col] = search_df[col].apply(safe_convert_to_float)
            
            # Add product group information to search terms
            # Only populate if there are actually product groups defined in Campaign Tagging
            if 'Campaign' in search_df.columns:
                if campaign_product_groups:  # Only if there are product groups defined
                    search_df['Product Group'] = search_df['Campaign'].apply(
                        lambda campaign: campaign_product_groups.get(str(campaign).upper(), '') or 'Untagged Group' if pd.notna(campaign) else 'Untagged Group'
                    )
                else:
                    search_df['Product Group'] = 'Untagged Group'  # Use 'Untagged Group' if no product groups defined
        
        # Add to our collection
        search_term_data.append(search_df)
    
    # Process Sponsored Display targeting data and add it to search term data
    # This will map SD targeting data to the Search Terms data source
    sd_targeting_data = []
    for sheet_name, df in bulk_data.items():
        if not isinstance(df, pd.DataFrame) or df.empty:
            continue
            
        # Only process Sponsored Display sheets
        if 'sponsored display' not in sheet_name.lower() and 'sd' not in sheet_name.lower():
            continue
            
        st.session_state.debug_messages.append(f"Processing Sponsored Display targeting data from sheet: {sheet_name}")
        
        # Look for targeting expression column
        targeting_expression_col = None
        for col in df.columns:
            if col.lower() in ['targeting expression', 'product targeting expression']:
                targeting_expression_col = col
                st.session_state.debug_messages.append(f"[SD Search Term Performance] Found targeting column: {col}")
                break
                
        # Look for Campaign Name column - prioritize informational name over ID
        campaign_col = None
        # First, try to find 'Campaign Name (Informational Only)' specifically
        for col in df.columns:
            if col.lower() == 'campaign name (informational only)':
                campaign_col = col
                st.session_state.debug_messages.append(f"[SD Search Term Performance] Found informational campaign column: {col}")
                break
                
        # If not found, try 'Campaign Name'
        if not campaign_col:
            for col in df.columns:
                if col.lower() == 'campaign name':
                    campaign_col = col
                    st.session_state.debug_messages.append(f"[SD Search Term Performance] Found campaign name column: {col}")
                    break
                    
        # Last resort, use 'Campaign' column
        if not campaign_col:
            for col in df.columns:
                if col.lower() == 'campaign':
                    campaign_col = col
                    st.session_state.debug_messages.append(f"[SD Search Term Performance] Found campaign column: {col}")
                    break
        
        # Debug available columns
        st.session_state.debug_messages.append(f"[SD Search Term Performance] Available columns: {', '.join(df.columns)}")

                
        # Skip if no targeting expression column found
        if targeting_expression_col is None:
            continue
            
        # Filter for relevant entities (targeting)
        entity_col = next((c for c in df.columns if c.lower() == 'entity'), None)
        if entity_col:
            valid_entities = ['product targeting', 'product target', 'contextual targeting', 'audience targeting']
            entity_mask = df[entity_col].fillna('').astype(str).str.strip().str.lower().apply(
                lambda x: any(entity in x for entity in valid_entities)
            )
            state_col = next((c for c in df.columns if c.lower() == 'state'), None)
            df_filtered = df
            if state_col:
                df_filtered = df[entity_mask]
            else:
                df_filtered = df[entity_mask]
            
        # Process each row with targeting expression
        for _, row in df_filtered.iterrows():
            if pd.isna(row.get(targeting_expression_col)):
                continue
                
            target_expr = str(row.get(targeting_expression_col)).strip()
            
            # Skip empty targeting expressions
            if not target_expr:
                continue
                
            # Create a search term-like entry from the targeting expression
            sd_entry = {}
            
            # Set campaign
            campaign_value = row.get(campaign_col) if campaign_col else None
            
            # Try harder to find a campaign name
            if not (campaign_value and pd.notna(campaign_value) and str(campaign_value).strip() != ''):
                # Try alternative campaign columns
                for alt_col in df.columns:
                    if 'campaign' in alt_col.lower() and alt_col != campaign_col:
                        alt_value = row.get(alt_col)
                        if alt_value and pd.notna(alt_value) and str(alt_value).strip() != '':
                            campaign_value = alt_value
                            st.session_state.debug_messages.append(f"[SD Search Term Performance] Found campaign in alternate column: {alt_col}")
                            break
            
            if campaign_value and pd.notna(campaign_value) and str(campaign_value).strip() != '':
                sd_entry['Campaign'] = str(campaign_value).strip()
            else:
                # Log debug info if we're falling back to 'Unknown Campaign'
                st.session_state.debug_messages.append(
                    f"[SD Search Term Performance] Using 'Unknown Campaign' for targeting expression: {target_expr[:50]}..."
                )
                sd_entry['Campaign'] = 'Unknown Campaign'
                
            # Use targeting expression as the search term
            sd_entry['Search Term'] = target_expr
            sd_entry['Target'] = target_expr
            sd_entry['Campaign Type'] = 'Sponsored Display'
            
            # Extract match type if available
            match_type_col = next((c for c in df.columns if c.lower() == 'match type'), None)
            if match_type_col and pd.notna(row.get(match_type_col)):
                sd_entry['Match Type'] = row.get(match_type_col)
            else:
                # Determine match type based on targeting expression
                if 'exact-product' in target_expr.lower():
                    sd_entry['Match Type'] = 'Remarketing - Branded'
                elif 'views' in target_expr.lower() or 'purchases' in target_expr.lower():
                    sd_entry['Match Type'] = 'Remarketing'
                elif 'category=' in target_expr.lower():
                    sd_entry['Match Type'] = 'Category Target'
                else:
                    sd_entry['Match Type'] = 'Product Target'
            
            # Determine Target Type based on the specified logic
            targeting_type_col = next((c for c in df.columns if c.lower() == 'targeting type'), None)
            if targeting_type_col and pd.notna(row.get(targeting_type_col)) and str(row.get(targeting_type_col)).strip().lower() == 'auto':
                sd_entry['Target Type'] = 'Auto'
            elif 'retargeting' in str(sd_entry.get('Match Type', '')).lower():
                sd_entry['Target Type'] = 'Remarketing'
            elif 'remarketing' in str(sd_entry.get('Match Type', '')).lower():
                sd_entry['Target Type'] = 'Remarketing'
            elif 'category' in str(sd_entry.get('Match Type', '')).lower():
                sd_entry['Target Type'] = 'Category Targeting'
            else:
                sd_entry['Target Type'] = 'Product Targeting'
            
            # Extract performance metrics
            for metric in ['Impressions', 'Clicks', 'Spend', 'Orders']:
                metric_col = next((c for c in df.columns if c.lower() == metric.lower()), None)
                if metric_col and pd.notna(row.get(metric_col)):
                    try:
                        sd_entry[metric] = float(str(row.get(metric_col)).replace('$', '').replace(',', ''))
                    except:
                        sd_entry[metric] = 0
                else:
                    sd_entry[metric] = 0
            
            # Determine sales column based on attribution choice
            sales_col = None
            if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)":
                sales_patterns = ['Sales (Views & Clicks)', 'Total Sales (Views & Clicks)', 'Sales', 'Total Sales']
            else:
                sales_patterns = ['Sales', 'Total Sales', 'Sales (Views & Clicks)', 'Total Sales (Views & Clicks)']
                
            for pattern in sales_patterns:
                col = next((c for c in df.columns if c.lower() == pattern.lower()), None)
                if col and pd.notna(row.get(col)):
                    sales_col = col
                    break
                    
            if sales_col:
                try:
                    sd_entry['Ad Sales'] = float(str(row.get(sales_col)).replace('$', '').replace(',', ''))
                    sd_entry['Sales'] = sd_entry['Ad Sales']
                except:
                    sd_entry['Ad Sales'] = 0
                    sd_entry['Sales'] = 0
            else:
                sd_entry['Ad Sales'] = 0
                sd_entry['Sales'] = 0
                
            # Calculate derived metrics
            if sd_entry['Clicks'] > 0:
                sd_entry['CPC'] = sd_entry['Spend'] / sd_entry['Clicks']
            else:
                sd_entry['CPC'] = 0
                
            if sd_entry['Ad Sales'] > 0:
                sd_entry['ACoS'] = (sd_entry['Spend'] / sd_entry['Ad Sales']) * 100
                sd_entry['ROAS'] = sd_entry['Ad Sales'] / sd_entry['Spend'] if sd_entry['Spend'] > 0 else 0
            else:
                sd_entry['ACoS'] = 0
                sd_entry['ROAS'] = 0
                
            if sd_entry['Clicks'] > 0:
                sd_entry['CVR'] = (sd_entry['Orders'] / sd_entry['Clicks']) * 100
            else:
                sd_entry['CVR'] = 0
                
            if sd_entry['Impressions'] > 0:
                sd_entry['CTR'] = (sd_entry['Clicks'] / sd_entry['Impressions']) * 100
            else:
                sd_entry['CTR'] = 0
                
            if sd_entry['Orders'] > 0:
                sd_entry['AOV'] = sd_entry['Ad Sales'] / sd_entry['Orders']
            else:
                sd_entry['AOV'] = 0
                
            # Get product group for this campaign (case-insensitive lookup)
            # Only populate if there are actually product groups defined in Campaign Tagging
            campaign_name = sd_entry.get('Campaign', '')
            product_group = 'Untagged Group'  # Default to 'Untagged Group'
            if campaign_product_groups and campaign_name and campaign_name.upper() in campaign_product_groups:
                product_group = campaign_product_groups[campaign_name.upper()] or 'Untagged Group'
            
            # Add product group to the entry
            sd_entry['Product Group'] = product_group
            
            # Add to SD targeting data
            sd_targeting_data.append(sd_entry)
    
    if sd_targeting_data:
        st.session_state.debug_messages.append(f"Added {len(sd_targeting_data)} Sponsored Display targeting entries to search term data")
        # Convert to DataFrame and add to search term data
        sd_df = pd.DataFrame(sd_targeting_data)
        search_term_data.append(sd_df)
    
    # Combine all search term data
    if search_term_data:
        combined_df = pd.concat(search_term_data, ignore_index=True)
        st.session_state.debug_messages.append(f"Combined search term data: {len(combined_df)} rows")
        # Remove any exact duplicate rows across all columns
        before_dedup = len(combined_df)
        combined_df = combined_df.drop_duplicates()
        after_dedup = len(combined_df)
        st.session_state.debug_messages.append(f"Dropped {before_dedup - after_dedup} exact duplicate search term rows (now {after_dedup} rows)")
        
        # Remove duplicate Sponsored Display targets
        if "Campaign Type" in combined_df.columns:
            sd_mask = combined_df["Campaign Type"] == "Sponsored Display"
            if sd_mask.any():
                original_sd_count = sd_mask.sum()
                sd_deduplicated = combined_df[sd_mask].drop_duplicates()
                combined_df = pd.concat([
                    combined_df[~sd_mask],
                    sd_deduplicated
                ], ignore_index=True)
                new_sd_count = len(sd_deduplicated)
                st.session_state.debug_messages.append(f"Deduplicated Sponsored Display targets (ALL columns must match): {original_sd_count} -> {new_sd_count} (removed {original_sd_count - new_sd_count} duplicates)")
        
        # Sort by Ad Sales by default (descending)
        combined_df['Ad_Sales_Numeric'] = combined_df['Ad Sales'].replace('[$,]', '', regex=True).astype(float)
        combined_df = combined_df.sort_values(by='Ad_Sales_Numeric', ascending=False)
        combined_df = combined_df.drop(columns=['Ad_Sales_Numeric'])
        
        # Classify search terms as Branded or Non-Branded
        combined_df['Is_Branded'] = False  # Default to Non-Branded
        
        # Get branded terms and ASINs from client config if available
        branded_terms = []
        branded_asins = set()
        
        if client_config is not None:
            # Extract branded terms (case-insensitive) - check both key formats
            if 'Branded Terms' in client_config:
                if isinstance(client_config['Branded Terms'], list):
                    branded_terms = [str(term).strip().lower() for term in client_config['Branded Terms'] if str(term).strip()]
                elif isinstance(client_config['Branded Terms'], str):
                    branded_terms = [str(term).strip().lower() for term in client_config['Branded Terms'].split(',') if str(term).strip()]
            # Fallback to legacy key name if the new format isn't found
            elif 'branded_keywords' in client_config:
                branded_terms = [str(term).strip().lower() for term in client_config.get('branded_keywords', []) 
                                if str(term).strip()]
            
            # Extract branded ASINs (uppercase for consistency) - use correct data source
            branded_asins = set()
            
            # Primary source: branded_asins_data (current format)
            if 'branded_asins_data' in client_config:
                branded_asins_data = client_config.get('branded_asins_data', {})
                branded_asins = {str(asin).strip().upper() for asin in branded_asins_data.keys() if str(asin).strip()}
            # Fallback to old format for backward compatibility
            elif 'Branded ASINs' in client_config:
                if isinstance(client_config['Branded ASINs'], list):
                    branded_asins = {str(asin).strip().upper() for asin in client_config['Branded ASINs'] if str(asin).strip()}
                elif isinstance(client_config['Branded ASINs'], str):
                    branded_asins = {str(asin).strip().upper() for asin in client_config['Branded ASINs'].split(',') if str(asin).strip()}
            
            st.session_state.debug_messages.append(f"[Search Term Classification] Found {len(branded_terms)} branded terms and {len(branded_asins)} branded ASINs")
        
        # Compile regex for finding ASINs (starting with B0 and 10 characters long)
        asin_pattern = re.compile(r'(B[0-9A-Z]{9})', re.IGNORECASE)
        
        # Classify each search term (enhanced to check both search term and target)
        for idx, row in combined_df.iterrows():
            search_term = str(row['Search Term']).strip() if pd.notna(row['Search Term']) else ''
            target = str(row.get('Target', '')).strip() if pd.notna(row.get('Target')) else ''
            
            # Skip empty search terms
            if not search_term:
                continue
                
            is_branded = False
            
            # Check if the search term contains an ASIN
            asin_matches = asin_pattern.findall(search_term.upper())
            
            if asin_matches:
                # Check if any of the ASINs found are branded
                for asin in asin_matches:
                    if asin.upper() in branded_asins:
                        is_branded = True
                        st.session_state.debug_messages.append(f"[Search Term Classification] Term '{search_term}' classified as Branded (contains branded ASIN {asin})")
                        break
            
            # Also check if the target contains branded ASINs
            if not is_branded and target:
                target_asin_matches = asin_pattern.findall(target.upper())
                for asin in target_asin_matches:
                    if asin.upper() in branded_asins:
                        is_branded = True
                        st.session_state.debug_messages.append(f"[Search Term Classification] Term '{search_term}' classified as Branded (target '{target}' contains branded ASIN {asin})")
                        break
            
            # Check if the search term contains any branded terms
            if not is_branded:
                search_term_lower = search_term.lower()
                for term in branded_terms:
                    if term.lower() in search_term_lower:
                        is_branded = True
                        st.session_state.debug_messages.append(f"[Search Term Classification] Term '{search_term}' classified as Branded (contains branded term '{term}')")
                        break
            
            # Set the classification
            if is_branded:
                combined_df.at[idx, 'Is_Branded'] = True
        
        # --- COMPANION EXPORTS SPECIAL LOGIC FOR SEARCH TERMS ---
        # For Companion Exports, apply additional classification rules
        if st.session_state.get('is_companion_data', False):
            st.session_state.debug_messages.append("[Search Term Classification] Applying Companion Export special rules")
            companion_reclassified_count = 0
            
            for idx, row in combined_df.iterrows():
                search_term = str(row['Search Term']).strip() if pd.notna(row['Search Term']) else ''
                match_type = str(row.get('Match Type', '')).strip() if pd.notna(row.get('Match Type')) else ''
                
                # Skip empty search terms
                if not search_term:
                    continue
                
                # Rule 1: "Remarketing - Branded" Match Type should be considered Branded
                if match_type == 'Remarketing - Branded':
                    if not combined_df.at[idx, 'Is_Branded']:  # Only reclassify if not already branded
                        combined_df.at[idx, 'Is_Branded'] = True
                        companion_reclassified_count += 1
                        st.session_state.debug_messages.append(f"[Companion Export Search Term] Classified '{search_term}' as BRANDED due to Match Type 'Remarketing - Branded'")
                
                # Rule 2: Check Search Term for ASINs against Branded ASINs
                if not combined_df.at[idx, 'Is_Branded']:  # Only check if not already branded
                    asin_pattern_companion = re.compile(r'(B[0-9A-Z]{9})', re.IGNORECASE)
                    search_term_asins = set(asin_pattern_companion.findall(search_term.upper()))
                    
                    if search_term_asins:
                        # Check if any of the ASINs found are branded
                        branded_asins_found = search_term_asins.intersection(branded_asins)
                        if branded_asins_found:
                            combined_df.at[idx, 'Is_Branded'] = True
                            companion_reclassified_count += 1
                            st.session_state.debug_messages.append(f"[Companion Export Search Term] Classified '{search_term}' as BRANDED due to branded ASIN(s): {branded_asins_found}")
            
            if companion_reclassified_count > 0:
                st.session_state.debug_messages.append(f"[Companion Export Search Term] Reclassified {companion_reclassified_count} search terms as Branded")
        
        # Log classification results
        branded_count = combined_df['Is_Branded'].sum()
        non_branded_count = len(combined_df) - branded_count
        st.session_state.debug_messages.append(f"[Search Term Classification] Results: {branded_count} Branded terms, {non_branded_count} Non-Branded terms")
        
        # Update Target Type for Sponsored Display remarketing campaigns based on Is_Branded classification
        sd_remarketing_updates = 0
        if 'Campaign Type' in combined_df.columns and 'Target Type' in combined_df.columns:
            sd_remarketing_mask = (combined_df['Campaign Type'] == 'Sponsored Display') & (combined_df['Target Type'] == 'Remarketing')
            for idx in combined_df[sd_remarketing_mask].index:
                is_branded = combined_df.at[idx, 'Is_Branded']
                if is_branded:
                    combined_df.at[idx, 'Target Type'] = 'Remarketing - Branded'
                    combined_df.at[idx, 'Match Type'] = 'Remarketing - Branded'
                else:
                    combined_df.at[idx, 'Target Type'] = 'Remarketing - Competitor'
                    combined_df.at[idx, 'Match Type'] = 'Remarketing - Competitor'
                sd_remarketing_updates += 1
        
        if sd_remarketing_updates > 0:
            st.session_state.debug_messages.append(f"[Sponsored Display Remarketing] Updated {sd_remarketing_updates} remarketing campaigns with branded/competitor classification")
        
        # Match with targeting data to populate Target and Match Type
        if targeting_data is not None:
            st.session_state.debug_messages.append(f"Attempting to match search terms with targeting data")
            
            # Create a mapping from Campaign + Target to Match Type
            campaign_target_to_match_type = {}
            campaign_to_targets = {}
            
            for _, row in targeting_data.iterrows():
                campaign = str(row['Campaign']).strip() if pd.notna(row['Campaign']) else ''
                target = str(row['Target']).strip() if pd.notna(row['Target']) else ''
                match_type = str(row['Match Type']).strip() if pd.notna(row['Match Type']) else ''
                target_type = str(row['Target Type']).strip() if pd.notna(row['Target Type']) else ''
                
                # Store the match type for this campaign + target combination
                campaign_target_to_match_type[(campaign, target)] = (match_type, target_type)
                
                # Also store all targets for each campaign for fuzzy matching
                if campaign not in campaign_to_targets:
                    campaign_to_targets[campaign] = []
                campaign_to_targets[campaign].append((target, match_type, target_type))
            
            # Function to find the best target match for a search term within a campaign
            def find_best_target_match(campaign, search_term):
                if campaign in campaign_to_targets:
                    targets = campaign_to_targets[campaign]
                    
                    # First try exact match
                    for target, match_type, target_type in targets:
                        if target.lower() == search_term.lower():
                            return target, match_type, target_type
                    
                    # Then try contains match for broad match keywords
                    for target, match_type, target_type in targets:
                        if target_type.lower() == 'keyword' and match_type.lower() == 'broad' and search_term.lower() in target.lower():
                            return target, match_type, target_type
                    
                    # Then try contains match for phrase match keywords
                    for target, match_type, target_type in targets:
                        if target_type.lower() == 'keyword' and match_type.lower() == 'phrase' and search_term.lower() in target.lower():
                            return target, match_type, target_type
                    
                    # If no match found, return the first target for this campaign
                    if targets:
                        return targets[0]
                
                return None, None, None
            
            # Apply the matching to populate Target and Match Type
            matched_count = 0
            for idx, row in combined_df.iterrows():
                campaign = str(row['Campaign']).strip() if pd.notna(row['Campaign']) else ''
                search_term = str(row['Search Term']).strip() if pd.notna(row['Search Term']) else ''
                current_target = str(row['Target']).strip() if pd.notna(row['Target']) else ''
                
                # If we already have a target, try to find its match type directly
                if current_target and campaign:
                    if (campaign, current_target) in campaign_target_to_match_type:
                        match_type, target_type = campaign_target_to_match_type[(campaign, current_target)]
                        combined_df.at[idx, 'Match Type'] = match_type
                        combined_df.at[idx, 'Target Type'] = target_type
                        matched_count += 1
                        continue
                
                # Otherwise try to find the best target match for this search term
                target, match_type, target_type = find_best_target_match(campaign, search_term)
                
                if target is not None:
                    if not current_target or current_target == 'None':
                        combined_df.at[idx, 'Target'] = target
                    combined_df.at[idx, 'Match Type'] = match_type
                    combined_df.at[idx, 'Target Type'] = target_type
                    matched_count += 1
            
            st.session_state.debug_messages.append(f"Matched {matched_count} search terms with targeting data")
        
        # Apply universal auto targeting cleanup to all search term data
        st.session_state.debug_messages.append("Applying universal auto targeting cleanup to search term data")
        cleanup_count = 0
        
        for idx, row in combined_df.iterrows():
            target = str(row.get('Target', '')).strip() if pd.notna(row.get('Target')) else ''
            campaign = str(row.get('Campaign', '')).strip() if pd.notna(row.get('Campaign')) else ''
            
            if target:
                original_target = target
                cleaned_target = target
                
                # Detect campaign type from campaign name
                campaign_type = 'SP'  # Default
                if 'SB' in campaign.upper() or 'SPONSORED BRAND' in campaign.upper():
                    campaign_type = 'SB'
                elif 'SD' in campaign.upper() or 'SPONSORED DISPLAY' in campaign.upper():
                    campaign_type = 'SD'
                
                # Handle JSON format targeting expressions first
                if target.startswith('[{') and target.endswith('}]'):
                    try:
                        import json
                        parsed = json.loads(target)
                        if isinstance(parsed, list) and len(parsed) > 0 and isinstance(parsed[0], dict):
                            target_type = parsed[0].get('type', '')
                            target_value = parsed[0].get('value', '')
                            
                            # Auto targeting cleanup
                            if target_type in ['queryBroadRelMatches', 'queryHighRelMatches', 'asinSubstituteRelated', 'asinAccessoryRelated']:
                                if target_type == 'queryBroadRelMatches':
                                    cleaned_target = 'Auto - Loose Match'
                                elif target_type == 'queryHighRelMatches':
                                    cleaned_target = 'Auto - Close Match'
                                elif target_type == 'asinSubstituteRelated':
                                    cleaned_target = 'Auto - Substitute'
                                elif target_type == 'asinAccessoryRelated':
                                    cleaned_target = 'Auto - Compliments'
                                
                                # Update Match Type and Target Type for auto targets
                                combined_df.at[idx, 'Match Type'] = 'Auto'
                                combined_df.at[idx, 'Target Type'] = 'Auto'
                            
                            # ASIN targeting cleanup
                            elif target_type == 'asinSameAs' and target_value:
                                if 'expanded' in target.lower():
                                    cleaned_target = f'ASIN-Expanded = {target_value}'
                                else:
                                    cleaned_target = f'ASIN = {target_value}'
                            
                            # Category targeting cleanup
                            elif target_type == 'asinCategorySameAs' and target_value:
                                cleaned_target = f'{campaign_type} Category Targeting'
                            
                            # Other JSON types - extract value if available
                            elif target_value:
                                cleaned_target = target_value
                                
                    except Exception as e:
                        # If JSON parsing fails, continue with original logic
                        st.session_state.debug_messages.append(f"[Search Term Performance] JSON parsing failed for target: {target[:50]}... Error: {e}")
                        pass
                
                # Handle non-JSON format targeting expressions
                else:
                    # Auto targeting cleanup for simple strings
                    if target in ['queryBroadRelMatches', 'queryHighRelMatches', 'asinSubstituteRelated', 'asinAccessoryRelated']:
                        if target == 'queryBroadRelMatches':
                            cleaned_target = 'Auto - Loose Match'
                        elif target == 'queryHighRelMatches':
                            cleaned_target = 'Auto - Close Match'
                        elif target == 'asinSubstituteRelated':
                            cleaned_target = 'Auto - Substitute'
                        elif target == 'asinAccessoryRelated':
                            cleaned_target = 'Auto - Compliments'
                        
                        # Update Match Type and Target Type for auto targets
                        combined_df.at[idx, 'Match Type'] = 'Auto'
                        combined_df.at[idx, 'Target Type'] = 'Auto'
                    
                    # ASIN detection and formatting for non-JSON format
                    elif 'asinSameAs' in target or 'asinsameas' in target.lower():
                        asin_pattern = re.compile(r'B0[A-Z0-9]{8}', re.IGNORECASE)  # Case-insensitive ASIN pattern
                        search_term = str(row.get('Search Term', '')).strip() if pd.notna(row.get('Search Term')) else ''
                        
                        # Try to find ASIN in search term first, then in target
                        asin_match = asin_pattern.search(search_term) or asin_pattern.search(target)
                        
                        if asin_match:
                            asin = asin_match.group().upper()  # Convert to uppercase for consistency
                            if 'expanded' in target.lower():
                                cleaned_target = f'ASIN-Expanded = {asin}'
                            else:
                                cleaned_target = f'ASIN = {asin}'
                        else:
                            # Enhanced fallback - try to extract any ASIN-like pattern from search term
                            # Look for patterns like b0xxxxxxxx (10 chars starting with b0)
                            fallback_pattern = re.compile(r'b0[a-z0-9]{8}', re.IGNORECASE)
                            fallback_match = fallback_pattern.search(search_term)
                            
                            if fallback_match:
                                asin = fallback_match.group().upper()
                                if 'expanded' in target.lower():
                                    cleaned_target = f'ASIN-Expanded = {asin}'
                                else:
                                    cleaned_target = f'ASIN = {asin}'
                            else:
                                # Final fallback if no ASIN found
                                if 'expanded' in target.lower():
                                    cleaned_target = 'ASIN-Expanded Target'
                                else:
                                    cleaned_target = 'ASIN Target'
                    
                    # Category targeting (campaign-specific)
                    elif 'category=' in target.lower() or 'categorysameas' in target.lower():
                        cleaned_target = f'{campaign_type} Category Targeting'
                
                # SD-specific remarketing logic (applies to both JSON and non-JSON)
                if campaign_type == 'SD':
                    if 'views' in target.lower() or 'purchases' in target.lower():
                        # Extract lookback days if present
                        days_match = re.search(r'(\d+)', target)
                        if days_match:
                            days = days_match.group(1)
                            if 'views' in target.lower():
                                cleaned_target = f'Views Remarketing - {days}d'
                            elif 'purchases' in target.lower():
                                cleaned_target = f'Purchases Remarketing - {days}d'
                        else:
                            if 'views' in target.lower():
                                cleaned_target = 'Views Remarketing'
                            elif 'purchases' in target.lower():
                                cleaned_target = 'Purchases Remarketing'
                
                # Update the target if it was cleaned
                if cleaned_target != original_target:
                    combined_df.at[idx, 'Target'] = cleaned_target
                    cleanup_count += 1
        
        if cleanup_count > 0:
            st.session_state.debug_messages.append(f"Cleaned up {cleanup_count} auto targeting expressions in search term data")
        
        return combined_df
    else:
        st.session_state.debug_messages.append("No search term data found in bulk file")
        return pd.DataFrame()
        
@st.cache_data(ttl=3600, show_spinner="Generating word cloud...")  # Cache for 1 hour
def generate_search_term_wordcloud(search_terms_df, filter_type='all', remove_asins=False):
    """
    Generates a word cloud visualization from search term data.
    
    Args:
        search_terms_df: DataFrame containing search term data with 'Search Term' and 'Is_Branded' columns
        filter_type: 'all', 'branded', or 'non-branded' to filter the search terms
        remove_asins: If True, removes terms that appear to be ASINs (start with B0 and are 10 chars long)
        
    Returns:
        matplotlib figure with the word cloud visualization
    """
    if search_terms_df is None or search_terms_df.empty or 'Search Term' not in search_terms_df.columns:
        # Create an empty figure with a message
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.text(0.5, 0.5, "No search term data available", 
                horizontalalignment='center', verticalalignment='center', fontsize=14)
        ax.axis('off')
        return fig
    
    # Filter data based on type
    if filter_type == 'branded' and 'Is_Branded' in search_terms_df.columns:
        filtered_df = search_terms_df[search_terms_df['Is_Branded'] == True].copy()
        title = 'Branded Search Terms'
    elif filter_type == 'non-branded' and 'Is_Branded' in search_terms_df.columns:
        filtered_df = search_terms_df[search_terms_df['Is_Branded'] == False].copy()
        title = 'Non-Branded Search Terms'
    else:
        filtered_df = search_terms_df.copy()
        title = 'All Search Terms'
    
    if filtered_df.empty:
        # Create an empty figure with a message
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.text(0.5, 0.5, f"No {filter_type.replace('-', ' ')} search terms found", 
                horizontalalignment='center', verticalalignment='center', fontsize=14)
        ax.axis('off')
        return fig
    
    # Prepare the text data
    if 'Spend' in filtered_df.columns and 'Clicks' in filtered_df.columns:
        # Weight by spend or clicks to emphasize important terms
        # Use spend by default, fall back to clicks if any terms have zero spend
        if filtered_df['Spend'].sum() > 0:
            weighted_terms = {}
            for _, row in filtered_df.iterrows():
                if pd.notna(row['Search Term']) and row['Search Term'] != '':
                    term = str(row['Search Term']).lower()
                    # Skip ASINs if remove_asins is True
                    if remove_asins and len(term) == 10 and term.startswith('b0'):
                        continue
                    weight = float(row['Spend']) if pd.notna(row['Spend']) else 0
                    weighted_terms[term] = weighted_terms.get(term, 0) + weight
        else:
            weighted_terms = {}
            for _, row in filtered_df.iterrows():
                if pd.notna(row['Search Term']) and row['Search Term'] != '':
                    term = str(row['Search Term']).lower()
                    # Skip ASINs if remove_asins is True
                    if remove_asins and len(term) == 10 and term.startswith('b0'):
                        continue
                    weight = float(row['Clicks']) if pd.notna(row['Clicks']) else 0
                    weighted_terms[term] = weighted_terms.get(term, 0) + weight
    else:
        # If no weight columns, just count frequency
        weighted_terms = {}
        for _, row in filtered_df.iterrows():
            if pd.notna(row['Search Term']) and row['Search Term'] != '':
                term = str(row['Search Term']).lower()
                # Skip ASINs if remove_asins is True
                if remove_asins and len(term) == 10 and term.startswith('b0'):
                    continue
                weighted_terms[term] = weighted_terms.get(term, 0) + 1
    
    if not weighted_terms:
        # Create an empty figure with a message
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.text(0.5, 0.5, f"No valid {filter_type.replace('-', ' ')} search terms found", 
                horizontalalignment='center', verticalalignment='center', fontsize=14)
        ax.axis('off')
        return fig
    
    # Create a set of stopwords (common words to exclude)
    stopwords = set(STOPWORDS)
    stopwords.update(['amazon', 'com', 'www'])  # Add custom stopwords if needed
    
    # Generate the word cloud with bright colors (similar to target word cloud)
    wordcloud = WordCloud(
        width=800, 
        height=400,
        background_color='#181818',  # Dark background to match the target word cloud
        colormap='summer',  # Bright yellow/green colors, similar to target word cloud
        stopwords=stopwords,
        max_words=100,
        collocations=False,  # Avoid repeated word pairs
        contour_width=2,
        contour_color='#bfa23a'  # Gold border like the target word cloud
    ).generate_from_frequencies(weighted_terms)
    
    # Create a figure and display the word cloud
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.set_title(title, fontsize=16, color='white')
    ax.axis('off')
    fig.tight_layout(pad=0)
    
    # Set figure background to match the target word cloud
    fig.patch.set_facecolor('#181818')
    
    return fig

@st.cache_data(ttl=3600, show_spinner="Processing campaign performance data...", hash_funcs={"_thread.RLock": lambda _: None})
def get_campaign_performance_data(bulk_data, client_config=None):
    """
    Extracts and processes campaign-level performance data from bulk advertising files.
    Only processes rows where Entity="Campaign" (case-insensitive) and excludes Portfolio and RAS sheets.
    
    Args:
        bulk_data: Dictionary containing bulk file data
        client_config: Configuration data including campaign tags
        
    Returns:
        DataFrame with campaign performance metrics
    """
    if not bulk_data or not isinstance(bulk_data, dict):
        return pd.DataFrame()
    
    st.session_state.debug_messages.append(f"Starting Campaign Performance data extraction")
    
    campaign_data = []
    
    # Helper function to safely convert values to float
    def safe_convert_to_float(val):
        if pd.isna(val):
            return 0.0
        try:
            return float(str(val).replace('$', '').replace(',', '').replace('%', ''))
        except:
            return 0.0
    
    # Helper function to find column case-insensitively
    def find_column(df, column_names):
        df_columns_lower = [col.lower() for col in df.columns]
        for name in column_names:
            for i, col_lower in enumerate(df_columns_lower):
                if col_lower == name.lower():
                    return df.columns[i]
        return None
    
    # Process each sheet in bulk data
    for sheet_name, df in bulk_data.items():
        if not isinstance(df, pd.DataFrame) or df.empty:
            continue
        
        # Skip Portfolio and RAS sheets as requested
        if any(exclude_sheet.lower() in sheet_name.lower() for exclude_sheet in ['Portfolio', 'RAS']):
            st.session_state.debug_messages.append(f"Skipping sheet {sheet_name} - Portfolio or RAS sheet")
            continue
        
        
        # Skip original SB Multi Ad Group Campaigns sheet to prevent double counting
        # (it's already been processed and stored as 'Sponsored Brands Campaigns')
        if sheet_name.lower() == 'sb multi ad group campaigns':
            st.session_state.debug_messages.append(f"Skipping sheet {sheet_name} - data already processed as 'Sponsored Brands Campaigns' to prevent double counting")
            continue

        # For Companion data, skip ASIN and Search Term reports to avoid double counting
        # Only process Campaign sheets for campaign performance
        if st.session_state.get('is_companion_data', False):
            if ('ASIN' in sheet_name and 'Campaign' not in sheet_name) or                ('Search Term' in sheet_name and 'Campaign' not in sheet_name):
                st.session_state.debug_messages.append(f"Skipping sheet {sheet_name} - Companion ASIN/Search Term report (avoiding double count)")
                continue
        
        # Find Entity column and filter for Campaign rows only
        entity_col = find_column(df, ['Entity'])
        if not entity_col:
            st.session_state.debug_messages.append(f"Skipping sheet {sheet_name} - no Entity column found")
            continue
        
        # Filter for rows where Entity equals "Campaign" (case-insensitive)
        entity_mask = df[entity_col].fillna('').astype(str).str.strip().str.lower() == 'campaign'
        campaign_rows = df[entity_mask]
        
        if campaign_rows.empty:
            st.session_state.debug_messages.append(f"Skipping sheet {sheet_name} - no Campaign entities found")
            continue
        
        st.session_state.debug_messages.append(f"Sheet {sheet_name}: Found {len(campaign_rows)} Campaign entity rows out of {len(df)} total rows")
        
        # Find required columns - now using campaign_rows instead of df
        campaign_col = find_column(campaign_rows, ['Campaign Name (Informational Only)', 'Campaign Name', 'Campaign'])
        product_col = find_column(campaign_rows, ['Product'])
        spend_col = find_column(campaign_rows, ['Spend'])
        clicks_col = find_column(campaign_rows, ['Clicks'])
        orders_col = find_column(campaign_rows, ['Orders'])
        campaign_state_col = find_column(campaign_rows, ['Campaign State (Informational Only)', 'Campaign State'])
        
        # Determine sales column based on attribution choice and product type
        sales_col = None
        if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)":
            # Check if this is a Sponsored Display sheet
            is_sponsored_display = False
            if product_col and not campaign_rows[product_col].empty:
                product_values = campaign_rows[product_col].dropna().unique()
                for product in product_values:
                    if isinstance(product, str) and 'sponsored display' in product.lower():
                        is_sponsored_display = True
                        break
            
            if is_sponsored_display:
                sales_col = find_column(campaign_rows, ['Sales (Views & Clicks)', 'Sales'])
            else:
                sales_col = find_column(campaign_rows, ['Sales'])
        else:
            sales_col = find_column(campaign_rows, ['Sales'])
        
        if not campaign_col or not sales_col or not spend_col:
            st.session_state.debug_messages.append(f"Skipping sheet {sheet_name} - missing required columns (Campaign: {campaign_col}, Sales: {sales_col}, Spend: {spend_col})")
            continue
        
        # Determine ad type from Product column
        ad_type = 'Unknown'
        if product_col and not campaign_rows[product_col].empty:
            product_values = campaign_rows[product_col].dropna().unique()
            for product in product_values:
                if isinstance(product, str):
                    if 'sponsored products' in product.lower():
                        ad_type = 'SP'
                        break
                    elif 'sponsored brands' in product.lower():
                        ad_type = 'SB'
                        break
                    elif 'sponsored display' in product.lower():
                        ad_type = 'SD'
                        break
        
        st.session_state.debug_messages.append(f"Processing sheet {sheet_name} - Ad Type: {ad_type}, Campaign rows: {len(campaign_rows)}")
        
        # Process each campaign row in the sheet
        for _, row in campaign_rows.iterrows():
            campaign_name = str(row[campaign_col]).strip() if pd.notna(row[campaign_col]) else ''
            if not campaign_name:
                continue
            
            # Extract metrics
            spend = safe_convert_to_float(row[spend_col]) if spend_col else 0
            ad_sales = safe_convert_to_float(row[sales_col]) if sales_col else 0
            clicks = safe_convert_to_float(row[clicks_col]) if clicks_col else 0
            orders = safe_convert_to_float(row[orders_col]) if orders_col else 0
            
            # Calculate derived metrics
            acos = (spend / ad_sales * 100) if ad_sales > 0 else 0
            roas = (ad_sales / spend) if spend > 0 else 0
            cpc = (spend / clicks) if clicks > 0 else 0
            cvr = (orders / clicks * 100) if clicks > 0 else 0
            aov = (ad_sales / orders) if orders > 0 else 0
            
            # Get product group from campaign tagging
            product_group = ''
            if client_config and 'campaign_tags_data' in client_config:
                campaign_info = client_config['campaign_tags_data'].get(campaign_name, {})
                product_group = campaign_info.get('tag_1', '') or 'Untagged Group'
            if not product_group:
                product_group = 'Untagged Group'
            
            campaign_data.append({
                'Ad Type': ad_type,
                'Product Group': product_group,
                'Campaign': campaign_name,
                'Spend': spend,
                'Ad Sales': ad_sales,
                'ACoS': acos,
                'ROAS': roas,
                'CPC': cpc,
                'CVR': cvr,
                'AOV': aov,
                'Clicks': clicks,
                'Orders': orders
            })
    
    if not campaign_data:
        st.session_state.debug_messages.append("No campaign performance data found")
        return pd.DataFrame()
    
    # Create DataFrame and aggregate by campaign (in case there are multiple rows per campaign across different sheets)
    df = pd.DataFrame(campaign_data)
    
    # Group by Campaign, Ad Type, and Product Group, summing metrics
    groupby_cols = ['Campaign', 'Ad Type', 'Product Group']
    agg_dict = {
        'Spend': 'sum',
        'Ad Sales': 'sum',
        'Clicks': 'sum',
        'Orders': 'sum'
    }
    
    grouped_df = df.groupby(groupby_cols, as_index=False).agg(agg_dict)
    
    # Recalculate derived metrics after aggregation
    grouped_df['ACoS'] = grouped_df.apply(
        lambda row: (row['Spend'] / row['Ad Sales'] * 100) if row['Ad Sales'] > 0 else 0, axis=1
    )
    grouped_df['ROAS'] = grouped_df.apply(
        lambda row: (row['Ad Sales'] / row['Spend']) if row['Spend'] > 0 else 0, axis=1
    )
    grouped_df['CPC'] = grouped_df.apply(
        lambda row: (row['Spend'] / row['Clicks']) if row['Clicks'] > 0 else 0, axis=1
    )
    grouped_df['CVR'] = grouped_df.apply(
        lambda row: (row['Orders'] / row['Clicks'] * 100) if row['Clicks'] > 0 else 0, axis=1
    )
    grouped_df['AOV'] = grouped_df.apply(
        lambda row: (row['Ad Sales'] / row['Orders']) if row['Orders'] > 0 else 0, axis=1
        )
    # Calculate percentage columns
    total_spend = grouped_df['Spend'].sum()
    total_ad_sales = grouped_df['Ad Sales'].sum()
    
    grouped_df['% Ad Spend'] = grouped_df.apply(
        lambda row: (row['Spend'] / total_spend * 100) if total_spend > 0 else 0, axis=1
    )
    grouped_df['% Ad Sales'] = grouped_df.apply(
        lambda row: (row['Ad Sales'] / total_ad_sales * 100) if total_ad_sales > 0 else 0, axis=1
    )
    
    st.session_state.debug_messages.append(f"Campaign Performance: Generated {len(grouped_df)} campaign records")
    
    return grouped_df 

# --- UI Functions ---
# --- Main App Logic ---

# Page config has been moved to the top of the file

# Load and display the main logo

# Load and display the main logo
def display_logo():
    logo_path = "assets/hand_logo.png"
    if os.path.exists(logo_path):
        logo = Image.open(logo_path)
        return logo
    else:
        st.error(f"Logo file not found at {logo_path}")
        return None

# Custom CSS to implement a dark charcoal gray theme that's compatible with charts
custom_css = """
<style>
/* Import professional fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

/* Base theme elements */
.stApp {
background-color: #1E1E1E;
font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
}

/* Custom styled message boxes */
.success-box {
    background-color: rgba(38, 166, 91, 0.15);
    border-left: 4px solid #26a65b;
    padding: 10px 15px;
    border-radius: 4px;
    margin: 10px 0;
    color: #e0e0e0;
}

.info-box {
    background-color: rgba(52, 152, 219, 0.15);
    border-left: 4px solid #3498db;
    padding: 10px 15px;
    border-radius: 4px;
    margin: 10px 0;
    color: #e0e0e0;
}

.warning-box {
    background-color: rgba(241, 196, 15, 0.15);
    border-left: 4px solid #f1c40f;
    padding: 10px 15px;
    border-radius: 4px;
    margin: 10px 0;
    color: #e0e0e0;
}

/* Typography for headings and text */
h1, h2, h3, h4, h5, h6 {
font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif !important;
font-weight: 600 !important;
letter-spacing: -0.01em !important;
color: #FFFFFF !important;
}

/* HERO TITLE (main dashboard title) */
.dashboard-hero-title {
font-weight: 800 !important;
color: #F0F0F0 !important;
font-size: 2.8rem !important;
margin-top: 1.5rem !important;
margin-bottom: 2.5rem !important;
letter-spacing: -0.02em !important;
text-shadow: 0 2px 8px rgba(0,0,0,0.15);
display: inline-block;
vertical-align: middle;
}
.dashboard-hero-title .client-name {
    font-weight: 900 !important;
    color: #2563eb !important;
    font-size: 3.2rem !important;
    letter-spacing: -0.03em !important;
    text-shadow: 0 2px 12px #10204055, 0 0px 2px #2563eb55;
}
.dashboard-hero-title {
    font-weight: 800 !important;
    color: #fff !important;
    font-size: 2.7rem !important;
    letter-spacing: -0.02em !important;
    text-shadow: 0 2px 12px #08080855, 0 0px 2px #2563eb33;
    display: inline-block;
    vertical-align: middle;
}
/* Header container for title and logo */
.header-container {
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 1.0rem !important;
    animation: fadeInHeader 0.7s cubic-bezier(.4,2,.6,1);
}
@keyframes fadeInHeader {
    0% { opacity: 0; transform: translateY(-30px); }
    100% { opacity: 1; transform: translateY(0); }
}
/* Logo styling in header */
.header-logo {
    max-height: 80px;
    float: right;
    filter: drop-shadow(0 2px 8px rgba(40,40,40,0.45));
    transition: transform 0.2s cubic-bezier(.4,2,.6,1);
}
.header-logo:hover {
    transform: scale(1.04) rotate(-2deg);
}
/* Thin blue divider below header */
.header-divider {
    width: 100%;
    height: 3px;
    background: linear-gradient(90deg, #2563eb 30%, #60a5fa 100%);
    border: none;
    margin: 0 0 1.2rem 0;
    opacity: 0.95;
    border-radius: 2px;
}
/* Section headers for main areas */
.main-section-header {
    background: linear-gradient(90deg, #f7d774 0%, #bfa23a 80%, #fffbe7 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
    text-fill-color: transparent;
    font-size: 2.2rem !important;
    font-weight: 900 !important;
    letter-spacing: 0.04em !important;
    text-shadow: 0 2px 8px rgba(191,162,58,0.10), 0 1px 1px #00000033;

font-size: 2.1rem !important;
font-weight: 800 !important;
color: #BFA23A !important;
margin-top: 2.8rem !important;
margin-bottom: 1.4rem !important;
letter-spacing: -0.01em !important;
text-shadow: 0 2px 8px rgba(0,0,0,0.10);
display: block;
}
/* Increase spacing between dashboard sections */
.dashboard-section {
margin-top: 2.8rem !important;
margin-bottom: 2.0rem !important;
padding-top: 0.5rem !important;
padding-bottom: 0.5rem !important;
}
/* Add extra spacing after navigation and attribution */
.stButton, .attribution {
    margin-bottom: 1rem;
}

/* Navigation bar styling */
.audit-nav-container {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    z-index: 9999;
    background-color: rgba(30, 30, 30, 0.95);
    padding: 12px 16px;
    margin-bottom: 20px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5);
    display: flex;
    flex-wrap: wrap;
    gap: 12px;
    align-items: center;
    justify-content: flex-start;
    backdrop-filter: blur(10px);
    -webkit-backdrop-filter: blur(10px);
    border-bottom: 1px solid rgba(255, 215, 0, 0.2);
    width: 100%;
    max-width: 100%;
    overflow-x: auto;
    white-space: nowrap;
}

/* Add padding to the top of the main content to account for fixed navbar */
.main .block-container {
    padding-top: 70px !important;
}

/* Fix for Streamlit's sidebar and main content layout */
.stApp {
    overflow-x: hidden;
}

/* Ensure the nav bar stays on top of all Streamlit elements */
.stApp > header {
    z-index: 998;
}

/* Add some space above the first section header */
.dashboard-section:first-of-type {
    margin-top: 20px;
}

.audit-nav-link {
    color: #cccccc;
    text-decoration: none;
    padding: 8px 14px;
    border-radius: 6px;
    font-size: 15px;
    font-weight: 500;
    transition: all 0.2s ease;
    white-space: nowrap;
    letter-spacing: 0.02em;
    border: 1px solid transparent;
}

.audit-nav-link:hover {
    background-color: #333333;
    color: #ffd700;
    transform: translateY(-2px);
    border: 1px solid rgba(255, 215, 0, 0.3);
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
}

/* Active class disabled per user request */
/*.audit-nav-link.active {
    background-color: rgba(255, 215, 0, 0.15);
    color: #ffd700;
    border: 1px solid rgba(255, 215, 0, 0.3);
    font-weight: 600;
}*/

/* Section anchor styling */
.section-anchor {
    display: block;
    position: relative;
    top: -100px;
    visibility: hidden;
}

/* Table filter dropdown styling */
.stDataFrame [data-testid="column-actions-menu"],
.st-df [data-testid="column-actions-menu"] {
    background-color: #f8f9fa !important;
    border-radius: 6px !important;
    border: 1px solid #e9ecef !important;
    box-shadow: 0 4px 15px rgba(0,0,0,0.1) !important;
}

/* Menu items inside the dropdown */
.stDataFrame [data-testid="column-actions-menu"] button,
.st-df [data-testid="column-actions-menu"] button {
    color: #495057 !important;
    font-size: 0.85rem !important;
    padding: 8px 12px !important;
    border-radius: 4px !important;
    margin: 2px 0 !important;
    transition: background-color 0.2s ease !important;
}

/* Hover effect for menu items */
.stDataFrame [data-testid="column-actions-menu"] button:hover,
.st-df [data-testid="column-actions-menu"] button:hover {
    background-color: #e9ecef !important;
    color: #2563eb !important;
}

/* Header row styling for better filter button appearance */
.stDataFrame th button,
.st-df th button {
    border: none !important;
    background: transparent !important;
}

/* Filter button icon color */
.stDataFrame th [data-testid="StyledIcon"],
.st-df th [data-testid="StyledIcon"] {
    color: #6c757d !important;
}

/* Default Streamlit headings (for reference, not used for main sections) */
h1 {
font-size: 1.8rem !important;
letter-spacing: -0.02em !important;
margin-bottom: 1rem !important;
}
h2 {
font-size: 1.5rem !important;
letter-spacing: -0.015em !important;
margin-top: 1.5rem !important;
margin-bottom: 0.75rem !important;
}
h3 {
font-size: 1.3rem !important;
margin-top: 1.2rem !important;
margin-bottom: 0.6rem !important;
}
p, div, span, li {
font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif !important;
font-weight: 400 !important;
font-size: 1rem !important;
line-height: 1.5 !important;
}
/* Section headers styling */
.main .block-container h1, .main .block-container h2 {
padding-bottom: 0.3rem !important;
border-bottom: 1px solid rgba(255, 255, 255, 0.1) !important;
}

/* Dataframe and table styling */
.stDataFrame, .dataframe, .st-df {
    border: none !important;
    box-shadow: 0 4px 12px rgba(0,0,0,0.08) !important;
    border-radius: 8px !important;
    overflow: hidden !important;
    background-color: #2C2C2C !important;
    color: #F0F0F0 !important;
    font-family: 'Inter', sans-serif !important;
}

.stDataFrame th {
    background-color: #333333 !important;
    color: #FFFFFF !important;
    font-weight: 600 !important;
    padding: 0.75rem 1rem !important;
    font-size: 0.9rem !important;
    letter-spacing: 0.01em !important;
    text-transform: uppercase !important;
    font-variant: small-caps !important;
}

/* Table filter dropdown styling */
.stDataFrame [data-testid="column-actions-menu"],
.st-df [data-testid="column-actions-menu"] {
    background-color: #3a3a3a !important;
    border-radius: 6px !important;
    border: 1px solid #4a4a4a !important;
    box-shadow: 0 4px 15px rgba(0,0,0,0.3) !important;
}

/* Menu items inside the dropdown */
.stDataFrame [data-testid="column-actions-menu"] button,
.st-df [data-testid="column-actions-menu"] button {
    color: #e0e0e0 !important;
    font-size: 0.85rem !important;
    padding: 8px 12px !important;
    border-radius: 4px !important;
    margin: 2px 0 !important;
    transition: background-color 0.2s ease !important;
}

/* Hover effect for menu items */
.stDataFrame [data-testid="column-actions-menu"] button:hover,
.st-df [data-testid="column-actions-menu"] button:hover {
    background-color: #4a4a4a !important;
    color: #BFA23A !important;
}

/* Header row styling for better filter button appearance */
.stDataFrame th button,
.st-df th button {
    border: none !important;
    background: transparent !important;
}

/* Filter button icon color */
.stDataFrame th [data-testid="StyledIcon"],
.st-df th [data-testid="StyledIcon"] {
    color: #BFA23A !important;
}

.stDataFrame td {
background-color: #2C2C2C !important;
color: #F0F0F0 !important;
padding: 0.5rem 1rem !important;
font-size: 0.95rem !important;
}

.stDataFrame tr:nth-child(even) td {
background-color: #333333 !important;
}

/* Widget styling */
.stSelectbox, .stMultiselect, .stSlider {
background-color: #333333 !important;
color: #F0F0F0 !important;
border-radius: 4px !important;
font-family: 'Inter', sans-serif !important;
}

/* Button styling - keep original colors but improve contrast */
.stButton button {
font-family: 'Inter', sans-serif !important;
font-weight: 500 !important;
font-size: 0.95rem !important;
letter-spacing: 0.01em !important;
border: none !important;
box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2) !important;
border-radius: 4px !important;
padding: 0.4rem 1rem !important;
}

/* Making all text consistent */
p, div, span, li, label, a, .stMarkdown, .stText {
font-family: 'Inter', sans-serif !important;
}

/* Standardize all small texts */
.stText p, .stMarkdown p, .stMarkdown ul li, .stInfoMessage p {
font-size: 0.95rem !important;
line-height: 1.5 !important;
color: #E0E0E0 !important;
margin-bottom: 0.75rem !important;
}
    
/* Expander styling */
.streamlit-expanderHeader {
background-color: #333333 !important;
color: #FFFFFF !important;
border-radius: 4px !important;
font-family: 'Inter', sans-serif !important;
font-weight: 500 !important;
font-size: 1rem !important;
}
    
.streamlit-expanderContent {
background-color: #2C2C2C !important;
border: 1px solid #444444 !important;
border-top: none !important;
border-radius: 0 0 4px 4px !important;
padding: 1rem !important;
}
    
/* Tab styling */
.stTabs [data-baseweb="tab-list"] {
background-color: #1E1E1E !important;
border-radius: 4px 4px 0 0 !important;
font-family: 'Inter', sans-serif !important;
}
    
.stTabs [data-baseweb="tab"] {
color: #CCCCCC !important;
background-color: #1E1E1E !important;
font-weight: 500 !important;
font-size: 0.95rem !important;
letter-spacing: 0.01em !important;
padding: 0.5rem 1rem !important;
}

.stTabs [aria-selected="true"] {
color: #FFFFFF !important;
background-color: #1E1E1E !important;
font-weight: 600 !important;
border-bottom: 2px solid #3B82F6 !important;
}

/* Metric styling */
[data-testid="stMetric"] {
background-color: #262626 !important;
border-radius: 6px !important;
padding: 1rem !important;
box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1) !important;
}

[data-testid="stMetric"] label {
color: #CCCCCC !important;
font-family: 'Inter', sans-serif !important;
font-weight: 500 !important;
font-size: 0.75rem !important;
letter-spacing: 0.03em !important;
text-transform: uppercase !important;
margin-bottom: 0.3rem !important;
}

[data-testid="stMetric"] .value {
color: #FFFFFF !important;
font-family: 'Inter', sans-serif !important;
font-weight: 700 !important;
font-size: 1.8rem !important;
letter-spacing: -0.01em !important;
line-height: 1.2 !important;
}

/* Info, warning, error box styling */
.stAlert {
border-radius: 4px !important;
font-family: 'Inter', sans-serif !important;
}

.stAlert [data-baseweb="notification"] {
border-radius: 4px !important;
}

/* Scrollbar styling */
::-webkit-scrollbar {
width: 10px;
height: 10px;
}

::-webkit-scrollbar-track {
background: #262626;
}

::-webkit-scrollbar-thumb {
background: #555555;
border-radius: 5px;
}

::-webkit-scrollbar-thumb:hover {
background: #777777;
}

/* Page title and app heading */
.stApp [data-testid="stAppViewContainer"] > div:first-child h1 {
font-weight: 700 !important;
font-size: 2rem !important;
letter-spacing: -0.03em !important;
color: #3B82F6 !important;
margin-bottom: 1.5rem !important;
}

/* File uploader styling */
.stUploader {
border: 1px dashed #555555 !important;
border-radius: 6px !important;
padding: 1rem !important;
background-color: #262626 !important;
margin-bottom: 0.75rem !important;
height: 90px !important;
}

.stUploader > div > div {
font-family: 'Inter', sans-serif !important;
display: flex !important;
flex-direction: column !important;
justify-content: center !important;
align-items: center !important;
height: 100% !important;
}

.stUploader [data-testid="stFileUploadDropzone"] {
height: 100% !important;
min-height: 90px !important;
display: flex !important;
align-items: center !important;
justify-content: center !important;
}

.stUploader span p {
font-family: 'Inter', sans-serif !important;
font-size: 0.9rem !important;
color: #CCCCCC !important;
margin-bottom: 0.25rem !important;
}

/* File Uploader button style */
.stUploader button {
font-family: 'Inter', sans-serif !important;
font-weight: 500 !important;
font-size: 0.9rem !important;
padding: 0.35rem 0.9rem !important;
border-radius: 4px !important;
margin-top: 0.5rem !important;
background-color: #333333 !important;
border: 1px solid #555555 !important;
color: #FFFFFF !important;
}

/* Dashboard section headers */
.main .block-container > div > div > div > div > h3 {
font-weight: 600 !important;
color: #E5E5E5 !important;
border-left: 3px solid #3B82F6 !important;
padding-left: 0.5rem !important;
margin-top: 1.5rem !important;
margin-bottom: 1rem !important;
}
</style>
"""

# Initialize session state if needed
if 'client_config' not in st.session_state:
    st.session_state.client_config = None
if 'bulk_data' not in st.session_state: 
    st.session_state.bulk_data = None 
if 'sales_report_data' not in st.session_state:
    st.session_state.sales_report_data = None 
if 'debug_messages' not in st.session_state:
    st.session_state.debug_messages = []
if 'active_tab' not in st.session_state:
    st.session_state.active_tab = "client_overview"
if 'is_companion_data' not in st.session_state:
    st.session_state.is_companion_data = False

# Apply custom CSS
st.markdown(custom_css, unsafe_allow_html=True)

# We'll add the logo in the header section alongside the title text later

# Create a dark sidebar with client selection
with st.sidebar:
    st.markdown("<h2 style='text-align: center;'>Client Selection</h2>", unsafe_allow_html=True)
    
    # Cache is automatically reset after 1 hour or when new data is uploaded
    
    existing_clients = get_existing_clients()

    # Load client if selected previously
    if 'selected_client_name' in st.session_state and st.session_state.client_config is None:
        client_name = st.session_state.selected_client_name
        st.session_state.client_config = load_client_config(client_name)

    # Radio button for action choice
    st.markdown("### Action")
    choice = st.radio("Client Action", ["Load Existing Client", "Create New Client"], label_visibility="collapsed")

    if choice == "Load Existing Client":
        if existing_clients:
            st.markdown("### Select Client")
            selected_client = st.selectbox("Select Client", existing_clients, label_visibility="collapsed")
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("Load Client", use_container_width=True):
                    st.session_state.selected_client_name = selected_client
                    st.session_state.client_config = load_client_config(selected_client)
                    st.session_state.bulk_data = None 
                    st.session_state.sales_report_data = None
                    st.session_state.current_page = 'file_uploads'  # Redirect to File Uploads page
                    st.rerun()
            
            with col2:
                if st.button("Delete Client", use_container_width=True):
                    # Set up confirmation state if not already present
                    if 'confirm_delete' not in st.session_state:
                        st.session_state.confirm_delete = False
                        st.session_state.client_to_delete = selected_client
                        st.rerun()
                    
            # Handle delete confirmation
            if 'confirm_delete' in st.session_state and st.session_state.confirm_delete:
                st.warning(f"Are you sure you want to delete '{st.session_state.client_to_delete}'? This cannot be undone.")
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("Yes, Delete", use_container_width=True):
                        # Get the client's config file path
                        client_file = Path(f"clients/{st.session_state.client_to_delete}.json")
                        
                        # Delete the client file
                        if client_file.exists():
                            client_file.unlink()  # Delete the file
                            
                            # Reset session state
                            if 'selected_client_name' in st.session_state and st.session_state.selected_client_name == st.session_state.client_to_delete:
                                st.session_state.selected_client_name = None
                                st.session_state.client_config = None
                            
                            # Reset confirmation state
                            st.session_state.confirm_delete = False
                            st.session_state.client_to_delete = None
                            st.success(f"Client '{st.session_state.client_to_delete}' has been deleted.")
                            st.rerun()  # Refresh to update the client list
                
                with col2:
                    if st.button("Cancel", use_container_width=True):
                        # Reset confirmation state
                        st.session_state.confirm_delete = False
                        st.session_state.client_to_delete = None
                        st.rerun()
            
            # Set up delete confirmation when Delete Client is clicked
            if 'client_to_delete' in st.session_state and st.session_state.client_to_delete == selected_client and not st.session_state.get('confirm_delete', False):
                st.session_state.confirm_delete = True
                st.rerun()
        else:
            st.warning("No existing clients found.")

    elif choice == "Create New Client":
        new_client_name = st.text_input("New Client Name")
        if st.button("Create Client"):
            clean_name = new_client_name.strip()
            if clean_name and clean_name not in existing_clients:
                new_config = {
                    "client_name": clean_name,
                    "branded_keywords": [],
                    "branded_asins": [],
                    "product_groups": {},
                    "goals": {
                        "account_wide_acos": None,
                        "branded_acos": None,
                        "non_branded_acos": None
                    }
                }
                save_client_config(clean_name, new_config)
                st.session_state.selected_client_name = clean_name
                st.session_state.client_config = new_config
                st.session_state.bulk_data = None 
                st.session_state.sales_report_data = None
                st.session_state.current_page = 'file_uploads'  # Redirect to File Uploads page
                st.success(f"Client '{clean_name}' created and loaded.")
                st.rerun()
            elif not clean_name:
                st.error("Please enter a client name.")
            else:
                st.error(f"Client '{clean_name}' already exists.")

# --- Main Panel --- #
if st.session_state.client_config:
    config = st.session_state.client_config
    
    # Initialize sales attribution choice in session state if not exists
    if 'sd_attribution_choice' not in st.session_state:
        st.session_state.sd_attribution_choice = "Sales"

    # Create navigation in sidebar
    with st.sidebar:
        st.markdown("")
        file_uploads_btn = st.button("File Uploads", use_container_width=True)
        client_settings_btn = st.button("Client Settings Center", use_container_width=True)
        advertising_audit_btn = st.button("Advertising Audit", use_container_width=True)
        
        # Add indicators for uploaded data
        st.markdown("")
        if 'bulk_data' in st.session_state and st.session_state.bulk_data:
            data_type = "Companion Data" if st.session_state.get('is_companion_data', False) else "Bulk File"
            st.success(f"✓ {data_type} loaded")
        
        if 'sales_report_data' in st.session_state and st.session_state.sales_report_data is not None:
            st.success("✓ Sales Report loaded")
            
        # Show overall status when both are loaded
        if ('bulk_data' in st.session_state and st.session_state.bulk_data and 
            'sales_report_data' in st.session_state and st.session_state.sales_report_data is not None):
            st.info("📊 All data ready for analysis")
        
    # Default to file uploads page
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "file_uploads"
    
    # Handle navigation
    if file_uploads_btn:
        st.session_state.current_page = "file_uploads"
    if client_settings_btn:
        st.session_state.current_page = "client_settings"
    if advertising_audit_btn:
        st.session_state.current_page = "advertising_audit"
    
    # Initialize sales attribution choice in session state if not exists (moved from global to Advertising Audit section)
    
    # Display the selected page
    if st.session_state.current_page == "file_uploads":
        # Create two columns for the two types of uploads
        col1, col2 = st.columns(2)
        
        # Initialize processing status in session state if not exists
        if 'processing_status' not in st.session_state:
            st.session_state.processing_status = {
                'advertising_data': {'status': 'idle', 'message': '', 'progress': 0},
                'sales_report': {'status': 'idle', 'message': '', 'progress': 0}
            }
        
        # Initialize upload method choice if not exists
        if 'upload_method' not in st.session_state:
            st.session_state.upload_method = "Bulk File"
        
        # Add navigation links to the respective tabs in the Advertising Audit section AFTER the file upload sections
        
        with col1:
            st.markdown("### Advertising Data Upload")
            
            # Radio button to choose upload method
            upload_method = st.radio(
                "Choose upload method:",
                ["Bulk File", "Companion"],
                key="upload_method_radio",
                horizontal=True
            )
            
            # Add a clear data button so users can intentionally clear data when needed
            if st.session_state.bulk_data is not None:
                if st.button("🗑️ Clear Current Data", key="clear_data_btn", help="Clear currently loaded data to upload new files"):
                    st.session_state.bulk_data = None
                    st.session_state.is_companion_data = False
                    st.session_state.processing_status['advertising_data'] = {'status': 'idle', 'message': '', 'progress': 0}
                    st.success("Data cleared. You can now upload new files.")
                    st.rerun()
            
            # Update session state when radio button changes
            if upload_method != st.session_state.upload_method:
                st.session_state.upload_method = upload_method
                # Reset processing status when method changes
                st.session_state.processing_status['advertising_data'] = {'status': 'idle', 'message': '', 'progress': 0}
                # Don't automatically clear data when changing upload methods
                # Users can use the "Clear Data" button if they want to start fresh
                st.rerun()
            
            if st.session_state.upload_method == "Bulk File":
                st.markdown("**Drag and drop file here**")
                st.markdown("*Limit 200MB per file • XLSX*")
                bulk_file_uploaded = st.file_uploader("Upload Bulk File", type=["xlsx"], key="bulk_file_uploader", label_visibility="collapsed")
                
                # Process bulk file upload
                if bulk_file_uploaded is not None:
                    if st.session_state.processing_status['advertising_data']['status'] == 'idle':
                        try:
                            st.session_state.processing_status['advertising_data']['status'] = 'processing'
                            st.session_state.processing_status['advertising_data']['message'] = 'Processing bulk file... please wait.'
                            st.session_state.processing_status['advertising_data']['progress'] = 50
                            st.rerun()
                        except Exception as e:
                            st.session_state.processing_status['advertising_data']['status'] = 'error'
                            st.session_state.processing_status['advertising_data']['message'] = f"Initial error: {e}"
                            st.rerun()

                    elif st.session_state.processing_status['advertising_data']['status'] == 'processing':
                        try:
                            # Clear caches when new data is uploaded
                            clear_caches()
                            st.session_state.last_cache_refresh = datetime.now()
                            processed_data = process_bulk_data(bulk_file_uploaded)
                            st.session_state.bulk_data = processed_data
                            st.session_state.is_companion_data = False
                            
                            st.session_state.processing_status['advertising_data']['status'] = 'complete'
                            st.session_state.processing_status['advertising_data']['message'] = '✓ Bulk file processed successfully'
                            st.session_state.processing_status['advertising_data']['progress'] = 100
                            st.rerun()
                        except Exception as e:
                            st.session_state.processing_status['advertising_data']['status'] = 'error'
                            st.session_state.processing_status['advertising_data']['message'] = f"Error processing bulk file: {e}"
                            st.session_state.processing_status['advertising_data']['progress'] = 0
                            st.error(st.session_state.processing_status['advertising_data']['message'])

                    elif st.session_state.processing_status['advertising_data']['status'] == 'complete':
                        st.success(st.session_state.processing_status['advertising_data']['message'])
                        if st.button("Process Again", key="reprocess_advertising_btn"):
                            st.session_state.processing_status['advertising_data']['status'] = 'idle'
                            st.rerun()
                    elif st.session_state.processing_status['advertising_data']['status'] == 'error':
                        st.error(f"Error: {st.session_state.processing_status['advertising_data']['message']}")
                        if st.button("Try Again", key="retry_advertising_btn"):
                            st.session_state.processing_status['advertising_data']['status'] = 'idle'
                            st.rerun()
                
            else:  # Companion upload
                st.markdown("**Drag and drop files here**")
                st.markdown("*Limit 200MB per file • CSV, XLSX*")
                
                # Three file uploaders for companion exports
                asin_file = st.file_uploader("ASIN Export", type=["csv", "xlsx"], key="companion_asin_uploader")
                search_term_file = st.file_uploader("Search Term Export", type=["csv", "xlsx"], key="companion_search_term_uploader")
                targeting_file = st.file_uploader("Targeting Export", type=["csv", "xlsx"], key="companion_targeting_uploader")
                
                # Process companion files when all three are uploaded
                if asin_file is not None and search_term_file is not None and targeting_file is not None:
                    if st.session_state.processing_status['advertising_data']['status'] == 'idle':
                        try:
                            st.session_state.processing_status['advertising_data']['status'] = 'processing'
                            st.session_state.processing_status['advertising_data']['message'] = 'Processing companion files... please wait.'
                            st.session_state.processing_status['advertising_data']['progress'] = 50
                            st.rerun()
                        except Exception as e:
                            st.session_state.processing_status['advertising_data']['status'] = 'error'
                            st.session_state.processing_status['advertising_data']['message'] = f"Initial error: {e}"
                            st.rerun()

                    elif st.session_state.processing_status['advertising_data']['status'] == 'processing':
                        try:
                            # Clear caches when new data is uploaded
                            clear_caches()
                            st.session_state.last_cache_refresh = datetime.now()
                            processed_data = process_companion_data(asin_file, search_term_file, targeting_file)
                            st.session_state.bulk_data = processed_data
                            st.session_state.is_companion_data = True
                            
                            st.session_state.processing_status['advertising_data']['status'] = 'complete'
                            st.session_state.processing_status['advertising_data']['message'] = '✓ Companion files processed successfully'
                            st.session_state.processing_status['advertising_data']['progress'] = 100
                            st.rerun()
                        except Exception as e:
                            st.session_state.processing_status['advertising_data']['status'] = 'error'
                            st.session_state.processing_status['advertising_data']['message'] = f"Error processing companion files: {e}"
                            st.session_state.processing_status['advertising_data']['progress'] = 0
                            st.error(st.session_state.processing_status['advertising_data']['message'])

                    elif st.session_state.processing_status['advertising_data']['status'] == 'complete':
                        st.success(st.session_state.processing_status['advertising_data']['message'])
                        if st.button("Process Again", key="reprocess_companion_btn"):
                            st.session_state.processing_status['advertising_data']['status'] = 'idle'
                            st.rerun()
                    elif st.session_state.processing_status['advertising_data']['status'] == 'error':
                        st.error(f"Error: {st.session_state.processing_status['advertising_data']['message']}")
                        if st.button("Try Again", key="retry_companion_btn"):
                            st.session_state.processing_status['advertising_data']['status'] = 'idle'
                            st.rerun()
                
                elif asin_file is not None or search_term_file is not None or targeting_file is not None:
                    st.info("Please upload all three files (ASIN Export, Search Term Export, and Targeting Export) to proceed.")
            
            # Show description based on upload method
            if st.session_state.upload_method == "Bulk File":
                st.markdown("Pull for desired date range. Include SP and SB Search Term Reports")
            else:
                st.markdown("Upload ASIN Export, Search Term Export, and Targeting Export from your in-house software")
            
            st.markdown("Used for the following:")
            st.markdown("* Advertising Audit - Ad Performance Metrics")
            st.markdown("* Advertising Audit - Product Allocation Analysis")
            st.markdown("* Advertising Audit - Targeting")
            st.markdown("* Client Settings Center - Updating Advertised ASINs")
            st.markdown("* Client Settings Center - Campaign Tagging")
        
        with col2:
            st.markdown("### Sales Report Upload")
            
            # Add a clear data button for sales report
            if st.session_state.sales_report_data is not None:
                if st.button("🗑️ Clear Sales Report", key="clear_sales_btn", help="Clear currently loaded sales report"):
                    st.session_state.sales_report_data = None
                    st.session_state.processing_status['sales_report'] = {'status': 'idle', 'message': '', 'progress': 0}
                    st.success("Sales report data cleared.")
                    st.rerun()
            
            sales_report_uploaded = st.file_uploader("Upload Sales Report", type=["csv", "xlsx"], key="sales_report_uploader", label_visibility="collapsed")

            # Display processing status and progress
            if sales_report_uploaded is not None:
                if st.session_state.processing_status['sales_report']['status'] == 'idle':
                    try:
                        st.session_state.processing_status['sales_report']['status'] = 'processing'
                        st.session_state.processing_status['sales_report']['message'] = 'Processing sales report... please wait.'
                        st.session_state.processing_status['sales_report']['progress'] = 50
                        st.rerun()
                    except Exception as e:
                        st.session_state.processing_status['sales_report']['status'] = 'error'
                        st.session_state.processing_status['sales_report']['message'] = f"Initial error: {e}"
                        st.rerun()

                elif st.session_state.processing_status['sales_report']['status'] == 'processing':
                    try:
                        # --- Actually process the file --- 
                        # Clear caches when new data is uploaded
                        clear_caches()
                        st.session_state.last_cache_refresh = datetime.now()
                        processed_data = process_sales_report(sales_report_uploaded)
                        
                        # Show detailed debugging info
                        if processed_data is not None:
                            st.write(f"DEBUG: Processed data returned with {len(processed_data)} rows and {list(processed_data.columns)} columns")
                            
                            # Extract ASINs and titles from the sales report
                            sales_asins_with_titles = extract_asins_from_sales_report(processed_data)
                            
                            # Get existing branded ASINs
                            existing_branded_asins = set()
                            if 'branded_asins_data' in st.session_state.client_config:
                                existing_branded_asins = set(str(asin).upper() for asin in st.session_state.client_config['branded_asins_data'].keys())
                            
                            # Find new ASINs that aren't already in branded_asins_data
                            new_sales_asins = set(sales_asins_with_titles.keys()) - existing_branded_asins
                            
                            # Filter the dictionary to only include new ASINs
                            new_sales_asins_dict = {asin: sales_asins_with_titles[asin] for asin in new_sales_asins}
                            
                            # Store new ASINs in session state for user confirmation
                            if new_sales_asins:
                                st.session_state.new_sales_asins = list(new_sales_asins)
                                st.session_state.new_sales_asins_titles = new_sales_asins_dict
                                st.session_state.show_new_sales_asins_prompt = True
                                st.session_state.debug_messages.append(f"Found {len(new_sales_asins)} new ASINs from sales report")
                            else:
                                st.session_state.new_sales_asins = []
                                st.session_state.new_sales_asins_titles = {}
                                st.session_state.show_new_sales_asins_prompt = False
                                
                            # Also update titles for existing ASINs if better titles are available
                            if 'branded_asins_data' in st.session_state.client_config:
                                for asin, title in sales_asins_with_titles.items():
                                    if asin in st.session_state.client_config['branded_asins_data'] and title != 'Title not available':
                                        current_title = st.session_state.client_config['branded_asins_data'][asin].get('product_title', '')
                                        if current_title == 'Title not available' or not current_title:
                                            st.session_state.client_config['branded_asins_data'][asin]['product_title'] = title
                                            st.session_state.debug_messages.append(f"Updated title for existing ASIN {asin}")
                        else:
                            st.write("DEBUG: Processed data is None")
                            
                        st.session_state.sales_report_data = processed_data
                        # --- Update status --- 
                        if processed_data is not None and not processed_data.empty:
                            st.session_state.processing_status['sales_report']['status'] = 'complete'
                            st.session_state.processing_status['sales_report']['message'] = '✓ Sales report processed successfully'
                            st.session_state.processing_status['sales_report']['progress'] = 100
                        else:
                            st.session_state.processing_status['sales_report']['status'] = 'error' # Or 'warning' if empty is ok
                            st.session_state.processing_status['sales_report']['message'] = 'Sales report processed, but no data was extracted.'
                            st.session_state.processing_status['sales_report']['progress'] = 100
                        st.rerun()
                    except Exception as e:
                        st.session_state.processing_status['sales_report']['status'] = 'error'
                        st.session_state.processing_status['sales_report']['message'] = f"Error processing sales report: {e}"
                        st.session_state.processing_status['sales_report']['progress'] = 0
                        st.error(st.session_state.processing_status['sales_report']['message'])
                        # No rerun here

                elif st.session_state.processing_status['sales_report']['status'] == 'complete':
                    # Display success message with checkmark
                    st.success(st.session_state.processing_status['sales_report']['message'])
                    if st.button("Process Again", key="reprocess_sales_btn"):
                        st.session_state.processing_status['sales_report']['status'] = 'idle'
                        st.rerun()
                elif st.session_state.processing_status['sales_report']['status'] == 'error':
                    st.error(st.session_state.processing_status['sales_report']['message'])
                    if st.button("Try Again", key="retry_sales_btn"):
                        st.session_state.processing_status['sales_report']['status'] = 'idle'
                        st.rerun()
                
            st.markdown("Can be either Vendor Central Sales Report or Seller Central Business Reports By Child ASIN")
            st.markdown("Used for the following:")
            st.markdown("* Client Overview - Calculating Total Sales, TACoS, Sessions, etc.")
            st.markdown("* Client Settings Center - Updating Advertised ASINs")
            st.markdown("* Client Settings Center - Product Tagging")
        
        # Display uploaded data viewer section
        st.markdown("---")
        
        # --- Show prompt for newly found ASINs (from sales report) ABOVE File Structure Checker ---
        # Add debug information to help troubleshoot
        st.session_state.debug_messages.append(f"show_new_sales_asins_prompt: {st.session_state.get('show_new_sales_asins_prompt', False)}")
        st.session_state.debug_messages.append(f"new_sales_asins count: {len(st.session_state.get('new_sales_asins', []))}")
        
        if st.session_state.get('show_new_sales_asins_prompt', False) and st.session_state.get('new_sales_asins', []):
            new_asins_count = len(st.session_state.new_sales_asins)
            st.warning(f"{new_asins_count} new Branded ASINs found in sales report. Add to Branded ASINs?")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Yes, add them", key="add_new_sales_asins_btn_1"):
                    # Initialize branded_asins_data if not present
                    if 'branded_asins_data' not in st.session_state.client_config:
                        st.session_state.client_config['branded_asins_data'] = {}
                    # Add new ASINs to branded_asins_data with their titles
                    added_count = 0
                    for asin in st.session_state.new_sales_asins:
                        # Standardize ASIN format
                        asin = str(asin).strip().upper()
                        if asin not in st.session_state.client_config['branded_asins_data']:
                            title = st.session_state.new_sales_asins_titles.get(asin, 'Title not available')
                            if isinstance(title, str) and title.strip() and title.lower() != 'nan':
                                title = title.strip()
                            else:
                                title = 'Title not available'
                            st.session_state.client_config['branded_asins_data'][asin] = {
                                'product_title': title,
                                'product_group': ''
                            }
                            added_count += 1
                    # Update the success message with the actual count of added ASINs
                    new_asins_count = added_count
                    # Save the updated config
                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                    # Clear the prompt flags
                    st.session_state.show_new_sales_asins_prompt = False
                    st.session_state.new_sales_asins = []
                    st.session_state.new_sales_asins_titles = {}
                    st.success(f"Added {new_asins_count} new ASINs to Branded ASINs list")
                    st.rerun()
            with col2:
                if st.button("No, ignore", key="ignore_new_sales_asins_btn_1"):
                    # Clear the prompt flags
                    st.session_state.show_new_sales_asins_prompt = False
                    st.session_state.new_sales_asins = []
                    st.rerun()
        # --- End ASIN prompt section ---
        # File Structure Checker section for uploaded files
        st.markdown("""
        <h3 style='font-family:"Inter","Roboto","Segoe UI",Arial,sans-serif; font-size:1.3rem; font-weight:600; color:#BFA23A; margin-top:1.5rem; margin-bottom:1.0rem;'>
            File Structure Checker
        </h3>""", unsafe_allow_html=True)
        st.markdown("This section allows you to verify the structure and columns of your uploaded files to ensure they're compatible with the dashboard.")
        
        # Create two columns for the two types of data
        data_col1, data_col2 = st.columns(2)
        
        with data_col1:
            st.markdown("### Bulk Advertising File Structure")
            
            # Show bulk data structure if available
            if 'bulk_data' in st.session_state and st.session_state.get('bulk_data') is not None:
                if isinstance(st.session_state.bulk_data, dict):
                    # Check for Search Term Reports
                    sp_search_term_sheet = None
                    sb_search_term_sheet = None
                    
                    # Look for sheets with 'Customer Search Term' or 'Search Term' columns
                    # Add debug information
                    st.session_state.debug_messages.append(f"Searching for search term data in {len(st.session_state.bulk_data)} sheets")
                    
                    # First pass: Identify all sheets with search term columns
                    search_term_sheets = []
                    for sheet_name, df in st.session_state.bulk_data.items():
                        if isinstance(df, pd.DataFrame) and not df.empty:
                            st.session_state.debug_messages.append(f"Examining sheet: {sheet_name} with {len(df)} rows and {len(df.columns)} columns")
                            
                            # Log all columns for debugging
                            st.session_state.debug_messages.append(f"Columns in {sheet_name}: {', '.join(df.columns)}")
                            
                            # Check for search term columns - with improved case-insensitive matching
                            has_search_term = False
                            search_term_col = None
                            
                            # Create a lowercase mapping of column names for case-insensitive matching
                            column_map = {col.lower(): col for col in df.columns}
                            
                            # Check for both 'search term' and 'customer search term' (case-insensitive)
                            if 'search term' in column_map:
                                search_term_col = column_map['search term']
                                has_search_term = True
                                st.session_state.debug_messages.append(f"Found 'Search Term' column (as '{search_term_col}') in sheet {sheet_name}")
                            elif 'customer search term' in column_map:
                                search_term_col = column_map['customer search term']
                                has_search_term = True
                                st.session_state.debug_messages.append(f"Found 'Customer Search Term' column (as '{search_term_col}') in sheet {sheet_name}")
                            
                            # If we found a search term column, add this sheet to our list
                            if has_search_term:
                                st.session_state.debug_messages.append(f"Adding sheet {sheet_name} to search term sheets list with column '{search_term_col}'")
                                search_term_sheets.append((sheet_name, df, search_term_col))
                    
                    # Log how many search term sheets we found
                    st.session_state.debug_messages.append(f"Found {len(search_term_sheets)} sheets with search term columns")
                    
                    # Second pass: Classify each search term sheet as SP or SB
                    for sheet_name, df, search_term_col in search_term_sheets:
                        # Determine if it's SP or SB based on sheet name or content
                        campaign_type = None
                        
                        # First check if 'Product' column exists
                        if 'Product' in df.columns:
                            st.session_state.debug_messages.append(f"Sheet {sheet_name} has 'Product' column. Checking values.")
                            
                            # Get unique values in the Product column - handle case sensitivity properly
                            try:
                                # First try to get the actual values
                                product_values = df['Product'].dropna().astype(str).unique()
                                product_values_str = ', '.join([str(val) for val in product_values[:5]])
                                st.session_state.debug_messages.append(f"Sample Product values: {product_values_str}")
                                
                                # Check for exact matches first
                                has_sp = any(val == 'Sponsored Products' for val in product_values)
                                has_sb = any(val == 'Sponsored Brands' for val in product_values)
                                
                                # If exact matches found, use them
                                if has_sp:
                                    campaign_type = 'Sponsored Products'
                                    st.session_state.debug_messages.append(f"Found exact match 'Sponsored Products' in Product column")
                                elif has_sb:
                                    campaign_type = 'Sponsored Brands'
                                    st.session_state.debug_messages.append(f"Found exact match 'Sponsored Brands' in Product column")
                                else:
                                    # If no exact matches, try case-insensitive search
                                    for product in product_values:
                                        product_lower = product.lower()
                                        if 'sponsored product' in product_lower:
                                            campaign_type = 'Sponsored Products'
                                            st.session_state.debug_messages.append(f"Found 'Sponsored Products' in Product column value: {product}")
                                            break
                                        elif 'sponsored brand' in product_lower:
                                            campaign_type = 'Sponsored Brands'
                                            st.session_state.debug_messages.append(f"Found 'Sponsored Brands' in Product column value: {product}")
                                            break
                            except Exception as e:
                                st.session_state.debug_messages.append(f"Error checking Product column: {str(e)}")
                                # Continue with other detection methods
                        
                        # If campaign type couldn't be determined from Product column, try to infer from sheet name
                        if campaign_type is None:
                            st.session_state.debug_messages.append(f"Could not determine campaign type from Product column for sheet {sheet_name}. Trying sheet name.")
                            sheet_name_lower = sheet_name.lower()
                            
                            if any(term in sheet_name_lower for term in ['product', 'sp', 'sponsored product']):
                                campaign_type = 'Sponsored Products'
                                st.session_state.debug_messages.append(f"Inferred 'Sponsored Products' from sheet name {sheet_name}")
                            elif any(term in sheet_name_lower for term in ['brand', 'sb', 'sponsored brand']):
                                campaign_type = 'Sponsored Brands'
                                st.session_state.debug_messages.append(f"Inferred 'Sponsored Brands' from sheet name {sheet_name}")
                        
                        # If still no campaign type, check for other columns that might indicate the type
                        if campaign_type is None and 'Campaign Type' in df.columns:
                            campaign_types = df['Campaign Type'].dropna().astype(str).unique()
                            campaign_types_str = ', '.join([str(val) for val in campaign_types[:5]])
                            st.session_state.debug_messages.append(f"Checking Campaign Type column values: {campaign_types_str}")
                            
                            for ct in campaign_types:
                                ct_lower = ct.lower()
                                if 'sponsored product' in ct_lower or 'sp' == ct_lower:
                                    campaign_type = 'Sponsored Products'
                                    st.session_state.debug_messages.append(f"Found 'Sponsored Products' in Campaign Type column")
                                    break
                                elif 'sponsored brand' in ct_lower or 'sb' == ct_lower:
                                    campaign_type = 'Sponsored Brands'
                                    st.session_state.debug_messages.append(f"Found 'Sponsored Brands' in Campaign Type column")
                                    break
                        
                        # Check for campaign name patterns if available
                        if campaign_type is None and 'Campaign' in df.columns:
                            campaign_names = df['Campaign'].dropna().astype(str).unique()
                            campaign_names_str = ', '.join([str(val) for val in campaign_names[:5]])
                            st.session_state.debug_messages.append(f"Checking Campaign column values: {campaign_names_str}")
                            
                            for name in campaign_names:
                                name_lower = name.lower()
                                if 'sp' in name_lower.split() or 'sponsored product' in name_lower:
                                    campaign_type = 'Sponsored Products'
                                    st.session_state.debug_messages.append(f"Found 'Sponsored Products' pattern in Campaign name")
                                    break
                                elif 'sb' in name_lower.split() or 'sponsored brand' in name_lower:
                                    campaign_type = 'Sponsored Brands'
                                    st.session_state.debug_messages.append(f"Found 'Sponsored Brands' pattern in Campaign name")
                                    break
                        
                        # As a last resort, check all other columns for campaign type indicators
                        if campaign_type is None and len(df) > 0:
                            st.session_state.debug_messages.append(f"Still could not determine campaign type. Examining all columns for clues.")
                            
                            # Check all columns for any indicators
                            for col in df.columns:
                                if col not in ['Search Term', 'Customer Search Term', search_term_col]:  # Skip the search term column
                                    try:
                                        col_values = df[col].dropna().astype(str).head(20).tolist()  # Check just first 20 values
                                        col_text = ' '.join(col_values).lower()
                                        
                                        if 'sponsored product' in col_text or ' sp ' in col_text:
                                            campaign_type = 'Sponsored Products'
                                            st.session_state.debug_messages.append(f"Found 'Sponsored Products' indicator in column {col}")
                                            break
                                        elif 'sponsored brand' in col_text or ' sb ' in col_text:
                                            campaign_type = 'Sponsored Brands'
                                            st.session_state.debug_messages.append(f"Found 'Sponsored Brands' indicator in column {col}")
                                            break
                                    except:
                                        # Skip columns that can't be processed
                                        continue
                        
                        # If we still can't determine, use a heuristic based on column structure
                        if campaign_type is None:
                            # Check for columns that are more common in SP vs SB reports
                            sp_indicator_cols = ['Match Type', 'Keyword', 'Target', 'Targeting']  
                            sb_indicator_cols = ['Keyword Status', 'Creative', 'Headline']
                            
                            sp_score = sum(1 for col in sp_indicator_cols if col in df.columns)
                            sb_score = sum(1 for col in sb_indicator_cols if col in df.columns)
                            
                            if sp_score > sb_score:
                                campaign_type = 'Sponsored Products'
                                st.session_state.debug_messages.append(f"Determined 'Sponsored Products' based on column structure (SP score: {sp_score}, SB score: {sb_score})")
                            elif sb_score > sp_score:
                                campaign_type = 'Sponsored Brands'
                                st.session_state.debug_messages.append(f"Determined 'Sponsored Brands' based on column structure (SP score: {sp_score}, SB score: {sb_score})")
                            else:
                                # Default to Sponsored Products if we still can't determine
                                campaign_type = 'Sponsored Products'
                                st.session_state.debug_messages.append(f"Could not determine campaign type for sheet {sheet_name}. Defaulting to Sponsored Products.")
                        
                        # Assign to appropriate variable based on campaign type
                        if campaign_type == 'Sponsored Products':
                            sp_search_term_sheet = (sheet_name, df, search_term_col)
                            st.session_state.debug_messages.append(f"✅ Assigned sheet {sheet_name} as Sponsored Products search term data")
                        elif campaign_type == 'Sponsored Brands':
                            sb_search_term_sheet = (sheet_name, df, search_term_col)
                            st.session_state.debug_messages.append(f"✅ Assigned sheet {sheet_name} as Sponsored Brands search term data")
                    # Create tabs for different sheets
                    sheet_names = list(st.session_state.bulk_data.keys())
                    if sheet_names:
                        st.success(f"✅ Bulk file processed successfully with {len(sheet_names)} sheets")
                        
                        # Display SP Search Term Report section if found
                        if sp_search_term_sheet:
                            sheet_name, df, search_term_col = sp_search_term_sheet
                            with st.expander(f"🔍 SP Search Term Report ({len(df)} rows)", expanded=False):
                                st.success(f"✅ Sponsored Products Search Term data found in sheet '{sheet_name}'")
                                st.markdown(f"**Search Term Column:** '{search_term_col}'")
                                
                                # Show column information
                                st.markdown("**Column Structure:**")
                                
                                # Create a dataframe with column information
                                col_info = []
                                required_cols = {
                                    search_term_col: ['customer search query', 'required'],
                                    'Campaign': ['campaign identification', 'required'],
                                    'Ad Group': ['ad group identification', 'recommended'],
                                    'Targeting': ['keyword targeting', 'recommended'],
                                    'Match Type': ['match type information', 'recommended'],
                                    'Impressions': ['performance metric', 'required'],
                                    'Clicks': ['performance metric', 'required'],
                                    'Spend': ['performance metric', 'required'],
                                    'Sales': ['performance metric', 'required'],
                                    'Orders': ['performance metric', 'recommended']
                                }
                                
                                for col in df.columns:
                                    data_sample = str(df[col].iloc[0]) if not df.empty else 'N/A'
                                    if len(data_sample) > 50:
                                        data_sample = data_sample[:47] + '...'
                                    
                                    status = '✅ Present' 
                                    if col in required_cols:
                                        purpose, importance = required_cols[col]
                                        if importance == 'required':
                                            status = '✅ Required - Present'
                                    else:
                                        purpose = 'additional data'
                                        
                                    col_info.append({
                                        'Column Name': col,
                                        'Data Type': str(df[col].dtype),
                                        'Purpose': purpose,
                                        'Sample Data': data_sample,
                                        'Status': status
                                    })
                                
                                # Check for missing required columns
                                for req_col, (purpose, importance) in required_cols.items():
                                    if importance == 'required' and req_col not in df.columns:
                                        # Check for alternative column names for Sales
                                        found = False
                                        if req_col == 'Sales':
                                            for alt in ['Ad Sales', 'Sales (Views & Clicks)']:
                                                if alt in df.columns:
                                                    found = True
                                                    break
                                        
                                        if not found:
                                            col_info.append({
                                                'Column Name': req_col,
                                                'Data Type': 'N/A',
                                                'Purpose': purpose,
                                                'Sample Data': 'N/A',
                                                'Status': '⚠️ Required - Missing'
                                            })
                                
                                # Display the column information
                                col_df = pd.DataFrame(col_info)
                                st.dataframe(col_df, use_container_width=True)
                                
                                # Show sample data
                                st.markdown("**Sample Search Terms:**")
                                if len(df) > 0:
                                    sample_df = df.head(5)[[search_term_col, 'Impressions', 'Clicks', 'Spend', 'Orders']].copy() if all(col in df.columns for col in ['Impressions', 'Clicks', 'Spend', 'Orders']) else df.head(5)[[search_term_col]].copy()
                                    st.dataframe(sample_df, use_container_width=True)
                        else:
                            st.warning("⚠️ No Sponsored Products Search Term data found in the bulk file")
                            st.markdown("**Required Column:** 'Customer Search Term' or 'Search Term'")
                            st.markdown("Make sure your bulk file includes the Search Term Report for Sponsored Products campaigns.")
                        
                        # Display SB Search Term Report section if found
                        if sb_search_term_sheet:
                            sheet_name, df, search_term_col = sb_search_term_sheet
                            with st.expander(f"🔍 SB Search Term Report ({len(df)} rows)", expanded=False):
                                st.success(f"✅ Sponsored Brands Search Term data found in sheet '{sheet_name}'")
                                st.markdown(f"**Search Term Column:** '{search_term_col}'")
                                
                                # Show column information
                                st.markdown("**Column Structure:**")
                                
                                # Create a dataframe with column information
                                col_info = []
                                required_cols = {
                                    search_term_col: ['customer search query', 'required'],
                                    'Campaign': ['campaign identification', 'required'],
                                    'Impressions': ['performance metric', 'required'],
                                    'Clicks': ['performance metric', 'required'],
                                    'Spend': ['performance metric', 'required'],
                                    'Sales': ['performance metric', 'required'],
                                    'Orders': ['performance metric', 'recommended']
                                }
                                
                                for col in df.columns:
                                    data_sample = str(df[col].iloc[0]) if not df.empty else 'N/A'
                                    if len(data_sample) > 50:
                                        data_sample = data_sample[:47] + '...'
                                    
                                    status = '✅ Present' 
                                    if col in required_cols:
                                        purpose, importance = required_cols[col]
                                        if importance == 'required':
                                            status = '✅ Required - Present'
                                    else:
                                        purpose = 'additional data'
                                        
                                    col_info.append({
                                        'Column Name': col,
                                        'Data Type': str(df[col].dtype),
                                        'Purpose': purpose,
                                        'Sample Data': data_sample,
                                        'Status': status
                                    })
                                
                                # Check for missing required columns
                                for req_col, (purpose, importance) in required_cols.items():
                                    if importance == 'required' and req_col not in df.columns:
                                        # Check for alternative column names for Sales
                                        found = False
                                        if req_col == 'Sales':
                                            for alt in ['Ad Sales', 'Sales (Views & Clicks)']:
                                                if alt in df.columns:
                                                    found = True
                                                    break
                                        
                                        if not found:
                                            col_info.append({
                                                'Column Name': req_col,
                                                'Data Type': 'N/A',
                                                'Purpose': purpose,
                                                'Sample Data': 'N/A',
                                                'Status': '⚠️ Required - Missing'
                                            })
                                
                                # Display the column information
                                col_df = pd.DataFrame(col_info)
                                st.dataframe(col_df, use_container_width=True)
                                
                                # Show sample data
                                st.markdown("**Sample Search Terms:**")
                                if len(df) > 0:
                                    sample_df = df.head(5)[[search_term_col, 'Impressions', 'Clicks', 'Spend', 'Orders']].copy() if all(col in df.columns for col in ['Impressions', 'Clicks', 'Spend', 'Orders']) else df.head(5)[[search_term_col]].copy()
                                    st.dataframe(sample_df, use_container_width=True)
                        else:
                            st.warning("⚠️ No Sponsored Brands Search Term data found in the bulk file")
                            st.markdown("**Required Column:** 'Customer Search Term' or 'Search Term'")
                            st.markdown("Make sure your bulk file includes the Search Term Report for Sponsored Brands campaigns.")
                        
                        
                        # Track which sheets have already been displayed to avoid duplicates
                        displayed_sheets = set()
                        if sp_search_term_sheet:
                            displayed_sheets.add(sp_search_term_sheet[0])  # Add SP search term sheet name
                        if sb_search_term_sheet:
                            displayed_sheets.add(sb_search_term_sheet[0])  # Add SB search term sheet name
                            
                        # Display remaining sheets that haven't been shown yet
                        for sheet_name in sheet_names:
                            # Skip sheets that have already been displayed as search term reports
                            if sheet_name in displayed_sheets:
                                continue
                                
                            df = st.session_state.bulk_data[sheet_name]
                            if isinstance(df, pd.DataFrame) and not df.empty:
                                with st.expander(f"📋 {sheet_name} ({len(df)} rows)", expanded=False):
                                    # Show column information
                                    st.markdown("**Column Structure:**")
                                    
                                    # Create a dataframe with column information
                                    col_info = []
                                    required_cols = {
                                        'Campaign Name': ['campaign identification', 'required'],
                                        'Ad Group': ['ad group identification', 'required'],
                                        'Targeting': ['keyword or product targeting', 'recommended'],
                                        'Match Type': ['match type information', 'recommended'],
                                        'Impressions': ['performance metric', 'required'],
                                        'Clicks': ['performance metric', 'required'],
                                        'Spend': ['performance metric', 'required'],
                                        'Sales': ['performance metric', 'required'],
                                        'Orders': ['performance metric', 'recommended'],
                                        'ACoS': ['performance metric', 'recommended']
                                    }
                                    
                                    for col in df.columns:
                                        data_sample = str(df[col].iloc[0]) if not df.empty else 'N/A'
                                        if len(data_sample) > 50:
                                            data_sample = data_sample[:47] + '...'
                                        
                                        status = '✅ Present' 
                                        if col in required_cols:
                                            purpose, importance = required_cols[col]
                                            if importance == 'required':
                                                status = '✅ Required - Present'
                                        else:
                                            purpose = 'additional data'
                                            
                                        col_info.append({
                                            'Column Name': col,
                                            'Data Type': str(df[col].dtype),
                                            'Purpose': purpose,
                                            'Sample Data': data_sample,
                                            'Status': status
                                        })
                                    
                                    # Check for missing required columns
                                    for req_col, (purpose, importance) in required_cols.items():
                                        if importance == 'required' and req_col not in df.columns:
                                            # Check for alternative column names
                                            found = False
                                            if req_col == 'Sales':
                                                for alt in ['Ad Sales', 'Sales (Views & Clicks)']:
                                                    if alt in df.columns:
                                                        found = True
                                                        break
                                            
                                            if not found:
                                                col_info.append({
                                                    'Column Name': req_col,
                                                    'Data Type': 'N/A',
                                                    'Purpose': purpose,
                                                    'Sample Data': 'N/A',
                                                    'Status': '⚠️ Required - Missing'
                                                })
                                    
                                    # Display the column information
                                    col_df = pd.DataFrame(col_info)
                                    st.dataframe(col_df, use_container_width=True)
                                    
                                    # Show data structure validation
                                    st.markdown("**Data Structure Validation:**")
                                    validations = []
                                    
                                    # Check for campaign name consistency
                                    if 'Campaign Name' in df.columns:
                                        campaign_count = len(df['Campaign Name'].unique())
                                        validations.append({
                                            'Check': 'Campaign Names',
                                            'Result': f'{campaign_count} unique campaigns found',
                                            'Status': '✅ Valid' if campaign_count > 0 else '⚠️ No campaigns found'
                                        })
                                    
                                    # Check for numeric data in performance metrics
                                    for metric in ['Impressions', 'Clicks', 'Spend', 'Sales', 'Orders']:
                                        if metric in df.columns:
                                            try:
                                                # Try to convert to numeric
                                                numeric_col = pd.to_numeric(df[metric].astype(str).str.replace('[$,%]', '', regex=True), errors='coerce')
                                                valid_count = numeric_col.notna().sum()
                                                valid_percent = (valid_count / len(df)) * 100 if len(df) > 0 else 0
                                                
                                                validations.append({
                                                    'Check': f'{metric} Data',
                                                    'Result': f'{valid_count}/{len(df)} rows have valid numeric data ({valid_percent:.1f}%)',
                                                    'Status': '✅ Valid' if valid_percent > 90 else '⚠️ Some invalid data'
                                                })
                                            except:
                                                validations.append({
                                                    'Check': f'{metric} Data',
                                                    'Result': 'Could not validate numeric data',
                                                    'Status': '⚠️ Validation failed'
                                                })
                                    
                                    # Display validation results
                                    st.dataframe(pd.DataFrame(validations), use_container_width=True)
                            else:
                                st.warning(f"Sheet '{sheet_name}' is empty or not a valid DataFrame")
                    else:
                        st.warning("Bulk file processed but no valid sheets found")
                else:
                    st.warning("Bulk data is not in the expected format (dictionary of DataFrames)")
            else:
                st.info("No bulk advertising data has been uploaded yet.")
        
        with data_col2:
            st.markdown("### Sales Report File Structure")
            
            # Show sales report structure if available
            if st.session_state.get('sales_report_data') is not None:
                sales_df = st.session_state.sales_report_data
                if isinstance(sales_df, pd.DataFrame):
                    st.success(f"✅ Sales report processed successfully with {len(sales_df)} rows and {len(sales_df.columns)} columns")
                    
                    with st.expander("📋 Sales Report Structure", expanded=False):
                        # Show column information
                        st.markdown("**Column Structure:**")
                        
                        # Create a dataframe with column information
                        col_info = []
                        required_cols = {
                            'ASIN': ['product identification', 'required'],
                            'SKU': ['seller SKU', 'recommended'],
                            'Product Title': ['product name', 'recommended'],
                            'Ordered Product Sales': ['sales amount', 'required'],
                            'Units Ordered': ['quantity sold', 'required'],
                            'Sessions': ['traffic data', 'recommended'],
                            'Session Percentage': ['traffic attribution', 'optional']
                        }
                        
                        # Check for alternative column names
                        sales_col_alternatives = {
                            'Ordered Product Sales': ['Total Sales', 'Sales', 'Revenue'],
                            'Units Ordered': ['Units Sold', 'Quantity', 'Units'],
                            'Product Title': ['Title', 'Item Name', 'Product Name']
                        }
                        
                        # Map actual columns to standard names
                        column_mapping = {}
                        for std_col, alternatives in sales_col_alternatives.items():
                            if std_col in sales_df.columns:
                                column_mapping[std_col] = std_col
                            else:
                                for alt in alternatives:
                                    if alt in sales_df.columns:
                                        column_mapping[std_col] = alt
                                        break
                        
                        for col in sales_df.columns:
                            data_sample = str(sales_df[col].iloc[0]) if not sales_df.empty else 'N/A'
                            if len(data_sample) > 50:
                                data_sample = data_sample[:47] + '...'
                            
                            # Determine if this column is a known required/recommended column or an alternative name
                            mapped_name = None
                            for std_col, alt_col in column_mapping.items():
                                if col == alt_col:
                                    mapped_name = std_col
                                    break
                            
                            if col in required_cols:
                                purpose, importance = required_cols[col]
                                status = '✅ Required - Present' if importance == 'required' else '✅ Recommended - Present'
                            elif mapped_name and mapped_name in required_cols:
                                purpose, importance = required_cols[mapped_name]
                                status = f'✅ Alternative for {mapped_name}'
                            else:
                                purpose = 'additional data'
                                status = '✅ Present'
                                
                            col_info.append({
                                'Column Name': col,
                                'Data Type': str(sales_df[col].dtype),
                                'Purpose': purpose,
                                'Sample Data': data_sample,
                                'Status': status
                            })
                        
                        # Check for missing required columns
                        for req_col, (purpose, importance) in required_cols.items():
                            if importance == 'required' and req_col not in sales_df.columns and req_col not in column_mapping:
                                col_info.append({
                                    'Column Name': req_col,
                                    'Data Type': 'N/A',
                                    'Purpose': purpose,
                                    'Sample Data': 'N/A',
                                    'Status': '⚠️ Required - Missing'
                                })
                        
                        # Display the column information
                        col_df = pd.DataFrame(col_info)
                        st.dataframe(col_df, use_container_width=True)
                        
                        # Show data structure validation
                        st.markdown("**Data Structure Validation:**")
                        validations = []
                        
                        # Check for ASIN format
                        asin_col = None
                        for col in sales_df.columns:
                            if col.upper() == 'ASIN' or 'ASIN' in col.upper():
                                asin_col = col
                                break
                        
                        if asin_col:
                            valid_asins = sales_df[asin_col].astype(str).str.match(r'^[A-Z0-9]{10}$').sum()
                            valid_percent = (valid_asins / len(sales_df)) * 100 if len(sales_df) > 0 else 0
                            validations.append({
                                'Check': 'ASIN Format',
                                'Result': f'{valid_asins}/{len(sales_df)} rows have valid ASIN format ({valid_percent:.1f}%)',
                                'Status': '✅ Valid' if valid_percent > 90 else '⚠️ Some invalid ASINs'
                            })
                        
                        # Check for numeric data in sales metrics
                        for metric_std, alternatives in sales_col_alternatives.items():
                            if metric_std in ['Ordered Product Sales', 'Units Ordered']:
                                # Find the actual column name
                                metric_col = None
                                if metric_std in sales_df.columns:
                                    metric_col = metric_std
                                else:
                                    for alt in alternatives:
                                        if alt in sales_df.columns:
                                            metric_col = alt
                                            break
                                
                                if metric_col:
                                    try:
                                        # Try to convert to numeric
                                        numeric_col = pd.to_numeric(sales_df[metric_col].astype(str).str.replace('[$,%]', '', regex=True), errors='coerce')
                                        valid_count = numeric_col.notna().sum()
                                        valid_percent = (valid_count / len(sales_df)) * 100 if len(sales_df) > 0 else 0
                                        
                                        validations.append({
                                            'Check': f'{metric_std} Data',
                                            'Result': f'{valid_count}/{len(sales_df)} rows have valid numeric data ({valid_percent:.1f}%)',
                                            'Status': '✅ Valid' if valid_percent > 90 else '⚠️ Some invalid data'
                                        })
                                    except:
                                        validations.append({
                                            'Check': f'{metric_std} Data',
                                            'Result': 'Could not validate numeric data',
                                            'Status': '⚠️ Validation failed'
                                        })
                        
                        # Display validation results
                        st.dataframe(pd.DataFrame(validations), use_container_width=True)
                else:
                    st.warning("Sales report data is not in the expected format (DataFrame)")
            else:
                st.info("No sales report data has been uploaded yet.")
        
        # Show any targeting data structure if available
        if ('branded_targets_df' in st.session_state and st.session_state.get('branded_targets_df') is not None) or \
           ('non_branded_targets_df' in st.session_state and st.session_state.get('non_branded_targets_df') is not None):
            st.markdown("### Targeting Data Structure")
            
            targeting_tabs = st.tabs(["Branded Targeting", "Non-Branded Targeting"])
            
            with targeting_tabs[0]:
                if 'branded_targets_df' in st.session_state and st.session_state.get('branded_targets_df') is not None:
                    branded_df = st.session_state.branded_targets_df
                    if isinstance(branded_df, pd.DataFrame):
                        st.success(f"✅ Branded targeting data processed successfully with {len(branded_df)} rows")
                        
                        with st.expander("📋 Branded Targeting Structure", expanded=False):
                            # Show column information
                            st.markdown("**Column Structure:**")
                            col_info = []
                            
                            for col in branded_df.columns:
                                data_sample = str(branded_df[col].iloc[0]) if not branded_df.empty else 'N/A'
                                if len(data_sample) > 50:
                                    data_sample = data_sample[:47] + '...'
                                
                                col_info.append({
                                    'Column Name': col,
                                    'Data Type': str(branded_df[col].dtype),
                                    'Sample Data': data_sample
                                })
                            
                            st.dataframe(pd.DataFrame(col_info), use_container_width=True)
                    else:
                        st.warning("Branded targeting data is not in the expected format (DataFrame)")
                else:
                    st.info("No branded targeting data available.")
            
            with targeting_tabs[1]:
                if 'non_branded_targets_df' in st.session_state and st.session_state.get('non_branded_targets_df') is not None:
                    non_branded_df = st.session_state.non_branded_targets_df
                    if isinstance(non_branded_df, pd.DataFrame):
                        st.success(f"✅ Non-branded targeting data processed successfully with {len(non_branded_df)} rows")
                        
                        with st.expander("📋 Non-Branded Targeting Structure", expanded=False):
                            # Show column information
                            st.markdown("**Column Structure:**")
                            col_info = []
                            
                            for col in non_branded_df.columns:
                                data_sample = str(non_branded_df[col].iloc[0]) if not non_branded_df.empty else 'N/A'
                                if len(data_sample) > 50:
                                    data_sample = data_sample[:47] + '...'
                                
                                col_info.append({
                                    'Column Name': col,
                                    'Data Type': str(non_branded_df[col].dtype),
                                    'Sample Data': data_sample
                                })
                            
                            st.dataframe(pd.DataFrame(col_info), use_container_width=True)
                    else:
                        st.warning("Non-branded targeting data is not in the expected format (DataFrame)")
                else:
                    st.info("No non-branded targeting data available.")
        
        # Display ASIN prompts in the File Upload page
        st.markdown("---")
        
        # Check if we need to show the new branded ASINs prompt from bulk advertising file
        if st.session_state.get('show_new_asins_prompt', False) and st.session_state.get('new_branded_asins', []):
            new_asins_count = len(st.session_state.new_branded_asins)
            st.warning(f"{new_asins_count} new Branded ASINs found in bulk advertising file. Add to Branded ASINs?")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Yes, add them", key="add_new_asins_btn"):
                    # Initialize branded_asins_data if not present
                    if 'branded_asins_data' not in st.session_state.client_config:
                        st.session_state.client_config['branded_asins_data'] = {}
                    
                    # Add new ASINs to branded_asins_data
                    for asin in st.session_state.new_branded_asins:
                        if asin not in st.session_state.client_config['branded_asins_data']:
                            # Get title from sales report if available
                            title = st.session_state.new_branded_asins_titles.get(asin, 'Title not available')
                            
                            st.session_state.client_config['branded_asins_data'][asin] = {
                                'product_title': title,
                                'product_group': ''
                            }
                    
                    # Save the updated config
                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                    
                    # Clear the prompt flags
                    st.session_state.show_new_asins_prompt = False
                    st.session_state.new_branded_asins = []
                    
                    st.success(f"Added {new_asins_count} new ASINs to Branded ASINs list")
                    st.rerun()
            
            with col2:
                if st.button("No, ignore", key="ignore_new_asins_btn"):
                    # Clear the prompt flags
                    st.session_state.show_new_asins_prompt = False
                    st.session_state.new_branded_asins = []
                    st.rerun()
        
        # Check if we need to show the new branded ASINs prompt from sales report
        # Add debug information to help troubleshoot
        st.session_state.debug_messages.append(f"show_new_sales_asins_prompt: {st.session_state.get('show_new_sales_asins_prompt', False)}")
        st.session_state.debug_messages.append(f"new_sales_asins count: {len(st.session_state.get('new_sales_asins', []))}")
        
        if st.session_state.get('show_new_sales_asins_prompt', False) and st.session_state.get('new_sales_asins', []):
            new_asins_count = len(st.session_state.new_sales_asins)
            st.warning(f"{new_asins_count} new Branded ASINs found in sales report. Add to Branded ASINs?")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Yes, add them", key="add_new_sales_asins_btn_2"):
                    # Initialize branded_asins_data if not present
                    if 'branded_asins_data' not in st.session_state.client_config:
                        st.session_state.client_config['branded_asins_data'] = {}
                    
                    # Add new ASINs to branded_asins_data with their titles
                    added_count = 0
                    for asin in st.session_state.new_sales_asins:
                        # Standardize ASIN format
                        asin = str(asin).strip().upper()
                        
                        if asin not in st.session_state.client_config['branded_asins_data']:
                            title = st.session_state.new_sales_asins_titles.get(asin, 'Title not available')
                            if isinstance(title, str) and title.strip() and title.lower() != 'nan':
                                title = title.strip()
                            else:
                                title = 'Title not available'
                                
                            st.session_state.client_config['branded_asins_data'][asin] = {
                                'product_title': title,
                                'product_group': ''
                            }
                            added_count += 1
                    
                    # Update the success message with the actual count of added ASINs
                    new_asins_count = added_count
                    
                    # Save the updated config
                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                    
                    # Clear the prompt flags
                    st.session_state.show_new_sales_asins_prompt = False
                    st.session_state.new_sales_asins = []
                    st.session_state.new_sales_asins_titles = {}
                    
                    st.success(f"Added {new_asins_count} new ASINs to Branded ASINs list")
                    st.rerun()
            
            with col2:
                if st.button("No, ignore", key="ignore_new_sales_asins_btn_2"):
                    # Clear the prompt flags
                    st.session_state.show_new_sales_asins_prompt = False
                    st.session_state.new_sales_asins = []
                    st.session_state.new_sales_asins_titles = {}
                    st.rerun()
    
    elif st.session_state.current_page == "client_settings":
        st.markdown("""
    <h2 style='font-family:'Inter','Roboto','Segoe UI',Arial,sans-serif; font-size:2.2rem; font-weight:700; color:#2196f3; margin-top:1.2rem; margin-bottom:1.0rem;'>
        Client Settings Center
    </h2>""", unsafe_allow_html=True)
        
        # Create tabs for different settings
        settings_tab1, settings_tab2, settings_tab3 = st.tabs(["Branded Terms", "Branded ASINs", "Campaign Tagging"])
        
        with settings_tab1:
            st.markdown("""
    <h4 style='font-family:'Inter','Roboto','Segoe UI',Arial,sans-serif; font-size:0.98rem; font-weight:600; color:#6c757d; margin-top:1.4rem; margin-bottom:0.7rem;'>
        Branded Terms
    </h4>""", unsafe_allow_html=True)
            # Use a temporary session state variable for edits
            if "branded_terms_area_temp" not in st.session_state:
                st.session_state.branded_terms_area_temp = "\n".join(config.get("branded_keywords", []))

            st.text_area("Enter branded terms (one per line)", 
                         height=200, key="branded_terms_area_temp")

            col_save, col_cancel = st.columns([1,1])
            with col_save:
                if st.button("Save Changes", key="save_branded_terms"):
                    config["branded_keywords"] = [term.strip() for term in st.session_state.branded_terms_area_temp.split("\n") if term.strip()]
                    save_client_config(st.session_state.selected_client_name, config)
                    st.session_state.client_config = config
                    st.success("Branded terms updated.")
            with col_cancel:
                if st.button("Cancel", key="cancel_branded_terms"):
                    # Revert changes by resetting temp area to last saved config
                    st.session_state.branded_terms_area_temp = "\n".join(config.get("branded_keywords", []))
                    st.info("Changes discarded.")

        
        with settings_tab2:
            st.markdown("""
    <h4 style='font-family:'Inter','Roboto','Segoe UI',Arial,sans-serif; font-size:0.98rem; font-weight:600; color:#6c757d; margin-top:1.4rem; margin-bottom:0.7rem;'>
        Branded ASINs
    </h4>""", unsafe_allow_html=True)
            
            # Initialize branded_asins_data if not present in client config
            if 'branded_asins_data' not in st.session_state.client_config:
                st.session_state.client_config['branded_asins_data'] = {}
            
            # Get ASINs from sales report if available
            if 'sales_report_data' in st.session_state and st.session_state.sales_report_data is not None:
                # Debug the available columns and data types
                st.session_state.debug_messages.append(f"Sales report columns: {list(st.session_state.sales_report_data.columns)}")
                
                # Debug the data types of key columns and branded_asins_data status
                if not st.session_state.sales_report_data.empty:
                    st.session_state.debug_messages.append(f"Sales report data types: {st.session_state.sales_report_data.dtypes}")
                    
                # Log the current state of branded_asins_data
                branded_asins_count = len(st.session_state.client_config.get('branded_asins_data', {}))
                st.session_state.debug_messages.append(f"Current branded_asins_data count: {branded_asins_count}")
                
                # Determine the ASIN column name based on priority order
                # First try exact matches for 'ASIN' or '(Child) ASIN'
                asin_col = None
                
                # Priority order: '(Child) ASIN' first, then 'ASIN' exact match
                for col_name in ['(Child) ASIN', 'ASIN']:
                    if col_name in st.session_state.sales_report_data.columns:
                        asin_col = col_name
                        st.session_state.debug_messages.append(f"Using {asin_col} column from sales report")
                        break
                        
                # If no exact match found, look for any column containing 'ASIN' as fallback
                if asin_col is None:
                    for col in st.session_state.sales_report_data.columns:
                        if 'ASIN' in col and '(Parent)' not in col:  # Avoid using (Parent) ASIN
                            asin_col = col
                            st.session_state.debug_messages.append(f"Falling back to {asin_col} column")
                            break
                            
                # Last resort: use any ASIN column including (Parent) ASIN
                if asin_col is None:
                    for col in st.session_state.sales_report_data.columns:
                        if 'ASIN' in col:
                            asin_col = col
                            st.session_state.debug_messages.append(f"Last resort using {asin_col} column")
                            break
                
                # Get ASINs and titles from sales report
                if asin_col in st.session_state.sales_report_data.columns:
                    # Check if Title column exists, if not, try to find it with case-insensitive search
                    title_col = 'Title'
                    if 'Title' not in st.session_state.sales_report_data.columns:
                        for col in st.session_state.sales_report_data.columns:
                            if col.lower() == 'title' or 'title' in col.lower() or 'product name' in col.lower():
                                title_col = col
                                st.session_state.debug_messages.append(f"Found alternative title column: {title_col}")
                                break
                        
                    # If we still don't have a title column, create a placeholder
                    if title_col not in st.session_state.sales_report_data.columns:
                        st.session_state.sales_report_data[title_col] = 'Title not available'
                        st.session_state.debug_messages.append("No title column found, using placeholder")
                    # Debug: Log the total number of unique ASINs in the sales report
                    # First clean the ASINs to ensure proper counting
                    st.session_state.sales_report_data[asin_col] = st.session_state.sales_report_data[asin_col].astype(str).str.strip().str.upper()
                    unique_asins = st.session_state.sales_report_data[asin_col].unique()
                    st.session_state.debug_messages.append(f"Found {len(unique_asins)} unique ASINs in sales report. First 5: {list(unique_asins)[:5]}")
                    
                    # Log how many of these ASINs are already in the branded_asins_data
                    existing_asins = set(st.session_state.client_config.get('branded_asins_data', {}).keys())
                    new_asins_count = len(set(unique_asins) - existing_asins)
                    st.session_state.debug_messages.append(f"Of these, {new_asins_count} ASINs are not yet in branded_asins_data")
                    
                    # Use the identified title column
                    title_col = title_col if title_col in st.session_state.sales_report_data.columns else 'Title'
                    
                    # ASINs have already been converted to string and standardized above
                    
                    # Create a clean dataframe with ASIN and Title
                    sales_asins_df = st.session_state.sales_report_data[[asin_col, title_col]].copy()
                    sales_asins_df.columns = [asin_col, 'Title']  # Standardize column name
                    sales_asins_df = sales_asins_df.drop_duplicates().reset_index(drop=True)
                    
                    # Debug: Show a sample of the data
                    st.session_state.debug_messages.append(f"Sample of sales_asins_df:\n{sales_asins_df.head(3)}")
                    st.session_state.debug_messages.append(f"After drop_duplicates: {len(sales_asins_df)} unique ASIN/Title pairs")
                    
                    # Collect new ASINs from sales report
                    new_asins_from_sales = []
                    new_asins_titles = {}
                    skipped_count = 0
                    title_updates = 0  # Initialize title updates counter
                    
                    for _, row in sales_asins_df.iterrows():
                        asin = row[asin_col]
                        title = row['Title']
                        
                        # Debug: Check if ASIN is valid
                        if not asin or pd.isna(asin) or str(asin).strip() == '' or str(asin).lower() == 'nan':
                            st.session_state.debug_messages.append(f"Skipping empty or invalid ASIN")
                            skipped_count += 1
                            continue
                            
                        # Standardize ASIN format
                        asin = str(asin).strip().upper()
                        
                        # Check if title is valid
                        if pd.isna(title) or str(title).strip() == '' or str(title).lower() == 'nan':
                            title = 'Title not available'
                        else:
                            title = str(title).strip()
                        
                        # Only collect if not already in the data
                        if asin not in st.session_state.client_config['branded_asins_data']:
                            new_asins_from_sales.append(asin)
                            new_asins_titles[asin] = title
                        # Always update title if it's available from the sales report and not empty
                        elif asin in st.session_state.client_config['branded_asins_data'] and title and str(title).strip() != '' and title != 'nan':
                            # Debug: Log title update
                            old_title = st.session_state.client_config['branded_asins_data'][asin]['product_title']
                            st.session_state.debug_messages.append(f"Updating title for existing ASIN {asin}: '{old_title}' -> '{title}'")
                            st.session_state.client_config['branded_asins_data'][asin]['product_title'] = title
                    
                    # Debug: Log how many new ASINs were found and skipped
                    st.session_state.debug_messages.append(f"Found {len(new_asins_from_sales)} new ASINs in sales report, skipped {skipped_count} invalid ASINs")
                    
                    # If there are no new ASINs from sales report but there are titles to update, still do that
                    if not new_asins_from_sales and title_updates > 0:
                        st.session_state.debug_messages.append(f"No new ASINs to add, but updated {title_updates} existing ASINs with titles")
                    
                    # If the branded_asins_data is empty but we have ASINs in the sales report, add all of them
                    if not st.session_state.client_config['branded_asins_data'] and len(sales_asins_df) > 0:
                        st.session_state.debug_messages.append(f"Branded ASINs list is empty. Adding all {len(sales_asins_df)} ASINs from sales report.")
                        for _, row in sales_asins_df.iterrows():
                            asin = str(row[asin_col]).strip().upper()
                            title = row['Title']
                            if not asin or pd.isna(asin) or str(asin).strip() == '' or str(asin).lower() == 'nan':
                                continue
                                
                            if pd.isna(title) or str(title).strip() == '' or str(title).lower() == 'nan':
                                title = 'Title not available'
                            else:
                                title = str(title).strip()
                                
                            new_asins_from_sales.append(asin)
                            new_asins_titles[asin] = title
                    
                    # Store new ASINs in session state for user confirmation
                    if new_asins_from_sales:
                        st.session_state.new_sales_asins = new_asins_from_sales
                        st.session_state.new_sales_asins_titles = new_asins_titles
                        st.session_state.show_new_sales_asins_prompt = True
                        st.session_state.debug_messages.append(f"Setting show_new_sales_asins_prompt to True with {len(new_asins_from_sales)} ASINs")
                    else:
                        st.session_state.new_sales_asins = []
                        st.session_state.new_sales_asins_titles = {}
                        st.session_state.show_new_sales_asins_prompt = False
                    
                    # Save the updated config (for title updates only at this point)
                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                    
                    # Also update existing ASINs with titles from the sales report
                    title_updates = 0
                    for asin in st.session_state.client_config['branded_asins_data']:
                        asin_match = sales_asins_df[sales_asins_df[asin_col] == asin]
                        if not asin_match.empty and 'Title' in asin_match.columns:
                            title = asin_match['Title'].iloc[0]
                            if title and str(title).strip() != '' and str(title).lower() != 'nan' and title != 'Title not available':
                                if st.session_state.client_config['branded_asins_data'][asin]['product_title'] == 'Title not available':
                                    st.session_state.client_config['branded_asins_data'][asin]['product_title'] = title
                                    title_updates += 1
                    
                    if title_updates > 0:
                        st.session_state.debug_messages.append(f"Updated {title_updates} existing ASINs with titles from sales report")
                        save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
            
            # Create DataFrame for display with columns in the specified order
            if st.session_state.client_config['branded_asins_data']:
                data = []
                for asin, info in st.session_state.client_config['branded_asins_data'].items():
                    data.append({
                        'Product Group': info.get('product_group', ''),
                        'ASIN': asin,
                        'Product Title': info.get('product_title', 'Title not available'),
                        'Delete': False  # Add Delete column with default value False
                    })
                
                branded_asins_df = pd.DataFrame(data)

                # -----------------------------------------------------------------------------
                # Product Group Auto-Tagging Rules (based on Product Title)
                # -----------------------------------------------------------------------------
                # Initialize rule storage in session state
                # Sync Product Title → Product Group tagging rules from client config each run
                if st.session_state.client_config and not st.session_state.get('asin_title_tag_rules'):
                    cfg_rules = st.session_state.client_config.get('asin_title_tag_rules', [])
                    st.session_state.asin_title_tag_rules = cfg_rules.copy()
                if 'asin_rule_modal_open' not in st.session_state:
                    st.session_state.asin_rule_modal_open = False

                # Helper to obtain Streamlit dialog/expander (mirrors Campaign Tagging implementation)
                from contextlib import nullcontext  # noqa: E402 – local import ok in Streamlit script
                def get_asin_dialog(title):
                    dlg_fn = getattr(st, 'dialog', None)
                    if callable(dlg_fn):
                        dlg = dlg_fn(title)
                        if hasattr(dlg, '__enter__') and hasattr(dlg, '__exit__'):
                            return dlg
                    return st.expander(title, expanded=True)

                # Modal for creating / editing rules ------------------------------------------------
                from typing import Optional  # Added for type hints compatible with Python 3.9

                def open_asin_rule_modal(edit_idx: Optional[int] = None):
                    """Open the Product Group rule builder for ASIN titles."""
                    if edit_idx is not None:
                        st.session_state.temp_asin_rule = st.session_state.asin_title_tag_rules[edit_idx].copy()
                        st.session_state.temp_asin_rule['edit_idx'] = edit_idx
                    else:
                        st.session_state.temp_asin_rule = {
                            'conditions': [{'operator': 'contains', 'value': ''}],
                            'combine': 'AND',
                            'tag': ''
                        }
                    st.session_state.asin_rule_modal_open = True

                # Render the rule-builder modal when requested
                if st.session_state.asin_rule_modal_open:
                    with get_asin_dialog("Create / Edit Product Group Rule"):
                        rule = st.session_state.temp_asin_rule

                        st.markdown("### Product Group to assign")
                        rule['tag'] = st.text_input("Product Group", value=rule.get('tag', ''), key="asin_rule_modal_tag")

                        st.markdown("### Conditions (evaluated against Product Title)")
                        rule['combine'] = st.selectbox(
                            "Combine all conditions with",
                            ["AND", "OR"],
                            index=0 if rule.get('combine', 'AND') == 'AND' else 1,
                            key="asin_rule_modal_combine"
                        )

                        # Render conditions list ----------------------------------------------
                        remove_cond_indices: list[int] = []
                        for c_idx, cond in enumerate(rule['conditions']):
                            col_op, col_val, col_del = st.columns([0.25, 0.6, 0.15])
                            with col_op:
                                cond['operator'] = st.selectbox(
                                    "Operator",
                                    ["contains", "doesn't contain"],
                                    index=0 if cond.get('operator', 'contains') == 'contains' else 1,
                                    key=f"asin_cond_operator_{c_idx}"
                                )
                            with col_val:
                                cond['value'] = st.text_input(
                                    "Value",
                                    value=cond.get('value', ''),
                                    key=f"asin_cond_value_{c_idx}"
                                )
                            with col_del:
                                if st.button("🗑️", key=f"asin_cond_del_{c_idx}"):
                                    remove_cond_indices.append(c_idx)
                        # Remove marked conditions
                        for i in sorted(remove_cond_indices, reverse=True):
                            del rule['conditions'][i]

                        if st.button("Add Condition", key="asin_add_condition_btn"):
                            rule['conditions'].append({'operator': 'contains', 'value': ''})

                        col_save, col_cancel = st.columns(2)
                        with col_save:
                            if st.button("Save", key="asin_save_rule_btn"):
                                # Validate rule – must have tag and at least one condition value
                                if rule['tag'] and any(cond['value'] for cond in rule['conditions']):
                                    if 'edit_idx' in rule:
                                        st.session_state.asin_title_tag_rules[rule['edit_idx']] = {
                                            k: rule[k] for k in ['conditions', 'combine', 'tag']
                                        }
                                    else:
                                        st.session_state.asin_title_tag_rules.append({
                                            k: rule[k] for k in ['conditions', 'combine', 'tag']
                                        })
                                    # Persist to client config
                                    st.session_state.client_config['asin_title_tag_rules'] = st.session_state.asin_title_tag_rules
                                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                                    st.session_state.asin_rule_modal_open = False
                                    st.session_state.temp_asin_rule = None
                                    st.rerun()
                                else:
                                    st.warning("Please provide at least one condition value and a Product Group.")
                        with col_cancel:
                            if st.button("Cancel", key="asin_cancel_rule_btn"):
                                st.session_state.asin_rule_modal_open = False
                                st.session_state.temp_asin_rule = None

                # Create an expander for the Bulk Tag ASINs by Rulesets section
                with st.expander("Bulk Tag ASINs by Rulesets", expanded=False):
                    # Option to only tag ASINs whose Product Group is blank
                    only_blank_asin_rule = st.checkbox("Only tag un-tagged ASINs", key="asin_rule_only_blank")
                    
                    # ----------------------------- Saved Rules list -----------------------------------
                    st.markdown("### Saved Rules")
                    removal_indices: list[int] = []
                    for idx, rule in enumerate(st.session_state.asin_title_tag_rules):
                        cond_strings = []
                        for cond in rule.get('conditions', []):
                            op = 'contains' if cond.get('operator') == 'contains' else "doesn't contain"
                            cond_strings.append(f"Product Title {op} \"{cond.get('value', '')}\"")
                        summary = (f" {rule.get('combine', 'AND')} ").join(cond_strings)
                        summary += f"  →  **{rule.get('tag', '')}**"
                        col_summary, col_edit, col_del = st.columns([0.8, 0.1, 0.1])
                        with col_summary:
                            st.markdown(summary)
                        with col_edit:
                            if st.button("✏️", key=f"asin_rule_edit_{idx}"):
                                open_asin_rule_modal(edit_idx=idx)
                        with col_del:
                            if st.button("🗑️", key=f"asin_rule_del_{idx}"):
                                removal_indices.append(idx)
                    for i in sorted(removal_indices, reverse=True):
                        del st.session_state.asin_title_tag_rules[i]
                    if removal_indices:
                        st.session_state.client_config['asin_title_tag_rules'] = st.session_state.asin_title_tag_rules
                        save_client_config(st.session_state.selected_client_name, st.session_state.client_config)

                    # Button to add a new rule
                    if st.button("Add Rule", key="asin_add_rule"):
                        open_asin_rule_modal()

                    # Apply rules to branded ASINs ------------------------------------------------------
                    if st.button("Apply Product Group Rules", key="apply_asin_rules"):
                        asins_updated = 0
                        for asin, asin_info in st.session_state.client_config['branded_asins_data'].items():
                            # Skip already-tagged ASINs when checkbox selected
                            if only_blank_asin_rule and asin_info.get('product_group', '').strip():
                                continue
                            title_lower = str(asin_info.get('product_title', '')).lower()
                            # Evaluate rules in order
                            for rule in st.session_state.asin_title_tag_rules:
                                tag_val = rule.get('tag', '').strip()
                                if not tag_val:
                                    continue
                                conditions = rule.get('conditions', [])
                                if not conditions:
                                    continue
                                cond_results = []
                                for cond in conditions:
                                    val = cond.get('value', '').strip().lower()
                                    if not val:
                                        continue
                                    op = cond.get('operator', 'contains')
                                    if op == 'contains':
                                        cond_results.append(val in title_lower)
                                    else:
                                        cond_results.append(val not in title_lower)
                                if not cond_results:
                                    continue
                                combine = rule.get('combine', 'AND')
                                matched = all(cond_results) if combine == 'AND' else any(cond_results)
                                if matched:
                                    asin_info['product_group'] = tag_val
                                    asins_updated += 1
                                    break  # Stop at first matching rule
                        if asins_updated > 0:
                            save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                            st.success(f"Updated {asins_updated} ASINs with Product Groups")
                            st.rerun()
                        else:
                            st.info("No ASINs matched the rules.")
            
                # -----------------------------------------------------------------------------
                # Bulk ASIN Product Group Tagger
                # -----------------------------------------------------------------------------
                with st.expander("Bulk Tag ASINs by List", expanded=False):
                    bulk_pg = st.text_input("Product Group", key="bulk_asin_product_group")
                    asin_text = st.text_area(
                        "Paste ASINs (one per line or comma-separated)",
                        height=150,
                        key="bulk_asin_list_input"
                    )
                    bulk_only_blank = st.checkbox(
                        "Only tag ASINs with blank Product Group",
                        key="bulk_asin_only_blank"
                    )
                    if st.button("Apply Bulk Tags", key="apply_bulk_asin_tags"):
                        import re  # local import permissible in Streamlit script
                        if not bulk_pg.strip():
                            st.warning("Please enter a Product Group to assign.")
                        else:
                            asin_list = [x.strip().upper() for x in re.split('[,\s]+', asin_text) if x.strip()]
                            if not asin_list:
                                st.warning("Please paste at least one ASIN.")
                            else:
                                updated_count = 0
                                for asin_key, asin_info in st.session_state.client_config['branded_asins_data'].items():
                                    if asin_key.upper() in asin_list:
                                        if bulk_only_blank and asin_info.get('product_group', '').strip():
                                            continue
                                        asin_info['product_group'] = bulk_pg.strip()
                                        updated_count += 1
                                if updated_count > 0:
                                    save_client_config(
                                        st.session_state.selected_client_name,
                                        st.session_state.client_config
                                    )
                                    st.success(f"Updated {updated_count} ASIN(s) with Product Group '{bulk_pg.strip()}'")
                                    st.rerun()
                                else:
                                    st.info("No matching ASINs found or nothing to update.")

                # Add filter options
                # Display current Product Groups across Campaign Tagging and Branded ASINs tabs
                display_pgs = set()
                # From campaign_tags_data
                for info in st.session_state.client_config.get('campaign_tags_data', {}).values():
                    pg_val = str(info.get('tag_1', '')).strip()
                    if pg_val and pg_val.lower() != 'none':
                        display_pgs.add(pg_val)
                # From branded_asins_data
                for asin_info in st.session_state.client_config.get('branded_asins_data', {}).values():
                    pg_val = str(asin_info.get('product_group', '')).strip()
                    if pg_val and pg_val.lower() != 'none':
                        display_pgs.add(pg_val)
                if display_pgs:
                    styled_groups = []
                    colors = ['#6CA8FF', '#FFC107']
                    for idx, pg in enumerate(sorted(display_pgs)):
                        color = colors[idx % 2]
                        styled_groups.append(f"<span style='color:{color};'>{pg}</span>")
                    groups_html = ", ".join(styled_groups)
                else:
                    groups_html = "No Product Groups yet"

                st.markdown(f"""<div style='margin-top: 10px; margin-bottom: 10px;'>
                    <span style='font-weight: 500; color: #FFFFFF;'>Current Product Groups: </span>{groups_html}
                </div>""", unsafe_allow_html=True)
                
                col1, col2, col3, col4 = st.columns([0.25, 0.25, 0.4, 0.1])
                
                # Get unique product groups for the filter
                product_groups = set()
                
                # First, get product groups from the client config
                if st.session_state.get('client_config'):
                    # Get from branded_asins_data
                    if 'branded_asins_data' in st.session_state.client_config:
                        for asin_info in st.session_state.client_config['branded_asins_data'].values():
                            product_group = asin_info.get('product_group', '')
                            if product_group and product_group.strip():
                                product_groups.add(product_group)
                    
                    # Get from campaign_tags_data
                    if 'campaign_tags_data' in st.session_state.client_config:
                        for campaign_info in st.session_state.client_config['campaign_tags_data'].values():
                            product_group = campaign_info.get('tag_1', '') or 'Untagged Group'
                            if product_group and product_group.strip():
                                product_groups.add(product_group)
                
                # Then get from the dataframe if available
                if not branded_asins_df.empty and 'Product Group' in branded_asins_df.columns:
                    groups = branded_asins_df['Product Group'].dropna().unique()
                    product_groups.update([g for g in groups if g and g.strip()])
                
                # Convert to sorted list
                product_groups = sorted(list(product_groups))
                
                # Initialize session state for product group filter if not exists
                if 'asin_product_group_filter' not in st.session_state:
                    st.session_state.asin_product_group_filter = []
                
                with col1:
                    # Display debug info if needed
                    if 'debug' in st.session_state and st.session_state.debug:
                        st.write(f"Available product groups: {product_groups}")
                    
                    # Use a different variable name to avoid conflicts
                    asin_selected_groups = st.multiselect(
                        "Filter by Product Group(s)",
                        options=product_groups,
                        key="asin_product_group_filter"
                    )
                    # Store filter state
                    st.session_state.asin_filter_active = len(asin_selected_groups) > 0
                
                with col2:
                    filter_asin = st.text_input("Filter by ASIN", key="filter_asin")
                    
                with col3:
                    filter_title = st.text_input("Filter by Product Title", key="filter_title")
                    
                with col4:
                    st.markdown("""<div style='height: 32px;'></div>""", unsafe_allow_html=True)
                    show_blank = st.checkbox("Show Blank", key="show_blank_asins", help="Show only ASINs with blank Product Group")
                
                # Apply filters
                filtered_df = branded_asins_df
                
                # Apply product group filter if active
                if asin_selected_groups:
                    try:
                        if 'Product Group' in filtered_df.columns:
                            # Convert both sides to string to ensure consistent comparison
                            filtered_df['Product Group'] = filtered_df['Product Group'].astype(str)
                            filtered_df = filtered_df[filtered_df['Product Group'].isin([str(pg) for pg in asin_selected_groups])]
                            st.caption(f"Filtered by Product Group(s): {', '.join(asin_selected_groups)}")
                            
                            # Debug information
                            if 'debug' in st.session_state and st.session_state.debug:
                                st.write(f"Product groups in data: {filtered_df['Product Group'].unique()}")
                                st.write(f"Selected product groups: {asin_selected_groups}")
                                st.write(f"Filtered dataframe shape: {filtered_df.shape}")
                        else:
                            st.warning("Product Group column not found in data. Cannot apply filter.")
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append("[Performance by ASIN] Product Group column not found in data.")
                    except Exception as e:
                        st.error(f"Error applying product group filter: {e}")
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[Performance by ASIN] Error applying product group filter: {e}")
                            
                        # If there's an error, continue with the unfiltered dataframe
                        filtered_df = branded_asins_df
                if filter_asin:
                    filtered_df = filtered_df[filtered_df['ASIN'].str.contains(filter_asin, case=False)]
                if filter_title:
                    filtered_df = filtered_df[filtered_df['Product Title'].str.contains(filter_title, case=False)]
                if st.session_state.get('show_blank_asins', False):
                    filtered_df = filtered_df[filtered_df['Product Group'] == '']
                
                # Get all existing product groups for data validation
                existing_product_groups = set()
                for asin_info in st.session_state.client_config['branded_asins_data'].values():
                    product_group = asin_info.get('product_group', '')
                    if product_group and product_group.strip():
                        existing_product_groups.add(product_group.strip())
                
                # Always use fresh filtered data for edits to prevent stale state bugs
                # Ensure desired column arrangement
                desired_cols = ['ASIN', 'Product Title', 'Product Group', 'Delete']
                existing_cols = [c for c in desired_cols if c in filtered_df.columns]
                remaining_cols = [c for c in filtered_df.columns if c not in existing_cols]
                filtered_df = filtered_df[existing_cols + remaining_cols]
                st.session_state.branded_asins_editor_temp = filtered_df.copy()
                # Apply select-all flag to mark all Delete checkboxes
                if st.session_state.get('asin_select_all', False):
                    if 'Delete' in st.session_state.branded_asins_editor_temp.columns:
                        st.session_state.branded_asins_editor_temp['Delete'] = True
                    st.session_state.asin_select_all = False

                # Display the editable table with the temp DataFrame
                edited_df = st.data_editor(
                    st.session_state.branded_asins_editor_temp,
                    key="branded_asins_editor",
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        'ASIN': st.column_config.TextColumn('ASIN', disabled=True),
                        'Product Title': st.column_config.TextColumn('Product Title', disabled=True),
                        'Product Group': st.column_config.TextColumn('Product Group'),
                        'Delete': st.column_config.CheckboxColumn('Delete Row')
                    }
                )
                st.session_state.branded_asins_editor_temp = edited_df.copy()

                # --- Action Buttons ---
                col_save, col_remove, col_delete_sel, col_select_all = st.columns([1,1,1,1])
                with col_save:
                    if st.button("Save Changes", key="save_branded_asins"):
                        # Write changes to config
                        for _, row in st.session_state.branded_asins_editor_temp.iterrows():
                            asin = row['ASIN']
                            product_group = row['Product Group']
                            if asin in st.session_state.client_config['branded_asins_data']:
                                st.session_state.client_config['branded_asins_data'][asin]['product_group'] = product_group
                        save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                        st.success("Branded ASINs updated.")
                with col_delete_sel:
                    if st.button("Delete Selected Rows", key="delete_branded_asins_btn"):
                        rows_to_delete = st.session_state.branded_asins_editor_temp[st.session_state.branded_asins_editor_temp['Delete'] == True]
                        if not rows_to_delete.empty:
                            for _, row in rows_to_delete.iterrows():
                                asin = row['ASIN']
                                if asin in st.session_state.client_config['branded_asins_data']:
                                    del st.session_state.client_config['branded_asins_data'][asin]
                            save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                            st.success(f"{len(rows_to_delete)} ASINs deleted successfully.")
                            st.rerun()
                        else:
                            st.info("No rows selected for deletion.")
                with col_remove:
                    if st.button("Remove Rows (Custom)", key="remove_all_asins_btn", help="Open options to remove or clear ASIN rows"):
                        st.session_state.show_remove_asins_dialog = True
                with col_select_all:
                    if st.button("Select All Rows", key="select_all_asin_rows"):
                        st.session_state.asin_select_all = True
                        st.rerun()
                
                # Show confirmation dialog if triggered
                if st.session_state.get('show_remove_asins_dialog', False):
                    st.markdown("---")
                    st.markdown("""<div style='padding: 15px; background-color: rgba(255, 193, 7, 0.1); border: 2px solid #ffc107; border-radius: 8px; margin: 10px 0;'>
                        <h4 style='margin: 0 0 10px 0; color: #856404;'>⚠️ Remove All Branded ASIN Rows</h4>
                        <p style='margin: 0; color: #856404;'>This will remove all ASIN rows. Are you sure?</p>
                    </div>""", unsafe_allow_html=True)
                    confirm_col1, confirm_col2 = st.columns(2)
                    with confirm_col1:
                        if st.button("🗑️ Delete All Rows", key="confirm_delete_all_asins"):
                            st.session_state.client_config['branded_asins_data'] = {}
                            save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                            st.session_state.show_remove_asins_dialog = False
                            st.success("All branded ASIN rows removed.")
                            st.rerun()
                    with confirm_col2:
                        if st.button("Cancel", key="cancel_delete_all_asins"):
                            st.session_state.show_remove_asins_dialog = False
                            st.rerun()

            else:
                st.info("No branded ASINs found. Upload a Sales Report to automatically extract ASINs.")
        
        with settings_tab3:
            st.markdown("""
    <h4 style='font-family:'Inter','Roboto','Segoe UI',Arial,sans-serif; font-size:0.98rem; font-weight:600; color:#6c757d; margin-top:1.4rem; margin-bottom:0.7rem;'>
        Campaign Tagging
    </h4>""", unsafe_allow_html=True)
            
            # Initialize campaign_tags_data if not present in client config
            if 'campaign_tags_data' not in st.session_state.client_config:
                st.session_state.client_config['campaign_tags_data'] = {}
            
            # Initialize dialog state
            if 'show_remove_rows_dialog' not in st.session_state:
                st.session_state.show_remove_rows_dialog = False
                
            # Add automatic tagging functionality with improved UI inside an expander
            with st.expander("Auto-Tag Campaigns", expanded=False):
                st.markdown("""<div style='margin-bottom: 15px;'></div>""", unsafe_allow_html=True)
                
                # Checkbox for processing only un-tagged campaigns in auto-tagging
                only_blank_auto = st.checkbox("Only tag un-tagged campaigns", key="auto_only_blank")
                
                col1, col2 = st.columns([0.7, 0.3])
                with col1:
                    auto_tag_threshold = st.slider(
                        "Minimum percentage of ASINs from the same Product Group to auto-tag a campaign",
                        min_value=50, max_value=100, value=65, step=5,
                        help="If a campaign has at least this percentage of ASINs from the same Product Group, it will be automatically tagged with that Product Group name."
                    )
                with col2:
                    st.markdown("""<div style='height: 32px;'></div>""", unsafe_allow_html=True)
                if st.button("Auto-Tag Campaigns", help="Automatically tag campaigns based on the ASINs they target", use_container_width=True):
                    if 'bulk_data' in st.session_state and st.session_state.bulk_data and 'branded_asins_data' in st.session_state.client_config:
                        # Get product groups from branded_asins_data
                        product_groups = {}
                        for asin, info in st.session_state.client_config['branded_asins_data'].items():
                            group = info.get('product_group', '')
                            if group:  # Only include ASINs with a product group
                                product_groups[asin.upper()] = group
                        
                        if product_groups:
                            # Process each campaign in the bulk file
                            campaigns_tagged = 0
                            for sheet_name, df in st.session_state.bulk_data.items():
                                # Check if required columns exist (case-insensitive)
                                campaign_col = None
                                asin_col = None
                                state_col = None
                                
                                for col in df.columns:
                                    if col.lower() == 'campaign name' or col.lower() == 'campaign name (informational only)':
                                        campaign_col = col
                                    elif col.lower() == 'asin' or col.lower() == 'asin (informational only)':
                                        asin_col = col
                                    elif col.lower() == 'state':
                                        state_col = col
                                
                                if campaign_col and asin_col and state_col:
                                    # Remove state filtering - include all rows regardless of state
                                    all_rows = df
                                    
                                    campaign_asins = {}
                                    for _, row in all_rows.iterrows():
                                        campaign_name = row[campaign_col]
                                        product_type = str(row.get('Product', ''))
                                        
                                        # Enhanced logic for Sponsored Brands: use 'Creative ASINs' column
                                        if product_type.strip().lower() == 'sponsored brands' and 'creative asins' in df.columns:
                                            creative_asins = str(row.get('Creative ASINs', '')).strip()
                                            asin_list = [a.strip().upper() for a in creative_asins.split(',') if a.strip().upper().startswith('B0') and len(a.strip().upper()) == 10]
                                            for asin in asin_list:
                                                if campaign_name and asin and asin in product_groups:
                                                    if campaign_name not in campaign_asins:
                                                        campaign_asins[campaign_name] = []
                                                    campaign_asins[campaign_name].append((asin, product_groups[asin]))
                                        else:
                                            # Original logic for other campaign types
                                            asin = str(row[asin_col]).strip().upper() if not pd.isna(row[asin_col]) else None
                                            if campaign_name and asin and asin in product_groups:
                                                if campaign_name not in campaign_asins:
                                                    campaign_asins[campaign_name] = []
                                                campaign_asins[campaign_name].append((asin, product_groups[asin]))
                                    
                                    # Analyze each campaign and tag if threshold is met
                                    for campaign_name, asins_list in campaign_asins.items():
                                        if len(asins_list) > 0:
                                            # Count ASINs by product group
                                            group_counts = {}
                                            for _, group in asins_list:
                                                group_counts[group] = group_counts.get(group, 0) + 1
                                            
                                            # Find the most common product group
                                            total_asins = len(asins_list)
                                            max_group = max(group_counts.items(), key=lambda x: x[1])
                                            max_group_name, max_count = max_group
                                            percentage = (max_count / total_asins) * 100
                                            
                                            # Tag if threshold is met
                                            if percentage >= auto_tag_threshold:
                                                # Update campaign tag if it exists in campaign_tags_data
                                                if campaign_name in st.session_state.client_config['campaign_tags_data']:
                                                    # Check if we should only tag blank campaigns
                                                    if only_blank_auto and st.session_state.client_config['campaign_tags_data'][campaign_name]['tag_1']:
                                                        # Skip this campaign as it already has a tag
                                                        pass
                                                    else:
                                                        st.session_state.client_config['campaign_tags_data'][campaign_name]['tag_1'] = max_group_name
                                                        campaigns_tagged += 1
                            
                            # Save the updated config
                            save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                            
                            if campaigns_tagged > 0:
                                st.markdown(f"""<div class='success-box'>
                                    <span style='font-weight: 500;'>Successfully auto-tagged {campaigns_tagged} campaigns based on product groups</span>
                                </div>""", unsafe_allow_html=True)
                            else:
                                st.markdown("""<div class='info-box'>
                                    <span style='font-weight: 500;'>No campaigns met the threshold for auto-tagging</span>
                                </div>""", unsafe_allow_html=True)
                        else:
                            st.markdown("""<div class='warning-box'>
                                <span style='font-weight: 500;'>No product groups found. Please assign product groups to your ASINs in the Branded ASINs tab first.</span>
                            </div>""", unsafe_allow_html=True)
                    else:
                        st.markdown("""<div class='warning-box'>
                            <span style='font-weight: 500;'>Please upload a Bulk File and set up Product Groups in the Branded ASINs tab first.</span>
                        </div>""", unsafe_allow_html=True)
            
            # -----------------------------------------------------------------------------
            # Campaign Name → Product Group Tagging Rules
            # -----------------------------------------------------------------------------
            
            # Initialize rule storage & modal helper state
            # Sync Campaign Name → Product Group tagging rules from client config each run
            if st.session_state.client_config and not st.session_state.get('campaign_name_tag_rules'):
                cfg_rules = st.session_state.client_config.get('campaign_name_tag_rules', [])
                st.session_state.campaign_name_tag_rules = cfg_rules.copy()
            if 'rule_modal_open' not in st.session_state:
                st.session_state.rule_modal_open = False
            if 'temp_rule' not in st.session_state:
                st.session_state.temp_rule = None
            
            # Put the ruleset functionality in a dropdown
            with st.expander("Bulk Tag Campaigns by Rulesets", expanded=False):
                st.markdown("""<div style='margin-bottom: 15px;'></div>""", unsafe_allow_html=True)
                
                # Checkbox for processing only un-tagged campaigns
                only_blank_rule = st.checkbox("Only tag un-tagged campaigns", key="rule_only_blank")
                
                # -----------------------------------------------------------------------------
                # Helper to obtain a dialog-like container (fallback to container with header to avoid nested expanders)
                from contextlib import contextmanager
                
                @contextmanager
                def simple_container(title):
                    """Create a simple container with a header to avoid nested expanders"""
                    st.markdown(f"### {title}")
                    st.markdown("---")
                    yield
                    st.markdown("---")
                
                def get_dialog(title):
                    dialog_func = getattr(st, 'dialog', None)
                    if callable(dialog_func):
                        dlg = dialog_func(title)
                        # Verify the returned object implements context manager protocol
                        if hasattr(dlg, '__enter__') and hasattr(dlg, '__exit__'):
                            return dlg
                    # Fallback: use simple container to avoid nested expanders
                    return simple_container(title)
    
                # Modal dialog for adding / editing rules
                # -----------------------------------------------------------------------------
                def open_rule_modal(edit_idx=None):
                    """Open the rule creation / editing modal."""
                    # If edit, start with existing rule; else blank
                    if edit_idx is not None:
                        st.session_state.temp_rule = st.session_state.campaign_name_tag_rules[edit_idx].copy()
                        st.session_state.temp_rule['edit_idx'] = edit_idx
                    else:
                        st.session_state.temp_rule = {
                            'conditions': [{'operator': 'contains', 'value': ''}],
                            'combine': 'AND',
                            'tag': ''
                        }
                    st.session_state.rule_modal_open = True

                if st.session_state.rule_modal_open:
                    with get_dialog("Create / Edit Tagging Rule"):
                        rule = st.session_state.temp_rule

                        st.markdown("### Product Group to assign")
                        rule['tag'] = st.text_input("Product Group", value=rule.get('tag', ''), key="rule_modal_tag")

                        st.markdown("### Conditions")
                        rule['combine'] = st.selectbox("Combine all conditions with", ["AND", "OR"],
                                                      index=0 if rule.get('combine', 'AND') == 'AND' else 1,
                                                      key="rule_modal_combine")
                        # Render conditions
                        remove_cond_indices = []
                        for c_idx, cond in enumerate(rule['conditions']):
                            col_op, col_val, col_del = st.columns([0.25, 0.6, 0.15])
                            with col_op:
                                cond['operator'] = st.selectbox(
                                    "Operator",
                                    ["contains", "doesn't contain"],
                                    index=0 if cond.get('operator', 'contains') == 'contains' else 1,
                                    key=f"cond_operator_{c_idx}")
                            with col_val:
                                cond['value'] = st.text_input("Value", value=cond.get('value', ''), key=f"cond_value_{c_idx}")
                            with col_del:
                                if st.button("🗑️", key=f"cond_del_{c_idx}"):
                                    remove_cond_indices.append(c_idx)
                        for i in sorted(remove_cond_indices, reverse=True):
                            del rule['conditions'][i]

                        if st.button("Add Condition", key="add_condition_btn"):
                            rule['conditions'].append({'operator': 'contains', 'value': ''})

                        col_save, col_cancel = st.columns(2)
                        with col_save:
                            if st.button("Save", key="save_rule_btn"):
                                # Validate rule
                                if rule['tag'] and any(cond['value'] for cond in rule['conditions']):
                                    if 'edit_idx' in rule:
                                        st.session_state.campaign_name_tag_rules[rule['edit_idx']] = {k: rule[k] for k in ['conditions','combine','tag']}
                                    else:
                                        st.session_state.campaign_name_tag_rules.append({k: rule[k] for k in ['conditions','combine','tag']})
                                    # Persist to client config
                                    st.session_state.client_config['campaign_name_tag_rules'] = st.session_state.campaign_name_tag_rules
                                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                                    st.session_state.rule_modal_open = False
                                    st.session_state.temp_rule = None
                                    st.rerun()
                                else:
                                    st.warning("Please provide at least one condition value and a Product Group.")
                        with col_cancel:
                            if st.button("Cancel", key="cancel_rule_btn"):
                                st.session_state.rule_modal_open = False
                                st.session_state.temp_rule = None

                # -----------------------------------------------------------------------------
                # Display existing rules
                st.markdown("### Saved Rules")
                removal_indices = []
                for idx, rule in enumerate(st.session_state.campaign_name_tag_rules):
                    # Build human-readable summary
                    cond_strings = []
                    for cond in rule.get('conditions', []):
                        op = 'contains' if cond.get('operator') == 'contains' else "doesn't contain"
                        cond_strings.append(f"Campaign Name {op} \"{cond.get('value','')}\"")
                    summary = (f" {rule.get('combine','AND')} ").join(cond_strings)
                    summary += f"  →  **{rule.get('tag','')}**"
                    col_summary, col_edit, col_del = st.columns([0.8,0.1,0.1])
                    with col_summary:
                        st.markdown(summary)
                    with col_edit:
                        if st.button("✏️", key=f"rule_edit_{idx}"):
                            open_rule_modal(edit_idx=idx)
                    with col_del:
                        if st.button("🗑️", key=f"rule_del_{idx}"):
                            removal_indices.append(idx)
                for i in sorted(removal_indices, reverse=True):
                    del st.session_state.campaign_name_tag_rules[i]
                if removal_indices:
                    st.session_state.client_config['campaign_name_tag_rules'] = st.session_state.campaign_name_tag_rules
                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)

                # Button to add a new blank rule
                if st.button("Add Rule", key="add_rule"):
                    open_rule_modal()

                # Apply rules button
                if st.button("Apply Tagging Rules", key="apply_rules"):
                    campaigns_updated = 0
                    for campaign_name, info in st.session_state.client_config['campaign_tags_data'].items():
                        # Skip already-tagged campaigns when checkbox selected
                        if only_blank_rule and info.get('tag_1', ''):
                            continue

                        # Evaluate rules in order (top priority first)
                        for rule in st.session_state.campaign_name_tag_rules:
                            tag_val = rule.get('tag','').strip()
                            if not tag_val:
                                continue
                            conditions = rule.get('conditions',[])
                            if not conditions:
                                continue
                            # Evaluate each condition
                            condition_results = []
                            for cond in conditions:
                                val = cond.get('value','').strip().lower()
                                if not val:
                                    continue
                                op = cond.get('operator','contains')
                                if op == 'contains':
                                    condition_results.append(val in campaign_name.lower())
                                else:
                                    condition_results.append(val not in campaign_name.lower())
                            if not condition_results:
                                continue
                            if rule.get('combine','AND') == 'AND':
                                matches = all(condition_results)
                            else:
                                matches = any(condition_results)
                            if matches:
                                if info.get('tag_1', '') != tag_val:
                                    st.session_state.client_config['campaign_tags_data'][campaign_name]['tag_1'] = tag_val
                                    campaigns_updated += 1
                                break  # stop at first matching rule

                    # Persist changes
                    save_client_config(st.session_state.selected_client_name, st.session_state.client_config)

                    if campaigns_updated:
                        st.markdown(f"""<div class='success-box'>
                            <span style='font-weight: 500;'>Successfully tagged {campaigns_updated} campaign(s) based on rules</span>
                        </div>""", unsafe_allow_html=True)
                    else:
                        st.markdown("""<div class='info-box'>
                            <span style='font-weight: 500;'>No campaigns matched the rules or all were already tagged</span>
                        </div>""", unsafe_allow_html=True)
            
            # -----------------------------------------------------------------------------
            # Get campaign data from bulk file if available
            if 'bulk_data' in st.session_state and st.session_state.bulk_data:
                # Dictionary to store unique campaigns with their types
                campaign_data = {}
                
                # Campaign type mapping
                campaign_type_map = {
                    'Sponsored Products Campaigns': 'Sponsored Products',
                    'Sponsored Brands Campaigns': 'Sponsored Brands',
                    'Sponsored Display Campaigns': 'Sponsored Display'
                }
                
                # Process each sheet to extract campaigns
                for sheet_name, df in st.session_state.bulk_data.items():
                    if sheet_name in campaign_type_map:
                        campaign_type = campaign_type_map[sheet_name]
                        
                        # Check if required columns exist
                        if 'Campaign Name' in df.columns and 'State' in df.columns and 'Entity' in df.columns:
                            # Remove state filtering - include all campaigns regardless of state
                            all_campaigns = df[df['Entity'] == 'Campaign']
                            # Extract unique campaign names
                            for _, row in all_campaigns.drop_duplicates(subset=['Campaign Name']).iterrows():
                                campaign_name = row['Campaign Name']
                                
                                # Only add if not already in the data
                                if campaign_name not in campaign_data:
                                    campaign_data[campaign_name] = campaign_type
                
                # Update the campaign_tags_data with new campaigns from bulk file
                for campaign_name, campaign_type in campaign_data.items():
                    if campaign_name not in st.session_state.client_config['campaign_tags_data']:
                        st.session_state.client_config['campaign_tags_data'][campaign_name] = {
                            'campaign_type': campaign_type,
                            'tag_1': ''
                        }
                    # Update campaign type if it was previously not available
                    elif st.session_state.client_config['campaign_tags_data'][campaign_name]['campaign_type'] == '':
                        st.session_state.client_config['campaign_tags_data'][campaign_name]['campaign_type'] = campaign_type
                
                # Save the updated config
                save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
            
            # Create DataFrame for display
            if st.session_state.client_config['campaign_tags_data']:
                data = []
                for campaign_name, info in st.session_state.client_config['campaign_tags_data'].items():
                    data.append({
                        'Campaign Name': campaign_name,
                        'Campaign Type': info.get('campaign_type', ''),
                        'Product Group': info.get('tag_1', ''),
                        'Delete': False
                    })
                
                campaigns_df = pd.DataFrame(data)
                
                # Add filter options
                # Show current Product Groups from Campaign Tagging & Branded ASINs
                product_groups = set()
                # From campaign_tags_data
                for info in st.session_state.client_config.get('campaign_tags_data', {}).values():
                    pg_val = str(info.get('tag_1', '')).strip()
                    if pg_val and pg_val.lower() != 'none':
                        product_groups.add(pg_val)
                # From branded_asins_data
                for asin_info in st.session_state.client_config.get('branded_asins_data', {}).values():
                    pg_val = str(asin_info.get('product_group', '')).strip()
                    if pg_val and pg_val.lower() != 'none':
                        product_groups.add(pg_val)

                if product_groups:
                    styled_groups = []
                    colors = ['#6CA8FF', '#FFC107']
                    for idx, pg in enumerate(sorted(product_groups)):
                        color = colors[idx % 2]
                        styled_groups.append(f"<span style='color:{color};'>{pg}</span>")
                    groups_html = ", ".join(styled_groups)
                else:
                    groups_html = "No Product Groups yet"

                st.markdown(f"""<div style='margin-top: 20px; margin-bottom: 10px;'>
                    <span style='font-weight: 500; color: #FFFFFF;'>Current Product Groups: </span>{groups_html}
                </div>""", unsafe_allow_html=True)
                
                col1, col2, col3, col4 = st.columns([0.3, 0.3, 0.3, 0.1])
                
                with col1:
                    filter_name = st.text_input("Filter by Campaign Name", key="filter_campaign_name")
                
                with col2:
                    filter_type = st.text_input("Filter by Campaign Type", key="filter_campaign_type")
                    
                with col3:
                    filter_group = st.text_input("Filter by Product Group", key="filter_campaign_group")
                    
                with col4:
                    st.markdown("""<div style='height: 32px;'></div>""", unsafe_allow_html=True)
                    show_blank = st.checkbox("Show Blank", key="show_blank_campaigns", help="Show only campaigns with blank Product Group")
                
                # Apply filters
                filtered_df = campaigns_df
                if filter_name:
                    filtered_df = filtered_df[filtered_df['Campaign Name'].str.contains(filter_name, case=False)]
                if filter_type:
                    filtered_df = filtered_df[filtered_df['Campaign Type'].str.contains(filter_type, case=False)]
                if filter_group:
                    filtered_df = filtered_df[filtered_df['Product Group'].str.contains(filter_group, case=False)]
                if st.session_state.get('show_blank_campaigns', False):
                    filtered_df = filtered_df[filtered_df['Product Group'] == '']
                
                # Always use fresh filtered data for edits to prevent stale state bugs
                st.session_state.campaign_tags_editor_temp = filtered_df.copy()

                # If a select-all flag is set from the previous click, mark all rows for deletion and reset the flag
                if st.session_state.get('campaign_select_all', False):
                    if 'Delete' in st.session_state.campaign_tags_editor_temp.columns:
                        st.session_state.campaign_tags_editor_temp['Delete'] = True
                    st.session_state.campaign_select_all = False

                
                # Display the editable table with the temp DataFrame
                edited_df = st.data_editor(
                    st.session_state.campaign_tags_editor_temp,
                    key="campaign_tags_editor",
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        'Campaign Name': st.column_config.TextColumn('Campaign Name', disabled=True),
                        'Campaign Type': st.column_config.TextColumn('Campaign Type', disabled=True),
                        'Product Group': st.column_config.TextColumn('Product Group'),
                        'Delete': st.column_config.CheckboxColumn('Delete Row')
                    }
                )
                st.session_state.campaign_tags_editor_temp = edited_df.copy()

                # --- Action Buttons ---
                col_save, col_remove, col_delete_sel, col_select_all = st.columns([1,1,1,1])
                with col_save:
                    if st.button("Save Changes", key="save_campaign_tags"):
                        # Write changes to config
                        for _, row in st.session_state.campaign_tags_editor_temp.iterrows():
                            campaign_name = row['Campaign Name']
                            product_group = row['Product Group']
                            if campaign_name in st.session_state.client_config['campaign_tags_data']:
                                st.session_state.client_config['campaign_tags_data'][campaign_name]['tag_1'] = product_group
                        save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                        st.success("Campaign tags updated.")
                
                with col_delete_sel:
                    if st.button("Delete Selected Rows", key="delete_selected_campaigns"):
                        rows_to_delete = st.session_state.campaign_tags_editor_temp[st.session_state.campaign_tags_editor_temp['Delete'] == True]
                        if not rows_to_delete.empty:
                            for _, row in rows_to_delete.iterrows():
                                cname = row['Campaign Name']
                                if cname in st.session_state.client_config['campaign_tags_data']:
                                    del st.session_state.client_config['campaign_tags_data'][cname]
                            save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                            st.success(f"Deleted {len(rows_to_delete)} campaign(s) successfully.")
                            st.rerun()
                        else:
                            st.info("No rows selected for deletion.")
                with col_remove:
                    if st.button("Remove Rows (Custom)", key="remove_all_rows_btn", help="Open options to remove rows in bulk or refresh from Bulk File"):
                        # Set dialog state to show confirmation
                        st.session_state.show_remove_rows_dialog = True
                with col_select_all:
                    if st.button("Select All Rows", key="select_all_campaign_rows"):
                        st.session_state.campaign_select_all = True
                        st.rerun()
                
                # Show confirmation dialog if triggered
                if st.session_state.get('show_remove_rows_dialog', False):
                    st.markdown("---")
                    st.markdown("""<div style='padding: 15px; background-color: rgba(255, 193, 7, 0.1); border: 2px solid #ffc107; border-radius: 8px; margin: 10px 0;'>
                        <h4 style='margin: 0 0 10px 0; color: #856404;'>⚠️ Remove All Campaign Rows</h4>
                        <p style='margin: 0; color: #856404;'>Choose what you want to do with all campaign data:</p>
                    </div>""", unsafe_allow_html=True)
                    
                    dialog_col1, dialog_col2, dialog_col3, dialog_col4 = st.columns(4)
                    
                    with dialog_col1:
                        if st.button("🔄 Refresh (Untagged)", key="option_1_btn", use_container_width=True, help="Remove all current rows and reload fresh, untagged campaign data from your uploaded Bulk File."):
                            # Option 1: Delete all rows and refresh from bulk file, clearing all tags.
                            st.session_state.client_config['campaign_tags_data'] = {}
                            
                            # Refresh campaigns from bulk file
                            if 'bulk_data' in st.session_state and st.session_state.bulk_data:
                                campaign_data = get_campaigns_from_bulk_file(st.session_state.bulk_data)
                                
                                # Update the campaign_tags_data with new campaigns from bulk file
                                for campaign_name, campaign_type in campaign_data.items():
                                    st.session_state.client_config['campaign_tags_data'][campaign_name] = {
                                        'campaign_type': campaign_type,
                                        'tag_1': ''
                                    }
                                
                                save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                                st.session_state.show_remove_rows_dialog = False
                                st.success(f"Removed all rows and refreshed {len(campaign_data)} campaigns from Bulk File.")
                                st.rerun()
                            else:
                                save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                                st.session_state.show_remove_rows_dialog = False
                                st.success("All campaign rows removed. No Bulk File available to refresh from.")
                                st.rerun()

                    with dialog_col2:
                        if st.button("🔄 Refresh & Keep Tags", key="option_3_btn", use_container_width=True, help="Reload campaigns from the Bulk File, keeping any existing tags."):
                            # Option 3: Refresh from bulk file but keep existing tags
                            existing_tags = {name: info.get('tag_1', '') for name, info in st.session_state.client_config.get('campaign_tags_data', {}).items()}
                            
                            st.session_state.client_config['campaign_tags_data'] = {}

                            if 'bulk_data' in st.session_state and st.session_state.bulk_data:
                                campaign_data = get_campaigns_from_bulk_file(st.session_state.bulk_data)
                                
                                for campaign_name, campaign_type in campaign_data.items():
                                    st.session_state.client_config['campaign_tags_data'][campaign_name] = {
                                        'campaign_type': campaign_type,
                                        'tag_1': existing_tags.get(campaign_name, '') # Keep old tag if it exists
                                    }
                                
                                save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                                st.session_state.show_remove_rows_dialog = False
                                st.success(f"Refreshed {len(campaign_data)} campaigns and preserved existing tags.")
                                st.rerun()
                            else:
                                save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                                st.session_state.show_remove_rows_dialog = False
                                st.warning("Campaign data cleared, but no Bulk File was available to refresh from.")
                                st.rerun()

                    with dialog_col3:
                        if st.button("🗑️ Delete All Rows Only", key="option_2_btn", use_container_width=True, help="Remove all campaign rows without refreshing from Bulk File"):
                            # Option 2: Delete all rows without refreshing
                            st.session_state.client_config['campaign_tags_data'] = {}
                            save_client_config(st.session_state.selected_client_name, st.session_state.client_config)
                            st.session_state.show_remove_rows_dialog = False
                            st.success("All campaign rows removed.")
                            st.rerun()
                            
                    with dialog_col4:
                        if st.button("Cancel", key="cancel_remove_rows_btn", use_container_width=True):
                            st.session_state.show_remove_rows_dialog = False
                            st.rerun()

                # Show status message
                st.markdown("""<div style='padding: 8px 12px; background-color: rgba(76, 175, 80, 0.1); border-left: 3px solid #4CAF50; border-radius: 4px; margin-top: 10px;'>
                    <span style='color: #2E7D32; font-size: 0.9rem;'>✓ Use the Save Changes button to save your edits</span>
                </div>""", unsafe_allow_html=True)

            else:
                st.markdown("""<div class='warning-box' style='margin-top: 20px;'>
                    <span style='font-weight: 500;'>Upload a Bulk File to see and tag campaigns.</span>
                </div>""", unsafe_allow_html=True)
        
        # ACoS Goals tab removed

        # Auto-save is now implemented for each individual setting
        st.divider() # Separator
        st.markdown("""<div style='padding: 10px 15px; background-color: rgba(38, 39, 48, 0.03); border-radius: 4px; margin-top: 10px;'>
            <span style='color: #555; font-size: 0.9rem;'>✓ Use the Save Changes buttons to save your edits</span>
        </div>""", unsafe_allow_html=True)


    elif st.session_state.current_page == "advertising_audit":
        # Check if settings have been updated and refresh data if needed
        if st.session_state.get('settings_updated', False):
            # Clear any cached targeting data to force recalculation
            if 'targeting_data' in st.session_state:
                del st.session_state.targeting_data
            if 'branded_targets_df' in st.session_state:
                del st.session_state.branded_targets_df
            if 'non_branded_targets_df' in st.session_state:
                del st.session_state.non_branded_targets_df
            if 'classified_campaigns' in st.session_state:
                del st.session_state.classified_campaigns
            
            # Reset the flag
            st.session_state.settings_updated = False
            
            # Add a notification that data has been refreshed
            # Silently apply changes without toast notification
            
        # Professional header with title and logo
        client_name = st.session_state.client_config.get('client_name', 'Client') if st.session_state.get('client_config') else 'Client'
        
        # Load the logo
        logo_path = "assets/hand_logo.png"
        logo_html = ""
        if os.path.exists(logo_path):
            # Convert the image to base64 for inline HTML display
            with open(logo_path, "rb") as img_file:
                img_data = base64.b64encode(img_file.read()).decode('utf-8')
                logo_html = f'<img src="data:image/png;base64,{img_data}" class="header-logo" alt="Hand Logo">'
        
        # Create a professional header with title and logo on the same line
        st.markdown(f"""
            <div class='header-container'>
                <span class='dashboard-hero-title'>
                    Advertising Audit - <span class='client-name'>{client_name}</span>
                </span>
                {logo_html}
            </div>
            <div class='header-divider'></div>
        """, unsafe_allow_html=True)

        
        # Global Sales Attribution Toggle - only shown on Advertising Audit page and not for companion data
        is_companion = st.session_state.get('is_companion_data', False)
        st.session_state.debug_messages.append(f"Is companion data: {is_companion}")
        if not is_companion:
            # Create two columns to place controls side by side
            attr_col, sales_col = st.columns([1, 1])
            
            with attr_col:
                st.markdown("### Sales Attribution Model")
                
                sd_attribution_choice = st.radio(
                    "Sponsored Display Sales Attribution:",
                    ["Sales", "Sales (Views & Clicks)"],
                    horizontal=True,
                    help="Choose which sales attribution model to use for Sponsored Display campaigns. (Views & Clicks) attribution can cause inflated ad sales numbers, but these are the ad sales that would match the AMS UI",
                    key="global_sd_attribution"
                )
            
            with sales_col:
                # Check if we have sales report data to determine available Total Sales metrics
                sales_df = st.session_state.get('sales_report_data')
                available_sales_metrics = []
                
                # Add debug information
                st.session_state.debug_messages.append(f"Sales DataFrame type: {type(sales_df)}")
                if isinstance(sales_df, pd.DataFrame):
                    st.session_state.debug_messages.append(f"Sales DataFrame columns: {list(sales_df.columns)}")
                
                if isinstance(sales_df, pd.DataFrame):
                    # Define all possible Total Sales metric columns
                    potential_sales_metrics = [
                        'Ordered Revenue', 'Shipped Revenue', 'Ordered Product Sales', 
                        'Shipped Product Sales', 'Product Sales', 'Gross Product Sales', 
                        'Shipped COGS', 'Total Sales', 'Net Sales', 'Revenue'
                    ]
                    
                    # Check which of these metrics actually exist in the data
                    for metric in potential_sales_metrics:
                        if metric in sales_df.columns:
                            available_sales_metrics.append(metric)
                
                # Add debug information about found metrics
                st.session_state.debug_messages.append(f"Available sales metrics found: {available_sales_metrics}")
                st.session_state.debug_messages.append(f"Number of available metrics: {len(available_sales_metrics)}")
                
                # Only show the dropdown if there are multiple metrics available
                if len(available_sales_metrics) > 1:
                    st.session_state.debug_messages.append("Showing Total Sales metric dropdown")
                    st.markdown("### Total Sales Metric")
                    
                    # Initialize the selected metric in session state if not exists
                    if 'selected_total_sales_metric' not in st.session_state:
                        # Default to 'Total Sales' if it exists, otherwise use the first available
                        if 'Total Sales' in available_sales_metrics:
                            st.session_state.selected_total_sales_metric = 'Total Sales'
                        else:
                            st.session_state.selected_total_sales_metric = available_sales_metrics[0]
                    
                    selected_sales_metric = st.selectbox(
                        "Use which Total Sales metric?",
                        options=available_sales_metrics,
                        index=available_sales_metrics.index(st.session_state.selected_total_sales_metric),
                        help="Choose which sales metric column to use for Total Sales calculations throughout the dashboard",
                        key="total_sales_metric_selector"
                    )
                    
                    # Update session state and clear caches if selection changed
                    if st.session_state.selected_total_sales_metric != selected_sales_metric:
                        st.session_state.selected_total_sales_metric = selected_sales_metric
                        clear_caches()
                        st.session_state.debug_messages.append(f"Total Sales metric changed to: {selected_sales_metric}, caches cleared")
                        st.rerun()
                else:
                    # If only one metric available, store it in session state but don't show dropdown
                    if len(available_sales_metrics) == 1:
                        st.session_state.selected_total_sales_metric = available_sales_metrics[0]
                        st.session_state.debug_messages.append(f"Only one metric available: {available_sales_metrics[0]}, not showing dropdown")
                    else:
                        # No sales metrics found, default to 'Total Sales'
                        st.session_state.selected_total_sales_metric = 'Total Sales'
                        st.session_state.debug_messages.append("No sales metrics found, defaulting to 'Total Sales'")
        else:
            # For companion data, force to "Sales" since Views & Clicks data is not available
            sd_attribution_choice = "Sales"
        
        # Store the selection in session state for global access
        if 'sd_attribution_choice' not in st.session_state or st.session_state.sd_attribution_choice != sd_attribution_choice:
            # Attribution choice changed, clear caches to force refresh
            st.session_state.sd_attribution_choice = sd_attribution_choice
            clear_caches()
            st.session_state.debug_messages.append(f"Attribution model changed to: {sd_attribution_choice}, caches cleared")
            st.rerun()
        
        # Add debug information
        st.session_state.debug_messages.append(f"Global Sales Attribution set to: {sd_attribution_choice}")
        
        st.divider()
        
        # Create navigation bar for Advertising Audit sections
        st.markdown("""
            <style>
            .audit-nav-container {
                display: flex;
                justify-content: flex-end;
                align-items: center;
                padding-right: 1.5rem;
                gap: 0.7rem;
            }
            .audit-nav-link {
                font-size: 0.98rem;
            }
            </style>
            <div class="audit-nav-container" id="nav-bar">
                <a href="#account-overview" class="audit-nav-link" data-section="account-overview">Overview</a>
                <a href="#branded-vs-non-branded-performance" class="audit-nav-link" data-section="branded-vs-non-branded-performance">Branded vs. Non-Branded</a>
                <a href="#targeting-performance" class="audit-nav-link" data-section="targeting-performance">Targeting</a>
                <a href="#search-term-performance" class="audit-nav-link" data-section="search-term-performance">Search Terms</a>
                <a href="#contradicting-targets" class="audit-nav-link" data-section="contradicting-targets">Contradicting Targets</a>
                <a href="#wasted-spend" class="audit-nav-link" data-section="wasted-spend">Wasted Spend</a>
                <a href="#acos-range-spend-distribution" class="audit-nav-link" data-section="acos-range-spend-distribution">ACoS Distribution</a>
                <a href="#performance-by-tactic-ad-type-match-type" class="audit-nav-link" data-section="performance-by-tactic-ad-type-match-type">Tactic Performance</a>
                <a href="#product-analysis" class="audit-nav-link" data-section="product-analysis">Products</a>
            </div>
            
            <script>
            // JavaScript to handle active section highlighting
            document.addEventListener('DOMContentLoaded', function() {
                // Get all section anchors
                const sections = Array.from(document.querySelectorAll('.section-anchor'));
                const navLinks = document.querySelectorAll('.audit-nav-link');

                // Helper: get scroll position and section offset
                function getSectionTops() {
                    return sections.map(section => ({
                        id: section.id,
                        top: section.getBoundingClientRect().top + window.scrollY
                    }));
                }

                function highlightNavOnScroll() {
                    const scrollPos = window.scrollY + 110; // adjust for nav bar height
                    let currentSection = sections[0] ? sections[0].id : '';
                    let sectionTops = getSectionTops();

                    // Find the last section whose top is above scrollPos
                    for (let i = 0; i < sectionTops.length; i++) {
                        if (scrollPos >= sectionTops[i].top) {
                            currentSection = sectionTops[i].id;
                        }
                    }

                    navLinks.forEach(link => {
                        link.classList.remove('active');
                        if (link.getAttribute('data-section') === currentSection) {
                            link.classList.add('active');
                        }
                    });
                }

                // Navigation highlighting disabled per user request
                // window.addEventListener('scroll', highlightNavOnScroll);
                // window.addEventListener('resize', highlightNavOnScroll);
                // highlightNavOnScroll();
            });
            </script>
        """, unsafe_allow_html=True)
        
        # Display Account Overview directly without tabs
        
        # Add anchor for Account Overview with reduced padding
        st.markdown("<div id='account-overview' class='section-anchor'></div>", unsafe_allow_html=True)
        st.markdown("<span class='main-section-header dashboard-section'>Account Overview</span>", unsafe_allow_html=True)
        st.markdown("<div style='margin-bottom:0.5rem;'></div>", unsafe_allow_html=True)
        
        # Check if we have both bulk data and sales report data
        if 'bulk_data' in st.session_state and st.session_state.bulk_data and \
           'sales_report_data' in st.session_state and st.session_state.sales_report_data is not None:
            # Use the global sales attribution choice from session state
            sd_attribution_choice = st.session_state.sd_attribution_choice
            
            # Add debug information about column search
            st.session_state.debug_messages.append(f"Using global Sales Attribution: {sd_attribution_choice}")
            st.session_state.debug_messages.append(f"Looking for patterns: {['Sales', 'Total Sales', '7 Day Total Sales']}")
            st.session_state.debug_messages.append(f"Looking for patterns: {['Orders', '7 Day Total Orders (#)']}")
            
            # Process data for metrics
            try:
                bulk_data = st.session_state.bulk_data
                sales_df = st.session_state.sales_report_data
                combined_ad_data_list = []
                found_sheets = []
                
                # Define sheets to aggregate for ad performance
                ad_performance_sheets = [
                    'Sponsored Products Campaigns',
                    'Sponsored Brands Campaigns',
                    'Sponsored Display Campaigns'
                ]
                
                # Define column patterns to search for
                sales_patterns = ['Sales', 'Total Sales', '7 Day Total Sales']
                orders_patterns = ['Orders', '7 Day Total Orders (#)']
                
                # Define the Helper Function HERE
                def find_col_pattern(df_cols, patterns, case_sensitive=False):
                    """Finds the first matching column name from a list."""
                    # First try exact matches
                    for pattern in patterns:
                        if pattern in df_cols:
                            return pattern
                    
                    # Then try case-insensitive if allowed
                    if not case_sensitive:
                        df_cols_lower = [col.lower() for col in df_cols]
                        for pattern in patterns:
                            pattern_lower = pattern.lower()
                            if pattern_lower in df_cols_lower:
                                idx = df_cols_lower.index(pattern_lower)
                                return df_cols[idx]  # Return original case
                        
                    # Finally try partial matches
                    for pattern in patterns:
                        pattern_lower = pattern.lower()
                        for col in df_cols:
                            if pattern_lower in col.lower():
                                return col
                    
                    # If no match found
                    return None
                
                # --- 1. Aggregate Ad Data from Specific Campaign Sheets ---
                ad_spend_col = 'Spend'
                ad_imp_col = 'Impressions'
                ad_clicks_col = 'Clicks'
                
                # Iterate through the defined sheets
                for sheet_name in ad_performance_sheets:
                    if sheet_name in bulk_data:
                        found_sheets.append(sheet_name)
                        df_sheet = bulk_data[sheet_name]
                        
                        # Determine which sales column to use based on sheet type and user selection
                        if 'Sponsored Display' in sheet_name:
                            if sd_attribution_choice == "Sales (Views & Clicks)":
                                current_sales_patterns = ['Sales (Views & Clicks)', 'Total Sales (Views & Clicks)']
                            else:
                                current_sales_patterns = ['Sales']
                        else:
                            # For non-SD campaigns, always use the default sales patterns
                            current_sales_patterns = sales_patterns
                        
                        # Find the appropriate columns in this sheet
                        sheet_sales_col = find_col_pattern(df_sheet.columns, current_sales_patterns)
                        sheet_orders_col = find_col_pattern(df_sheet.columns, orders_patterns)
                        
                        # Check if required columns exist
                        missing_cols = [col for col in [ad_spend_col, ad_imp_col, ad_clicks_col] if col not in df_sheet.columns]
                        if missing_cols:
                            st.session_state.debug_messages.append(f"Missing required columns in {sheet_name}: {missing_cols}")
                            st.session_state.debug_messages.append(f"Available columns in {sheet_name}: {list(df_sheet.columns)}")
                            st.warning(f"Missing required metric columns in {sheet_name}: {missing_cols}. Skipping.")
                            continue
                        
                        # Extract and rename columns
                        cols_to_extract = {
                            ad_spend_col: 'Spend',
                            ad_imp_col: 'Impressions',
                            ad_clicks_col: 'Clicks'
                        }
                        
                        if sheet_sales_col:
                            cols_to_extract[sheet_sales_col] = 'Sales'
                        if sheet_orders_col:
                            cols_to_extract[sheet_orders_col] = 'Orders'
                        
                        # Handle different data types: Campaign vs Targeting data
                        filtered_df = df_sheet
                        if 'Entity' in df_sheet.columns:
                            # Check if we have campaign-level data or targeting-level data
                            entities = df_sheet['Entity'].str.lower().fillna('').unique()
                            has_campaign_rows = any('campaign' in entity for entity in entities)
                            has_targeting_rows = any(entity in ['keyword', 'product targeting', 'auto', 'product target'] for entity in entities)
                            
                            if has_campaign_rows:
                                # Use campaign-level data (traditional bulk data)
                                filtered_df = df_sheet[df_sheet['Entity'].str.lower().fillna('') == 'campaign']
                                st.session_state.debug_messages.append(f"Using campaign-level data from {sheet_name}: {len(filtered_df)} rows from {len(df_sheet)} total")
                            elif has_targeting_rows:
                                # Use all targeting data and aggregate (Targeting Export)
                                # Filter for enabled targeting rows only
                                state_mask = True
                                # Remove state filtering - include all data regardless of state
                                
                                targeting_mask = df_sheet['Entity'].str.lower().fillna('').isin(['keyword', 'product targeting', 'auto', 'product target'])
                                filtered_df = df_sheet[targeting_mask & state_mask]
                                st.session_state.debug_messages.append(f"Using targeting-level data from {sheet_name}: {len(filtered_df)} targeting rows from {len(df_sheet)} total")
                            else:
                                # No recognizable entity types, use all data
                                st.session_state.debug_messages.append(f"No recognized entity types in {sheet_name}, using all {len(df_sheet)} rows")
                        else:
                            st.session_state.debug_messages.append(f"No Entity column in {sheet_name}, using all {len(df_sheet)} rows")
                        
                        # Extract only the necessary columns
                        extracted_data = filtered_df[list(cols_to_extract.keys())].rename(columns=cols_to_extract)
                        
                        # Ensure all extracted columns are numeric
                        for col in extracted_data.columns:
                            extracted_data[col] = pd.to_numeric(extracted_data[col], errors='coerce')
                        
                        extracted_data = extracted_data.fillna(0)
                        combined_ad_data_list.append(extracted_data)
                    
                if combined_ad_data_list:
                    # Combine all the data
                    aggregated_ad_data = pd.concat(combined_ad_data_list, ignore_index=True)
                    
                    # Sum up the metrics
                    total_ad_spend = aggregated_ad_data['Spend'].sum()
                    total_impressions = aggregated_ad_data['Impressions'].sum()
                    total_clicks = aggregated_ad_data['Clicks'].sum()
                    total_ad_sales = aggregated_ad_data['Sales'].sum() if 'Sales' in aggregated_ad_data else 0
                    total_ad_orders = aggregated_ad_data['Orders'].sum() if 'Orders' in aggregated_ad_data else 0
                    
                    # Find total sales and sessions from sales report
                    # Use user-selected Total Sales metric if available, otherwise fall back to default search
                    if 'selected_total_sales_metric' in st.session_state and st.session_state.selected_total_sales_metric in sales_df.columns:
                        total_sales_col = st.session_state.selected_total_sales_metric
                    else:
                        total_sales_col = find_col_pattern(sales_df.columns, ['Total Sales'])
                    sessions_col = find_col_pattern(sales_df.columns, ['Sessions'])
                    
                    # Calculate total sales revenue
                    total_sales_revenue = None
                    if total_sales_col:
                        total_sales_revenue = pd.to_numeric(sales_df[total_sales_col], errors='coerce').sum()
                        
                        # Calculate total sessions
                        total_sessions = None
                        if sessions_col:
                            total_sessions = pd.to_numeric(sales_df[sessions_col], errors='coerce').sum()
                        
                        # Calculate KPIs
                        acos = (total_ad_spend / total_ad_sales) * 100 if total_ad_sales > 0 else 0
                        roas = total_ad_sales / total_ad_spend if total_ad_spend > 0 else 0
                        cpc = total_ad_spend / total_clicks if total_clicks > 0 else 0
                        cvr = (total_ad_orders / total_clicks) * 100 if total_clicks > 0 else 0
                        ctr = (total_clicks / total_impressions) * 100 if total_impressions > 0 else 0
                        aov = total_ad_sales / total_ad_orders if total_ad_orders > 0 else 0
                        cpa = total_ad_spend / total_ad_orders if total_ad_orders > 0 else 0
                        
                        # Calculate TACoS and Ad Traffic %
                        tacos = (total_ad_spend / total_sales_revenue) * 100 if total_sales_revenue and total_sales_revenue > 0 else None
                        ad_sales_perc = (total_ad_sales / total_sales_revenue) * 100 if total_sales_revenue and total_sales_revenue > 0 else None
                        ad_traffic_perc_sessions = (total_clicks / total_sessions) * 100 if total_sessions and total_sessions > 0 else None
                        
                        # Display metrics in a clean layout
                        st.markdown("""
    <h4 style='font-family:'Inter','Roboto','Segoe UI',Arial,sans-serif; font-size:1.0rem; font-weight:600; color:#bfa94a; margin-top:1.5rem; margin-bottom:0.7rem;'>
        Advertising Performance
    </h4>""", unsafe_allow_html=True)
                        
                        # First row of metrics
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("Spend", f"${total_ad_spend:,.2f}")
                        col2.metric("Ad Sales", f"${total_ad_sales:,.2f}" if total_ad_sales is not None else "N/A")
                        col3.metric("ACoS", f"{acos:.2f}%" if acos is not None else "N/A")
                        col4.metric("ROAS", f"{roas:.2f}x" if roas is not None else "N/A")
                        
                        # Second row of metrics
                        col5, col6, col7, col8 = st.columns(4)
                        col5.metric("CPC", f"${cpc:.2f}" if cpc is not None else "N/A")
                        col6.metric("CVR", f"{cvr:.2f}%" if cvr is not None else "N/A")
                        col7.metric("CTR", f"{ctr:.2f}%" if ctr is not None else "N/A")
                        col8.metric("AOV", f"${aov:.2f}" if aov is not None else "N/A")
                        
                        # Third row of metrics
                        col9, col10, col11, col12 = st.columns(4)
                        col9.metric("CPA", f"${cpa:.2f}" if cpa is not None else "N/A")
                        col10.metric("Impressions", f"{total_impressions:,}")
                        col11.metric("Clicks", f"{total_clicks:,}")
                        col12.metric("Orders", f"{total_ad_orders:,}" if total_ad_orders is not None else "N/A")
                        
                        st.divider()
                        st.markdown("""
    <h4 style='font-family:'Inter','Roboto','Segoe UI',Arial,sans-serif; font-size:1.0rem; font-weight:600; color:#bfa94a; margin-top:1.5rem; margin-bottom:0.7rem;'>
        Topline & Advertising Performance
    </h4>""", unsafe_allow_html=True)
                        
                        # Topline metrics
                        col13, col14, col15 = st.columns(3)
                        if total_sales_revenue is not None:
                            col13.metric("Total Sales", f"${total_sales_revenue:,.2f}", help=f"Using '{total_sales_col}' column")
                        else:
                            col13.metric("Total Sales", "N/A", help="'Total Sales' column not found in Sales Report.")
                        
                        if tacos is not None:
                            col14.metric("TACoS", f"{tacos:.2f}%", help="Total Advertising Cost of Sales (Spend / Total Sales)")
                        else:
                            col14.metric("TACoS", "N/A", help="Cannot calculate - Total Sales missing.")
                        
                        if ad_sales_perc is not None:
                            col15.metric("Ad Sales % of Total", f"{ad_sales_perc:.2f}%", help="Percentage of Total Sales from Advertising")
                        else:
                            col15.metric("Ad Sales % of Total", "N/A", help="Cannot calculate - Total Sales missing.")
                        
                        col16, col17 = st.columns(2)
                        if total_sessions is not None:
                            col16.metric("Total Sessions", f"{total_sessions:,}", help=f"Using '{sessions_col}' column")
                        else:
                            col16.metric("Total Sessions", "-", help="'Sessions' column not found in Sales Report.")
                        
                        if ad_traffic_perc_sessions is not None:
                            col17.metric("Ad Traffic % Sessions", f"{ad_traffic_perc_sessions:.2f}%", help="Percentage of Sessions from Ad Clicks")
                        else:
                            col17.metric("Ad Traffic % Sessions", "-", help="Cannot calculate - Sessions or Ad Clicks missing.")
                            
                        # Add Sales Distribution Pie Chart
                        if total_sales_revenue is not None and total_sales_revenue > 0 and total_ad_sales is not None:
                            st.divider()
                            # No need for the main title anymore as each chart has its own title
                            
                            # Calculate organic sales (total sales - ad sales)
                            organic_sales = max(0, total_sales_revenue - total_ad_sales)  # Ensure it's not negative
                            
                            # Calculate percentages
                            ad_sales_percentage = (total_ad_sales / total_sales_revenue) * 100
                            organic_sales_percentage = (organic_sales / total_sales_revenue) * 100
                            
                            # Create a centered container for the pie chart
                            # Create two columns for side-by-side charts
                            col_sales, col_traffic = st.columns(2)
                            
                            with col_sales:
                                # Add title for sales chart
                                st.markdown("""
                                <h2 style='text-align: center; color: #2196f3; font-family: Inter,Roboto,Segoe UI,Arial,sans-serif; font-size:1.6rem; font-weight:700; margin-top:1.2rem; margin-bottom:1.0rem;'>
                                    Organic vs Paid Sales
                                </h2>""", unsafe_allow_html=True)
                                
                                # Format the data for the pie chart
                                sales_data = {
                                    'Category': ['Ad Sales', 'Organic Sales'],
                                    'Sales': [total_ad_sales, organic_sales],
                                    'Percentage': [ad_sales_percentage, organic_sales_percentage]
                                }
                                sales_df = pd.DataFrame(sales_data)
                                
                                # Create a horizontal bar chart with context-aware styling
                                fig_sales = {
                                    'data': [
                                        {
                                            'type': 'bar',
                                            'orientation': 'h',
                                            'y': sales_df['Category'],
                                            'x': sales_df['Sales'],
                                            'text': [f'${val:,.2f}' for val in sales_df['Sales']],
                                            'textposition': 'inside',
                                            'textfont': {'color': 'white', 'size': 14, 'weight': 'bold'},
                                            'hoverinfo': 'text',
                                            'hovertext': [f'{cat}: ${val:,.2f} ({pct:.1f}%)' for cat, val, pct in zip(sales_df['Category'], sales_df['Sales'], sales_df['Percentage'])],
                                            'marker': {
                                                'color': ['#1E3A8A', '#3B82F6'],  # Darker blue for Ad Sales, lighter blue for Organic Sales
                                                'line': {
                                                    'width': 1,
                                                    'color': 'rgba(229, 231, 235, 0.3)'
                                                }
                                            }
                                        }
                                    ],
                                    'layout': {
                                        'title': None,  # Remove title from chart itself
                                        'showlegend': False,
                                        'height': 250,
                                        'margin': {'t': 20, 'b': 40, 'l': 120, 'r': 60},
                                        'xaxis': {
                                            'title': 'Sales ($)',
                                            'tickformat': '$,.0f',
                                            'gridcolor': 'rgba(229, 231, 235, 0.3)',
                                            'gridwidth': 0.5,
                                            'color': 'rgba(255, 255, 255, 0.8)'  # Text color that works in both light/dark modes
                                        },
                                        'yaxis': {
                                            'title': '',
                                            'tickfont': {'size': 14},
                                            'ticksuffix': '  ',
                                            'color': 'rgba(255, 255, 255, 0.8)'  # Text color that works in both light/dark modes
                                        },
                                        'annotations': [
                                            {
                                                'x': sales_df['Sales'][i],
                                                'y': sales_df['Category'][i],
                                                'text': f'{sales_df["Percentage"][i]:.1f}%',
                                                'showarrow': False,
                                                'font': {'size': 14, 'color': 'rgba(255, 255, 255, 0.9)'},
                                                'xanchor': 'left',
                                                'xshift': 10,
                                                'bgcolor': 'rgba(0, 0, 0, 0.4)',
                                                'borderpad': 2,
                                                'bordercolor': 'rgba(255, 255, 255, 0.2)',
                                                'borderwidth': 1
                                            } for i in range(len(sales_df))
                                        ],
                                        'plot_bgcolor': 'rgba(0, 0, 0, 0.1)',  # Transparent background
                                        'paper_bgcolor': 'rgba(0, 0, 0, 0)'    # Transparent paper
                                    }
                                }
                                # Add config to make chart responsive and add the dark-mode-compatible class
                                st.plotly_chart(fig_sales, use_container_width=True, config={'responsive': True, 'displayModeBar': False})
                            
                            # --- Organic vs Paid Traffic Chart ---
                            if total_sessions is not None and total_sessions > 0 and ad_traffic_perc_sessions is not None:
                                ad_traffic_sessions = total_sessions * (ad_traffic_perc_sessions / 100)
                                organic_traffic_sessions = total_sessions - ad_traffic_sessions
                                ad_traffic_pct = (ad_traffic_sessions / total_sessions) * 100 if total_sessions > 0 else 0
                                organic_traffic_pct = (organic_traffic_sessions / total_sessions) * 100 if total_sessions > 0 else 0
                                
                                with col_traffic:
                                    # Add title for traffic chart
                                    st.markdown("""
                                    <h2 style='text-align: center; color: #2196f3; font-family: Inter,Roboto,Segoe UI,Arial,sans-serif; font-size:1.6rem; font-weight:700; margin-top:1.2rem; margin-bottom:1.0rem;'>
                                        Organic vs Paid Traffic
                                    </h2>""", unsafe_allow_html=True)
                                    traffic_data = {
                                        'Category': ['Ad Traffic', 'Organic Traffic'],
                                        'Sessions': [ad_traffic_sessions, organic_traffic_sessions],
                                        'Percentage': [ad_traffic_pct, organic_traffic_pct]
                                    }
                                    traffic_df = pd.DataFrame(traffic_data)
                                    fig_traffic = {
                                        'data': [
                                            {
                                                'type': 'bar',
                                                'orientation': 'h',
                                                'y': traffic_df['Category'],
                                                'x': traffic_df['Sessions'],
                                                'text': [f'{val:,.0f}' for val in traffic_df['Sessions']],
                                                'textposition': 'inside',
                                                'textfont': {'color': 'white', 'size': 14, 'weight': 'bold'},
                                                'hoverinfo': 'text',
                                                'hovertext': [f'{cat}: {val:,.0f} ({pct:.1f}%)' for cat, val, pct in zip(traffic_df['Category'], traffic_df['Sessions'], traffic_df['Percentage'])],
                                                'marker': {
                                                    'color': ['#0f5132', '#10b981'],
                                                    'line': {
                                                        'width': 1,
                                                        'color': 'rgba(229, 231, 235, 0.3)'
                                                    }
                                                }
                                            }
                                        ],
                                        'layout': {
                                            'title': None,
                                            'showlegend': False,
                                            'height': 250,
                                            'margin': {'t': 20, 'b': 40, 'l': 120, 'r': 60},
                                            'xaxis': {
                                                'title': 'Sessions',
                                                'tickformat': ',.0f',
                                                'gridcolor': 'rgba(229, 231, 235, 0.3)',
                                                'gridwidth': 0.5,
                                                'color': 'rgba(255, 255, 255, 0.8)'
                                            },
                                            'yaxis': {
                                                'title': '',
                                                'tickfont': {'size': 14},
                                                'ticksuffix': '  ',
                                                'color': 'rgba(255, 255, 255, 0.8)'
                                            },
                                            'annotations': [
                                                {
                                                    # Position the annotation at the end of the bar plus some padding
                                                    'x': traffic_df['Sessions'][i] * 1.05,
                                                    'y': traffic_df['Category'][i],
                                                    'text': f'{traffic_df["Percentage"][i]:.1f}%',
                                                    'showarrow': False,
                                                    'font': {'size': 14, 'color': 'rgba(255, 255, 255, 0.9)'},
                                                    'xanchor': 'left',
                                                    'xshift': 5,
                                                    'bgcolor': 'rgba(0, 0, 0, 0.4)',
                                                    'borderpad': 2,
                                                    'bordercolor': 'rgba(255, 255, 255, 0.2)',
                                                    'borderwidth': 1
                                                } for i in range(len(traffic_df))
                                            ],
                                            'plot_bgcolor': 'rgba(0, 0, 0, 0.1)',
                                            'paper_bgcolor': 'rgba(0, 0, 0, 0)'
                                        }
                                    }
                                    st.plotly_chart(fig_traffic, use_container_width=True, config={'responsive': True, 'displayModeBar': False})

                        
                        # Add Branded vs. Non-Branded Performance section
                        st.divider()
                        st.markdown("<div id='branded-vs-non-branded-performance' class='section-anchor'></div>", unsafe_allow_html=True)
                        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
                        st.markdown("<span class='main-section-header'>Branded vs. Non-Branded Performance</span>", unsafe_allow_html=True)
                        st.markdown("<div style='margin-bottom:1.2rem;'></div>", unsafe_allow_html=True)
                        # Add toggle for data source (Search Terms or Targets)
                        if 'branded_data_source' not in st.session_state:
                            st.session_state.branded_data_source = "Targets"
                            
                        # Left-align the data source picker
                        toggle_col, desc_col = st.columns([0.2, 0.8])
                        with toggle_col:
                            data_source = st.radio(
                                "Data Source",
                                options=["Targets", "Search Terms"],
                                horizontal=True,
                                key="branded_data_source"
                            )
                            
                        # No descriptions needed
                        
                        # Get the appropriate data based on the selected source
                        if data_source == "Targets":
                            # Get the targeting performance data
                            branded_targets_df, non_branded_targets_df = get_targeting_performance_data(
                                bulk_data, 
                                st.session_state.client_config
                            )
                            st.session_state.debug_messages.append(f"[Branded Performance] Using Targets data source")
                        else:  # Search Terms
                            # Get search term data and split into branded/non-branded
                            search_term_df = get_search_term_data(bulk_data, st.session_state.client_config)
                            
                            if not search_term_df.empty:
                                # Check if 'Is Branded' column exists, if not, add it based on client configuration
                                if 'Is Branded' not in search_term_df.columns:
                                    st.session_state.debug_messages.append(f"[Branded Performance] 'Is Branded' column not found in search term data, adding it")
                                    
                                    # Get branded terms and ASINs from client config
                                    client_config = st.session_state.client_config
                                    branded_terms = []
                                    branded_asins = []
                                    
                                    if client_config:
                                        # Extract branded terms from client config (handling different possible formats)
                                        if 'Branded Terms' in client_config:
                                            if isinstance(client_config['Branded Terms'], list):
                                                branded_terms = client_config['Branded Terms']
                                            elif isinstance(client_config['Branded Terms'], str):
                                                branded_terms = [term.strip() for term in client_config['Branded Terms'].split(',')]
                                        
                                        # Extract branded ASINs from the correct source: branded_asins_data
                                        branded_asins_data = client_config.get('branded_asins_data', {})
                                        branded_asins = [str(asin).strip().upper() for asin in branded_asins_data.keys() if str(asin).strip()]
                                        
                                        # Fallback: check old format for backward compatibility
                                        if not branded_asins and 'Branded ASINs' in client_config:
                                            if isinstance(client_config['Branded ASINs'], list):
                                                branded_asins = [str(asin).strip().upper() for asin in client_config['Branded ASINs'] if str(asin).strip()]
                                            elif isinstance(client_config['Branded ASINs'], str):
                                                branded_asins = [asin.strip().upper() for asin in client_config['Branded ASINs'].split(',') if asin.strip()]
                                    
                                    # Function to check if a search term contains any branded terms
                                    def is_branded_term(term):
                                        if pd.isna(term) or not isinstance(term, str):
                                            return False
                                        
                                        term_lower = term.lower()
                                        
                                        # Check if term contains any branded terms
                                        for branded_term in branded_terms:
                                            if branded_term and isinstance(branded_term, str) and branded_term.lower() in term_lower:
                                                return True
                                        
                                        # Check if term contains any branded ASINs (using uppercase comparison for ASINs)
                                        for branded_asin in branded_asins:
                                            if branded_asin and isinstance(branded_asin, str) and branded_asin in term.upper():
                                                return True
                                        
                                        return False
                                    
                                    # Apply the function to classify search terms
                                    search_term_col = 'Search Term' if 'Search Term' in search_term_df.columns else 'Customer Search Term'
                                    if search_term_col in search_term_df.columns:
                                        # Enhanced classification: check both search term and target for branded content
                                        def classify_search_term_row(row):
                                            search_term = row.get(search_term_col, '')
                                            target = row.get('Target', '')
                                            
                                            # Check if search term is branded
                                            if is_branded_term(search_term):
                                                return True
                                            
                                            # Check if target contains branded ASINs
                                            if target and isinstance(target, str) and not pd.isna(target):
                                                target_upper = target.upper()
                                                for branded_asin in branded_asins:
                                                    if branded_asin and isinstance(branded_asin, str) and branded_asin in target_upper:
                                                        return True
                                            
                                            return False
                                        
                                        search_term_df['Is Branded'] = search_term_df.apply(classify_search_term_row, axis=1)
                                    else:
                                        # If no search term column found, default all to non-branded
                                        search_term_df['Is Branded'] = False
                                        st.session_state.debug_messages.append(f"[Branded Performance] No search term column found in data")
                                
                                # Check which column name is being used for branding classification
                                if 'Is_Branded' in search_term_df.columns:
                                    branded_column = 'Is_Branded'
                                elif 'Is Branded' in search_term_df.columns:
                                    branded_column = 'Is Branded'
                                else:
                                    # If neither column exists, add it with default values
                                    search_term_df['Is Branded'] = False
                                    branded_column = 'Is Branded'
                                    st.session_state.debug_messages.append(f"[Branded Performance] No branding column found, defaulting all to non-branded")
                                
                                # Split into branded and non-branded using the correct column
                                branded_targets_df = search_term_df[search_term_df[branded_column] == True].copy()
                                non_branded_targets_df = search_term_df[search_term_df[branded_column] == False].copy()
                                
                                # Add debug information
                                st.session_state.debug_messages.append(f"[Branded Performance] Using column '{branded_column}' for branding classification")
                                st.session_state.debug_messages.append(f"[Branded Performance] Found {len(branded_targets_df)} branded and {len(non_branded_targets_df)} non-branded terms")
                                
                                # Rename 'Search Term' column to 'Target' for consistency with the targeting data display
                                search_term_col = None
                                for col in ['Search Term', 'Customer Search Term']:
                                    if col in branded_targets_df.columns:
                                        search_term_col = col
                                        break
                                        
                                if search_term_col and search_term_col != 'Target':
                                    branded_targets_df = branded_targets_df.rename(columns={search_term_col: 'Target'})
                                    non_branded_targets_df = non_branded_targets_df.rename(columns={search_term_col: 'Target'})
                                    
                                st.session_state.debug_messages.append(f"[Branded Performance] Using Search Terms data source: {len(search_term_df)} terms found, {len(branded_targets_df)} branded, {len(non_branded_targets_df)} non-branded")
                            else:
                                # If no search term data, create empty DataFrames
                                branded_targets_df = pd.DataFrame()
                                non_branded_targets_df = pd.DataFrame()
                                st.session_state.debug_messages.append(f"[Branded Performance] No search term data found")
                                st.warning("No search term data found. Please upload a report with search term data or switch to Targets view.")

                        # --- Harmonize columns between branded and non-branded targets ---
                        import numpy as np
                        # Define a global list of required columns for harmonization
                        REQUIRED_TARGET_COLUMNS = [
                            'Campaign', 'Target', 'Match Type', 'Spend', 'Ad Sales', '% of Spend', '% of Ad Sales',
                            'ACoS', 'ROAS', 'CPC', 'CVR', 'Impressions', 'Clicks', 'Orders', 'AOV', 'CTR', 'CPA', 'Ad Type'
                        ]
                        branded_cols = set(branded_targets_df.columns)
                        non_branded_cols = set(non_branded_targets_df.columns)
                        all_cols = list(set(REQUIRED_TARGET_COLUMNS).union(branded_cols).union(non_branded_cols))
                        for col in all_cols:
                            if col not in branded_targets_df.columns:
                                branded_targets_df[col] = np.nan
                            if col not in non_branded_targets_df.columns:
                                non_branded_targets_df[col] = np.nan
                        # Ensure 'Ad Sales' is always present and populated (should be from get_targeting_performance_data)
                        # Ensure both 'Sales' and 'Ad Sales' columns exist for compatibility
                        # with different parts of the code
                        if 'Sales' in branded_targets_df.columns and 'Ad Sales' not in branded_targets_df.columns:
                            branded_targets_df['Ad Sales'] = branded_targets_df['Sales']
                        elif 'Ad Sales' in branded_targets_df.columns and 'Sales' not in branded_targets_df.columns:
                            branded_targets_df['Sales'] = branded_targets_df['Ad Sales']
                            
                        if 'Sales' in non_branded_targets_df.columns and 'Ad Sales' not in non_branded_targets_df.columns:
                            non_branded_targets_df['Ad Sales'] = non_branded_targets_df['Sales']
                        elif 'Ad Sales' in non_branded_targets_df.columns and 'Sales' not in non_branded_targets_df.columns:
                            non_branded_targets_df['Sales'] = non_branded_targets_df['Ad Sales']
                        
                        # Ensure 'Ad Sales' is always present
                        if 'Ad Sales' not in branded_targets_df.columns:
                            branded_targets_df['Ad Sales'] = np.nan
                        if 'Ad Sales' not in non_branded_targets_df.columns:
                            non_branded_targets_df['Ad Sales'] = np.nan
                        # Reorder columns to match REQUIRED_TARGET_COLUMNS order (with extras at the end)
                        # Make sure 'Bid' is the very last column
                        ordered_cols = [col for col in REQUIRED_TARGET_COLUMNS if col in all_cols]
                        extra_cols = [col for col in all_cols if col not in REQUIRED_TARGET_COLUMNS and col != 'Bid']
                        if 'Bid' in all_cols:
                            ordered_cols = ordered_cols + extra_cols + ['Bid']
                        else:
                            ordered_cols = ordered_cols + extra_cols
                        branded_targets_df = branded_targets_df[ordered_cols]
                        non_branded_targets_df = non_branded_targets_df[ordered_cols]
                        # Debug: Show harmonized columns
                        st.session_state.debug_messages.append(f"[Harmonized Branded Columns] {list(branded_targets_df.columns)}")
                        st.session_state.debug_messages.append(f"[Harmonized Non-Branded Columns] {list(non_branded_targets_df.columns)}")
                        st.session_state.debug_messages.append(f"[Ad Sales Column] Branded targets has {branded_targets_df['Ad Sales'].notna().sum()} non-NaN values, Non-Branded has {non_branded_targets_df['Ad Sales'].notna().sum()} non-NaN values.")

                        # Defensive: If DataFrames are None, create empty DataFrames with required columns
                        if branded_targets_df is None or not isinstance(branded_targets_df, pd.DataFrame):
                            branded_targets_df = pd.DataFrame(columns=REQUIRED_TARGET_COLUMNS)
                        if non_branded_targets_df is None or not isinstance(non_branded_targets_df, pd.DataFrame):
                            non_branded_targets_df = pd.DataFrame(columns=REQUIRED_TARGET_COLUMNS)

                        # Create a function to calculate metrics from targeting dataframes
                        def calculate_metrics_from_targets(df):
                            if df.empty:
                                return {
                                    'Total Spend': 0.0,
                                    'Total Ad Sales': 0.0,
                                    'ACoS': 0.0,
                                    'ROAS': 0.0,
                                    'CPC': 0.0,
                                    'CVR': 0.0,
                                    'CTR': 0.0,
                                    'Total Impressions': 0,
                                    'Total Clicks': 0,
                                    'AOV': 0.0,
                                    'CPA': 0.0,
                                    'Total Orders': 0
                                }
                            
                            # Calculate aggregated metrics
                            total_spend = df['Spend'].sum()
                            total_sales = df['Sales'].sum()
                            total_impressions = df['Impressions'].sum()
                            total_clicks = df['Clicks'].sum()
                            total_orders = df['Orders'].sum()
                            
                            # Calculate derived metrics (handling division by zero)
                            acos = (total_spend / total_sales) * 100 if total_sales > 0 else 0
                            roas = total_sales / total_spend if total_spend > 0 else 0
                            cpc = total_spend / total_clicks if total_clicks > 0 else 0
                            ctr = (total_clicks / total_impressions) * 100 if total_impressions > 0 else 0
                            cvr = (total_orders / total_clicks) * 100 if total_clicks > 0 else 0
                            aov = total_sales / total_orders if total_orders > 0 else 0
                            cpa = total_spend / total_orders if total_orders > 0 else 0
                            
                            return {
                                'Total Spend': total_spend,
                                'Total Ad Sales': total_sales,
                                'ACoS': round(acos, 2),
                                'ROAS': roas,
                                'CPC': cpc,
                                'CVR': cvr,
                                'CTR': ctr,
                                'Total Impressions': total_impressions,
                                'Total Clicks': total_clicks,
                                'AOV': aov,
                                'CPA': cpa,
                                'Total Orders': total_orders
                            }
                        
                        # Calculate metrics for branded and non-branded targets
                        branded_metrics = calculate_metrics_from_targets(branded_targets_df)
                        non_branded_metrics = calculate_metrics_from_targets(non_branded_targets_df)
                        
                        if not (branded_targets_df.empty and non_branded_targets_df.empty):
                            # Calculate totals for each metric
                            total_metrics = {
                                'Total Spend': branded_metrics['Total Spend'] + non_branded_metrics['Total Spend'],
                                'Total Ad Sales': branded_metrics['Total Ad Sales'] + non_branded_metrics['Total Ad Sales'],
                                'ACoS': (branded_metrics['Total Spend'] + non_branded_metrics['Total Spend']) / (branded_metrics['Total Ad Sales'] + non_branded_metrics['Total Ad Sales']) * 100 if (branded_metrics['Total Ad Sales'] + non_branded_metrics['Total Ad Sales']) != 0 else 0,
                                'ROAS': (branded_metrics['Total Ad Sales'] + non_branded_metrics['Total Ad Sales']) / (branded_metrics['Total Spend'] + non_branded_metrics['Total Spend']) if (branded_metrics['Total Spend'] + non_branded_metrics['Total Spend']) != 0 else 0,
                                'CPC': (branded_metrics['Total Spend'] + non_branded_metrics['Total Spend']) / (branded_metrics['Total Clicks'] + non_branded_metrics['Total Clicks']) if (branded_metrics['Total Clicks'] + non_branded_metrics['Total Clicks']) != 0 else 0,
                                'CVR': (branded_metrics['Total Orders'] + non_branded_metrics['Total Orders']) / (branded_metrics['Total Clicks'] + non_branded_metrics['Total Clicks']) * 100 if (branded_metrics['Total Clicks'] + non_branded_metrics['Total Clicks']) != 0 else 0,
                                'CTR': (branded_metrics['Total Clicks'] + non_branded_metrics['Total Clicks']) / (branded_metrics['Total Impressions'] + non_branded_metrics['Total Impressions']) * 100 if (branded_metrics['Total Impressions'] + non_branded_metrics['Total Impressions']) != 0 else 0,
                                'AOV': (branded_metrics['Total Ad Sales'] + non_branded_metrics['Total Ad Sales']) / (branded_metrics['Total Orders'] + non_branded_metrics['Total Orders']) if (branded_metrics['Total Orders'] + non_branded_metrics['Total Orders']) != 0 else 0,
                                'CPA': (branded_metrics['Total Spend'] + non_branded_metrics['Total Spend']) / (branded_metrics['Total Orders'] + non_branded_metrics['Total Orders']) if (branded_metrics['Total Orders'] + non_branded_metrics['Total Orders']) != 0 else 0,
                                'Total Impressions': branded_metrics['Total Impressions'] + non_branded_metrics['Total Impressions'],
                                'Total Clicks': branded_metrics['Total Clicks'] + non_branded_metrics['Total Clicks'],
                                'Total Orders': branded_metrics['Total Orders'] + non_branded_metrics['Total Orders'],
                            }

                            # Prepare formatted values for display
                            metrics = {
                                "Spend": [f"${branded_metrics['Total Spend']:,.2f}", f"${non_branded_metrics['Total Spend']:,.2f}", f"${total_metrics['Total Spend']:,.2f}"],
                                "Ad Sales": [f"${branded_metrics['Total Ad Sales']:,.2f}", f"${non_branded_metrics['Total Ad Sales']:,.2f}", f"${total_metrics['Total Ad Sales']:,.2f}"],
                                "ACoS": [f"{branded_metrics['ACoS']:.2f}%", f"{non_branded_metrics['ACoS']:.2f}%", f"{total_metrics['ACoS']:.2f}%"],
                                "ROAS": [f"{branded_metrics['ROAS']:.2f}x", f"{non_branded_metrics['ROAS']:.2f}x", f"{total_metrics['ROAS']:.2f}x"],
                                "CPC": [f"${branded_metrics['CPC']:.2f}", f"${non_branded_metrics['CPC']:.2f}", f"${total_metrics['CPC']:,.2f}"],
                                "CVR": [f"{branded_metrics['CVR']:.2f}%", f"{non_branded_metrics['CVR']:.2f}%", f"{total_metrics['CVR']:.2f}%"],
                                "CTR": [f"{branded_metrics['CTR']:.2f}%", f"{non_branded_metrics['CTR']:.2f}%", f"{total_metrics['CTR']:.2f}%"],
                                "Impressions": [f"{int(branded_metrics['Total Impressions']):,}", f"{int(non_branded_metrics['Total Impressions']):,}", f"{int(total_metrics['Total Impressions']):,}"],
                                "Clicks": [f"{int(branded_metrics['Total Clicks']):,}", f"{int(non_branded_metrics['Total Clicks']):,}", f"{int(total_metrics['Total Clicks']):,}"],
                                "Orders": [f"{int(branded_metrics['Total Orders']):,}", f"{int(non_branded_metrics['Total Orders']):,}", f"{int(total_metrics['Total Orders']):,}"],
                                "AOV": [f"${branded_metrics['AOV']:.2f}", f"${non_branded_metrics['AOV']:.2f}", f"${total_metrics['AOV']:,.2f}"],
                                "CPA": [f"${branded_metrics['CPA']:.2f}", f"${non_branded_metrics['CPA']:.2f}", f"${total_metrics['CPA']:,.2f}"],
                            }
                            index = ["Branded", "Non-Branded", "Total"]
                            df_metrics = pd.DataFrame(metrics, index=index)
                            
                            # Prepare ACoS targets for each row
                            config = st.session_state.get('client_config', {})
                            goals = config.get('goals', {})
                            branded_target = goals.get('branded_acos')
                            non_branded_target = goals.get('non_branded_acos')
                            account_target = goals.get('account_wide_acos')

                            def highlight_and_acos(row):
                                # Function simplified to remove ACoS coloring based on user goals
                                styles = ['' for _ in row]
                                # Keep Total row styling
                                if row.name == 'Total':
                                    styles = ['border-top: 3px solid #FFD700; font-weight: bold;'.strip() for _ in row]
                                # Keep CPA column styling for contrast
                                if 'CPA' in row.index:
                                    cpa_idx = list(row.index).index('CPA')
                                    styles[cpa_idx] += 'color: white;'
                                return [s.replace('\n', ' ').strip() for s in styles]

                            # Filter out rows with all zeros before displaying
                            # Create a copy to avoid modifying the original
                            df_metrics_filtered = df_metrics.copy()
                            
                            # Remove empty rows (rows where both Spend and Ad Sales are zero/empty)
                            rows_to_keep = []
                            for idx, row in df_metrics.iterrows():
                                # Extract numeric values from formatted strings
                                spend_val = float(row['Spend'].replace('$', '').replace(',', ''))
                                sales_val = float(row['Ad Sales'].replace('$', '').replace(',', ''))
                                
                                # Keep row if either spend or sales is non-zero, or if it's the Total row
                                if spend_val > 0 or sales_val > 0 or idx == 'Total':
                                    rows_to_keep.append(idx)
                            
                            # Filter the dataframe to keep only non-empty rows and the Total row
                            if len(rows_to_keep) > 0:  # Make sure we have at least one row to keep
                                df_metrics_filtered = df_metrics_filtered.loc[rows_to_keep]
                            
                            # Display the dataframe with styling
                            st.dataframe(
                                df_metrics_filtered.style.apply(highlight_and_acos, axis=1),
                                height=150  # Reduced height since we're removing empty rows
                            )

                            st.markdown("</div>", unsafe_allow_html=True)
                            
                            # Add charts for branded vs. non-branded spend and sales distribution
                            st.divider()
                            st.subheader(f"Branded vs. Non-Branded Distribution ({data_source})")
                            
                            # Calculate total spend and sales across both branded and non-branded
                            total_spend = branded_metrics['Total Spend'] + non_branded_metrics['Total Spend']
                            total_sales = branded_metrics['Total Ad Sales'] + non_branded_metrics['Total Ad Sales']
                            
                            # Calculate percentages
                            if total_spend > 0:
                                branded_spend_pct = (branded_metrics['Total Spend'] / total_spend) * 100
                                non_branded_spend_pct = (non_branded_metrics['Total Spend'] / total_spend) * 100
                            else:
                                branded_spend_pct = 0
                                non_branded_spend_pct = 0
                                     
                            if total_sales > 0:
                                branded_sales_pct = (branded_metrics['Total Ad Sales'] / total_sales) * 100
                                non_branded_sales_pct = (non_branded_metrics['Total Ad Sales'] / total_sales) * 100
                            else:
                                branded_sales_pct = 0
                                non_branded_sales_pct = 0
                            
                            # Create two columns for the charts with a small gap between them
                            pie_col1, gap, pie_col2 = st.columns([0.48, 0.04, 0.48])
                            
                            with pie_col1:
                                # Center the header above the chart
                                st.markdown("<h3 style='text-align: center;'>Spend Distribution</h3>", unsafe_allow_html=True)
                                
                                # Format the data for the pie chart
                                spend_data = {
                                    'Category': ['Branded', 'Non-Branded'],
                                    'Spend': [branded_metrics['Total Spend'], non_branded_metrics['Total Spend']],
                                    'Percentage': [branded_spend_pct, non_branded_spend_pct]
                                }
                                spend_df = pd.DataFrame(spend_data)
                                
                                # Create the chart
                                if total_spend > 0:
                                    # Create a horizontal bar chart with context-aware styling
                                    fig_spend = {
                                        'data': [
                                            {
                                                'type': 'bar',
                                                'orientation': 'h',
                                                'y': spend_df['Category'],
                                                'x': spend_df['Spend'],
                                                'text': [f'${val:,.2f}' for val in spend_df['Spend']],
                                                'textposition': 'inside',
                                                'textfont': {'color': 'white', 'size': 14, 'weight': 'bold'},
                                                'hoverinfo': 'text',
                                                'hovertext': [f'{cat}: ${val:,.2f} ({pct:.1f}%)' for cat, val, pct in zip(spend_df['Category'], spend_df['Spend'], spend_df['Percentage'])],
                                                'marker': {
                                                    'color': ['#1E3A8A', '#3B82F6'],
                                                    'line': {
                                                        'width': 1,
                                                        'color': 'rgba(229, 231, 235, 0.3)'
                                                    }
                                                }
                                            }
                                        ],
                                        'layout': {
                                            'title': None,  # Remove title from chart itself
                                            'showlegend': False,
                                            'height': 250,
                                            'margin': {'t': 20, 'b': 40, 'l': 120, 'r': 60},
                                            'xaxis': {
                                                'title': 'Spend',
                                                'tickformat': '$,.0f',
                                                'gridcolor': 'rgba(229, 231, 235, 0.3)',
                                                'gridwidth': 0.5,
                                                'color': 'rgba(255, 255, 255, 0.8)'  # Text color that works in both light/dark modes
                                            },
                                            'yaxis': {
                                                'title': '',
                                                'tickfont': {'size': 14},
                                                'ticksuffix': '  ',
                                                'color': 'rgba(255, 255, 255, 0.8)'  # Text color that works in both light/dark modes
                                            },
                                            'annotations': [
                                                {
                                                    # Position the annotation at the end of the bar plus some padding
                                                    'x': spend_df['Spend'][i] * 1.05,
                                                    'y': spend_df['Category'][i],
                                                    'text': f'{spend_df["Percentage"][i]:.1f}%',
                                                    'showarrow': False,
                                                    'font': {'size': 14, 'color': 'rgba(255, 255, 255, 0.9)'},
                                                    'xanchor': 'left',
                                                    'xshift': 5,
                                                    'bgcolor': 'rgba(0, 0, 0, 0.4)',
                                                    'borderpad': 2,
                                                    'bordercolor': 'rgba(255, 255, 255, 0.2)',
                                                    'borderwidth': 1
                                                } for i in range(len(spend_df))
                                            ],
                                            'plot_bgcolor': 'rgba(0, 0, 0, 0.1)',  # Transparent background
                                            'paper_bgcolor': 'rgba(0, 0, 0, 0)'    # Transparent paper
                                        }
                                    }
                                    # Add config to make chart responsive and add the dark-mode-compatible class
                                    st.plotly_chart(fig_spend, use_container_width=True, config={'responsive': True, 'displayModeBar': False})
                                else:
                                    st.info("No spend data available to generate chart.")
                            
                            with pie_col2:
                                # Center the header above the chart
                                st.markdown("<h3 style='text-align: center;'>Ad Sales Distribution</h3>", unsafe_allow_html=True)
                                
                                # Format the data for the pie chart
                                sales_data = {
                                    'Category': ['Branded', 'Non-Branded'],
                                    'Sales': [branded_metrics['Total Ad Sales'], non_branded_metrics['Total Ad Sales']],
                                    'Percentage': [branded_sales_pct, non_branded_sales_pct]
                                }
                                sales_df = pd.DataFrame(sales_data)
                                
                                # Create the chart
                                if total_sales > 0:
                                    # Create a horizontal bar chart with context-aware styling
                                    fig_sales = {
                                        'data': [
                                            {
                                                'type': 'bar',
                                                'orientation': 'h',
                                                'y': sales_df['Category'],
                                                'x': sales_df['Sales'],
                                                'text': [f'${val:,.2f}' for val in sales_df['Sales']],
                                                'textposition': 'inside',
                                                'textfont': {'color': 'white', 'size': 14, 'weight': 'bold'},
                                                'hoverinfo': 'text',
                                                'hovertext': [f'{cat}: ${val:,.2f} ({pct:.1f}%)' for cat, val, pct in zip(sales_df['Category'], sales_df['Sales'], sales_df['Percentage'])],
                                                'marker': {
                                                    'color': ['#0f5132', '#10b981'],
                                                    'line': {
                                                        'width': 1,
                                                        'color': 'rgba(229, 231, 235, 0.3)'
                                                    }
                                                }
                                            }
                                        ],
                                        'layout': {
                                            'title': None,  # Remove title from chart itself
                                            'showlegend': False,
                                            'height': 250,
                                            'margin': {'t': 20, 'b': 40, 'l': 120, 'r': 60},
                                            'xaxis': {
                                                'title': 'Sales ($)',
                                                'tickformat': '$,.0f',
                                                'gridcolor': 'rgba(229, 231, 235, 0.3)',
                                                'gridwidth': 0.5,
                                                'color': 'rgba(255, 255, 255, 0.8)'  # Text color that works in both light/dark modes
                                            },
                                            'yaxis': {
                                                'title': '',
                                                'tickfont': {'size': 14},
                                                'ticksuffix': '  ',
                                                'color': 'rgba(255, 255, 255, 0.8)'  # Text color that works in both light/dark modes
                                            },
                                            'annotations': [
                                                {
                                                    # Position the annotation at the end of the bar plus some padding
                                                    'x': sales_df['Sales'][i] * 1.05,
                                                    'y': sales_df['Category'][i],
                                                    'text': f'{sales_df["Percentage"][i]:.1f}%',
                                                    'showarrow': False,
                                                    'font': {'size': 14, 'color': 'rgba(255, 255, 255, 0.9)'},
                                                    'xanchor': 'left',
                                                    'xshift': 5,
                                                    'bgcolor': 'rgba(0, 0, 0, 0.4)',
                                                    'borderpad': 2,
                                                    'bordercolor': 'rgba(255, 255, 255, 0.2)',
                                                    'borderwidth': 1
                                                } for i in range(len(sales_df))
                                            ],
                                            'plot_bgcolor': 'rgba(0, 0, 0, 0.1)',  # Transparent background
                                            'paper_bgcolor': 'rgba(0, 0, 0, 0)'    # Transparent paper
                                        }
                                    }
                                    # Add config to make chart responsive and add the dark-mode-compatible class
                                    st.plotly_chart(fig_sales, use_container_width=True, config={'responsive': True, 'displayModeBar': False})
                                else:
                                    st.info("No sales data available to generate chart.")
                        else:
                            st.info("No branded/non-branded targeting data available. Please ensure you have uploaded a bulk file and configured branded terms and ASINs in the Client Settings Center.")
                    
                    else:
                        st.warning("No advertising campaign data found or processed for aggregation.")
                
            except Exception as e:
                st.error(f"An error occurred calculating overview KPIs: {e}")
                with st.expander("Error Details"):
                    import traceback
                    st.code(traceback.format_exc())
        else:
            st.info("Upload Bulk Operations & Sales reports to populate the overview.")
    
    # The 'Advertising Audit: Comply Foam' section has been removed as requested
    # KPIs are now only shown in the 'Account Overview' section of the 'Advertising Audit' tab
    # --- Campaign Performance Section ---
    if st.session_state.current_page == "advertising_audit":
        # Gold main header for Campaign Performance with anchor
        st.markdown("<div id='campaign-performance' class='section-anchor'></div>", unsafe_allow_html=True)
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<span class='main-section-header dashboard-section'>Campaign Performance</span>", unsafe_allow_html=True)
        st.markdown("<div style='margin-bottom:1.2rem;'></div>", unsafe_allow_html=True)
        
        if st.session_state.get('bulk_data') and st.session_state.get('client_config'):
            try:
                # Get campaign performance data
                campaign_performance_df = get_campaign_performance_data(
                    st.session_state.bulk_data,
                    st.session_state.client_config
                )
                
                if not campaign_performance_df.empty:
                    # Get available product groups from campaign tagging
                    campaign_product_groups = set()
                    if 'campaign_tags_data' in st.session_state.client_config:
                        for campaign_data in st.session_state.client_config['campaign_tags_data'].values():
                            if 'tag_1' in campaign_data and campaign_data['tag_1']:
                                campaign_product_groups.add(campaign_data['tag_1'])
                    
                        # Add Untagged Group as a filter option for campaigns that could be untagged
                        if st.session_state.client_config["campaign_tags_data"]:
                            campaign_product_groups.add("Untagged Group")
                    # Get available ad types from the data
                    available_ad_types = set()
                    if 'Ad Type' in campaign_performance_df.columns:
                        available_ad_types = set(campaign_performance_df['Ad Type'].dropna().unique())
                    
                    # Filters section
                    filter_col1, filter_col2, filter_col3 = st.columns(3)
                    
                    with filter_col1:
                        # Campaign search bar
                        campaign_search = st.text_input(
                            "Campaign Search:",
                            placeholder="Enter campaign name phrase...",
                            key="campaign_performance_campaign_search"
                        )
                    
                    with filter_col2:
                        # Ad Type filter - show dropdown for each that exists
                        selected_ad_types = []
                        if available_ad_types:
                            ad_type_options = sorted(list(available_ad_types))
                            selected_ad_types = st.multiselect(
                                "Ad Type:",
                                options=ad_type_options,
                                key="campaign_performance_ad_type_filter"
                            )
                    
                    with filter_col3:
                        # Product Group filter - only show if there are product groups
                        selected_product_groups = []
                        if campaign_product_groups:
                            product_group_options = sorted(list(campaign_product_groups))
                            selected_product_groups = st.multiselect(
                                "Product Group:",
                                options=product_group_options,
                                key="campaign_performance_product_group_filter"
                            )
                    
                    # Apply filters to the data
                    filtered_df = campaign_performance_df.copy()
                    
                    # Apply product group filter
                    if selected_product_groups and 'Product Group' in filtered_df.columns:
                        filtered_df = filtered_df[filtered_df['Product Group'].isin(selected_product_groups)]
                    
                    # Apply ad type filter
                    if selected_ad_types and 'Ad Type' in filtered_df.columns:
                        filtered_df = filtered_df[filtered_df['Ad Type'].isin(selected_ad_types)]
                    
                    # Apply campaign search filter (case-insensitive)
                    if campaign_search and 'Campaign' in filtered_df.columns:
                        matched_campaigns = filtered_df['Campaign'].astype(str).apply(lambda x: phrase_match(x, campaign_search))
                        filtered_df = filtered_df[matched_campaigns]
                    
                    # Summary cards
                    if not filtered_df.empty:
                        # Calculate summary metrics
                        total_spend = filtered_df['Spend'].sum() if 'Spend' in filtered_df.columns else 0
                        total_ad_sales = filtered_df['Ad Sales'].sum() if 'Ad Sales' in filtered_df.columns else 0
                        total_clicks = filtered_df['Clicks'].sum() if 'Clicks' in filtered_df.columns else 0
                        total_orders = filtered_df['Orders'].sum() if 'Orders' in filtered_df.columns else 0
                        
                        # Calculate derived metrics
                        avg_acos = (total_spend / total_ad_sales * 100) if total_ad_sales > 0 else 0
                        avg_roas = (total_ad_sales / total_spend) if total_spend > 0 else 0
                        avg_cpc = (total_spend / total_clicks) if total_clicks > 0 else 0
                        avg_cvr = (total_orders / total_clicks * 100) if total_clicks > 0 else 0
                        avg_aov = (total_ad_sales / total_orders) if total_orders > 0 else 0
                        
                        # Display summary cards
                        st.subheader("Campaign Performance Summary")
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Spend", f"${total_spend:,.2f}")
                            st.metric("CPC", f"${avg_cpc:.2f}")
                        with col2:
                            st.metric("Ad Sales", f"${total_ad_sales:,.2f}")
                            st.metric("CVR", f"{avg_cvr:.2f}%")
                        with col3:
                            st.metric("ACoS", f"{avg_acos:.2f}%")
                            st.metric("AOV", f"${avg_aov:.2f}")
                        with col4:
                            st.metric("ROAS", f"{avg_roas:.2f}")
                            st.metric("Orders", f"{total_orders:,.0f}")
                        
                        
                        # Define columns to display
                        display_columns = ['Ad Type', 'Campaign', 'Spend', 'Ad Sales', '% Ad Spend', '% Ad Sales', 'ACoS', 'ROAS', 'CPC', 'CVR', 'AOV', 'Clicks', 'Orders']
                        
                        # Only include Product Group column if there are product groups
                        if campaign_product_groups:
                            display_columns.insert(1, 'Product Group')
                        
                        # Filter to only show available columns
                        available_columns = [col for col in display_columns if col in filtered_df.columns]
                        
                        if available_columns:
                            # Sort by spend for display
                            display_df = filtered_df[available_columns].sort_values('Spend', ascending=False).reset_index(drop=True)
                            
                            # Convert numeric columns for styling
                            numeric_df = display_df.copy()
                            for col in numeric_df.columns:
                                if col not in ['Ad Type', 'Product Group', 'Campaign']:
                                    numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
                            
                            # Create formatting dictionary
                            fmt_dict = {}
                            for col in numeric_df.columns:
                                if col in ['Ad Type', 'Product Group', 'Campaign']:
                                    continue
                                elif col == 'ROAS':
                                    fmt_dict[col] = lambda x: f"{x:.2f}"
                                elif col in ['ACoS', 'CVR', '% Ad Spend', '% Ad Sales']:
                                    fmt_dict[col] = lambda x: f"{x:.2f}%"
                                elif col in ['CPC', 'AOV']:
                                    fmt_dict[col] = lambda x: f"${x:.2f}"
                                elif col in ['Spend', 'Ad Sales']:
                                    fmt_dict[col] = lambda x: f"${x:,.2f}"
                                else:
                                    fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
                            
                            # Style the dataframe
                            styled_df = numeric_df.style.format(fmt_dict)
                            
                            # Apply color gradients to percentage columns
                            if '% Ad Spend' in numeric_df.columns:
                                styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% Ad Spend' else [''] * len(x), axis=0)
                            if '% Ad Sales' in numeric_df.columns:
                                styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% Ad Sales' else [''] * len(x), axis=0)
                            
                            # Display the styled table
                            st.dataframe(
                                styled_df,
                                use_container_width=True,
                                hide_index=True
                            )
                        else:
                            st.info("No data available to display.")
                    else:
                        st.info("No campaigns match the current filters.")
                else:
                    st.info("No campaign performance data available. Please ensure you have uploaded bulk advertising files.")
                    
            except Exception as e:
                st.error(f"An error occurred while loading campaign performance data: {e}")
                import traceback
                with st.expander("Error Details"):
                    st.code(traceback.format_exc())     # --- Targeting Performance Section ---
        else:
            st.info("Upload Bulk Operations & Sales reports to populate campaign performance data.")
    
    # --- Targeting Performance Section ---
    if st.session_state.current_page == "advertising_audit":
        # Gold main header for Targeting Performance with anchor
        st.markdown("<div id='targeting-performance' class='section-anchor'></div>", unsafe_allow_html=True)
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<span class='main-section-header dashboard-section'>Targeting Performance</span>", unsafe_allow_html=True)
        st.markdown("<div style='margin-bottom:1.2rem;'></div>", unsafe_allow_html=True)
        if st.session_state.get('bulk_data') and st.session_state.get('client_config'):
            import math
            goals = st.session_state.client_config.get('goals', {})

            shared_column_config = {
                # Currency
                "Spend": st.column_config.NumberColumn(label="Spend", format="dollar"),
                "Ad Sales": st.column_config.NumberColumn(label="Ad Sales", format="dollar"),
                "Total Sales": st.column_config.NumberColumn(label="Total Sales ($)", format="dollar"),
                "AOV": st.column_config.NumberColumn(label="AOV ($)", format="dollar"),
                "CPA": st.column_config.NumberColumn(label="CPA ($)", format="dollar"),
                "CPC": st.column_config.NumberColumn(label="CPC ($)", format="dollar"),
                "Bid": st.column_config.NumberColumn(label="Bid ($)", format="dollar"),
                # Percentages
                "ACoS": st.column_config.NumberColumn(label="ACoS (%)", format="%.2f%%"),
                "CVR": st.column_config.NumberColumn(label="CVR (%)", format="%.2f%%"),
                "CTR": st.column_config.NumberColumn(label="CTR (%)", format="%.2f%%"),
                "TACoS": st.column_config.NumberColumn(label="TACoS (%)", format="%.2f%%"),
                "% Ad Sales": st.column_config.NumberColumn(label="% Ad Sales", format="%.2f%%"),
                "Ad Traffic % Sessions": st.column_config.NumberColumn(label="Ad Traffic % Sessions", format="%.2f%%"),
                # Integers with Commas
                "Impressions": st.column_config.NumberColumn(label="Impressions", format="localized"),
                "Clicks": st.column_config.NumberColumn(label="Clicks", format="localized"),
                "Orders": st.column_config.NumberColumn(label="Orders", format="localized"),
                "Units Sold": st.column_config.NumberColumn(label="Units Sold", format="localized"),
                "Sessions": st.column_config.NumberColumn(label="Sessions", format="localized"),
                # General Numbers
                "ROAS": st.column_config.NumberColumn(label="ROAS", format="%.2f"),
                # Text columns
                "Campaign": st.column_config.TextColumn(label="Campaign"),
                "Target": st.column_config.TextColumn(label="Target"),
                "Match Type": st.column_config.TextColumn(label="Match Type"),
                "Target Type": st.column_config.TextColumn(label="Target Type"),
                "Ad Type": st.column_config.TextColumn(label="Ad Type"),
                "Search Term": st.column_config.TextColumn(label="Search Term"),
                "Product Group": st.column_config.TextColumn(label="Product Group")
            }

            # Retrieve ACoS targets
            branded_acos = goals.get('branded_acos', None)
            non_branded_acos = goals.get('non_branded_acos', None)
            account_wide_acos = goals.get('account_wide_acos', None)

            # Get targeting data
            # No descriptions needed
            
            try:
                branded_targets_df, non_branded_targets_df = get_targeting_performance_data(
                    st.session_state.bulk_data,
                    st.session_state.client_config
                )
                st.session_state.branded_targets_df = branded_targets_df
                st.session_state.non_branded_targets_df = non_branded_targets_df
                st.session_state.all_targets_df = pd.concat([branded_targets_df, non_branded_targets_df], ignore_index=True)

                # Extract product groups for filtering
                product_groups = set()
                for df in [st.session_state.all_targets_df, branded_targets_df, non_branded_targets_df]:
                    if not df.empty and 'Product Group' in df.columns:
                        groups = df['Product Group'].dropna().unique()
                        product_groups.update([g for g in groups if g])
                
                # Initialize session state for product group filter if not exists
                if 'targeting_performance_product_group_filter' not in st.session_state:
                    st.session_state.targeting_performance_product_group_filter = []
                
                # Add product group filter above the tabs
                if product_groups:
                    product_groups = sorted(list(product_groups))
                    filter_col1, filter_col2 = st.columns([0.4, 0.6])
                    with filter_col1:
                        # Use the session state value as the default
                        selected_product_groups = st.multiselect(
                            "Filter by Product Group(s):",
                            options=product_groups,
                            key="targeting_performance_product_group_filter"
                        )
                        # Update the filter active state based on selection
                        st.session_state.targeting_performance_filter_active = len(selected_product_groups) > 0
                

                
                tab_labels = ["All Targets", "Branded Targets", "Non-Branded Targets"]
                tabs = st.tabs(tab_labels)
                target_dfs = [st.session_state.all_targets_df, branded_targets_df, non_branded_targets_df]
                target_acos_list = [account_wide_acos, branded_acos, non_branded_acos]

                for tab, label, df, target_acos in zip(tabs, tab_labels, target_dfs, target_acos_list):
                    with tab:
                        # Defensive: If df is a dict, display warning and show each DataFrame
                        if isinstance(df, dict):
                            st.warning(f"{label} data is a dictionary. Displaying each item individually.")
                            for subkey, subdf in df.items():
                                st.subheader(subkey)
                                try:
                                    st.dataframe(subdf)
                                except Exception as e:
                                    st.error(f"Error displaying {subkey}: {e}")
                            continue

                        # Apply product group filtering if active
                        filtered_df = df.copy()
                        
                        # --- Patch: Ensure Product Group is always campaign-level ---
                        # Build a mapping from campaign name to tag_1 (campaign-level product group)
                        campaign_tag_map = {}
                        if 'client_config' in st.session_state and 'campaign_tags_data' in st.session_state.client_config:
                            for cname, cinfo in st.session_state.client_config['campaign_tags_data'].items():
                                if cinfo.get('tag_1'):
                                    campaign_tag_map[cname.upper()] = cinfo['tag_1']
                        # Overwrite Product Group column with the campaign-level tag_1
                        # Only populate if there are actually product groups defined in Campaign Tagging
                        if 'Campaign' in filtered_df.columns:
                            if campaign_tag_map:  # Only if there are product groups defined
                                filtered_df['Product Group'] = filtered_df['Campaign'].apply(lambda x: campaign_tag_map.get(str(x).upper(), '') or 'Untagged Group')
                            else:
                                filtered_df['Product Group'] = 'Untagged Group'  # Use 'Untagged Group' if no product groups defined
                        
                        # Apply product group filter if active
                        if st.session_state.get('targeting_performance_filter_active', False) and len(st.session_state.targeting_performance_product_group_filter) > 0:
                            if 'Product Group' in filtered_df.columns:
                                filtered_df = filtered_df[filtered_df['Product Group'].isin(st.session_state.targeting_performance_product_group_filter)]
                                st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.targeting_performance_product_group_filter)}")
                            else:
                                st.warning("Product Group column not found in data. Cannot apply filter.")
                                st.session_state.debug_messages.append("[Targeting Performance] Product Group column not found in data.")
                        
                            
                        # Sort by Ad Sales if the column exists
                        sales_col = None
                        if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and 'Sponsored Display' in str(filtered_df.get('Campaign Type', '')).upper():
                            sales_col = 'Sales (Views & Clicks)' if 'Sales (Views & Clicks)' in filtered_df.columns else 'Sales'
                        else:
                            sales_col = 'Ad Sales'
                                
                        if sales_col in filtered_df.columns:
                            filtered_df = filtered_df.sort_values(by=sales_col, ascending=False)

                        # Remove KPI Summary Cards
                        if not filtered_df.empty:
                            # Debug information only
                            st.session_state.debug_messages.append(f"Targeting Performance Summary - Using sales column: {sales_col}")
                            st.session_state.debug_messages.append(f"Available columns: {filtered_df.columns.tolist()}")

                        # --- Table Filters: Text Input (Contains) and Dropdowns ---
                        campaign_filter, target_filter, match_type_filter, target_type_filter = '', '', '', ''
                        
                        # First row of filters
                        row1_cols = st.columns(2)
                        with row1_cols[0]:
                            campaign_filter = st.text_input("Filter by Campaign", key=f"filter_{label}_campaign")
                        with row1_cols[1]:
                            target_filter = st.text_input("Filter by Target", key=f"filter_{label}_target")
                        
                        # Second row of filters (dropdowns)
                        row2_cols = st.columns(3)
                        with row2_cols[0]:
                            # Get unique match types from the data
                            if 'Match Type' in filtered_df.columns:
                                match_types = ['All'] + sorted(filtered_df['Match Type'].dropna().unique().tolist())
                            else:
                                match_types = ['All']
                            match_type_filter = st.selectbox("Filter by Match Type", match_types, key=f"filter_{label}_match_type")
                        with row2_cols[1]:
                            # Get unique target types from the data
                            if 'Target Type' in filtered_df.columns:
                                target_types = ['All'] + sorted(filtered_df['Target Type'].dropna().unique().tolist())
                            else:
                                target_types = ['All']
                            target_type_filter = st.selectbox("Filter by Target Type", target_types, key=f"filter_{label}_target_type")
                        with row2_cols[2]:
                            # Get unique ad types from the data
                            # First ensure 'Ad Type' column exists by renaming 'Sheet Source' if needed
                            temp_df = filtered_df.copy()
                            if 'Sheet Source' in temp_df.columns and 'Ad Type' not in temp_df.columns:
                                temp_df['Ad Type'] = temp_df['Sheet Source']
                            ad_types = ['All']
                            if 'Ad Type' in temp_df.columns:
                                ad_types += sorted(temp_df['Ad Type'].dropna().unique().tolist())
                            ad_type_filter = st.selectbox("Filter by Ad Type", ad_types, key=f"filter_{label}_ad_type")
                        
                        filtered_df_original = filtered_df.copy()
                        filter_changed = False
                        if campaign_filter:
                            import re

                            def phrase_match(value, filter_value):
                                if not isinstance(value, str):
                                    return False
                                pattern = re.escape(filter_value)
                                # Match as a whole phrase (preceded/followed by |, start/end, or whitespace)
                                regex = rf"(^|[|\s]){pattern}([|\s]|$)"
                                return re.search(regex, value, re.IGNORECASE) is not None or value.strip().lower() == filter_value.strip().lower()

                            if campaign_filter:
                                matched_campaigns = filtered_df['Campaign'].astype(str).apply(lambda x: phrase_match(x, campaign_filter))
                                filtered_df = filtered_df[matched_campaigns]
                                st.session_state.debug_messages.append(f"Campaign filter '{campaign_filter}' matched: {filtered_df['Campaign'].unique().tolist()}")
                                filter_changed = True
                        if target_filter:
                            # Clean and normalize the search term and target values
                            search_terms = [term.strip().lower() for term in target_filter.split('|') if term.strip()]
                            
                            # Debug logging
                            st.session_state.debug_messages.append(f"[Target Search] Looking for terms: {search_terms}")
                            
                            # Create a mask for matching any of the search terms (OR condition)
                            mask = pd.Series(False, index=filtered_df.index)
                            for term in search_terms:
                                # Check if the search term contains a pipe (indicating multiple targets)
                                if '|' in term:
                                    # If it's a pipe-separated list, split and check for any match
                                    sub_terms = [t.strip() for t in term.split('|') if t.strip()]
                                    for sub_term in sub_terms:
                                        mask = mask | filtered_df['Target'].astype(str).str.lower().str.contains(re.escape(sub_term), regex=True, na=False)
                                else:
                                    # Single term search
                                    mask = mask | filtered_df['Target'].astype(str).str.lower().str.contains(re.escape(term), regex=True, na=False)
                            
                            # Apply the combined mask
                            filtered_df = filtered_df[mask]
                            filter_changed = True
                            
                            # Log the results
                            st.session_state.debug_messages.append(f"[Target Search] Found {len(filtered_df)} matches for terms: {search_terms}")
                        if match_type_filter and match_type_filter != 'All' and 'Match Type' in filtered_df.columns:
                            filtered_df = filtered_df[filtered_df['Match Type'] == match_type_filter]
                            filter_changed = True
                        if target_type_filter and target_type_filter != 'All' and 'Target Type' in filtered_df.columns:
                            filtered_df = filtered_df[filtered_df['Target Type'] == target_type_filter]
                            filter_changed = True
                        if ad_type_filter and ad_type_filter != 'All':
                            # Ensure we have an Ad Type column
                            if 'Ad Type' not in filtered_df.columns and 'Sheet Source' in filtered_df.columns:
                                filtered_df['Ad Type'] = filtered_df['Sheet Source']
                            if 'Ad Type' in filtered_df.columns:
                                filtered_df = filtered_df[filtered_df['Ad Type'] == ad_type_filter]
                                filter_changed = True
                        # Reset to page 1 if filters changed
                        if filter_changed:
                            st.session_state[f"{label}_page_number"] = 1

                        # --- Summary Metrics from Filtered Data ---
                        if not filtered_df.empty:
                            spend = filtered_df['Spend'].replace('[\$,]', '', regex=True).astype(float).sum() if 'Spend' in filtered_df.columns else 0
                            
                            # Use the appropriate sales column based on attribution choice
                            sales_col = None
                            if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)" and 'Sponsored Display' in str(filtered_df.get('Campaign Type', '')).upper():
                                sales_col = 'Sales (Views & Clicks)' if 'Sales (Views & Clicks)' in filtered_df.columns else 'Ad Sales'
                            else:
                                sales_col = 'Ad Sales'
                                
                            sales = filtered_df[sales_col].replace('[\$,]', '', regex=True).astype(float).sum() if sales_col in filtered_df.columns else 0
                            acos = (spend / sales * 100) if sales > 0 else 0
                            roas = (sales / spend) if spend > 0 else 0
                            clicks = filtered_df['Clicks'].replace(',', '', regex=True).astype(float).sum() if 'Clicks' in filtered_df.columns else 0
                            cpc = (spend / clicks) if clicks > 0 else 0
                            cvr = (filtered_df['Orders'].replace(',', '', regex=True).astype(float).sum() / filtered_df['Clicks'].replace(',', '', regex=True).astype(float).sum() * 100) if 'Clicks' in filtered_df.columns and 'Orders' in filtered_df.columns and filtered_df['Clicks'].sum() > 0 else 0
                            aov = (sales / filtered_df['Orders'].replace(',', '', regex=True).astype(float).sum()) if 'Orders' in filtered_df.columns and filtered_df['Orders'].sum() > 0 else 0
                            
                            # Display summary cards
                            kpi_cols = st.columns(6)
                            kpi_cols[0].metric("TOTAL SPEND", f"${spend:,.2f}")
                            kpi_cols[1].metric("AD SALES", f"${sales:,.2f}")
                            kpi_cols[2].metric("ACOS", f"{acos:.2f}%")
                            kpi_cols[3].metric("CPC", f"${cpc:.2f}")
                            kpi_cols[4].metric("CVR", f"{cvr:.2f}%")
                            kpi_cols[5].metric("AOV", f"${aov:.2f}")

                        # --- Main Table: Paginated, Styled ---
                        if not filtered_df.empty:
                            # --- Main Table: Styled ---
                            # No pagination - display all rows
                            display_df = filtered_df.copy()

                            # --- Remove unwanted columns ---
                            cols_to_remove = ["Classification", "Classification Reason", "Ad Group"]
                            
                            # Also remove Product Group column if no product groups are defined in Campaign Tagging
                            has_product_groups = False
                            if 'client_config' in st.session_state and 'campaign_tags_data' in st.session_state.client_config:
                                has_product_groups = any(v.get('tag_1', '') for v in st.session_state.client_config['campaign_tags_data'].values())
                            
                            if not has_product_groups:
                                cols_to_remove.append("Product Group")
                            
                            display_df = display_df.drop(columns=[col for col in cols_to_remove if col in display_df.columns], errors="ignore")

                            # --- Rename and reorder columns ---
                            if "Sheet Source" in display_df.columns:
                                # Check if 'Ad Type' column already exists
                                if 'Ad Type' in display_df.columns:
                                    # If Ad Type already exists, don't rename Sheet Source, just drop it
                                    display_df = display_df.drop(columns=['Sheet Source'])
                                else:
                                    # If Ad Type doesn't exist, rename Sheet Source to Ad Type
                                    display_df = display_df.rename(columns={"Sheet Source": "Ad Type"})
                                    
                            # Ensure no duplicate column names exist
                            cols = list(display_df.columns)
                            seen = set()
                            deduped_cols = []
                            for col in cols:
                                if col in seen:
                                    # Skip duplicate columns
                                    continue
                                seen.add(col)
                                deduped_cols.append(col)
                            display_df = display_df[deduped_cols]
                                    
                            # Make sure 'Ad Sales' exists, but keep 'Sales' for the dataframe
                            # Only remove 'Sales' from the display
                            if 'Sales' in display_df.columns and 'Ad Sales' not in display_df.columns:
                                display_df['Ad Sales'] = display_df['Sales']
                            elif 'Ad Sales' in display_df.columns and 'Sales' not in display_df.columns:
                                display_df['Sales'] = display_df['Ad Sales']
                                
                            # For display purposes, we'll hide the 'Sales' column
                            display_cols = [col for col in display_df.columns if col != 'Sales']
                                
                            # Move 'Bid' column to the end if it exists
                            if 'Bid' in display_df.columns:
                                cols = list(display_df.columns)
                                cols.remove('Bid')
                                cols.append('Bid')
                                display_df = display_df[display_cols]

                            # --- Main Table: Display with formatting and sorting preserved ---
                            try:
                                if target_acos is not None:
                                    use_avg_fallback = False
                                    if 'client_config' in st.session_state:
                                        goals = st.session_state.client_config.get('goals', {})
                                        if 'Branded' in label:
                                            use_avg_fallback = goals.get('use_avg_acos_branded', False)
                                        elif 'Non-Branded' in label:
                                            use_avg_fallback = goals.get('use_avg_acos_nonbranded', False)
                                        else:
                                            use_avg_fallback = goals.get('use_avg_acos_account', False)
                                    style_acos(display_df, target_acos, column_config=shared_column_config, use_avg_as_fallback=use_avg_fallback, title=f"{label} Targeting", use_expander=True)
                                else:
                                    st.dataframe(display_df, use_container_width=True, hide_index=True, column_config=shared_column_config)
                            except Exception as e:
                                st.error(f"Error displaying styled table: {e}")
                                st.session_state.debug_messages.append(f"[Targeting Table Error] {e}")

                            # Display row count
                            st.caption(f"Total Rows: {len(filtered_df)}")
                                
                        else:
                            st.info(f"No {label.lower()} found.")
                            
                # After all tabs are processed, add the ACoS Range Distribution section with its own tabs
                # --- Target ACoS Range Distribution section commented out by request ---
                # (existing commented code remains unchanged)

                # --- Dynamic Word Cloud Section ---
                if not st.session_state.branded_targets_df.empty or not st.session_state.non_branded_targets_df.empty or not st.session_state.all_targets_df.empty:
                    st.markdown("<div style='margin-top:2rem;'></div>", unsafe_allow_html=True)
                    with st.expander("Show Target Word Cloud", expanded=False):
                        st.markdown("""
                            <div style='font-size:1.1rem; color:#bfa23a; font-weight:600; margin-bottom:0.5rem;'>Target Word Cloud</div>
                            <style>
                            .wordcloud-container {
                                background: #181818;
                                border-radius: 16px;
                                box-shadow: 0 2px 12px rgba(0,0,0,0.25);
                                padding: 1.5rem 1rem 1rem 1rem;
                                margin-bottom: 1.5rem;
                            }
                            </style>
                        """, unsafe_allow_html=True)
                        
                        # Always remove ASINs from target word cloud
                        remove_asins_target = True

                        # Outer tabs for All, Branded, Non-Branded
                        wc_outer_labels = ["All", "Branded", "Non-Branded"]
                        wc_outer_tabs = st.tabs(wc_outer_labels)
                        wc_dfs = [st.session_state.all_targets_df, st.session_state.branded_targets_df, st.session_state.non_branded_targets_df]

                        for wc_outer_idx, (wc_outer_tab, wc_outer_label, wc_df) in enumerate(zip(wc_outer_tabs, wc_outer_labels, wc_dfs)):
                            with wc_outer_tab:
                                wc_tab_labels = ["Spend", "Ad Sales"]
                                wc_tabs = st.tabs(wc_tab_labels)
                                for wc_tab_label, wc_metric in zip(wc_tab_labels, ["Spend", "Ad Sales"]):
                                    with wc_tabs[wc_tab_labels.index(wc_tab_label)]:
                                        st.markdown("<div class='wordcloud-container'>", unsafe_allow_html=True)
                                        # Defensive: check columns
                                        if wc_df is not None and not wc_df.empty and 'Target' in wc_df.columns and wc_metric in wc_df.columns:
                                            wc_data = wc_df[["Target", wc_metric]].copy()
                                            wc_data[wc_metric] = (
                                                wc_data[wc_metric]
                                                .replace('[\$,]', '', regex=True)
                                                .replace(',', '', regex=True)
                                                .astype(str)
                                                .str.replace(',', '')
                                                .astype(float)
                                            )
                                            wc_data = wc_data.groupby("Target")[wc_metric].sum().reset_index()
                                            wc_dict = dict(zip(wc_data["Target"], wc_data[wc_metric]))
                                            wc_dict = {k: v for k, v in wc_dict.items() if v > 0}
                                            
                                            # Always filter out ASINs from target word cloud
                                            wc_dict = {k: v for k, v in wc_dict.items() 
                                                      if not (len(str(k)) == 10 and str(k).lower().startswith('b0'))}
                                            
                                            if wc_dict:
                                                wc = WordCloud(
                                                    width=900,
                                                    height=350,
                                                    background_color="#181818",
                                                    colormap="summer",
                                                    prefer_horizontal=0.95,
                                                    contour_color="#bfa23a",
                                                    contour_width=2
                                                ).generate_from_frequencies(wc_dict)
                                                fig, ax = plt.subplots(figsize=(12, 4), facecolor="#181818")
                                                ax.imshow(wc, interpolation="bilinear")
                                                ax.axis("off")
                                                fig.patch.set_facecolor('#181818')
                                                plt.tight_layout(pad=0)
                                                st.pyplot(fig)
                                                plt.close(fig)
                                            else:
                                                st.info(f"No {wc_metric.lower()} data available for word cloud.")
                                        else:
                                            st.info(f"No data available for {wc_metric} word cloud.")
                                        st.markdown("</div>", unsafe_allow_html=True)

                    # --- Search Term Table Section ---
                    st.markdown("<div style='margin-top:3rem;'></div>", unsafe_allow_html=True)
                    st.markdown("<div id='search-term-performance' class='section-anchor'></div>", unsafe_allow_html=True)
                    st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
                    st.markdown("<span class='main-section-header'>Search Term Performance</span>", unsafe_allow_html=True)
                    
                    # No descriptions needed
                    
                    # Initialize session state variables for search term product group filter if they don't exist
                    if 'search_term_product_group_filter' not in st.session_state:
                        st.session_state.search_term_product_group_filter = []
                    if 'search_term_filter_active' not in st.session_state:
                        st.session_state.search_term_filter_active = False
                    
                    # Define a callback function to update the filter state
                    def update_search_term_filter_state():
                        st.session_state.search_term_filter_active = len(st.session_state.search_term_product_group_filter) > 0
                    
                    # Add product group filter above the tabs
                    filter_col1, filter_col2 = st.columns([0.4, 0.6])
                    with filter_col1:
                        # Get unique product groups from the data if available
                        product_groups = []
                        if 'bulk_data' in st.session_state:
                            search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                            if not search_term_df.empty and 'Product Group' in search_term_df.columns:
                                product_groups = sorted([str(g) for g in search_term_df['Product Group'].dropna().unique() if g])
                        
                        if product_groups:
                            st.multiselect(
                                "Filter by Product Group(s):",
                                options=product_groups,
                                key="search_term_product_group_filter",
                                on_change=update_search_term_filter_state
                            )
                        else:
                            # Show disabled multiselect with informative label if no product groups found
                            st.multiselect(
                                "Filter by Product Group(s) (Add in Client Settings):",
                                options=[],
                                disabled=True,
                                key="search_term_product_group_filter_disabled"
                            )
                            # Reset filter state if no product groups
                            if st.session_state.search_term_product_group_filter:
                                st.session_state.search_term_product_group_filter = []
                                st.session_state.search_term_filter_active = False
                    
                    # Create tabs for All Terms, Branded Terms, and Non-Branded Terms
                    st.markdown("<div style='margin-top:0.5rem;'></div>", unsafe_allow_html=True)
                    all_tab, branded_tab, non_branded_tab = st.tabs(["All Terms", "Branded Terms", "Non-Branded Terms"])
                    
                    # Function to display table with pagination for each tab
                    def display_search_term_table(df, tab_key, is_branded=None, show_metrics=False, show_filters=False):
                        # Get ACoS targets from client config
                        goals = st.session_state.client_config.get('goals', {}) if 'client_config' in st.session_state else {}
                        branded_target = goals.get('branded_acos')
                        non_branded_target = goals.get('non_branded_acos')
                        account_target = goals.get('account_wide_acos')
                        
                        # Determine which target to use based on tab type
                        target_acos = None
                        if is_branded is True:
                            target_acos = branded_target or account_target
                            use_avg_fallback = goals.get('use_avg_acos_branded', False)
                        elif is_branded is False:
                            target_acos = non_branded_target or account_target
                            use_avg_fallback = goals.get('use_avg_acos_nonbranded', False)
                        else:
                            target_acos = account_target
                            use_avg_fallback = goals.get('use_avg_acos_account', False)
                        
                        # No pagination - display all rows
                    
                        # Ensure we have all required columns and use shared_column_config for formatting
                        required_columns = ['Campaign', 'Target Type', 'Match Type', 'Target', 'Search Term', 'Spend', 'Ad Sales', 'Orders', 'Impressions', 'Clicks', 'ACoS', 'ROAS', 'CPC', 'CTR', 'CVR', 'AOV']
                        
                        # Check if Product Group should be included based on whether there are product groups defined
                        has_product_groups = False
                        if 'client_config' in st.session_state and 'campaign_tags_data' in st.session_state.client_config:
                            has_product_groups = any(v.get('tag_1', '') for v in st.session_state.client_config['campaign_tags_data'].values())
                        
                        # Only include Product Group in required columns if there are product groups defined
                        if has_product_groups and 'Product Group' in df.columns:
                            required_columns.insert(1, 'Product Group')  # Insert after Campaign
                        
                        for col in required_columns:
                            if col not in df.columns:
                                # Use 0 for numeric columns, '' for text
                                if col in ['Spend', 'Ad Sales', 'Orders', 'Impressions', 'Clicks', 'ROAS', 'CPC', 'CTR', 'CVR', 'AOV']:
                                    df[col] = 0
                                else:
                                    df[col] = ''

                        # Reorder columns as specified
                        display_columns = [col for col in required_columns if col in df.columns]

                        # Sort by Ad Sales numerically if present
                        if 'Ad Sales' in df.columns and not df.empty:
                            df = df.copy()
                            # Clean numeric columns to fix weird characters
                            for col in ['Spend', 'Ad Sales']:
                                if col in df.columns:
                                    # Convert to numeric, removing any currency symbols or formatting
                                    df[col] = pd.to_numeric(df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                            df['Ad_Sales_Numeric'] = df['Ad Sales']
                            df = df.sort_values(by='Ad_Sales_Numeric', ascending=False)
                            df = df.drop(columns=['Ad_Sales_Numeric'])

                        # Remove any manual string formatting for display
                        # Use shared_column_config for column formatting
                        try:
                            from . import shared_column_config
                        except ImportError:
                            shared_column_config = {
                                "Spend": st.column_config.NumberColumn(label="Spend", format="dollar"),
                                "Ad Sales": st.column_config.NumberColumn(label="Ad Sales", format="dollar"),
                                "Orders": st.column_config.NumberColumn(label="Orders", format="localized"),
                                "Impressions": st.column_config.NumberColumn(label="Impressions", format="localized"),
                                "Clicks": st.column_config.NumberColumn(label="Clicks", format="localized"),
                                "ACoS": st.column_config.NumberColumn(label="ACoS (%)", format="%.2f%%"),
                                "ROAS": st.column_config.NumberColumn(label="ROAS", format="%.2f"),
                                "CPC": st.column_config.NumberColumn(label="CPC ($)", format="dollar"),
                                "CTR": st.column_config.NumberColumn(label="CTR (%)", format="%.2f%%"),
                                "CVR": st.column_config.NumberColumn(label="CVR (%)", format="%.2f%%"),
                                "AOV": st.column_config.NumberColumn(label="AOV ($)", format="dollar"),
                                "Target Type": st.column_config.TextColumn(label="Target Type"),
                                "Match Type": st.column_config.TextColumn(label="Match Type"),
                                "Target": st.column_config.TextColumn(label="Target"),
                                "Search Term": st.column_config.TextColumn(label="Search Term"),
                                "Campaign": st.column_config.TextColumn(label="Campaign"),
                            }

                        # Only display filters if show_filters is True
                        filter_prefix = f"filter_search_term_{tab_key}_"
                        campaign_filter, target_filter, search_term_filter, match_type_filter = '', '', '', ''
                        
                        if show_filters:
                            row1_cols = st.columns(2)
                            with row1_cols[0]:
                                campaign_filter = st.text_input("Filter by Campaign", key=filter_prefix + "campaign")
                            with row1_cols[1]:
                                target_filter = st.text_input("Filter by Target", key=filter_prefix + "target")
                            row2_cols = st.columns(2)
                            with row2_cols[0]:
                                search_term_filter = st.text_input("Filter by Search Term", key=filter_prefix + "search_term")
                            with row2_cols[1]:
                                match_types = ['All'] + sorted(df['Match Type'].dropna().unique().tolist())
                                match_type_filter = st.selectbox("Filter by Match Type", match_types, key=filter_prefix + "match_type")

                        # Apply filters
                        filtered_df = df.copy()
                        
                        # Clean numeric columns to fix weird characters
                        for col in ['Spend', 'Ad Sales']:
                            if col in filtered_df.columns:
                                # Convert to numeric, removing any currency symbols or formatting
                                filtered_df[col] = pd.to_numeric(filtered_df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        
                        if campaign_filter:
                            matched_campaigns = filtered_df['Campaign'].astype(str).apply(lambda x: phrase_match(x, campaign_filter))
                            filtered_df = filtered_df[matched_campaigns]
                        if target_filter:
                            filtered_df = filtered_df[filtered_df['Target'].astype(str).str.contains(target_filter, case=False, na=False)]
                        if search_term_filter:
                            filtered_df = filtered_df[filtered_df['Search Term'].astype(str).str.contains(search_term_filter, case=False, na=False)]
                        if match_type_filter and match_type_filter != 'All':
                            filtered_df = filtered_df[filtered_df['Match Type'].astype(str) == match_type_filter]
                            
                        # Display summary metrics if requested
                        if show_metrics and not filtered_df.empty:
                            # Calculate summary metrics with proper numeric conversion
                            spend = filtered_df['Spend'].sum() if 'Spend' in filtered_df.columns else 0
                            sales = filtered_df['Ad Sales'].sum() if 'Ad Sales' in filtered_df.columns else 0
                            acos = (spend / sales * 100) if sales > 0 else 0
                            clicks = filtered_df['Clicks'].replace(',', '', regex=True).astype(float).sum() if 'Clicks' in filtered_df.columns else 0
                            cpc = (spend / clicks) if clicks > 0 else 0
                            orders_sum = filtered_df['Orders'].replace(',', '', regex=True).astype(float).sum() if 'Orders' in filtered_df.columns else 0
                            clicks_sum = filtered_df['Clicks'].replace(',', '', regex=True).astype(float).sum() if 'Clicks' in filtered_df.columns else 0
                            
                            # Calculate CVR and AOV with simplified conditionals
                            cvr = (orders_sum / clicks_sum * 100) if clicks_sum > 0 else 0
                            aov = (sales / orders_sum) if orders_sum > 0 else 0
                            
                            # Display summary cards
                            kpi_cols = st.columns(6)
                            kpi_cols[0].metric("TOTAL SPEND", f"${spend:,.2f}")
                            kpi_cols[1].metric("AD SALES", f"${sales:,.2f}")
                            kpi_cols[2].metric("ACOS", f"{acos:.2f}%")
                            kpi_cols[3].metric("CPC", f"${cpc:.2f}")
                            kpi_cols[4].metric("CVR", f"{cvr:.2f}%")
                            kpi_cols[5].metric("AOV", f"${aov:.2f}")

                        # Use style_acos for ACoS highlighting if available, otherwise st.dataframe
                        if 'ACoS' in filtered_df.columns and (target_acos is not None or use_avg_fallback):
                            try:
                                style_acos(filtered_df[display_columns], target_acos, column_config=shared_column_config, use_avg_as_fallback=use_avg_fallback, title=f"{'Branded' if is_branded else 'Non-Branded' if is_branded is not None else 'All'} Search Terms")
                            except Exception as e:
                                st.dataframe(filtered_df[display_columns], use_container_width=True, column_config=shared_column_config, hide_index=True)
                        else:
                            st.dataframe(filtered_df[display_columns], use_container_width=True, column_config=shared_column_config, hide_index=True)

                    with all_tab:
                        if 'bulk_data' in st.session_state:
                            # Get search term data with branding classification
                            search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                            
                            # Apply product group filter if active
                            if st.session_state.get('search_term_filter_active', False) and 'Product Group' in search_term_df.columns and st.session_state.search_term_product_group_filter:
                                search_term_df = search_term_df[search_term_df['Product Group'].isin(st.session_state.search_term_product_group_filter)]
                            
                            if search_term_df.empty:
                                st.info("No search term data available. Please upload bulk advertising files with search term data.")
                            else:
                                # Display the table with summary cards between filters and table
                                display_search_term_table(search_term_df, "all", is_branded=None, show_metrics=True, show_filters=True)
                        else:
                            st.info("No bulk advertising data available. Please upload bulk advertising files with search term data.")
                    
                    with branded_tab:
                        if 'bulk_data' in st.session_state:
                            # Get search term data with branding classification
                            search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                            
                            # Apply product group filter if active
                            if st.session_state.get('search_term_filter_active', False) and 'Product Group' in search_term_df.columns and st.session_state.search_term_product_group_filter:
                                search_term_df = search_term_df[search_term_df['Product Group'].isin(st.session_state.search_term_product_group_filter)]
                            
                            if search_term_df.empty:
                                st.info("No search term data available. Please upload bulk advertising files with search term data.")
                            else:
                                # Get targeting data to merge for Target Type
                                targeting_data = None
                                # Check if we have both branded and non-branded targeting data in session state
                                if 'branded_targets_df' in st.session_state and 'non_branded_targets_df' in st.session_state:
                                    branded_df = st.session_state.branded_targets_df
                                    non_branded_df = st.session_state.non_branded_targets_df
                                    if not branded_df.empty or not non_branded_df.empty:
                                        targeting_data = pd.concat([branded_df, non_branded_df], ignore_index=True)
                                        st.session_state.debug_messages.append(f"[Search Term Table] Combined targeting data: {len(targeting_data)} rows")
                                
                                # Merge Target Type from targeting data if available
                                if targeting_data is not None and 'Target Type' in targeting_data.columns:
                                    # Create a mapping dictionary from Target to Target Type
                                    target_type_map = dict(zip(targeting_data['Target'], targeting_data['Target Type']))
                                    
                                    # Apply the mapping to search term data
                                    search_term_df['Target Type'] = search_term_df['Target'].map(target_type_map)
                                    
                                    # For any missing Target Types, use a default value
                                    search_term_df['Target Type'] = search_term_df['Target Type'].fillna('Keyword')
                                    
                                    st.session_state.debug_messages.append(f"[Search Term Table] Added Target Type from targeting data")
                                else:
                                    # If targeting data not available, use a default value
                                    search_term_df['Target Type'] = 'Keyword'
                                    st.session_state.debug_messages.append(f"[Search Term Table] Using default Target Type 'Keyword'")
                                
                                # Filter for branded terms only
                                branded_df = search_term_df[search_term_df['Is_Branded'] == True].copy() if 'Is_Branded' in search_term_df.columns else pd.DataFrame()
                                
                                # --- Table Filters: Text Input (Contains) and Dropdown ---
                                campaign_filter, target_filter, search_term_filter, match_type_filter = '', '', '', ''
                                
                                # First row of filters
                                row1_cols = st.columns(2)
                                with row1_cols[0]:
                                    campaign_filter = st.text_input("Filter by Campaign", key="filter_search_term_campaign_branded")
                                with row1_cols[1]:
                                    target_filter = st.text_input("Filter by Target", key="filter_search_term_target_branded")
                                
                                # Second row of filters
                                row2_cols = st.columns(2)
                                with row2_cols[0]:
                                    search_term_filter = st.text_input("Filter by Search Term", key="filter_search_term_branded")
                                with row2_cols[1]:
                                    # Get unique match types from the data
                                    match_types = ['All'] + sorted(branded_df['Match Type'].dropna().unique().tolist())
                                    match_type_filter = st.selectbox("Filter by Match Type", match_types, key="filter_search_term_match_type_branded")
                                
                                # Apply filters
                                filtered_df = branded_df.copy()
                                filter_changed = False
                                
                                if campaign_filter:
                                    matched_campaigns = filtered_df['Campaign'].astype(str).apply(lambda x: phrase_match(x, campaign_filter))
                                    filtered_df = filtered_df[matched_campaigns]
                                    filter_changed = True
                                if target_filter:
                                    filtered_df = filtered_df[filtered_df['Target'].astype(str).str.contains(target_filter, case=False, na=False)]
                                    filter_changed = True
                                if search_term_filter:
                                    filtered_df = filtered_df[filtered_df['Search Term'].astype(str).str.contains(search_term_filter, case=False, na=False)]
                                    filter_changed = True
                                if match_type_filter and match_type_filter != 'All':
                                    filtered_df = filtered_df[filtered_df['Match Type'].astype(str) == match_type_filter]
                                    filter_changed = True
                                
                                # Reset to page 1 if filters changed
                                if filter_changed:
                                    st.session_state["search_term_table_branded_page_number"] = 1
                                
                                if not filtered_df.empty:
                                    # Display the table with summary cards between filters and table
                                    display_search_term_table(filtered_df, "branded", is_branded=True, show_metrics=True, show_filters=False)
                                else:
                                    st.info("No branded search term data found.")
                        else:
                            st.info("No bulk advertising data available. Please upload bulk advertising files with search term data.")
                    
                    with non_branded_tab:
                        if 'bulk_data' in st.session_state:
                            # Get search term data with branding classification
                            search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                            
                            # Apply product group filter if active
                            if st.session_state.get('search_term_filter_active', False) and 'Product Group' in search_term_df.columns and st.session_state.search_term_product_group_filter:
                                search_term_df = search_term_df[search_term_df['Product Group'].isin(st.session_state.search_term_product_group_filter)]
                            
                            if search_term_df.empty:
                                st.info("No search term data available. Please upload bulk advertising files with search term data.")
                            else:
                                # Get targeting data to merge for Target Type
                                targeting_data = None
                                # Check if we have both branded and non-branded targeting data in session state
                                if 'branded_targets_df' in st.session_state and 'non_branded_targets_df' in st.session_state:
                                    branded_df = st.session_state.branded_targets_df
                                    non_branded_df = st.session_state.non_branded_targets_df
                                    if not branded_df.empty or not non_branded_df.empty:
                                        targeting_data = pd.concat([branded_df, non_branded_df], ignore_index=True)
                                        st.session_state.debug_messages.append(f"[Search Term Table] Combined targeting data: {len(targeting_data)} rows")
                                
                                # Merge Target Type from targeting data if available
                                if targeting_data is not None and 'Target Type' in targeting_data.columns:
                                    # Create a mapping dictionary from Target to Target Type
                                    target_type_map = dict(zip(targeting_data['Target'], targeting_data['Target Type']))
                                    
                                    # Apply the mapping to search term data
                                    search_term_df['Target Type'] = search_term_df['Target'].map(target_type_map)
                                    
                                    # For any missing Target Types, use a default value
                                    search_term_df['Target Type'] = search_term_df['Target Type'].fillna('Keyword')
                                    
                                    st.session_state.debug_messages.append(f"[Search Term Table] Added Target Type from targeting data")
                                else:
                                    # If targeting data not available, use a default value
                                    search_term_df['Target Type'] = 'Keyword'
                                    st.session_state.debug_messages.append(f"[Search Term Table] Using default Target Type 'Keyword'")
                                
                                # Filter for non-branded terms only
                                non_branded_df = search_term_df[search_term_df['Is_Branded'] == False].copy() if 'Is_Branded' in search_term_df.columns else pd.DataFrame()
                                
                                # --- Table Filters: Text Input (Contains) and Dropdown ---
                                campaign_filter, target_filter, search_term_filter, match_type_filter = '', '', '', ''
                                
                                # First row of filters
                                row1_cols = st.columns(2)
                                with row1_cols[0]:
                                    campaign_filter = st.text_input("Filter by Campaign", key="filter_search_term_campaign_nonbranded")
                                with row1_cols[1]:
                                    target_filter = st.text_input("Filter by Target", key="filter_search_term_target_nonbranded")
                                
                                # Second row of filters
                                row2_cols = st.columns(2)
                                with row2_cols[0]:
                                    search_term_filter = st.text_input("Filter by Search Term", key="filter_search_term_nonbranded")
                                with row2_cols[1]:
                                    # Get unique match types from the data
                                    match_types = ['All'] + sorted(non_branded_df['Match Type'].dropna().unique().tolist())
                                    match_type_filter = st.selectbox("Filter by Match Type", match_types, key="filter_search_term_match_type_nonbranded")
                                
                                # Apply filters
                                filtered_df = non_branded_df.copy()
                                filter_changed = False
                                
                                if campaign_filter:
                                    matched_campaigns = filtered_df['Campaign'].astype(str).apply(lambda x: phrase_match(x, campaign_filter))
                                    filtered_df = filtered_df[matched_campaigns]
                                    filter_changed = True
                                if target_filter:
                                    filtered_df = filtered_df[filtered_df['Target'].astype(str).str.contains(target_filter, case=False, na=False)]
                                    filter_changed = True
                                if search_term_filter:
                                    filtered_df = filtered_df[filtered_df['Search Term'].astype(str).str.contains(search_term_filter, case=False, na=False)]
                                    filter_changed = True
                                if match_type_filter and match_type_filter != 'All':
                                    filtered_df = filtered_df[filtered_df['Match Type'].astype(str) == match_type_filter]
                                    filter_changed = True
                                
                                # Reset to page 1 if filters changed
                                if filter_changed:
                                    st.session_state["search_term_table_non_branded_page_number"] = 1
                                
                                if not filtered_df.empty:
                                    # Display the table with summary cards between filters and table
                                    display_search_term_table(filtered_df, "non_branded", is_branded=False, show_metrics=True, show_filters=False)
                                else:
                                    st.info("No non-branded search term data found.")
                        else:
                            st.info("No bulk advertising data available. Please upload bulk advertising files with search term data.")
                    
                    # --- Search Term Word Cloud Section ---
                    st.markdown("<div style='margin-top:2rem;'></div>", unsafe_allow_html=True)
                    if 'bulk_data' in st.session_state:
                        # Get search term data
                        search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                        
                        if not search_term_df.empty:
                            with st.expander("Show Search Term Word Cloud", expanded=False):
                                st.markdown("""
                                    <div style='font-size:1.1rem; color:#bfa23a; font-weight:600; margin-bottom:0.5rem;'>Search Term Word Cloud</div>
                                    <style>
                                    .wordcloud-container {
                                        background: #181818;
                                        border-radius: 16px;
                                        box-shadow: 0 2px 12px rgba(0,0,0,0.25);
                                        padding: 1.5rem 1rem 1rem 1rem;
                                        margin-bottom: 1.5rem;
                                    }
                                    </style>
                                """, unsafe_allow_html=True)
                                
                                # Add option to remove ASINs
                                remove_asins_search = st.checkbox("Remove ASINs from search term word cloud", 
                                                          help="Remove terms that appear to be ASINs (starting with B0 and 10 characters long)")
                                
                                # Create tabs for All, Branded, Non-Branded search terms
                                wc_labels = ["All Search Terms", "Branded Search Terms", "Non-Branded Search Terms"]
                                wc_tabs = st.tabs(wc_labels)
                                
                                # Filter data for each tab
                                if 'Is_Branded' in search_term_df.columns:
                                    all_terms = search_term_df
                                    branded_terms = search_term_df[search_term_df['Is_Branded'] == True]
                                    non_branded_terms = search_term_df[search_term_df['Is_Branded'] == False]
                                else:
                                    all_terms = search_term_df
                                    branded_terms = pd.DataFrame()
                                    non_branded_terms = pd.DataFrame()
                                
                                term_dfs = [all_terms, branded_terms, non_branded_terms]
                                term_types = ['all', 'branded', 'non-branded']
                                
                                # Generate word clouds for each tab
                                for idx, (wc_tab, term_df, term_type) in enumerate(zip(wc_tabs, term_dfs, term_types)):
                                    with wc_tab:
                                        st.markdown("<div class='wordcloud-container'>", unsafe_allow_html=True)
                                        if not term_df.empty:
                                            # Generate the word cloud
                                            fig = generate_search_term_wordcloud(term_df, filter_type=term_type, remove_asins=remove_asins_search)
                                            st.pyplot(fig)
                                        else:
                                            st.info(f"No {term_type.replace('-', ' ')} search term data available.")
                                        st.markdown("</div>", unsafe_allow_html=True)
                    
                    # Helper function to calculate wasted spend score
                    def calculate_wasted_spend_score(df):
                            # Create a mapping of targets to their classification (Branded/Non-Branded)
                            target_classification = {}
                            
                            # Add Branded targets to the mapping
                            if not branded_targets_df.empty and 'Target' in branded_targets_df.columns:
                                for target in branded_targets_df['Target'].dropna().unique():
                                    target_classification[str(target).lower()] = "Branded"
                            
                            # Add Non-Branded targets to the mapping
                            if not non_branded_targets_df.empty and 'Target' in non_branded_targets_df.columns:
                                for target in non_branded_targets_df['Target'].dropna().unique():
                                    target_classification[str(target).lower()] = "Non-Branded"
                            
                            # Filter for Sponsored Products and Sponsored Brands only
                            sp_sb_search_terms = search_term_df[
                                search_term_df['Campaign Type'].str.contains('Sponsored Products|Sponsored Brands', case=False, na=False)
                            ].copy() if 'Campaign Type' in search_term_df.columns else search_term_df.copy()
                            
                            # Ensure we have the necessary columns
                            required_cols = ['Search Term', 'Target', 'Is_Branded', 'Campaign', 'Spend', 'Sales', 'Orders', 'Clicks', 'Impressions']
                            for col in required_cols:
                                if col not in sp_sb_search_terms.columns:
                                    sp_sb_search_terms[col] = None
                            
                            # Create a column for search term classification
                            sp_sb_search_terms['Search Term Classification'] = sp_sb_search_terms['Is_Branded'].apply(
                                lambda x: "Branded" if x else "Non-Branded"
                            )
                            
                            # Create a column for target classification
                            sp_sb_search_terms['Target Classification'] = sp_sb_search_terms['Target'].apply(
                                lambda x: target_classification.get(str(x).lower(), "Unknown") if pd.notna(x) else "Unknown"
                            )
                            
                            # Ensure Match Type column exists
                            if 'Match Type' not in sp_sb_search_terms.columns:
                                sp_sb_search_terms['Match Type'] = "Unknown"
                            
                            # Filter for contradicting classifications
                            contradicting_terms = sp_sb_search_terms[
                                (sp_sb_search_terms['Search Term Classification'] != sp_sb_search_terms['Target Classification']) & 
                                (sp_sb_search_terms['Target Classification'] != "Unknown")
                            ].copy()
                            
                            # Calculate metrics
                            if not contradicting_terms.empty:
                                # Calculate ACoS and ROAS as numeric values
                                contradicting_terms['ACoS'] = contradicting_terms.apply(
                                    lambda row: (row['Spend'] / row['Sales'] * 100) if pd.notna(row['Sales']) and row['Sales'] > 0 else 0,
                                    axis=1
                                )
                                contradicting_terms['ROAS'] = contradicting_terms.apply(
                                    lambda row: (row['Sales'] / row['Spend']) if pd.notna(row['Spend']) and row['Spend'] > 0 else 0,
                                    axis=1
                                )
                                
                                # Rename 'Sales' to 'Ad Sales' for clarity, but first check if it already exists
                                if 'Ad Sales' not in contradicting_terms.columns and 'Sales' in contradicting_terms.columns:
                                    contradicting_terms = contradicting_terms.rename(columns={'Sales': 'Ad Sales'})
                                
                                # Create filters
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    search_term_filter = st.text_input("Filter by Search Term", "", key="contradicting_search_term_filter")
                                with col2:
                                    target_filter = st.text_input("Filter by Target", "", key="contradicting_target_filter")
                                with col3:
                                    campaign_filter = st.text_input("Filter by Campaign", "", key="contradicting_campaign_filter")
                                
                                col4, col5 = st.columns(2)
                                with col4:
                                    search_term_class_filter = st.selectbox(
                                        "Filter by Search Term Classification",
                                        ["All", "Branded", "Non-Branded"],
                                        key="contradicting_search_term_class_filter"
                                    )
                                with col5:
                                    # Get unique match types from the data
                                    match_types = ["All"] + sorted(contradicting_terms['Match Type'].dropna().unique().tolist()) if 'Match Type' in contradicting_terms.columns else ["All"]
                                    match_type_filter = st.selectbox(
                                        "Filter by Match Type",
                                        match_types,
                                        key="contradicting_match_type_filter"
                                    )
                                
                                # Apply filters
                                filtered_df = contradicting_terms.copy()
                                if search_term_filter:
                                    filtered_df = filtered_df[filtered_df['Search Term'].astype(str).str.contains(search_term_filter, case=False, na=False)]
                                if target_filter:
                                    filtered_df = filtered_df[filtered_df['Target'].astype(str).str.contains(target_filter, case=False, na=False)]
                                if campaign_filter:
                                    filtered_df = filtered_df[filtered_df['Campaign'].astype(str).str.contains(campaign_filter, case=False, na=False)]
                                if search_term_class_filter != "All":
                                    filtered_df = filtered_df[filtered_df['Search Term Classification'] == search_term_class_filter]
                                if match_type_filter != "All" and 'Match Type' in filtered_df.columns:
                                    filtered_df = filtered_df[filtered_df['Match Type'] == match_type_filter]
                                
                                # Display the table
                                if not filtered_df.empty:
                                    # Calculate summary metrics
                                    # Calculate summary metrics directly without creating new columns
                                    try:
                                        # For Spend
                                        if 'Spend' in filtered_df.columns:
                                            # Convert to numeric safely
                                            numeric_spend = pd.to_numeric(
                                                filtered_df['Spend'].replace('[$,]', '', regex=True) if isinstance(filtered_df['Spend'], pd.Series) else 
                                                filtered_df['Spend'].astype(str), 
                                                errors='coerce'
                                            ).fillna(0)
                                            spend = numeric_spend.sum()
                                        else:
                                            spend = 0
                                            
                                        # For Ad Sales
                                        if 'Ad Sales' in filtered_df.columns:
                                            # Convert to numeric safely
                                            numeric_sales = pd.to_numeric(
                                                filtered_df['Ad Sales'].replace('[$,]', '', regex=True) if isinstance(filtered_df['Ad Sales'], pd.Series) else 
                                                filtered_df['Ad Sales'].astype(str), 
                                                errors='coerce'
                                            ).fillna(0)
                                            sales = numeric_sales.sum()
                                        else:
                                            sales = 0
                                    except Exception as e:
                                        # Fallback if there's any error in conversion
                                        st.error(f"Error calculating metrics: {str(e)}")
                                        spend = 0
                                        sales = 0
                                        
                                    # Calculate ACoS and ROAS using scalar values
                                    acos = (spend / sales * 100) if sales > 0 else 0
                                    roas = (sales / spend) if spend > 0 else 0
                                    
                                    # Display summary cards
                                    kpi_cols = st.columns(4)
                                    kpi_cols[0].metric("TOTAL SPEND", f"${spend:,.2f}")
                                    kpi_cols[1].metric("AD SALES", f"${sales:,.2f}")
                                    kpi_cols[2].metric("ACoS", f"{acos:.2f}%")
                                    kpi_cols[3].metric("ROAS", f"{roas:.2f}")
                                    
                                    # Check for duplicate columns in a safer way
                                    if 'Ad Sales' in filtered_df.columns and filtered_df.columns.duplicated().any():
                                        # Create a new DataFrame with unique column names
                                        # This approach preserves the first occurrence of each column
                                        filtered_df = filtered_df.loc[:, ~filtered_df.columns.duplicated()]
                                    
                                    # Select columns to display
                                    display_cols = [
                                        'Campaign', 'Search Term', 'Search Term Classification', 
                                        'Target', 'Target Classification', 'Match Type', 'Spend', 'Ad Sales', 
                                        'ACoS', 'ROAS'
                                    ]
                                    
                                    # Ensure all required columns exist
                                    for col in display_cols:
                                        if col not in filtered_df.columns:
                                            filtered_df[col] = "N/A"
                                    
                                    # Clean numeric columns to fix weird characters
                                    for col in ['Spend', 'Ad Sales']:
                                        if col in filtered_df.columns:
                                            # Convert to numeric, removing any currency symbols or formatting
                                            filtered_df[col] = pd.to_numeric(filtered_df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                    
                                    # Select columns to display
                                    display_df = filtered_df[display_cols].copy()
                                    
                                    # Create column configuration for proper formatting and sorting
                                    column_config = {
                                        'Campaign': st.column_config.TextColumn(label="Campaign"),
                                        'Search Term': st.column_config.TextColumn(label="Search Term"),
                                        'Search Term Classification': st.column_config.TextColumn(label="Search Term Classification"),
                                        'Target': st.column_config.TextColumn(label="Target"),
                                        'Target Classification': st.column_config.TextColumn(label="Target Classification"),
                                        'Match Type': st.column_config.TextColumn(label="Match Type"),
                                        'Spend': st.column_config.NumberColumn(label="Spend", format="dollar"),
                                        'Ad Sales': st.column_config.NumberColumn(label="Ad Sales", format="dollar"),
                                        'ACoS': st.column_config.NumberColumn(label="ACoS (%)", format="%.2f%%"),
                                        'ROAS': st.column_config.NumberColumn(label="ROAS", format="%.2f")
                                    }
                                    
                                    # Convert ACoS and ROAS to numeric values for proper display
                                    if 'ACoS' in display_df.columns:
                                        display_df['ACoS'] = pd.to_numeric(display_df['ACoS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                    
                                    if 'ROAS' in display_df.columns:
                                        display_df['ROAS'] = pd.to_numeric(display_df['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                    
                                    # Display the table with column config for proper formatting and sorting
                                    st.dataframe(
                                        display_df,
                                        use_container_width=True,
                                        hide_index=True,
                                        column_config=column_config
                                    )
                    # --- Wasted Spend Analysis Section ---
                    st.markdown("<div style='margin-top:3rem;'></div>", unsafe_allow_html=True)
                    st.markdown("<div id='wasted-spend' class='section-anchor'></div>", unsafe_allow_html=True)
                    st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
                    st.markdown("<span class='main-section-header'>Wasted Spend Analysis</span>", unsafe_allow_html=True)
                    
                    # Helper function to calculate wasted spend score
                    def calculate_wasted_spend_score(df):
                        """Calculate a wasted spend score for each target focused on ROAS efficiency and spend impact.
                        The score prioritizes targets with poor ROAS performance relative to budget consumption.
                        
                        Args:
                            df: DataFrame containing targeting data
                        
                        Returns:
                            DataFrame with wasted spend score and components
                        """
                        if df.empty:
                            return pd.DataFrame()
                            
                        # Make a copy to avoid modifying the original
                        result_df = df.copy()
                        
                        # Ensure we have the necessary columns
                        required_cols = ['ROAS', 'Spend', 'Ad Sales'] 
                        for col in required_cols:
                            if col not in result_df.columns:
                                if 'debug_messages' in st.session_state:
                                    st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Missing required column: {col}")
                                return result_df
                        
                        # Calculate segment metrics
                        avg_roas = result_df['ROAS'].mean() if not result_df.empty else 0
                        total_spend = result_df['Spend'].sum() if not result_df.empty else 0
                        median_spend = result_df['Spend'].median() if not result_df.empty else 0
                        
                        # Set minimum spend threshold - filter out targets with less than $30 spend
                        min_spend_threshold = 30.0
                        result_df['Below_Min_Spend'] = result_df['Spend'] < min_spend_threshold
                        
                        # Add debug info
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Segment metrics - Avg ROAS: {avg_roas:.2f}, Total Spend: ${total_spend:.2f}, Median Spend: ${median_spend:.2f}")
                            st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Filtering out {result_df['Below_Min_Spend'].sum()} targets with spend below ${min_spend_threshold}")
                        
                        # Flag targets with no sales
                        result_df['No_Sales'] = (result_df['Ad Sales'] == 0) & (result_df['Spend'] > 0)
                        
                        # Calculate ROAS efficiency score - how efficiently spend is converted to sales
                        result_df['ROAS_Efficiency'] = 0.0
                        
                        # Calculate ROAS threshold based on segment average
                        # Using a dynamic threshold that adapts to the segment's performance
                        roas_threshold = max(avg_roas * 0.75, 0.5)  # At least 0.5 to avoid extreme thresholds in low ROAS segments
                        
                        # Add threshold to debug info
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[Wasted Spend Analysis] ROAS threshold: {roas_threshold:.6f}")
                        
                        # Handle targets with ROAS > 0
                        has_sales_mask = (~result_df['No_Sales']) & (result_df['ROAS'] > 0)
                        
                        # Safety check - if no targets with sales or avg_roas is 0, skip this section
                        if avg_roas <= 0:
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Skipping ROAS efficiency calculation - avg_roas is {avg_roas}")
                        elif not has_sales_mask.any():
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] No targets with sales found")
                        else:
                            # Calculate ROAS efficiency for all targets with sales
                            # This is a more nuanced approach that considers how far below optimal each target is
                            
                            # Calculate ROAS efficiency for all targets with sales
                            # Higher values = worse efficiency
                            result_df.loc[has_sales_mask, 'ROAS_Efficiency'] = 1 - (result_df.loc[has_sales_mask, 'ROAS'] / roas_threshold)
                            
                            # Cap efficiency scores between 0 and 1
                            # 0 = meeting or exceeding threshold (good)
                            # 1 = extremely inefficient (bad)
                            result_df.loc[has_sales_mask, 'ROAS_Efficiency'] = result_df.loc[has_sales_mask, 'ROAS_Efficiency'].clip(0, 1)
                            
                            # Apply exponential scaling to emphasize very poor performers
                            # This creates more separation between slightly poor and very poor performers
                            result_df.loc[has_sales_mask, 'ROAS_Efficiency'] = result_df.loc[has_sales_mask, 'ROAS_Efficiency'] ** 1.5
                            
                            # Targets with ROAS above threshold get a score of 0 (not wasteful)
                            above_threshold_mask = (result_df['ROAS'] >= roas_threshold) & has_sales_mask
                            result_df.loc[above_threshold_mask, 'ROAS_Efficiency'] = 0.0
                            
                            # Flag targets above the ROAS threshold to be excluded later
                            result_df['Above_Threshold'] = False
                            result_df.loc[above_threshold_mask, 'Above_Threshold'] = True
                            
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Found {above_threshold_mask.sum()} targets with ROAS above threshold (will be excluded)")
                            
                            # Add debug info about efficiency scores
                            if 'debug_messages' in st.session_state and has_sales_mask.any():
                                avg_efficiency = result_df.loc[has_sales_mask, 'ROAS_Efficiency'].mean()
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Average ROAS efficiency score: {avg_efficiency:.6f}")
                        
                        # Initialize Below_Guardrail as all False since we're not using guardrail anymore
                        result_df['Below_Guardrail'] = False
                        
                        # Handle targets with no sales - they get maximum inefficiency score
                        # but will be categorized based on spend amount
                        no_sales_mask = result_df['No_Sales']
                        if no_sales_mask.any():
                            # Base value for no sales is maximum (1.0)
                            result_df.loc[no_sales_mask, 'ROAS_Efficiency'] = 1.0
                            
                            # Create a new column for no sales categorization
                            result_df['No_Sales_Category'] = 'Low'
                            
                            # Categorize no sales targets based on spend
                            # $100+ spend and no sales = Critical
                            critical_no_sales_mask = no_sales_mask & (result_df['Spend'] >= 100)
                            result_df.loc[critical_no_sales_mask, 'No_Sales_Category'] = 'Critical'
                            
                            # $75-99.99 spend and no sales = High
                            high_no_sales_mask = no_sales_mask & (result_df['Spend'] >= 75) & (result_df['Spend'] < 100)
                            result_df.loc[high_no_sales_mask, 'No_Sales_Category'] = 'High'
                            
                            # $50-74.99 spend and no sales = Medium
                            medium_no_sales_mask = no_sales_mask & (result_df['Spend'] >= 50) & (result_df['Spend'] < 75)
                            result_df.loc[medium_no_sales_mask, 'No_Sales_Category'] = 'Medium'
                            
                            # Below $50 spend and no sales = Low (default)
                            
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Found {no_sales_mask.sum()} targets with no sales")
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] No sales categories: Critical={critical_no_sales_mask.sum()}, High={high_no_sales_mask.sum()}, Medium={medium_no_sales_mask.sum()}, Low={(no_sales_mask & (result_df['Spend'] < 50)).sum()}")
                        
                        # Calculate spend impact - how much of the total budget is being consumed
                        # Normalize spend to create a 0-1 scale where higher values = higher spend
                        if total_spend > 0:
                            # Calculate raw spend percentage
                            result_df['Spend_Pct'] = result_df['Spend'] / total_spend
                            
                            # Apply a more aggressive scaling to emphasize high-spend targets
                            # Using a power function instead of logarithmic to give more weight to higher spend
                            max_spend_pct = result_df['Spend_Pct'].max()
                            if max_spend_pct > 0:
                                # Power scaling with exponent 0.7 gives more emphasis to high spenders
                                # while still preventing extreme domination
                                result_df['Spend_Impact'] = (result_df['Spend_Pct'] / max_spend_pct) ** 0.7
                            else:
                                result_df['Spend_Impact'] = 0.0
                        else:
                            result_df['Spend_Pct'] = 0.0
                            result_df['Spend_Impact'] = 0.0
                            
                        # Calculate final wasted spend score combining ROAS efficiency and spend impact
                        # This creates a score that prioritizes inefficient targets that consume significant budget
                        # Significantly increased weight for spend impact to emphasize high-spending targets
                        result_df['Wasted_Spend_Score'] = (
                            (result_df['ROAS_Efficiency'] * 0.25) +  # Reduced weight for ROAS efficiency (25%)
                            (result_df['Spend_Impact'] * 0.75)       # Significantly increased weight for spend impact (75%)
                        )
                        
                        # Set score to 0 for targets below minimum spend threshold, below ROAS guardrail, or above ROAS threshold
                        result_df.loc[result_df['Below_Min_Spend'], 'Wasted_Spend_Score'] = 0.0
                        result_df.loc[result_df['Below_Guardrail'], 'Wasted_Spend_Score'] = 0.0
                        result_df.loc[result_df['Above_Threshold'], 'Wasted_Spend_Score'] = 0.0
                        
                        # Normalize waste scores to 0-100 scale for better interpretability
                        if not result_df.empty and result_df['Wasted_Spend_Score'].max() > 0:
                            # Scale scores to 0-100 range
                            max_score = result_df['Wasted_Spend_Score'].max()
                            result_df['Wasted_Spend_Score'] = (result_df['Wasted_Spend_Score'] / max_score) * 100
                            
                            # Round to 2 decimal places for cleaner display
                            result_df['Wasted_Spend_Score'] = result_df['Wasted_Spend_Score'].round(2)
                            
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Normalized waste scores to 0-100 scale")
                        
                        # Sort by wasted spend score in descending order
                        result_df = result_df.sort_values('Wasted_Spend_Score', ascending=False)
                        
                        # Remove targets below minimum spend threshold
                        result_df = result_df[~result_df['Below_Min_Spend']]
                        
                        # Remove targets above the ROAS threshold (we keep all targets below threshold regardless of ROAS)
                        result_df = result_df[~result_df['Above_Threshold']]
                        
                        # Remove targets with zero waste score (but keep all others, even with very low ROAS)
                        result_df = result_df[result_df['Wasted_Spend_Score'] > 0]
                        
                        # Add waste score category for easier interpretation
                        result_df['Waste_Category'] = pd.cut(
                            result_df['Wasted_Spend_Score'], 
                            bins=[0, 25, 50, 75, 100], 
                            labels=['Low', 'Medium', 'High', 'Critical']
                        )
                        
                        # Override waste category for no sales targets based on spend amount
                        no_sales_mask = result_df['No_Sales']
                        if no_sales_mask.any():
                            result_df.loc[no_sales_mask, 'Waste_Category'] = result_df.loc[no_sales_mask, 'No_Sales_Category']
                        
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Final count of targets with waste score > 0: {len(result_df)}")
                            category_counts = result_df['Waste_Category'].value_counts().to_dict()
                            st.session_state.debug_messages.append(f"[Wasted Spend Analysis] Waste categories: {category_counts}")
                        
                        return result_df
                    
                    # Create tabs for the Wasted Spend Analysis
                    waste_tab_labels = ["All Targets", "Branded Targets", "Non-Branded Targets"]
                    waste_tabs = st.tabs(waste_tab_labels)
                    
                    # Get the dataframes for each tab
                    waste_dfs = [st.session_state.all_targets_df, st.session_state.branded_targets_df, st.session_state.non_branded_targets_df]
                    waste_titles = ["All", "Branded", "Non-Branded"]
                    
                    # Process each tab
                    for i, (tab, df, title) in enumerate(zip(waste_tabs, waste_dfs, waste_titles)):
                        with tab:
                            if not df.empty:
                                # Calculate wasted spend scores for all targets
                                waste_df = calculate_wasted_spend_score(df)
                                
                                if not waste_df.empty:
                                    # Allow user to select how many targets to view
                                    col1, col2 = st.columns([1, 3])
                                    with col1:
                                        num_targets = st.selectbox(
                                            f"Number of {title} Targets to View", 
                                            options=[5, 10, 15, 20, 25, 50, 100], 
                                            index=1,  # Default to 10
                                            key=f"waste_num_targets_{i}"
                                        )
                                    
                                    # Sort by priority first (Critical -> High -> Medium -> Low), then by waste score
                                    # Create a priority order mapping (higher value = higher priority)
                                    priority_order = {'Critical': 3, 'High': 2, 'Medium': 1, 'Low': 0}
                                    waste_df['Priority_Order'] = waste_df['Waste_Category'].map(priority_order)
                                    
                                    # Sort the dataframe - priority first (descending to put highest priority on top), then waste score
                                    waste_df = waste_df.sort_values(['Priority_Order', 'Wasted_Spend_Score'], 
                                                                 ascending=[False, False])
                                    
                                    # Now limit to the selected number of targets AFTER sorting
                                    selected_waste_df = waste_df.head(num_targets).copy()
                                    
                                    # Calculate metrics for the selected targets
                                    selected_avg_roas = selected_waste_df['ROAS'].mean() if 'ROAS' in selected_waste_df.columns else 0
                                    selected_total_spend = selected_waste_df['Spend'].sum() if 'Spend' in selected_waste_df.columns else 0
                                    
                                    with col2:
                                        st.markdown(f"<div style='padding-top:2rem;'><b>Average ROAS:</b> {selected_avg_roas:.2f}x &nbsp;&nbsp; <b>Total Spend:</b> ${selected_total_spend:,.2f}</div>", unsafe_allow_html=True)
                                    
                                    # Create a display dataframe with relevant columns
                                    display_cols = [
                                        'Campaign', 'Target', 'Match Type', 'Spend', 'Ad Sales', 
                                        'ROAS', 'ACoS', 'Clicks', 'Orders', 'CPC', 'Bid', 'Waste_Category'
                                    ]
                                    # Filter to only columns that exist
                                    display_cols = [col for col in display_cols if col in selected_waste_df.columns]
                                    
                                    # Use the already limited dataframe
                                    display_df = selected_waste_df[display_cols].copy()
                                    
                                    # Format the display dataframe
                                    display_df['Spend'] = display_df['Spend'].apply(lambda x: f"${x:,.2f}" if x >= 1000 else f"${x:.2f}")
                                    display_df['Ad Sales'] = display_df['Ad Sales'].apply(lambda x: f"${x:,.2f}" if x >= 1000 else f"${x:.2f}")
                                    display_df['ROAS'] = display_df['ROAS'].apply(lambda x: f"{x:.2f}x")
                                    display_df['CPC'] = display_df['CPC'].apply(lambda x: f"${x:.2f}")
                                    display_df['ACoS'] = display_df['ACoS'].apply(lambda x: f"{x:.2f}%")
                                    # Format Bid column if it exists
                                    if 'Bid' in display_df.columns:
                                        display_df['Bid'] = display_df['Bid'].apply(lambda x: f"${x:.2f}")
                                    display_df['Clicks'] = display_df['Clicks'].apply(lambda x: f"{int(x):,}")
                                    display_df['Orders'] = display_df['Orders'].apply(lambda x: f"{int(x):,}")
                                    
                                    # Rename columns for display
                                    display_df = display_df.rename(columns={
                                        'Waste_Category': 'Priority'
                                    })
                                    
                                    # Apply conditional formatting based on waste category
                                    def highlight_waste_score(val):
                                        if 'Critical' in str(val):
                                            return 'background-color: rgba(255, 0, 0, 0.2); color: #ff4d4d; font-weight: bold'
                                        elif 'High' in str(val):
                                            return 'background-color: rgba(255, 165, 0, 0.2); color: #ffa500; font-weight: bold'
                                        elif 'Medium' in str(val):
                                            return 'background-color: rgba(255, 255, 0, 0.1); color: #cccc00; font-weight: bold'
                                        elif 'Low' in str(val):
                                            return 'background-color: rgba(0, 128, 0, 0.1); color: #00cc00; font-weight: bold'
                                        return ''
                                    
                                    # Apply styling to the waste score column
                                    styled_df = display_df.style.map(
                                        highlight_waste_score, 
                                        subset=['Priority']
                                    )
                                    
                                    # Create column configuration for proper formatting and sorting
                                    column_config = {
                                        'Campaign': st.column_config.TextColumn(
                                            'Campaign',
                                            width='medium'
                                        ),
                                        'Target': st.column_config.TextColumn(
                                            'Target',
                                            width='medium'
                                        ),
                                        'Match Type': st.column_config.TextColumn(
                                            'Match Type',
                                            width='small'
                                        ),
                                        'Spend': st.column_config.NumberColumn(
                                            'Spend',
                                            format='$%.2f',
                                            width='small'
                                        ),
                                        'Ad Sales': st.column_config.NumberColumn(
                                            'Ad Sales',
                                            format='$%.2f',
                                            width='small'
                                        ),
                                        'ROAS': st.column_config.NumberColumn(
                                            'ROAS',
                                            format='%.2fx',
                                            width='small'
                                        ),
                                        'ACoS': st.column_config.NumberColumn(
                                            'ACoS',
                                            format='%.2f%%',
                                            width='small'
                                        ),
                                        'Clicks': st.column_config.NumberColumn(
                                            'Clicks',
                                            format='%d',
                                            width='small'
                                        ),
                                        'Orders': st.column_config.NumberColumn(
                                            'Orders',
                                            format='%d',
                                            width='small'
                                        ),
                                        'CPC': st.column_config.NumberColumn(
                                            'CPC',
                                            format='$%.2f',
                                            width='small'
                                        ),
                                        'Bid': st.column_config.NumberColumn(
                                            'Bid',
                                            format='$%.2f',
                                            width='small'
                                        ),
                                        'Priority': st.column_config.TextColumn(
                                            'Priority',
                                            width='small'
                                        )
                                    }

                                    # Convert formatted string values to numeric for sorting
                                    numeric_df = display_df.copy()
                                    
                                    # Convert currency and numeric columns from formatted strings to numeric values
                                    for col in ['Spend', 'Ad Sales', 'CPC', 'Bid']:
                                        if col in numeric_df.columns:
                                            numeric_df[col] = numeric_df[col].apply(lambda x: float(str(x).replace('$', '').replace(',', '')) if pd.notna(x) and str(x).strip() != '' else 0)
                                    
                                    # Convert percentage columns
                                    if 'ACoS' in numeric_df.columns:
                                        numeric_df['ACoS'] = numeric_df['ACoS'].apply(lambda x: float(str(x).replace('%', '')) if pd.notna(x) and str(x) != 'N/A' else 0)
                                    
                                    # Convert ROAS
                                    if 'ROAS' in numeric_df.columns:
                                        numeric_df['ROAS'] = numeric_df['ROAS'].apply(lambda x: float(str(x).replace('x', '')) if pd.notna(x) and str(x) != 'N/A' else 0)
                                    
                                    # Convert Clicks and Orders
                                    for col in ['Clicks', 'Orders']:
                                        if col in numeric_df.columns:
                                            numeric_df[col] = numeric_df[col].apply(lambda x: int(str(x).replace(',', '')) if pd.notna(x) and str(x).strip() != '' else 0)
                                    
                                    # Apply styling to the priority column
                                    styled_df = numeric_df.style.map(
                                        highlight_waste_score, 
                                        subset=['Priority']
                                    )
                                    
                                    # Display the table with column config for proper formatting and sorting
                                    st.dataframe(
                                        styled_df,
                                        use_container_width=True,
                                        hide_index=True,
                                        column_config=column_config
                                    )
                                    

                                    
                                    # Add explanation of the waste score
                                    # Add explanation of the waste score
                                    with st.expander("How is the Waste Score calculated?"):
                                        st.markdown("""
                                        The **Waste Score** is calculated on a scale of 0-100 using an improved formula that focuses on two key factors:
                                        
                                        1. **ROAS Efficiency (25%)**: How efficiently your Spend is generating sales relative to the segment's threshold
                                        2. **Spend Impact (75%)**: How much of your total budget this target consumes
                                        
                                        **Key features of this improved approach:**
                                        
                                        - **Minimum Spend Threshold**: Targets with less than $30 in spend are excluded entirely
                                        - **ROAS Guardrail**: Targets with ROAS more than 75% below segment average are excluded
                                        - **Priority Categories**: Scores are grouped into Low (0-25), Medium (25-50), High (50-75), and Critical (75-100)
                                        - **No Sales Categorization**:
                                          - $100+ spend with no sales: Critical priority
                                          - $75-99.99 spend with no sales: High priority
                                          - $50-74.99 spend with no sales: Medium priority
                                          - Under $50 spend with no sales: Low priority
                                        
                                        This approach helps you identify targets that are both inefficient (poor ROAS) and significant budget consumers, with strong emphasis on high-spending targets.
                                        """)
                                else:
                                    st.info(f"No {title} targets available for analysis.")
                            else:
                                st.info(f"No {title} targets available for analysis.")
                    
                    # --- Contradicting Targets and Search Terms Section ---
                    st.markdown("<div style='margin-top:3rem;'></div>", unsafe_allow_html=True)
                    st.markdown("<div id='contradicting-targets' class='section-anchor'></div>", unsafe_allow_html=True)
                    st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
                    st.markdown("<span class='main-section-header'>Contradicting Targets and Search Terms</span>", unsafe_allow_html=True)
                    
                    # Hide function docstrings by not displaying them
                    if 'bulk_data' in st.session_state and 'client_config' in st.session_state:
                        # Get search term data with branding classification
                        search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                        
                        # Get targeting data with branding classification
                        branded_targets_df, non_branded_targets_df = get_targeting_performance_data(
                            st.session_state.bulk_data,
                            st.session_state.client_config
                        )
                        
                        # Combine branded and non-branded targets
                        all_targets_df = pd.concat([branded_targets_df, non_branded_targets_df], ignore_index=True) if not (branded_targets_df.empty and non_branded_targets_df.empty) else pd.DataFrame()
                        if not search_term_df.empty and not all_targets_df.empty:
                        # Create a mapping of targets to their classification (Branded/Non-Branded)
                            target_classification = {}
                            
                            # Add Branded targets to the mapping
                            if not branded_targets_df.empty and 'Target' in branded_targets_df.columns:
                                for target in branded_targets_df['Target'].dropna().unique():
                                    target_classification[str(target).lower()] = "Branded"
                            
                            # Add Non-Branded targets to the mapping
                            if not non_branded_targets_df.empty and 'Target' in non_branded_targets_df.columns:
                                for target in non_branded_targets_df['Target'].dropna().unique():
                                    target_classification[str(target).lower()] = "Non-Branded"
                            
                            # Filter for Sponsored Products and Sponsored Brands only
                            sp_sb_search_terms = search_term_df[
                                search_term_df['Campaign Type'].str.contains('Sponsored Products|Sponsored Brands', case=False, na=False)
                            ].copy() if 'Campaign Type' in search_term_df.columns else search_term_df.copy()
                            
                            # Ensure we have the necessary columns
                            required_cols = ['Search Term', 'Target', 'Is_Branded', 'Campaign', 'Spend', 'Sales', 'Orders', 'Clicks', 'Impressions']
                            for col in required_cols:
                                if col not in sp_sb_search_terms.columns:
                                    sp_sb_search_terms[col] = None
                            
                            # Create a column for search term classification
                            sp_sb_search_terms['Search Term Classification'] = sp_sb_search_terms['Is_Branded'].apply(
                                lambda x: "Branded" if x else "Non-Branded"
                            )
                            
                            # Create a column for target classification
                            sp_sb_search_terms['Target Classification'] = sp_sb_search_terms['Target'].apply(
                                lambda x: target_classification.get(str(x).lower(), "Unknown") if pd.notna(x) else "Unknown"
                            )
                            
                            # Ensure Match Type column exists
                            if 'Match Type' not in sp_sb_search_terms.columns:
                                sp_sb_search_terms['Match Type'] = "Unknown"
                            
                            # Filter for contradicting classifications
                            contradicting_terms = sp_sb_search_terms[
                                (sp_sb_search_terms['Search Term Classification'] != sp_sb_search_terms['Target Classification']) & 
                                (sp_sb_search_terms['Target Classification'] != "Unknown")
                            ].copy()
                            
                            # Calculate metrics
                            if not contradicting_terms.empty:
                                # Calculate ACoS and ROAS as numeric values
                                contradicting_terms['ACoS'] = contradicting_terms.apply(
                                    lambda row: (row['Spend'] / row['Sales'] * 100) if pd.notna(row['Sales']) and row['Sales'] > 0 else 0,
                                    axis=1
                                )
                                contradicting_terms['ROAS'] = contradicting_terms.apply(
                                    lambda row: (row['Sales'] / row['Spend']) if pd.notna(row['Spend']) and row['Spend'] > 0 else 0,
                                    axis=1
                                )
                                
                                # Rename 'Sales' to 'Ad Sales' for clarity, but first check if it already exists
                                if 'Ad Sales' not in contradicting_terms.columns and 'Sales' in contradicting_terms.columns:
                                    contradicting_terms = contradicting_terms.rename(columns={'Sales': 'Ad Sales'})
                                
                                # Create filters
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    search_term_filter = st.text_input("Filter by Search Term", "", key="contradicting_search_term_filter")
                                with col2:
                                    target_filter = st.text_input("Filter by Target", "", key="contradicting_target_filter")
                                with col3:
                                    campaign_filter = st.text_input("Filter by Campaign", "", key="contradicting_campaign_filter")
                                
                                col4, col5 = st.columns(2)
                                with col4:
                                    search_term_class_filter = st.selectbox(
                                        "Filter by Search Term Classification",
                                        ["All", "Branded", "Non-Branded"],
                                        key="contradicting_search_term_class_filter"
                                    )
                                with col5:
                                    # Get unique match types from the data
                                    match_types = ["All"] + sorted(contradicting_terms['Match Type'].dropna().unique().tolist()) if 'Match Type' in contradicting_terms.columns else ["All"]
                                    match_type_filter = st.selectbox(
                                        "Filter by Match Type",
                                        match_types,
                                        key="contradicting_match_type_filter"
                                    )
                                
                                # Apply filters
                                filtered_df = contradicting_terms.copy()
                                if search_term_filter:
                                    filtered_df = filtered_df[filtered_df['Search Term'].astype(str).str.contains(search_term_filter, case=False, na=False)]
                                if target_filter:
                                    filtered_df = filtered_df[filtered_df['Target'].astype(str).str.contains(target_filter, case=False, na=False)]
                                if campaign_filter:
                                    filtered_df = filtered_df[filtered_df['Campaign'].astype(str).str.contains(campaign_filter, case=False, na=False)]
                                if search_term_class_filter != "All":
                                    filtered_df = filtered_df[filtered_df['Search Term Classification'] == search_term_class_filter]
                                if match_type_filter != "All" and 'Match Type' in filtered_df.columns:
                                    filtered_df = filtered_df[filtered_df['Match Type'] == match_type_filter]
                                
                                # Display the table
                                if not filtered_df.empty:
                                    # Calculate summary metrics
                                    # Calculate summary metrics directly without creating new columns
                                    try:
                                        # For Spend
                                        if 'Spend' in filtered_df.columns:
                                            # Convert to numeric safely
                                            numeric_spend = pd.to_numeric(
                                                filtered_df['Spend'].replace('[$,]', '', regex=True) if isinstance(filtered_df['Spend'], pd.Series) else 
                                                filtered_df['Spend'].astype(str), 
                                                errors='coerce'
                                            ).fillna(0)
                                            spend = numeric_spend.sum()
                                        else:
                                            spend = 0
                                            
                                        # For Ad Sales
                                        if 'Ad Sales' in filtered_df.columns:
                                            # Convert to numeric safely
                                            numeric_sales = pd.to_numeric(
                                                filtered_df['Ad Sales'].replace('[$,]', '', regex=True) if isinstance(filtered_df['Ad Sales'], pd.Series) else 
                                                filtered_df['Ad Sales'].astype(str), 
                                                errors='coerce'
                                            ).fillna(0)
                                            sales = numeric_sales.sum()
                                        else:
                                            sales = 0
                                    except Exception as e:
                                        # Fallback if there's any error in conversion
                                        st.error(f"Error calculating metrics: {str(e)}")
                                        spend = 0
                                        sales = 0
                                        
                                    # Calculate ACoS and ROAS using scalar values
                                    acos = (spend / sales * 100) if sales > 0 else 0
                                    roas = (sales / spend) if spend > 0 else 0
                                    
                                    # Display summary cards
                                    kpi_cols = st.columns(4)
                                    kpi_cols[0].metric("TOTAL SPEND", f"${spend:,.2f}")
                                    kpi_cols[1].metric("AD SALES", f"${sales:,.2f}")
                                    kpi_cols[2].metric("ACoS", f"{acos:.2f}%")
                                    kpi_cols[3].metric("ROAS", f"{roas:.2f}")
                                    
                                    # Check for duplicate columns in a safer way
                                    if 'Ad Sales' in filtered_df.columns and filtered_df.columns.duplicated().any():
                                        # Create a new DataFrame with unique column names
                                        # This approach preserves the first occurrence of each column
                                        filtered_df = filtered_df.loc[:, ~filtered_df.columns.duplicated()]
                                    
                                    # Select columns to display
                                    display_cols = [
                                        'Campaign', 'Search Term', 'Search Term Classification', 
                                        'Target', 'Target Classification', 'Match Type', 'Spend', 'Ad Sales', 
                                        'ACoS', 'ROAS'
                                    ]
                                    
                                    # Ensure all required columns exist
                                    for col in display_cols:
                                        if col not in filtered_df.columns:
                                            filtered_df[col] = "N/A"
                                    
                                    # Clean numeric columns to fix weird characters
                                    for col in ['Spend', 'Ad Sales']:
                                        if col in filtered_df.columns:
                                            # Convert to numeric, removing any currency symbols or formatting
                                            filtered_df[col] = pd.to_numeric(filtered_df[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                    
                                    # Select columns to display
                                    display_df = filtered_df[display_cols].copy()
                                    
                                    # Create column configuration for proper formatting and sorting
                                    column_config = {
                                        'Campaign': st.column_config.TextColumn(label="Campaign"),
                                        'Search Term': st.column_config.TextColumn(label="Search Term"),
                                        'Search Term Classification': st.column_config.TextColumn(label="Search Term Classification"),
                                        'Target': st.column_config.TextColumn(label="Target"),
                                        'Target Classification': st.column_config.TextColumn(label="Target Classification"),
                                        'Match Type': st.column_config.TextColumn(label="Match Type"),
                                        'Spend': st.column_config.NumberColumn(label="Spend", format="$%.2f"),
                                        'Ad Sales': st.column_config.NumberColumn(label="Ad Sales", format="$%.2f"),
                                        'ACoS': st.column_config.NumberColumn(label="ACoS", format="%.2f"),
                                        'ROAS': st.column_config.NumberColumn(label="ROAS", format="%.2f")
                                    }
                                    
                                    # Display the table
                                    st.dataframe(
                                        display_df,
                                        column_config=column_config,
                                        use_container_width=True,
                                        hide_index=True
                                    )
                                    

                                else:
                                    st.info("No contradicting targets and search terms found with the current filters.")
                            else:
                                st.info("No contradicting targets and search terms found in the data.")
                        else:
                            st.info("Insufficient data to analyze contradicting targets and search terms. Please upload bulk advertising files with search term and targeting data.")
                    else:
                        st.info("Please upload bulk advertising files to analyze contradicting targets and search terms.")
                    # --- Contradicting Targets in Campaigns Section ---
                    st.markdown("<div style='margin-top:3rem;'></div>", unsafe_allow_html=True)
                    st.markdown("<div id='contradicting-targets-campaigns' class='section-anchor'></div>", unsafe_allow_html=True)
                    st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
                    st.markdown("<span class='main-section-header'>Contradicting Targets in Campaigns</span>", unsafe_allow_html=True)
                    
                    if 'bulk_data' in st.session_state and 'client_config' in st.session_state:
                        # Get search term data with branding classification
                        search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                        
                        # Get targeting data with branding classification
                        branded_targets_df, non_branded_targets_df = get_targeting_performance_data(
                            st.session_state.bulk_data,
                            st.session_state.client_config
                        )
                        
                        # Combine branded and non-branded targets
                        all_targets_df = pd.concat([branded_targets_df, non_branded_targets_df], ignore_index=True) if not (branded_targets_df.empty and non_branded_targets_df.empty) else pd.DataFrame()
                        
                        # Function to classify campaigns
                        def classify_campaign(campaign_name):
                            if pd.isna(campaign_name):
                                return "Unknown"
                            campaign_str = str(campaign_name).lower()
                            if 'brand' in campaign_str:
                                return "Branded"
                            elif 'non' in campaign_str and 'brand' not in campaign_str:
                                return "Non-Branded"
                            else:
                                return "Unknown"
                        
                        # Create tabs for Targets and Search Terms
                        contradicting_campaigns_tabs = st.tabs(["Search Terms", "Targets"])
                        
                        # Tab 1: Search Terms
                        with contradicting_campaigns_tabs[0]:
                            if not search_term_df.empty:
                                # Filter for Sponsored Products and Sponsored Brands only
                                sp_sb_search_terms = search_term_df[
                                    search_term_df['Campaign Type'].str.contains('Sponsored Products|Sponsored Brands', case=False, na=False)
                                ].copy() if 'Campaign Type' in search_term_df.columns else search_term_df.copy()
                                
                                if not sp_sb_search_terms.empty:
                                    # Add campaign classification
                                    sp_sb_search_terms['Campaign Classification'] = sp_sb_search_terms['Campaign'].apply(classify_campaign)
                                    
                                    # Create search term classification
                                    sp_sb_search_terms['Search Term Classification'] = sp_sb_search_terms['Is_Branded'].apply(
                                        lambda x: "Branded" if x else "Non-Branded"
                                    )
                                    
                                    # Filter for contradicting classifications
                                    contradicting_search_terms = sp_sb_search_terms[
                                        (sp_sb_search_terms['Campaign Classification'] != sp_sb_search_terms['Search Term Classification']) & 
                                        (sp_sb_search_terms['Campaign Classification'] != "Unknown")
                                    ].copy()
                                    
                                    if not contradicting_search_terms.empty:
                                        # Calculate ACoS
                                        contradicting_search_terms['ACoS'] = contradicting_search_terms.apply(
                                            lambda row: (row['Spend'] / row['Sales'] * 100) if pd.notna(row['Sales']) and row['Sales'] > 0 else 0,
                                            axis=1
                                        )
                                        
                                        # Rename 'Sales' to 'Ad Sales' for consistency
                                        if 'Ad Sales' not in contradicting_search_terms.columns and 'Sales' in contradicting_search_terms.columns:
                                            contradicting_search_terms = contradicting_search_terms.rename(columns={'Sales': 'Ad Sales'})
                                        
                                        # Create filters
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            campaign_filter_st = st.text_input("Filter by Campaign", "", key="contradicting_campaign_st_filter")
                                        with col2:
                                            search_term_filter_st = st.text_input("Filter by Search Term", "", key="contradicting_search_term_st_filter")
                                        with col3:
                                            match_type_options_st = ["All"] + sorted(contradicting_search_terms['Match Type'].dropna().unique().tolist()) if 'Match Type' in contradicting_search_terms.columns else ["All"]
                                            match_type_filter_st = st.selectbox(
                                                "Filter by Match Type",
                                                match_type_options_st,
                                                key="contradicting_match_type_st_filter"
                                            )
                                        
                                        # Apply filters
                                        filtered_search_terms = contradicting_search_terms.copy()
                                        if campaign_filter_st:
                                            filtered_search_terms = filtered_search_terms[filtered_search_terms['Campaign'].astype(str).str.contains(campaign_filter_st, case=False, na=False)]
                                        if search_term_filter_st:
                                            filtered_search_terms = filtered_search_terms[filtered_search_terms['Search Term'].astype(str).str.contains(search_term_filter_st, case=False, na=False)]
                                        if match_type_filter_st != "All" and 'Match Type' in filtered_search_terms.columns:
                                            filtered_search_terms = filtered_search_terms[filtered_search_terms['Match Type'] == match_type_filter_st]
                                        
                                        if not filtered_search_terms.empty:
                                            # Calculate summary metrics
                                            spend = pd.to_numeric(filtered_search_terms['Spend'].replace('[$,]', '', regex=True), errors='coerce').fillna(0).sum()
                                            sales = pd.to_numeric(filtered_search_terms['Ad Sales'].replace('[$,]', '', regex=True), errors='coerce').fillna(0).sum()
                                            acos = (spend / sales * 100) if sales > 0 else 0
                                            
                                            # Display summary cards
                                            kpi_cols = st.columns(3)
                                            kpi_cols[0].metric("TOTAL SPEND", f"${spend:,.2f}")
                                            kpi_cols[1].metric("AD SALES", f"${sales:,.2f}")
                                            kpi_cols[2].metric("ACoS", f"{acos:.2f}%")
                                            
                                            # Select and display columns
                                            display_cols = [
                                                'Campaign', 'Campaign Classification', 'Target', 'Match Type',
                                                'Search Term', 'Search Term Classification', 'Spend', 'Ad Sales', 'ACoS'
                                            ]
                                            
                                            # Ensure all required columns exist
                                            for col in display_cols:
                                                if col not in filtered_search_terms.columns:
                                                    filtered_search_terms[col] = "N/A"
                                            
                                            # Clean numeric columns
                                            for col in ['Spend', 'Ad Sales']:
                                                if col in filtered_search_terms.columns:
                                                    filtered_search_terms[col] = pd.to_numeric(filtered_search_terms[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                            
                                            display_df = filtered_search_terms[display_cols].copy()
                                            
                                            # Sort by Spend in descending order by default
                                            display_df = display_df.sort_values("Spend", ascending=False)
                                            
                                            # Create column configuration
                                            column_config = {
                                                'Campaign': st.column_config.TextColumn(label="Campaign Name"),
                                                'Campaign Classification': st.column_config.TextColumn(label="Campaign Classification"),
                                                'Target': st.column_config.TextColumn(label="Target"),
                                                'Match Type': st.column_config.TextColumn(label="Match Type"),
                                                'Search Term': st.column_config.TextColumn(label="Search Term"),
                                                'Search Term Classification': st.column_config.TextColumn(label="Search Term Classification"),
                                                'Spend': st.column_config.NumberColumn(label="Spend", format="$%.2f"),
                                                'Ad Sales': st.column_config.NumberColumn(label="Ad Sales", format="$%.2f"),
                                                'ACoS': st.column_config.NumberColumn(label="ACoS", format="%.2f%%")
                                            }
                                            
                                            # Display the table
                                            st.dataframe(
                                                display_df,
                                                column_config=column_config,
                                                use_container_width=True,
                                                hide_index=True
                                            )
                                        else:
                                            st.info("No contradicting search terms found with the current filters.")
                                    else:
                                        st.info("No contradicting search terms found between campaigns and their search term classifications.")
                                else:
                                    st.info("No search term data available for Sponsored Products/Sponsored Brands campaigns.")
                            else:
                                st.info("No search term data available for analysis.")
                    else:
                        st.info("Please upload bulk advertising files to analyze contradicting targets in campaigns.")                     

                        with contradicting_campaigns_tabs[1]:
                            if not all_targets_df.empty:
                                # Add campaign classification
                                all_targets_df['Campaign Classification'] = all_targets_df['Campaign'].apply(classify_campaign)
                                
                                # Add target classification based on whether it came from branded or non-branded dataframe
                                all_targets_df['Target Classification'] = 'Unknown'
                                if not branded_targets_df.empty:
                                    branded_mask = all_targets_df['Target'].isin(branded_targets_df['Target'])
                                    all_targets_df.loc[branded_mask, 'Target Classification'] = 'Branded'
                                if not non_branded_targets_df.empty:
                                    non_branded_mask = all_targets_df['Target'].isin(non_branded_targets_df['Target'])
                                    all_targets_df.loc[non_branded_mask, 'Target Classification'] = 'Non-Branded'
                                
                                # Filter for contradicting classifications
                                contradicting_targets = all_targets_df[
                                    (all_targets_df['Campaign Classification'] != all_targets_df['Target Classification']) & 
                                    (all_targets_df['Campaign Classification'] != "Unknown") &
                                    (all_targets_df['Target Classification'] != "Unknown")
                                ].copy()
                                
                                if not contradicting_targets.empty:
                                    # Calculate ACoS
                                    contradicting_targets['ACoS'] = contradicting_targets.apply(
                                        lambda row: (row['Spend'] / row['Ad Sales'] * 100) if pd.notna(row['Ad Sales']) and row['Ad Sales'] > 0 else 0,
                                        axis=1
                                    )
                                    
                                    # Create filters
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        campaign_filter_targets = st.text_input("Filter by Campaign", "", key="contradicting_campaign_targets_filter")
                                    with col2:
                                        target_filter_targets = st.text_input("Filter by Target", "", key="contradicting_target_targets_filter")
                                    with col3:
                                        match_type_options = ["All"] + sorted(contradicting_targets['Match Type'].dropna().unique().tolist()) if 'Match Type' in contradicting_targets.columns else ["All"]
                                        match_type_filter_targets = st.selectbox(
                                            "Filter by Match Type",
                                            match_type_options,
                                            key="contradicting_match_type_targets_filter"
                                        )
                                    
                                    # Apply filters
                                    filtered_targets = contradicting_targets.copy()
                                    if campaign_filter_targets:
                                        filtered_targets = filtered_targets[filtered_targets['Campaign'].astype(str).str.contains(campaign_filter_targets, case=False, na=False)]
                                    if target_filter_targets:
                                        filtered_targets = filtered_targets[filtered_targets['Target'].astype(str).str.contains(target_filter_targets, case=False, na=False)]
                                    if match_type_filter_targets != "All" and 'Match Type' in filtered_targets.columns:
                                        filtered_targets = filtered_targets[filtered_targets['Match Type'] == match_type_filter_targets]
                                    
                                    if not filtered_targets.empty:
                                        # Calculate summary metrics
                                        spend = pd.to_numeric(filtered_targets['Spend'].replace('[$,]', '', regex=True), errors='coerce').fillna(0).sum()
                                        sales = pd.to_numeric(filtered_targets['Ad Sales'].replace('[$,]', '', regex=True), errors='coerce').fillna(0).sum()
                                        acos = (spend / sales * 100) if sales > 0 else 0
                                        
                                        # Display summary cards
                                        kpi_cols = st.columns(3)
                                        kpi_cols[0].metric("TOTAL SPEND", f"${spend:,.2f}")
                                        kpi_cols[1].metric("AD SALES", f"${sales:,.2f}")
                                        kpi_cols[2].metric("ACoS", f"{acos:.2f}%")
                                        
                                        # Select and display columns
                                        display_cols = [
                                            'Campaign', 'Campaign Classification', 'Target', 'Match Type',
                                            'Target Classification', 'Spend', 'Ad Sales', 'ACoS'
                                        ]
                                        
                                        # Ensure all required columns exist
                                        for col in display_cols:
                                            if col not in filtered_targets.columns:
                                                filtered_targets[col] = "N/A"
                                        
                                        # Clean numeric columns
                                        for col in ['Spend', 'Ad Sales']:
                                            if col in filtered_targets.columns:
                                                filtered_targets[col] = pd.to_numeric(filtered_targets[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                        
                                        display_df = filtered_targets[display_cols].copy()
                                        
                                        # Sort by Spend in descending order by default
                                        display_df = display_df.sort_values("Spend", ascending=False)
                                        
                                        # Create column configuration
                                        column_config = {
                                            'Campaign': st.column_config.TextColumn(label="Campaign Name"),
                                            'Campaign Classification': st.column_config.TextColumn(label="Campaign Classification"),
                                            'Target': st.column_config.TextColumn(label="Target"),
                                            'Match Type': st.column_config.TextColumn(label="Match Type"),
                                            'Target Classification': st.column_config.TextColumn(label="Target Classification"),
                                            'Spend': st.column_config.NumberColumn(label="Spend", format="$%.2f"),
                                            'Ad Sales': st.column_config.NumberColumn(label="Ad Sales", format="$%.2f"),
                                            'ACoS': st.column_config.NumberColumn(label="ACoS", format="%.2f%%")
                                        }
                                        
                                        # Display the table
                                        st.dataframe(
                                            display_df,
                                            column_config=column_config,
                                            use_container_width=True,
                                            hide_index=True
                                        )
                                    else:
                                        st.info("No contradicting targets found with the current filters.")
                                else:
                                    st.info("No contradicting targets found between campaigns and their target classifications.")
                            else:
                                st.info("No targeting data available for analysis.")
                        
                        # Tab 2: Targets                    # ACoS Range Tables Section
                    st.markdown("<div style='margin-top:3rem;'></div>", unsafe_allow_html=True)
                    st.markdown("<div id='acos-range-tables' class='section-anchor'></div>", unsafe_allow_html=True)
                    st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
                    st.markdown("<span class='main-section-header'>ACoS Range Tables</span>", unsafe_allow_html=True)
                    
                    # Create main tabs for Target Performance and Search Term Performance views
                    acos_tables_main_tabs = st.tabs(["Target Performance", "Search Term Performance"])
                    
                    # TARGET PERFORMANCE TAB
                    with acos_tables_main_tabs[0]:
                        # Extract product groups for filtering from all target dataframes
                        product_groups = set()
                        for df in [st.session_state.all_targets_df, st.session_state.branded_targets_df, st.session_state.non_branded_targets_df]:
                            if not df.empty and 'Product Group' in df.columns:
                                groups = df['Product Group'].dropna().unique()
                                product_groups.update([g for g in groups if g])
                        
                        # Initialize session state variables for target product group filter
                        if 'target_product_group_filter' not in st.session_state:
                            st.session_state.target_product_group_filter = []
                        if 'target_filter_active' not in st.session_state:
                            st.session_state.target_filter_active = False
                        
                        # Define a callback function to update related session state variables
                        def update_target_filter_state():
                            # Update filter active state based on current selection
                            st.session_state.target_filter_active = len(st.session_state.target_product_group_filter) > 0
                        
                        # Add product group filter above the tabs
                        filter_col1, filter_col2 = st.columns([0.4, 0.6])
                        with filter_col1:
                            if product_groups:
                                product_groups = sorted(list(product_groups))
                                st.multiselect(
                                    "Filter by Product Group(s):",
                                    options=product_groups,
                                    key="target_product_group_filter",
                                    on_change=update_target_filter_state
                                )
                                # The callback will handle updating session state
                            else:
                                # Show disabled multiselect with informative label
                                st.multiselect(
                                    "Filter by Product Group(s) (Add in Client Settings):",
                                    options=[],
                                    disabled=True,
                                    key="target_product_group_filter_disabled"
                                )
                                # Reset filter state safely
                                if st.session_state.target_product_group_filter:
                                    st.session_state.target_product_group_filter = []
                                    st.session_state.target_filter_active = False
                        
                        # Create tabs for the Target tables
                        target_tab_labels = ["All Targets", "Branded Targets", "Non-Branded Targets"]
                        target_tabs = st.tabs(target_tab_labels)
                        
                        # Get the dataframes for each target tab
                        target_dfs = [st.session_state.all_targets_df, st.session_state.branded_targets_df, st.session_state.non_branded_targets_df]
                        
                        # Apply product group filter to all dataframes if active
                        if st.session_state.get('target_filter_active', False) and len(st.session_state.get('target_product_group_filter', [])) > 0:
                            filtered_target_dfs = []
                            for df in target_dfs:
                                if not df.empty and 'Product Group' in df.columns:
                                    filtered_df = df[df['Product Group'].isin(st.session_state.target_product_group_filter)]
                                    filtered_target_dfs.append(filtered_df)
                                else:
                                    filtered_target_dfs.append(df)
                            target_dfs = filtered_target_dfs
                            st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.target_product_group_filter)}")
                        
                        # Process each target tab
                        for i, (target_label, target_df) in enumerate(zip(target_tab_labels, target_dfs)):
                            with target_tabs[i]:
                                if not target_df.empty and 'ACoS' in target_df.columns and 'Spend' in target_df.columns:
                                    # Calculate ACoS range distribution
                                    # Get number of ranges from session state or use default
                                    range_key = f"num_acos_ranges_{target_label.replace(' ', '_')}"
                                    num_ranges = st.session_state.get(range_key, 5)
                                    
                                    # Calculate ACoS range distribution with user-selected number of ranges
                                    acos_distribution = calculate_acos_range_distribution(target_df, num_ranges=num_ranges)
                                    
                                    if not acos_distribution.empty:
                                        # Create a column layout for the range selector controls
                                        range_cols = st.columns([1, 2])
                                        
                                        # Add number of ranges input in the first column
                                        with range_cols[0]:
                                            # Initialize session state for number of ranges if not exists
                                            range_key = f"num_acos_ranges_{target_label.replace(' ', '_')}"
                                            if range_key not in st.session_state:
                                                st.session_state[range_key] = 5
                                                
                                            # Input for number of ACoS ranges with help text
                                            num_ranges = st.number_input(
                                                "Number of ACoS Ranges",
                                                min_value=3,
                                                max_value=20,
                                                value=st.session_state[range_key],
                                                step=1,
                                                help="Set how many ACoS ranges to display (100%+ and No Sales ranges will be added automatically)",
                                                key=f"num_ranges_input_{target_label.replace(' ', '_')}"
                                            )
                                            
                                            # Update session state when value changes
                                            if num_ranges != st.session_state[range_key]:
                                                st.session_state[range_key] = num_ranges
                                                # Use st.rerun() instead of experimental_rerun
                                                st.rerun()
                                        
                                        # Add ACoS range dropdown in the second column
                                        with range_cols[1]:
                                            # Create a dropdown selector for ACoS ranges
                                            acos_range = st.selectbox(
                                                "Select ACoS Range", 
                                                acos_distribution['ACoS Range'].tolist(),
                                                key=f"acos_range_selector_{target_label.replace(' ', '_')}"
                                            )
                                        
                                        # Filter targets for this ACoS range
                                        if acos_range == 'No Sales':
                                            # Create a safe numeric version of Ad Sales
                                            target_df_copy = target_df.copy()
                                            target_df_copy['Ad_Sales_numeric'] = safe_convert_to_numeric(target_df_copy['Ad Sales'])
                                            range_df = target_df_copy[target_df_copy['Ad_Sales_numeric'] == 0]
                                        else:
                                            # Extract the range bounds
                                            if acos_range == '100%+':
                                                lower = 100
                                                upper = float('inf')
                                            else:
                                                bounds = acos_range.replace('%', '').split('-')
                                                lower = float(bounds[0])
                                                upper = float(bounds[1])
                                        
                                            # Clean ACoS values and create numeric Ad Sales
                                            target_df_copy = target_df.copy()
                                            target_df_copy['ACoS_numeric'] = target_df_copy['ACoS'].apply(lambda x: clean_acos(x))
                                            target_df_copy['Ad_Sales_numeric'] = safe_convert_to_numeric(target_df_copy['Ad Sales'])
                                            
                                            # Filter by ACoS range
                                            range_df = target_df_copy[(target_df_copy['ACoS_numeric'] >= lower) & 
                                                                     (target_df_copy['ACoS_numeric'] < upper) & 
                                                                     (target_df_copy['Ad_Sales_numeric'] > 0)]
                                            
                                            if not range_df.empty:
                                                # Group by Target and Match Type
                                                if 'Match Type' not in range_df.columns:
                                                    range_df['Match Type'] = range_df.get('Target Type', 'Unknown')
                                                
                                                # Select and prepare columns for display
                                                display_cols = ['Target', 'Match Type', 'Spend', 'Ad Sales', 'ACoS', 'ROAS', 'CPC', 'CVR']
                                                
                                                # Ensure all required columns exist
                                                for col in display_cols:
                                                    if col not in range_df.columns:
                                                        range_df[col] = None
                                                
                                                # Group by Target and Match Type
                                                # Create numeric columns for aggregation
                                                range_df = range_df.copy()
                                                
                                                # Convert Spend and Ad Sales to numeric using the global helper function
                                                range_df['Spend_numeric'] = safe_convert_to_numeric(range_df['Spend'])
                                                range_df['Ad_Sales_numeric'] = safe_convert_to_numeric(range_df['Ad Sales'])
                                                
                                                # Group by Target and Match Type
                                                grouped_df = range_df.groupby(['Target', 'Match Type']).agg({
                                                    'Spend_numeric': 'sum',
                                                    'Ad_Sales_numeric': 'sum',
                                                    'Impressions': 'sum',
                                                    'Clicks': 'sum',
                                                    'Orders': 'sum'
                                                }).reset_index()
                                                
                                                # Calculate metrics with both display and numeric versions for proper sorting
                                                # ACoS calculation
                                                grouped_df['ACoS_sort'] = grouped_df.apply(
                                                    lambda row: (row['Spend_numeric'] / row['Ad_Sales_numeric'] * 100) if row['Ad_Sales_numeric'] > 0 else float('inf'), 
                                                    axis=1
                                                )
                                                grouped_df['ACoS'] = grouped_df['ACoS_sort'].apply(
                                                    lambda x: f"{x:.2f}%" if x != float('inf') else 'N/A'
                                                )
                                                
                                                # ROAS calculation
                                                grouped_df['ROAS_sort'] = grouped_df.apply(
                                                    lambda row: (row['Ad_Sales_numeric'] / row['Spend_numeric']) if row['Spend_numeric'] > 0 else 0, 
                                                    axis=1
                                                )
                                                grouped_df['ROAS'] = grouped_df['ROAS_sort'].apply(
                                                    lambda x: f"{x:.2f}" if x > 0 else 'N/A'
                                                )
                                                
                                                # CPC calculation
                                                grouped_df['CPC_sort'] = grouped_df.apply(
                                                    lambda row: (row['Spend_numeric'] / row['Clicks']) if row['Clicks'] > 0 else 0, 
                                                    axis=1
                                                )
                                                grouped_df['CPC'] = grouped_df['CPC_sort'].apply(
                                                    lambda x: f"${x:.2f}" if x > 0 else 'N/A'
                                                )
                                                
                                                # CVR calculation
                                                grouped_df['CVR_sort'] = grouped_df.apply(
                                                    lambda row: (row['Orders'] / row['Clicks'] * 100) if row['Clicks'] > 0 else 0, 
                                                    axis=1
                                                )
                                                grouped_df['CVR'] = grouped_df['CVR_sort'].apply(
                                                    lambda x: f"{x:.2f}%" if x > 0 else 'N/A'
                                                )
                                                
                                                # Format currency columns
                                                # Always format currency columns with commas for consistent display
                                                grouped_df['Spend'] = grouped_df['Spend_numeric'].apply(lambda x: f"${x:,.2f}")
                                                grouped_df['Ad Sales'] = grouped_df['Ad_Sales_numeric'].apply(lambda x: f"${x:,.2f}")
                                                
                                                # Create a dataframe with the display columns and the numeric values for sorting
                                                # First, create a copy of the numeric columns for sorting
                                                sort_df = grouped_df.copy()
                                                
                                                # Create a display dataframe with formatted columns for display
                                                display_df = sort_df.copy()
                                                
                                                # Format the display columns
                                                display_df['ACoS'] = sort_df['ACoS_sort'].apply(lambda x: f"{x:.2f}%" if x != float('inf') else 'N/A')
                                                display_df['ROAS'] = sort_df['ROAS_sort'].apply(lambda x: f"{x:.2f}" if x > 0 else 'N/A')
                                                display_df['CPC'] = sort_df['CPC_sort'].apply(lambda x: f"${x:.2f}" if x > 0 else 'N/A')
                                                display_df['CVR'] = sort_df['CVR_sort'].apply(lambda x: f"{x:.2f}%" if x > 0 else 'N/A')
                                                # Always format currency columns with commas for consistent display
                                                display_df['Spend'] = sort_df['Spend_numeric'].apply(lambda x: f"${x:,.2f}")
                                                display_df['Ad Sales'] = sort_df['Ad_Sales_numeric'].apply(lambda x: f"${x:,.2f}")
                                                
                                                # Select only the display columns
                                                display_df = display_df[display_cols]
                                                
                                                # For proper sorting, we'll use a different approach that works with older Streamlit versions
                                                # Create a DataFrame where the display columns have their original numeric values
                                                # but are formatted for display using the Streamlit column configuration
                                                
                                                # First, create a DataFrame with the numeric columns for sorting
                                                sort_df = pd.DataFrame({
                                                    "Target": grouped_df["Target"],
                                                    "Match Type": grouped_df["Match Type"],
                                                    "Spend": grouped_df["Spend_numeric"],
                                                    "Ad Sales": grouped_df["Ad_Sales_numeric"],
                                                    "ACoS": grouped_df["ACoS_sort"],
                                                    "ROAS": grouped_df["ROAS_sort"],
                                                    "CPC": grouped_df["CPC_sort"],
                                                    "CVR": grouped_df["CVR_sort"]
                                                })
                                                
                                                # Store the numeric values for sorting
                                                sort_df_numeric = sort_df.copy()
                                                
                                                # Format the display columns with dollar signs and commas
                                                formatted_df = sort_df.copy()
                                                formatted_df["Spend"] = formatted_df["Spend"].apply(lambda x: "${:,.2f}".format(x))
                                                formatted_df["Ad Sales"] = formatted_df["Ad Sales"].apply(lambda x: "${:,.2f}".format(x))
                                                
                                                # Create column configuration for display formatting
                                                column_config = {
                                                    "Target": st.column_config.TextColumn("Target"),
                                                    "Match Type": st.column_config.TextColumn("Match Type"),
                                                    "Spend": st.column_config.NumberColumn("Spend", help="Ad spend", format="dollar"),
                                                    "Ad Sales": st.column_config.NumberColumn("Ad Sales", help="Sales attributed to ads", format="dollar"),
                                                    "ACoS": st.column_config.NumberColumn("ACoS", help="Advertising Cost of Sales", format="%.2f%%"),
                                                    "ROAS": st.column_config.NumberColumn("ROAS", help="Return on Ad Spend", format="%.2f"),
                                                    "CPC": st.column_config.NumberColumn("CPC", help="Cost Per Click", format="$%.2f"),
                                                    "CVR": st.column_config.NumberColumn("CVR", help="Conversion Rate", format="%.2f%%")
                                                }
                                                
                                                # Sort by Ad Sales in descending order
                                                sort_df = sort_df.sort_values(by='Ad Sales', ascending=False)
                                                st.dataframe(sort_df, use_container_width=True, hide_index=True, column_config=column_config)
                                            else:
                                                st.info(f"No targets found in the {acos_range} range.")
                                    else:
                                        st.info(f"Unable to generate tables for {target_label}. Check if ACoS and Spend columns are available.")
                                else:
                                    st.info(f"No data available for {target_label}. Check if ACoS and Spend columns are available.")
                    
                    # SEARCH TERM PERFORMANCE TAB
                    with acos_tables_main_tabs[1]:
                        if 'bulk_data' in st.session_state:
                            # Get search term data with branding classification
                            search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                            
                            if search_term_df.empty:
                                st.info("No search term data available. Please upload bulk advertising files with search term data.")
                            else:
                                # Extract product groups for filtering
                                product_groups = set()
                                if 'Product Group' in search_term_df.columns:
                                    groups = search_term_df['Product Group'].dropna().unique()
                                    product_groups.update([g for g in groups if g])
                                
                                # Initialize all session state variables if they don't exist
                                if 'search_term_product_group_filter1' not in st.session_state:
                                    st.session_state.search_term_product_group_filter1 = []
                                if 'search_term_filter_active1' not in st.session_state:
                                    st.session_state.search_term_filter_active1 = False
                                
                                # Define a callback function to update related session state variables
                                def update_search_term_filter1_state():
                                    # Update filter active state based on current selection
                                    st.session_state.search_term_filter_active1 = len(st.session_state.search_term_product_group_filter1) > 0
                                
                                # Add product group filter above the tabs
                                filter_col1, filter_col2 = st.columns([0.4, 0.6])
                                with filter_col1:
                                    if product_groups:
                                        product_groups = sorted(list(product_groups))
                                        st.multiselect(
                                            "Filter by Product Group(s):",
                                            options=product_groups,
                                            key="search_term_product_group_filter1",
                                            on_change=update_search_term_filter1_state
                                        )
                                        # The callback will handle updating session state
                                    else:
                                        # Show disabled multiselect with informative label
                                        st.multiselect(
                                            "Filter by Product Group(s) (Add in Client Settings):",
                                            options=[],
                                            disabled=True,
                                            key="search_term_product_group_filter1_disabled"
                                        )
                                        # Reset filter state safely
                                        if st.session_state.search_term_product_group_filter1:
                                            st.session_state.search_term_product_group_filter1 = []
                                            st.session_state.search_term_filter_active1 = False
                                        
                                # Apply product group filter if active
                                filtered_search_term_df = search_term_df.copy()
                                st.subheader("Contradicting Targets and Search Terms")
        
                                if st.session_state.get('search_term_filter_active1', False) and len(st.session_state.get('search_term_product_group_filter1', [])) > 0:
                                    if 'Product Group' in filtered_search_term_df.columns:
                                        filtered_search_term_df = filtered_search_term_df[filtered_search_term_df['Product Group'].isin(st.session_state.search_term_product_group_filter1)]
                                        st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.search_term_product_group_filter1)}")
                                    else:
                                        st.warning("Product Group column not found in data. Cannot apply filter.")
                                        st.session_state.debug_messages.append("[Search Term Performance] Product Group column not found in data.")
                                
                                # Create tabs for the Search Term tables
                                search_tab_labels = ["All Search Terms", "Branded Search Terms", "Non-Branded Search Terms"]
                                search_tabs = st.tabs(search_tab_labels)
                                
                                # Filter data for each tab
                                if 'Is_Branded' in filtered_search_term_df.columns:
                                    all_terms = filtered_search_term_df
                                    branded_terms = filtered_search_term_df[filtered_search_term_df['Is_Branded'] == True]
                                    non_branded_terms = filtered_search_term_df[filtered_search_term_df['Is_Branded'] == False]
                                else:
                                    all_terms = filtered_search_term_df
                                    branded_terms = pd.DataFrame()
                                    non_branded_terms = pd.DataFrame()
                                
                                term_dfs = [all_terms, branded_terms, non_branded_terms]

                                # Initialize session state for ACoS Range Spend Distribution if not exists
                                if "acos_range_spend_distribution_ranges" not in st.session_state:
                                    st.session_state.acos_range_spend_distribution_ranges = 10
                                
                                # Calculate consistent ACoS ranges for all search term tabs
                                search_consistent_ranges, search_consistent_labels = get_consistent_acos_ranges(term_dfs, st.session_state.acos_range_spend_distribution_ranges)
                                
                                # Process each search term tab
                                for i, (search_label, search_df) in enumerate(zip(search_tab_labels, term_dfs)):
                                    with search_tabs[i]:
                                        if not search_df.empty and 'ACoS' in search_df.columns and 'Spend' in search_df.columns:
                                            # Calculate ACoS range distribution
                                            # Get number of ranges from session state or use default
                                            range_key = f"num_acos_ranges_{search_label.replace(' ', '_')}"
                                            num_ranges = st.session_state.get(range_key, 5)
                                            
                                            # Calculate ACoS range distribution with user-selected number of ranges
                                            acos_distribution = calculate_acos_range_distribution(search_df, num_ranges=num_ranges)
                                            
                                            if not acos_distribution.empty:
                                                # Create a column layout for the range selector controls
                                                range_cols = st.columns([1, 2])
                                                
                                                # Add number of ranges input in the first column
                                                with range_cols[0]:
                                                    # Initialize session state for number of ranges if not exists
                                                    range_key = f"num_acos_ranges_{search_label.replace(' ', '_')}"
                                                    if range_key not in st.session_state:
                                                        st.session_state[range_key] = 5
                                                        
                                                    # Input for number of ACoS ranges with help text
                                                    num_ranges = st.number_input(
                                                        "Number of ACoS Ranges",
                                                        min_value=3,
                                                        max_value=20,
                                                        value=st.session_state[range_key],
                                                        step=1,
                                                        help="Set how many ACoS ranges to display (100%+ and No Sales ranges will be added automatically)",
                                                        key=f"num_ranges_input_{search_label.replace(' ', '_')}"
                                                    )
                                                    
                                                    # Update session state when value changes
                                                    if num_ranges != st.session_state[range_key]:
                                                        st.session_state[range_key] = num_ranges
                                                        # Use st.rerun() instead of experimental_rerun
                                                        st.rerun()
                                                
                                                # Add ACoS range dropdown in the second column
                                                with range_cols[1]:
                                                    # Create a dropdown selector for ACoS ranges
                                                    acos_range = st.selectbox(
                                                        "Select ACoS Range", 
                                                        acos_distribution['ACoS Range'].tolist(),
                                                        key=f"acos_range_selector_{search_label.replace(' ', '_')}"
                                                    )
                                                
                                                # Filter search terms for this ACoS range
                                                if acos_range == 'No Sales':
                                                    # Create a safe numeric version of Ad Sales
                                                    search_df_copy = search_df.copy()
                                                    search_df_copy['Ad_Sales_numeric'] = safe_convert_to_numeric(search_df_copy['Ad Sales'])
                                                    range_df = search_df_copy[search_df_copy['Ad_Sales_numeric'] == 0]
                                                else:
                                                    # Extract the range bounds
                                                    if acos_range == '100%+':
                                                        lower = 100
                                                        upper = float('inf')
                                                    else:
                                                        bounds = acos_range.replace('%', '').split('-')
                                                        lower = float(bounds[0])
                                                        upper = float(bounds[1])
                                                    
                                                    # Clean ACoS values and create numeric Ad Sales
                                                    search_df_copy = search_df.copy()
                                                    search_df_copy['ACoS_numeric'] = search_df_copy['ACoS'].apply(lambda x: clean_acos(x))
                                                    search_df_copy['Ad_Sales_numeric'] = safe_convert_to_numeric(search_df_copy['Ad Sales'])
                                                    
                                                    # Filter by ACoS range
                                                    range_df = search_df_copy[(search_df_copy['ACoS_numeric'] >= lower) & 
                                                                             (search_df_copy['ACoS_numeric'] < upper) & 
                                                                             (search_df_copy['Ad_Sales_numeric'] > 0)]
                                                
                                                if not range_df.empty:
                                                    # Group by Search Term, Target, and Match Type
                                                    if 'Match Type' not in range_df.columns:
                                                        range_df['Match Type'] = range_df.get('Target Type', 'Unknown')
                                                    
                                                    # Select and prepare columns for display
                                                    display_cols = ['Search Term', 'Target', 'Match Type', 'Spend', 'Ad Sales', 'ACoS', 'ROAS', 'CPC', 'CVR']
                                                    
                                                    # Ensure all required columns exist
                                                    for col in display_cols:
                                                        if col not in range_df.columns:
                                                            range_df[col] = None
                                                    
                                                    # Create numeric columns for aggregation
                                                    range_df = range_df.copy()
                                                    
                                                    # Convert Spend and Ad Sales to numeric using the global helper function
                                                    range_df['Spend_numeric'] = safe_convert_to_numeric(range_df['Spend'])
                                                    range_df['Ad_Sales_numeric'] = safe_convert_to_numeric(range_df['Ad Sales'])
                                                    
                                                    # Group by Search Term, Target and Match Type
                                                    grouped_df = range_df.groupby(['Search Term', 'Target', 'Match Type']).agg({
                                                        'Spend_numeric': 'sum',
                                                        'Ad_Sales_numeric': 'sum',
                                                        'Impressions': 'sum',
                                                        'Clicks': 'sum',
                                                        'Orders': 'sum'
                                                    }).reset_index()
                                                    
                                                    # Calculate metrics with both display and numeric versions for proper sorting
                                                    # ACoS calculation
                                                    grouped_df['ACoS_sort'] = grouped_df.apply(
                                                        lambda row: (row['Spend_numeric'] / row['Ad_Sales_numeric'] * 100) if row['Ad_Sales_numeric'] > 0 else float('inf'), 
                                                        axis=1
                                                    )
                                                    grouped_df['ACoS'] = grouped_df['ACoS_sort'].apply(
                                                        lambda x: f"{x:.2f}%" if x != float('inf') else 'N/A'
                                                    )
                                                    
                                                    # ROAS calculation
                                                    grouped_df['ROAS_sort'] = grouped_df.apply(
                                                        lambda row: (row['Ad_Sales_numeric'] / row['Spend_numeric']) if row['Spend_numeric'] > 0 else 0, 
                                                        axis=1
                                                    )
                                                    grouped_df['ROAS'] = grouped_df['ROAS_sort'].apply(
                                                        lambda x: f"{x:.2f}" if x > 0 else 'N/A'
                                                    )
                                                    
                                                    # CPC calculation
                                                    grouped_df['CPC_sort'] = grouped_df.apply(
                                                        lambda row: (row['Spend_numeric'] / row['Clicks']) if row['Clicks'] > 0 else 0, 
                                                        axis=1
                                                    )
                                                    grouped_df['CPC'] = grouped_df['CPC_sort'].apply(
                                                        lambda x: f"${x:.2f}" if x > 0 else 'N/A'
                                                    )
                                                    
                                                    # CVR calculation
                                                    grouped_df['CVR_sort'] = grouped_df.apply(
                                                        lambda row: (row['Orders'] / row['Clicks'] * 100) if row['Clicks'] > 0 else 0, 
                                                        axis=1
                                                    )
                                                    grouped_df['CVR'] = grouped_df['CVR_sort'].apply(
                                                        lambda x: f"{x:.2f}%" if x > 0 else 'N/A'
                                                    )
                                                    
                                                    # Format currency columns
                                                    grouped_df['Spend'] = grouped_df['Spend_numeric'].apply(lambda x: f"${x:,.2f}")
                                                    grouped_df['Ad Sales'] = grouped_df['Ad_Sales_numeric'].apply(lambda x: f"${x:,.2f}")
                                                    
                                                    # For proper sorting, we'll use a different approach that works with older Streamlit versions
                                                    # Create a DataFrame where the display columns have their original numeric values
                                                    # but are formatted for display using the Streamlit column configuration
                                                    
                                                    # First, create a DataFrame with the numeric columns for sorting
                                                    sort_df = pd.DataFrame({
                                                        "Search Term": grouped_df["Search Term"],
                                                        "Target": grouped_df["Target"],
                                                        "Match Type": grouped_df["Match Type"],
                                                        "Spend": grouped_df["Spend_numeric"],
                                                        "Ad Sales": grouped_df["Ad_Sales_numeric"],
                                                        "ACoS": grouped_df["ACoS_sort"],
                                                        "ROAS": grouped_df["ROAS_sort"],
                                                        "CPC": grouped_df["CPC_sort"],
                                                        "CVR": grouped_df["CVR_sort"]
                                                    })
                                                    
                                                    # Store the numeric values for sorting
                                                    sort_df_numeric = sort_df.copy()
                                                    
                                                    # Format the display columns with dollar signs and commas
                                                    formatted_df = sort_df.copy()
                                                    formatted_df["Spend"] = formatted_df["Spend"].apply(lambda x: "${:,.2f}".format(x))
                                                    formatted_df["Ad Sales"] = formatted_df["Ad Sales"].apply(lambda x: "${:,.2f}".format(x))
                                                    
                                                    # Create column configuration for display formatting
                                                    column_config = {
                                                        "Search Term": st.column_config.TextColumn("Search Term"),
                                                        "Target": st.column_config.TextColumn("Target"),
                                                        "Match Type": st.column_config.TextColumn("Match Type"),
                                                        "Spend": st.column_config.NumberColumn("Spend", help="Ad spend", format="dollar"),
                                                        "Ad Sales": st.column_config.NumberColumn("Ad Sales", help="Sales attributed to ads", format="dollar"),
                                                        "ACoS": st.column_config.NumberColumn("ACoS", help="Advertising Cost of Sales", format="%.2f%%"),
                                                        "ROAS": st.column_config.NumberColumn("ROAS", help="Return on Ad Spend", format="%.2f"),
                                                        "CPC": st.column_config.NumberColumn("CPC", help="Cost Per Click", format="$%.2f"),
                                                        "CVR": st.column_config.NumberColumn("CVR", help="Conversion Rate", format="%.2f%%")
                                                    }
                                                    
                                                    # Display the table with sorting enabled and hide index
                                                    # Sort by Ad Sales in descending order
                                                    sort_df = sort_df.sort_values(by='Ad Sales', ascending=False)
                                                    st.dataframe(sort_df, use_container_width=True, hide_index=True, column_config=column_config)
                                                else:
                                                    st.info(f"No search terms found in the {acos_range} range.")
                                            else:
                                                st.info(f"Unable to generate tables for {search_label}. Check if ACoS and Spend columns are available.")
                                        else:
                                            st.info(f"No data available for {search_label}. Check if ACoS and Spend columns are available.")
                        else:
                            st.info("No bulk advertising data available. Please upload bulk advertising files with search term data.")
                    
                    # ACoS Range Spend Distribution Section
                    st.markdown("<div style='margin-top:3rem;'></div>", unsafe_allow_html=True)
                    st.markdown("<div id='acos-range-spend-distribution' class='section-anchor'></div>", unsafe_allow_html=True)
                    st.markdown("<span class='main-section-header'>ACoS Range Spend Distribution</span>", unsafe_allow_html=True)
                    
                    # Add a dedicated ACoS Range number selector for this section
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        # Initialize session state for ACoS Range Spend Distribution if not exists
                        if "acos_range_spend_distribution_ranges" not in st.session_state:
                            st.session_state.acos_range_spend_distribution_ranges = 10
                        
                        # Number input for ACoS Range Spend Distribution
                        num_ranges_value = st.number_input(
                            "Number of ACoS Ranges",
                            min_value=3,
                            max_value=20,
                            value=st.session_state.acos_range_spend_distribution_ranges,
                            step=1,
                            help="Set how many ACoS ranges to display in the distribution charts (100%+ and No Sales ranges will be added automatically)",
                            key="acos_range_spend_distribution_input"
                        )
                        
                        # Update session state when value changes
                        st.session_state.acos_range_spend_distribution_ranges = num_ranges_value
                    
                    # Create main tabs for Target Performance and Search Term Performance views
                    main_tabs = st.tabs(["Target Performance", "Search Term Performance"])
                    
                    # TARGET PERFORMANCE TAB
                    with main_tabs[0]:
                        # Add Targeting Performance Summary header
                        st.subheader("Targeting Performance Summary")
                        
                        # Extract product groups for filtering from targets data
                        target_product_groups = set()
                        
                        # Check all target dataframes for Product Group column
                        for df in [st.session_state.all_targets_df, st.session_state.branded_targets_df, st.session_state.non_branded_targets_df]:
                            if not df.empty and 'Product Group' in df.columns:
                                groups = df['Product Group'].dropna().unique()
                                target_product_groups.update([g for g in groups if g])
                        
                        # Initialize all session state variables for target product group filter if they don't exist
                        if 'target_product_group_filter_acos_range' not in st.session_state:
                            st.session_state.target_product_group_filter_acos_range = []
                        if 'target_filter_active_acos_range' not in st.session_state:
                            st.session_state.target_filter_active_acos_range = False
                        
                        # Define a callback function to update related session state variables
                        def update_target_filter_acos_range_state():
                            # Update filter active state based on current selection
                            st.session_state.target_filter_active_acos_range = len(st.session_state.target_product_group_filter_acos_range) > 0
                        
                        # Add product group filter above the tabs
                        filter_col1, filter_col2 = st.columns([0.4, 0.6])
                        with filter_col1:
                            if target_product_groups:
                                target_product_groups = sorted(list(target_product_groups))
                                st.multiselect(
                                    "Filter by Product Group(s):",
                                    options=target_product_groups,
                                    key="target_product_group_filter_acos_range",
                                    on_change=update_target_filter_acos_range_state
                                )
                                # The callback will handle updating session state
                            else:
                                # Show disabled multiselect with informative label
                                st.multiselect(
                                    "Filter by Product Group(s) (Add in Client Settings):",
                                    options=[],
                                    disabled=True,
                                    key="target_product_group_filter_acos_range_disabled"
                                )
                                # Reset filter state safely
                                if st.session_state.target_product_group_filter_acos_range:
                                    st.session_state.target_product_group_filter_acos_range = []
                                    st.session_state.target_filter_active_acos_range = False
                        
                        # Apply product group filter to each dataframe if active
                        filtered_all_targets_df = st.session_state.all_targets_df.copy()
                        filtered_branded_targets_df = st.session_state.branded_targets_df.copy()
                        filtered_non_branded_targets_df = st.session_state.non_branded_targets_df.copy()
                        
                        if st.session_state.get('target_filter_active_acos_range', False) and len(st.session_state.get('target_product_group_filter_acos_range', [])) > 0:
                            # Filter all targets
                            if 'Product Group' in filtered_all_targets_df.columns:
                                filtered_all_targets_df = filtered_all_targets_df[filtered_all_targets_df['Product Group'].isin(st.session_state.target_product_group_filter_acos_range)]
                            else:
                                st.warning("Product Group column not found in All Targets data. Cannot apply filter.")
                                st.session_state.debug_messages.append("[Target Performance] Product Group column not found in All Targets data.")
                            
                            # Filter branded targets
                            if not filtered_branded_targets_df.empty and 'Product Group' in filtered_branded_targets_df.columns:
                                filtered_branded_targets_df = filtered_branded_targets_df[filtered_branded_targets_df['Product Group'].isin(st.session_state.target_product_group_filter_acos_range)]
                            
                            # Filter non-branded targets
                            if not filtered_non_branded_targets_df.empty and 'Product Group' in filtered_non_branded_targets_df.columns:
                                filtered_non_branded_targets_df = filtered_non_branded_targets_df[filtered_non_branded_targets_df['Product Group'].isin(st.session_state.target_product_group_filter_acos_range)]
                            
                            # Show filter caption
                            st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.target_product_group_filter_acos_range)}")
                        
                        # Create tabs for the Target Spend Distribution Graph
                        graph_tab_labels = ["All Targets", "Branded Targets", "Non-Branded Targets"]
                        graph_tabs = st.tabs(graph_tab_labels)
                        
                        # Get the filtered dataframes for each target tab
                        graph_dfs = [filtered_all_targets_df, filtered_branded_targets_df, filtered_non_branded_targets_df]
                        
                        # Calculate consistent ACoS ranges for all target tabs
                        consistent_ranges, consistent_labels = get_consistent_acos_ranges(graph_dfs, st.session_state.acos_range_spend_distribution_ranges)
                        
                        # Process each target tab
                        for graph_tab, graph_label, graph_df in zip(graph_tabs, graph_tab_labels, graph_dfs):
                            with graph_tab:
                                if not graph_df.empty and 'ACoS' in graph_df.columns and 'Spend' in graph_df.columns:
                                    # Calculate ACoS range distribution for the graph using the dedicated selector value
                                    if consistent_ranges and consistent_labels:
                                        acos_distribution = calculate_acos_distribution_with_ranges(graph_df, consistent_ranges, consistent_labels)
                                    else:
                                        acos_distribution = calculate_acos_range_distribution(graph_df, num_ranges=st.session_state.acos_range_spend_distribution_ranges)
                                    
                                    
                                    # Prepare data for the graph
                                    if not acos_distribution.empty:
                                        # Convert spend values from formatted strings to numeric
                                        acos_distribution['Spend_numeric'] = acos_distribution['Spend'].str.replace('$', '').str.replace(',', '').astype(float)
                                        
                                        # Create a bar chart of spend by ACoS range
                                        # Create a custom color array for the bars (green to red)
                                        num_ranges = len(acos_distribution)
                                        # Create a list of indices for each ACoS range
                                        range_indices = list(range(num_ranges))
                                        
                                        # Create a bar chart of spend by ACoS range
                                        fig = px.bar(
                                            acos_distribution,
                                            x='ACoS Range',
                                            y='Spend_numeric',
                                            labels={'Spend_numeric': 'Spend', 'ACoS Range': 'ACoS Range'},
                                            title=f'Spend Distribution by ACoS Range - {graph_label}',
                                            color=range_indices,  # Use indices for coloring
                                            color_continuous_scale=['#2ecc71', '#27ae60', '#2ecc71', '#7dce70', '#a4d86e', '#d4e157', '#f1c40f', '#f39c12', '#f5b041', '#e67e22', '#d35400', '#ff0000'],
                                            height=500
                                        )
                                        
                                        # Customize the graph
                                        fig.update_layout(
                                            xaxis_title='ACoS Range',
                                            yaxis_title='Spend',
                                            plot_bgcolor='rgba(0,0,0,0)',
                                            paper_bgcolor='rgba(0,0,0,0)',
                                            font=dict(color='#FFFFFF'),
                                            coloraxis_showscale=False,
                                            margin=dict(l=40, r=40, t=50, b=40)
                                        )
                                        
                                        # Add spend values as text on top of bars
                                        fig.update_traces(
                                            text=acos_distribution['Spend'],
                                            textposition='outside'
                                        )
                                        
                                        # Display the graph
                                        st.plotly_chart(fig, use_container_width=True)
                                    else:
                                        st.info(f"Unable to generate spend distribution graph for {graph_label}. Check if ACoS and Spend columns are available.")
                                else:
                                    st.info(f"No data available for {graph_label} graph. Check if ACoS and Spend columns are available.")
                    
                    # SEARCH TERM PERFORMANCE TAB
                    with main_tabs[1]:
                        # Add Search Term Performance Summary header
                        st.subheader("Search Term Performance Summary")
                        
                        if 'bulk_data' in st.session_state:
                            # Get search term data with branding classification
                            search_term_df = get_search_term_data(st.session_state.bulk_data, st.session_state.client_config)
                            
                            if search_term_df.empty:
                                st.info("No search term data available. Please upload bulk advertising files with search term data.")
                            else:
                                # Extract product groups for filtering
                                product_groups = set()
                                if 'Product Group' in search_term_df.columns:
                                    groups = search_term_df['Product Group'].dropna().unique()
                                    product_groups.update([g for g in groups if g])
                                
                                # Initialize all session state variables if they don't exist
                                if 'search_term_product_group_filter2' not in st.session_state:
                                    st.session_state.search_term_product_group_filter2 = []
                                if 'search_term_filter_active2' not in st.session_state:
                                    st.session_state.search_term_filter_active2 = False
                                
                                # Define a callback function to update related session state variables
                                def update_search_term_filter2_state():
                                    # Update filter active state based on current selection
                                    st.session_state.search_term_filter_active2 = len(st.session_state.search_term_product_group_filter2) > 0
                                
                                # Add product group filter above the tabs
                                filter_col1, filter_col2 = st.columns([0.4, 0.6])
                                with filter_col1:
                                    if product_groups:
                                        product_groups = sorted(list(product_groups))
                                        st.multiselect(
                                            "Filter by Product Group(s):",
                                            options=product_groups,
                                            key="search_term_product_group_filter2",
                                            on_change=update_search_term_filter2_state
                                        )
                                        # The callback will handle updating session state
                                    else:
                                        # Show disabled multiselect with informative label
                                        st.multiselect(
                                            "Filter by Product Group(s) (Add in Client Settings):",
                                            options=[],
                                            disabled=True,
                                            key="search_term_product_group_filter2_disabled"
                                        )
                                        # Reset filter state safely
                                        if st.session_state.search_term_product_group_filter2:
                                            st.session_state.search_term_product_group_filter2 = []
                                            st.session_state.search_term_filter_active2 = False
                                        
                                # Apply product group filter if active
                                filtered_search_term_df = search_term_df.copy()
                                if st.session_state.get('search_term_filter_active2', False) and len(st.session_state.get('search_term_product_group_filter2', [])) > 0:
                                    if 'Product Group' in filtered_search_term_df.columns:
                                        filtered_search_term_df = filtered_search_term_df[filtered_search_term_df['Product Group'].isin(st.session_state.search_term_product_group_filter2)]
                                        st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.search_term_product_group_filter2)}")
                                    else:
                                        st.warning("Product Group column not found in data. Cannot apply filter.")
                                        st.session_state.debug_messages.append("[Search Term Performance] Product Group column not found in data.")
                                # Create tabs for the Search Term Spend Distribution Graph
                                graph_tab_labels = ["All Search Terms", "Branded Search Terms", "Non-Branded Search Terms"]
                                graph_tabs = st.tabs(graph_tab_labels)
                                
                                # Filter data for each tab
                                if 'Is_Branded' in filtered_search_term_df.columns:
                                    all_terms = filtered_search_term_df
                                    branded_terms = filtered_search_term_df[filtered_search_term_df['Is_Branded'] == True]
                                    non_branded_terms = filtered_search_term_df[filtered_search_term_df['Is_Branded'] == False]
                                else:
                                    all_terms = filtered_search_term_df
                                    branded_terms = pd.DataFrame()
                                    non_branded_terms = pd.DataFrame()
                                
                                term_dfs = [all_terms, branded_terms, non_branded_terms]
                                
                                # Calculate consistent ACoS ranges for all search term tabs
                                search_consistent_ranges, search_consistent_labels = get_consistent_acos_ranges(term_dfs, st.session_state.acos_range_spend_distribution_ranges)
                                
                                # Process each search term tab
                                for graph_tab, graph_label, graph_df in zip(graph_tabs, graph_tab_labels, term_dfs):
                                    with graph_tab:
                                        if not graph_df.empty and 'ACoS' in graph_df.columns and 'Spend' in graph_df.columns:
                                            # Calculate ACoS range distribution for the graph using the dedicated selector value
                                            if search_consistent_ranges and search_consistent_labels:
                                                acos_distribution = calculate_acos_distribution_with_ranges(graph_df, search_consistent_ranges, search_consistent_labels)
                                            else:
                                                acos_distribution = calculate_acos_range_distribution(graph_df, num_ranges=st.session_state.acos_range_spend_distribution_ranges)
                                            
                                            # Prepare data for the graph
                                            if not acos_distribution.empty:
                                                # Convert spend values from formatted strings to numeric
                                                acos_distribution['Spend_numeric'] = acos_distribution['Spend'].str.replace('$', '').str.replace(',', '').astype(float)
                                                
                                                # Create a bar chart of spend by ACoS range
                                                # Create a custom color array for the bars (green to red)
                                                num_ranges = len(acos_distribution)
                                                # Create a list of indices for each ACoS range
                                                range_indices = list(range(num_ranges))
                                                
                                                # Create a bar chart of spend by ACoS range
                                                fig = px.bar(
                                                    acos_distribution,
                                                    x='ACoS Range',
                                                    y='Spend_numeric',
                                                    labels={'Spend_numeric': 'Spend', 'ACoS Range': 'ACoS Range'},
                                                    title=f'Spend Distribution by ACoS Range - {graph_label}',
                                                    color=range_indices,  # Use indices for coloring
                                                    color_continuous_scale=['#2ecc71', '#27ae60', '#2ecc71', '#7dce70', '#a4d86e', '#d4e157', '#f1c40f', '#f39c12', '#f5b041', '#e67e22', '#d35400', '#ff0000'],
                                                    height=500
                                                )
                                                
                                                # Customize the graph
                                                fig.update_layout(
                                                    xaxis_title='ACoS Range',
                                                    yaxis_title='Spend',
                                                    plot_bgcolor='rgba(0,0,0,0)',
                                                    paper_bgcolor='rgba(0,0,0,0)',
                                                    font=dict(color='#FFFFFF'),
                                                    coloraxis_showscale=False,
                                                    margin=dict(l=40, r=40, t=50, b=40)
                                                )
                                                
                                                # Add spend values as text on top of bars
                                                fig.update_traces(
                                                    text=acos_distribution['Spend'],
                                                    textposition='outside'
                                                )
                                                
                                                # Display the graph
                                                st.plotly_chart(fig, use_container_width=True)
                                            else:
                                                st.info(f"Unable to generate spend distribution graph for {graph_label}. Check if ACoS and Spend columns are available.")
                                        else:
                                            st.info(f"No data available for {graph_label} graph. Check if ACoS and Spend columns are available.")
                        else:
                            st.info("No bulk advertising data available. Please upload bulk advertising files with search term data.")
                     
                    # The aggregation tables are now implemented in the sections below
                    # No need for placeholder tabs here

            except Exception as e:
                import traceback
                st.error(f"An error occurred calculating targeting performance: {e}\n{traceback.format_exc()}")
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f"[Targeting Performance Error] {e}\n{traceback.format_exc()}")
                # Initialize empty DataFrames to avoid further errors
                st.session_state.branded_targets_df = pd.DataFrame()
                st.session_state.non_branded_targets_df = pd.DataFrame()
                st.session_state.all_targets_df = pd.DataFrame()

        # END Targeting Performance Section

        # Note: Search Term Performance is now fully integrated in the main dashboard tabs
        # and is no longer duplicated as a separate section

    # --- Performance by Product Group ---
# Only show on the Advertising Audit page
if st.session_state.current_page == "advertising_audit":

    # Moved to top level of file - see top of file for implementation



    def normalize_match_types(df):
        # Define match_type_col within the function to avoid global variable issues
        match_type_col = 'Match Type' if 'Match Type' in df.columns else 'Target Type'
    
        if match_type_col not in df.columns or df.empty:
            return df
        df = df.copy()
        # Replace 'Sponsored Brands Target' and 'Sponsored Display Target' with 'Product Target'
        df[match_type_col] = df[match_type_col].apply(lambda x: 'Product Target' 
                                                      if x in ['Sponsored Brands Target', 'Sponsored Display Target'] 
                                                      else x)
        return df


    def kpi_agg(df, account_total_spend=0, account_total_sales=0):
        # Aggregates KPIs for a grouped df
        # Calculate total spend and sales for percentage calculations
    
        # Handle different possible sales column names
        sales_col = None
        # First check for Ad Sales, then Sales, then other variants
        if 'Ad Sales' in df.columns and df['Ad Sales'].notna().any():
            sales_col = 'Ad Sales'
        elif 'Sales' in df.columns and df['Sales'].notna().any():
            sales_col = 'Sales'
        elif 'Sales (Views & Clicks)' in df.columns and df['Sales (Views & Clicks)'].notna().any():
            sales_col = 'Sales (Views & Clicks)'
        else:
            # If no column with data is found, default to Ad Sales and it will be handled as 0
            sales_col = 'Ad Sales'
            if 'Ad Sales' not in df.columns:
                df['Ad Sales'] = 0
    
        # Ensure numeric values for calculations
        df_numeric = df.copy()
        for col in ['Spend', 'Impressions', 'Clicks', 'Orders']:
            if col in df_numeric.columns:
                df_numeric[col] = pd.to_numeric(df_numeric[col].astype(str).str.replace('[$,%]', '', regex=True), errors='coerce').fillna(0)
    
        if sales_col:
            df_numeric[sales_col] = pd.to_numeric(df_numeric[sales_col].astype(str).str.replace('[$,%]', '', regex=True), errors='coerce').fillna(0)
    
        # Calculate metrics
        group_spend = df_numeric['Spend'].sum() if 'Spend' in df_numeric.columns else 0
        group_sales = df_numeric[sales_col].sum() if sales_col else 0
    
        return pd.Series({
            'Spend': group_spend,
            'Ad Sales': group_sales,
            '% of Spend': (group_spend / account_total_spend) * 100 if account_total_spend > 0 else 0,
            '% of Ad Sales': (group_sales / account_total_sales) * 100 if account_total_sales > 0 else 0,
            'ACoS': (group_spend / group_sales) * 100 if group_sales > 0 else 0,
            'ROAS': (group_sales / group_spend) if group_spend > 0 else 0,
            'CPC': (group_spend / df_numeric['Clicks'].sum()) if 'Clicks' in df_numeric.columns and df_numeric['Clicks'].sum() > 0 else 0,
            'CVR': (df_numeric['Orders'].sum() / df_numeric['Clicks'].sum()) * 100 if 'Orders' in df_numeric.columns and 'Clicks' in df_numeric.columns and df_numeric['Clicks'].sum() > 0 else 0,
            'CTR': (df_numeric['Clicks'].sum() / df_numeric['Impressions'].sum()) * 100 if 'Clicks' in df_numeric.columns and 'Impressions' in df_numeric.columns and df_numeric['Impressions'].sum() > 0 else 0,
            'AOV': (group_sales / df_numeric['Orders'].sum()) if 'Orders' in df_numeric.columns and df_numeric['Orders'].sum() > 0 else 0,
            'CPA': (group_spend / df_numeric['Orders'].sum()) if 'Orders' in df_numeric.columns and df_numeric['Orders'].sum() > 0 else 0,
            'Impressions': df_numeric['Impressions'].sum() if 'Impressions' in df_numeric.columns else 0,
            'Clicks': df_numeric['Clicks'].sum() if 'Clicks' in df_numeric.columns else 0,
            'Orders': df_numeric['Orders'].sum() if 'Orders' in df_numeric.columns else 0,
            'Units Sold': df_numeric['Orders'].sum() if 'Orders' in df_numeric.columns else 0 # Alias for Orders
        })

    # Formatting helper for aggregation tables

    def ensure_acos_column(df):
        # Rename 'ACOS' to 'ACoS' if present and not already renamed
        if 'ACOS' in df.columns and 'ACoS' not in df.columns:
            df = df.rename(columns={'ACOS': 'ACoS'})
        # Ensure 'ACoS' is numeric before formatting
        if 'ACoS' in df.columns:
            df['ACoS'] = pd.to_numeric(df['ACoS'], errors='coerce')
        return df

    def format_table_with_styling(df, index_col=None, sort_by=None, sort_ascending=False):
        """
        Format a DataFrame with proper styling for currency, percentage, and numeric values.
        Also enables proper sorting capabilities.
    
        Args:
            df: DataFrame to format
            index_col: Column to use as the index/first column
            sort_by: Column to sort by
            sort_ascending: Whether to sort in ascending order
        
        Returns:
            Styled DataFrame ready for display
        """
        if df.empty:
            return df
    
        # Create a clean copy of the dataframe
        df_fmt = df.copy()
    
        # Ensure ACoS column is present and numeric before formatting
        df_fmt = ensure_acos_column(df_fmt)
    
        # Clean and convert percentage columns to numeric values
        percentage_cols = ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales', '% of Total Sales', 
                           'TACoS', 'Ad Sales % of Total']
        for col in percentage_cols:
            if col in df_fmt.columns:
                # Clean and convert to float
                def clean_percent(val):
                    if pd.isnull(val):
                        return np.nan
                    try:
                        # Remove percent, commas, whitespace, and any non-numeric prefix/suffix
                        if isinstance(val, str):
                            val = val.split(';')[0]  # Remove any CSS if present
                            val = val.replace('%', '').replace(',', '').replace('\n', '').strip()
                        return float(val)
                    except Exception:
                        return np.nan
                df_fmt[col] = df_fmt[col].apply(clean_percent)
    
        # Convert currency columns to numeric values
        currency_cols = ['Spend', 'Ad Sales', 'Sales', 'CPC', 'AOV', 'CPA', 'Total Sales']
        for col in currency_cols:
            if col in df_fmt.columns:
                df_fmt[col] = pd.to_numeric(df_fmt[col], errors='coerce')
    
        # Convert ratio columns to numeric
        ratio_cols = ['ROAS']
        for col in ratio_cols:
            if col in df_fmt.columns:
                df_fmt[col] = pd.to_numeric(df_fmt[col], errors='coerce')
    
        # Convert integer columns to numeric
        integer_cols = ['Impressions', 'Clicks', 'Orders', 'Units Sold', 'ASIN Count']
        for col in integer_cols:
            if col in df_fmt.columns:
                df_fmt[col] = pd.to_numeric(df_fmt[col], errors='coerce').fillna(0).astype(int)
    
        # Reorder columns if index_col is provided
        if index_col and index_col in df_fmt.columns:
            cols = [index_col] + [c for c in df_fmt.columns if c != index_col]
            df_fmt = df_fmt[cols]
    
        # Apply sorting if specified
        if sort_by and sort_by in df_fmt.columns:
            df_fmt = df_fmt.sort_values(by=sort_by, ascending=sort_ascending)
        elif 'Ad Sales' in df_fmt.columns:
            # Default sort by Ad Sales descending
            df_fmt = df_fmt.sort_values('Ad Sales', ascending=False)
    
        # Replace NaN values with 0 for display
        df_fmt = df_fmt.fillna(0)
    
        # Define formatting functions
        def currency_fmt(x):
            return f"${x:,.2f}" if pd.notnull(x) and x != 0 else "$0.00"
    
        def percent_fmt(x):
            return f"{x*100:.1f}%" if pd.notnull(x) and x != 0 else "0.0%"
    
        def ratio_fmt(x):
            return f"{x:.2f}" if pd.notnull(x) and x != 0 else "0.00"
    
        def count_fmt(x):
            return f"{int(x):,}" if pd.notnull(x) and x != 0 else "0"
    
        # Create formatting dictionary
        fmt_dict = {}
    
        # Add currency columns to formatting dictionary
        for col in currency_cols:
            if col in df_fmt.columns:
                fmt_dict[col] = currency_fmt
    
        # Add percentage columns to formatting dictionary
        for col in percentage_cols:
            if col in df_fmt.columns:
                fmt_dict[col] = percent_fmt
    
        # Add ratio columns to formatting dictionary
        for col in ratio_cols:
            if col in df_fmt.columns:
                fmt_dict[col] = ratio_fmt
    
        # Add integer columns to formatting dictionary
        for col in integer_cols:
            if col in df_fmt.columns:
                fmt_dict[col] = count_fmt
    
        # Apply formatting
        styled_df = df_fmt.style.format(fmt_dict)
    
        return styled_df

    def format_agg_table(df, index_col=None):
        # Ensure ACoS column is present and numeric before formatting
        df = ensure_acos_column(df)
        # Sort by Ad Sales in descending order
        if 'Ad Sales' in df.columns:
            df = df.sort_values('Ad Sales', ascending=False)
    
        # Create a clean copy of the dataframe with proper numeric types
        df_fmt = df.copy()
    
        # Clean and convert percentage columns to numeric values
        for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
            if col in df_fmt.columns:
                # Clean and convert to float
                def clean_percent(val):
                    if pd.isnull(val):
                        return np.nan
                    try:
                        # Remove percent, commas, whitespace, and any non-numeric prefix/suffix
                        if isinstance(val, str):
                            val = val.split(';')[0]  # Remove any CSS if present
                            val = val.replace('%', '').replace(',', '').replace('\n', '').strip()
                        return float(val)
                    except Exception:
                        return np.nan
                df_fmt[col] = df_fmt[col].apply(clean_percent)
    
        # Convert currency columns to numeric values
        for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
            if col in df_fmt.columns:
                df_fmt[col] = pd.to_numeric(df_fmt[col], errors='coerce')
    
        # Convert ROAS to numeric
        if 'ROAS' in df_fmt.columns:
            df_fmt['ROAS'] = pd.to_numeric(df_fmt['ROAS'], errors='coerce')
    
        # Convert integer columns to numeric
        for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
            if col in df_fmt.columns:
                df_fmt[col] = pd.to_numeric(df_fmt[col], errors='coerce').fillna(0).astype(int)
    
        # Reorder columns if index_col is provided
        if index_col and index_col in df_fmt.columns:
            cols = [index_col] + [c for c in df_fmt.columns if c != index_col]
            df_fmt = df_fmt[cols]
    
        return df_fmt

    # Column config for aggregation tables (match main tables)
    agg_column_config = {
        # Currency columns with dollar formatting and comma separators
        "Spend": st.column_config.NumberColumn(
            "Spend",
            format="$,.2f",
            help="Total ad spend"
        ),
        "Ad Sales": st.column_config.NumberColumn(
            "Ad Sales",
            format="$,.2f",
            help="Sales attributed to advertising"
        ),
        "CPC": st.column_config.NumberColumn(
            "CPC",
            format="$,.2f",
            help="Cost per click"
        ),
        "AOV": st.column_config.NumberColumn(
            "AOV",
            format="$,.2f",
            help="Average order value"
        ),
        "CPA": st.column_config.NumberColumn(
            "CPA",
            format="$,.2f",
            help="Cost per acquisition"
        ),
    
        # Percentage columns
        "% of Total Spend": st.column_config.NumberColumn(
            "% of Total Spend",
            format="%.2f%%",
            help="Percentage of total advertising spend"
        ),
        "% of Total Ad Sales": st.column_config.NumberColumn(
            "% of Total Ad Sales",
            format="%.2f%%",
            help="Percentage of total advertising sales"
        ),
        "ACoS": st.column_config.NumberColumn(
            "ACoS",
            format="%.2f%%",
            help="Advertising cost of sales"
        ),
        "CVR": st.column_config.NumberColumn(
            "CVR",
            format="%.2f%%",
            help="Conversion rate"
        ),
        "CTR": st.column_config.NumberColumn(
            "CTR",
            format="%.2f%%",
            help="Click-through rate"
        ),
    
        # Decimal columns
        "ROAS": st.column_config.NumberColumn(
            "ROAS",
            format="%.2f",
            help="Return on ad spend"
        ),
    
        # Integer columns with comma formatting
        "Impressions": st.column_config.NumberColumn(
            "Impressions",
            format="%,d",
            help="Number of ad impressions"
        ),
        "Clicks": st.column_config.NumberColumn(
            "Clicks",
            format="%,d",
            help="Number of ad clicks"
        ),
        "Orders": st.column_config.NumberColumn(
            "Orders",
            format="%,d",
            help="Number of orders"
        ),
        "Units Sold": st.column_config.NumberColumn(
            "Units Sold",
            format="%,d",
            help="Number of units sold"
        ),
    }

    # Helper for Sponsored Display Product Target remarketing classification

    def split_sd_product_target_remarketing(df, branded_asins):
        """
        Categorize Sponsored Display rows based on Targeting Expression content.
        Categories:
        - Product Target: Contains ASIN but no views/purchases
        - Remarketing - Branded: Contains ASIN + views/purchases and ASIN is branded
        - Remarketing - Competitor: Contains ASIN + views/purchases and ASIN is not branded
        - Remarketing - Competitor: Contains views/purchases but no ASIN
        - Category Target: Contains neither ASIN nor views/purchases
        All checks are case-insensitive.
        """
        # Make a copy to avoid modifying the original dataframe
        df = df.copy()
    
        # Check if dataframe is empty
        if df.empty:
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append("[SD Categorization] Empty dataframe passed to function")
            return df
    
        # Add Product column if not present
        if 'Product' not in df.columns:
            df['Product'] = 'Sponsored Display'
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append("[SD Categorization] Added missing 'Product' column")
    
        # Add Match Type column if not present
        if 'Match Type' not in df.columns:
            df['Match Type'] = 'Product Target'
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append("[SD Categorization] Added missing 'Match Type' column")
    
        # Find the Targeting Expression column (case-insensitive)
        te_col = next((c for c in df.columns if c.strip().lower() == 'targeting expression'), None)
        if not te_col:
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f"[SD Categorization] No 'Targeting Expression' column found. Available columns: {list(df.columns)}")
            return df
    
        # Convert branded ASINs to uppercase for case-insensitive comparison
        branded_asins_upper = set(str(a).upper() for a in branded_asins) if branded_asins else set()
    
        # Debug information
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append(f"[SD Categorization] Found {len(branded_asins_upper)} branded ASINs for comparison")
    
        # Check for Entity column to identify audience targeting rows
        entity_col = None
        for possible_name in ['Entity', 'entity']:
            if possible_name in df.columns:
                entity_col = possible_name
                break
    
        # Count of rows processed in each category
        category_counts = {'Product Target': 0, 'Remarketing - Branded': 0, 'Remarketing - Competitor': 0, 'Category Target': 0}
    
        def classify_row(row):
            # Only process Sponsored Display rows
            if str(row['Product']).strip().lower() != 'sponsored display':
                return row['Match Type']
        
            # Get targeting expression and convert to lowercase for consistent checks
            expr = str(row[te_col]).lower() if pd.notna(row[te_col]) else ''
            expr_upper = str(row[te_col]).upper() if pd.notna(row[te_col]) else ''
        
            # HIGHEST PRIORITY: Check for exact-product targeting - this should always be Branded
            # Handle both direct 'exact-product' and nested formats like 'views=(exact-product lookback=7)'
            contains_exact_product = 'exact-product' in expr
        
            # Debug the expression to help diagnose issues
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f"[SD Row] Examining expression: '{expr}'")
            
            if contains_exact_product:
                category_counts['Remarketing - Branded'] += 1
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f"[SD Row] HIGHEST PRIORITY: Classified as Remarketing - Branded due to exact-product in: {expr}")
                return 'Remarketing - Branded'
            
            # Check if this is an Audience Targeting row based on Entity column
            is_audience_targeting = False
            if entity_col and pd.notna(row.get(entity_col)):
                entity_value = str(row[entity_col]).lower()
                is_audience_targeting = 'audience' in entity_value or 'targeting' in entity_value
        
            # Check if expression contains an ASIN (B0...)
            contains_asin = bool(re.search(r'b0[0-9a-z]{8}', expr, re.IGNORECASE)) or 'asin=' in expr.lower()
            contains_views_purchases = 'views' in expr or 'purchases' in expr
            contains_category = 'category=' in expr
        
            # Extract ASIN from the expression if it exists
            # First try standard pattern
            asin_match = re.search(r'(b0[0-9a-z]{8})', expr_upper)
        
            # If not found, try the asin="BXXXXXXXX" format
            if not asin_match and 'asin=' in expr.lower():
                asin_match = re.search(r'asin="?(b0[0-9a-z]{8})"?', expr_upper, re.IGNORECASE)
        
            asin_value = asin_match.group(1) if asin_match else None
        
            # Skip debug message for ASIN extraction
            
            is_branded_asin = asin_value in branded_asins_upper if asin_value else False
        
            # Debug specific rows if needed
            if 'debug_messages' in st.session_state and (contains_asin or contains_views_purchases):
                st.session_state.debug_messages.append(f"[SD Row] ASIN: {asin_value}, Views/Purchases: {contains_views_purchases}, Branded: {is_branded_asin}, Expr: {expr[:50]}...")
        
            # Special handling for Audience Targeting rows
            if is_audience_targeting:
                if contains_views_purchases:
                    # If it contains views/purchases, it's remarketing
                    if contains_asin and is_branded_asin:
                        category_counts['Remarketing - Branded'] += 1
                        return 'Remarketing - Branded'
                    else:
                        category_counts['Remarketing - Competitor'] += 1
                        return 'Remarketing - Competitor'
                elif contains_category:
                    category_counts['Category Target'] += 1
                    return 'Category Target'
            # Enhanced detection for Auto targeting in SD campaigns
            if 'auto' in expr.lower() or 'targeting type' in str(row.get('Targeting Type', '')).lower():
                targeting_type_col = next((c for c in df.columns if c.strip().lower() == 'targeting type'), None)
                if targeting_type_col and pd.notna(row.get(targeting_type_col)) and str(row.get(targeting_type_col)).strip().lower() == 'auto':
                    category_counts['Product Target'] += 1
                    return 'Product Target'  # SD Auto campaigns are typically Product Targeting
        

        
            # Apply categorization logic for other rows
            if contains_asin:
                if contains_views_purchases:
                    if is_branded_asin:
                        category_counts['Remarketing - Branded'] += 1
                        return 'Remarketing - Branded'
                    else:
                        category_counts['Remarketing - Competitor'] += 1
                        return 'Remarketing - Competitor'
                else:
                    category_counts['Product Target'] += 1
                    return 'Product Target'
            elif contains_views_purchases:
                category_counts['Remarketing - Competitor'] += 1
                return 'Remarketing - Competitor'
            elif contains_category:
                category_counts['Category Target'] += 1
                return 'Category Target'
            else:
                category_counts['Product Target'] += 1
                return 'Product Target'  # Default to Product Target if no other criteria match
        df = df.copy()
        df['Match Type'] = df.apply(classify_row, axis=1)
        return df

    # (normalize_match_types is already at top-level, do not duplicate)

    # --- Targeting Performance Section logic continues ---
    # Get ACoS targets from config
    config = st.session_state.get('client_config', {})
    goals = config.get('goals', {}) if config else {}
    branded_target = goals.get('branded_acos')
    non_branded_target = goals.get('non_branded_acos')

    # Only show targeting tables on the Advertising Audit page
    if st.session_state.current_page == "advertising_audit":
        # Add debug message for this section if needed
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append("[INFO] Displaying Targeting by Match Type section")
    
        # --- Performance by Tactic Section ---
        st.markdown("<div id='performance-by-tactic-ad-type-match-type' class='section-anchor'></div>", unsafe_allow_html=True)
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<span class='main-section-header'>Performance by Tactic (Ad Type & Match Type)</span>", unsafe_allow_html=True)
    
        # --- 1. Match Type Aggregation ---
        st.markdown('#### Targeting by Match Type')

        # Use the targeting data stored in session state
        branded_targets_df = st.session_state.get('branded_targets_df', pd.DataFrame())
        non_branded_targets_df = st.session_state.get('non_branded_targets_df', pd.DataFrame())
        all_df = pd.concat([branded_targets_df, non_branded_targets_df], ignore_index=True)

        match_type_col = 'Match Type' if 'Match Type' in branded_targets_df.columns else 'Target Type'
        kpi_cols = ['Spend','Ad Sales','% of Spend','% of Ad Sales','ACoS','ROAS','CPC','CVR','CTR','AOV','CPA','Impressions','Clicks','Orders','Units Sold']

        # Get Branded ASINs from client config
        branded_asins = []
        config = st.session_state.get('client_config', {})
        goals = config.get('goals', {}) if config else {}
        branded_target = goals.get('branded_acos')
        non_branded_target = goals.get('non_branded_acos')
    
        if config:
            branded_asins = config.get('branded_asins_data', [])

        # Create the tabs
        match_tabs = st.tabs(["All", "Branded", "Non-Branded"])

        # All
        with match_tabs[0]:
            all_df = pd.concat([branded_targets_df, non_branded_targets_df], ignore_index=True)
            if not all_df.empty and match_type_col in all_df.columns:
                # Normalize match types before grouping
                normalized_df = normalize_match_types(all_df)
                # Split SD Product Target into Remarketing types
                normalized_df = split_sd_product_target_remarketing(normalized_df, branded_asins)
                # Calculate account totals for percentage calculations
                all_total_spend = normalized_df['Spend'].sum()
                all_total_sales = normalized_df['Sales'].sum()
                mt_all = normalized_df.groupby(match_type_col).apply(lambda x: kpi_agg(x, all_total_spend, all_total_sales), include_groups=False).reset_index()
                expected_match_types = [
                    "Exact", "Phrase", "Broad", "Auto", "Product Target", "Category Targeting",
                    "Remarketing - Branded", "Remarketing - Competitor"
                ]
                mt_all = mt_all.set_index(match_type_col)
                mt_all = mt_all.reindex(expected_match_types, fill_value=0).reset_index().rename(columns={"index": match_type_col})
                mt_all_fmt = format_agg_table(mt_all, index_col=match_type_col)
                # Apply ACoS styling to the All tab with account-wide target
                account_target = goals.get('account_wide_acos')
                # Calculate average ACoS if needed
                use_avg_acos = st.session_state.client_config.get('goals', {}).get('use_avg_acos_account', False)
                avg_acos = None
                if account_target is None and use_avg_acos:
                    # Calculate ACoS properly as (total spend / total sales) * 100
                    total_spend = mt_all['Spend'].sum() if 'Spend' in mt_all.columns else 0
                    total_sales = mt_all['Sales'].sum() if 'Sales' in mt_all.columns else 0
                
                    if total_sales > 0 and total_spend > 0:
                        avg_acos = (total_spend / total_sales) * 100
                        avg_acos = round(avg_acos, 1)
                    else:
                        avg_acos = None
            
                # Display the target being used
                target_to_use = None
                if account_target is not None:
                    target_to_use = float(account_target)
                elif avg_acos is not None and use_avg_acos:
                    target_to_use = float(avg_acos)
                else:
                    target_to_use = None
            
                try:
                    # Initialize sorting state if not exists
                    if 'all_targets_sort_by' not in st.session_state:
                        st.session_state.all_targets_sort_by = None
                    if 'all_targets_sort_ascending' not in st.session_state:
                        st.session_state.all_targets_sort_ascending = False
                
                    # Apply sorting if specified
                    if st.session_state.all_targets_sort_by is not None:
                        mt_all_fmt = mt_all_fmt.sort_values(
                            by=st.session_state.all_targets_sort_by,
                            ascending=st.session_state.all_targets_sort_ascending
                        )
                
                    # Display the table with ACoS styling if target is available
                    if target_to_use is not None:
                        # Log the target value for debugging
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[All Targets Display] Using ACoS target: {target_to_use}")
                        # Use the toggle value from client config for 'use_avg_as_fallback'
                        use_avg_fallback = st.session_state.client_config.get('goals', {}).get('use_avg_acos_account', False)
                    
                        # Handle sorting when clicked on column headers
                        clicked = style_acos(mt_all_fmt, target_to_use, column_config=agg_column_config, use_avg_as_fallback=use_avg_fallback)
                        if clicked and clicked.column:
                            # Toggle sorting direction if same column is clicked again
                            if st.session_state.all_targets_sort_by == clicked.column:
                                st.session_state.all_targets_sort_ascending = not st.session_state.all_targets_sort_ascending
                            else:
                                st.session_state.all_targets_sort_by = clicked.column
                                st.session_state.all_targets_sort_ascending = True
                            st.rerun()
                    else:  # target_to_use is None
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[All Targets Display - {match_type_col}] No ACoS target. Displaying table without ACoS-based colors.")
                    
                        # Create a custom column config based on the actual columns in the dataframe
                        custom_column_config = {}
                    
                        # Add Match Type column
                        custom_column_config[match_type_col] = st.column_config.TextColumn(label=match_type_col)
                    
                        # Add currency columns with dollar formatting
                        for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                            if col in mt_all_fmt.columns:
                                # Convert to numeric first
                                mt_all_fmt[col] = pd.to_numeric(mt_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
                    
                        # Add percentage columns
                        for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                            if col in mt_all_fmt.columns:
                                # Convert to numeric first (as decimal, not percentage)
                                mt_all_fmt[col] = pd.to_numeric(mt_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                                custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
                    
                        # Add ROAS as decimal
                        if 'ROAS' in mt_all_fmt.columns:
                            mt_all_fmt['ROAS'] = pd.to_numeric(mt_all_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                            custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
                    
                        # Add integer columns with comma formatting
                        for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                            if col in mt_all_fmt.columns:
                                mt_all_fmt[col] = pd.to_numeric(mt_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                                custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
                    
                        # Apply sorting if specified
                        if st.session_state.get('all_targets_sort_by') is not None:
                            sort_by_col = st.session_state.all_targets_sort_by
                            sort_ascending = st.session_state.get('all_targets_sort_ascending', False)
                            if sort_by_col in mt_all_fmt.columns:
                                try:
                                    mt_all_fmt = mt_all_fmt.sort_values(by=sort_by_col, ascending=sort_ascending)
                                except Exception as e:
                                    if 'debug_messages' in st.session_state:
                                        st.session_state.debug_messages.append(f"[ERROR] Sorting 'All' tab failed for column '{sort_by_col}': {e}. Displaying unsorted.")
                    
                        # Create a copy for numeric processing for styling
                        numeric_df = mt_all_fmt.copy()
                    
                        # Convert to numeric for styling
                        for col in numeric_df.columns:
                            if col != match_type_col:
                                numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
                    
                        # Create formatting dictionary
                        fmt_dict = {}
                        for col in numeric_df.columns:
                            if col == match_type_col:
                                continue
                            elif col == 'ROAS':
                                fmt_dict[col] = lambda x: f"{x:.2f}"
                            elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                                fmt_dict[col] = lambda x: f"{x:.2f}%"
                            elif col in ['CPC', 'AOV', 'CPA']:
                                fmt_dict[col] = lambda x: f"${x:.2f}"
                            elif col in ['Spend', 'Sales', 'Ad Sales']:
                                fmt_dict[col] = lambda x: f"${x:,.2f}"
                            else:
                                fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
                    
                        # Style the dataframe
                        styled_df = numeric_df.style.format(fmt_dict)
                    
                        # Apply color gradients to percentage columns
                        if '% of Spend' in numeric_df.columns:
                            styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                                if not pd.isna(v) else '' 
                                                                for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                        if '% of Ad Sales' in numeric_df.columns:
                            styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                                if not pd.isna(v) else '' 
                                                                for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
                    
                        # Display the styled dataframe
                        st.dataframe(styled_df, use_container_width=True, hide_index=True)
                    
                        if clicked and clicked.column:
                            # Toggle sorting direction if same column is clicked again
                            if st.session_state.all_targets_sort_by == clicked.column:
                                st.session_state.all_targets_sort_ascending = not st.session_state.all_targets_sort_ascending
                            else:
                                st.session_state.all_targets_sort_by = clicked.column
                                st.session_state.all_targets_sort_ascending = True
                            st.rerun()
                
                    # Display row count
                    st.caption(f"Total Rows: {len(mt_all_fmt)}")
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append('[All Targets Display] Successfully displayed All Targeting table.')
                except Exception as e:
                    import traceback
                    tb = traceback.format_exc()
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f"[All Targets Display Error] {e}\n{tb}")
            else:
                st.info("No targeting data by Match Type.")

        # Branded
        with match_tabs[1]:
            if not branded_targets_df.empty and match_type_col in branded_targets_df.columns:
                # Normalize match types before grouping
                normalized_df = normalize_match_types(branded_targets_df)
                normalized_df = split_sd_product_target_remarketing(normalized_df, branded_asins)
                # Calculate account totals for percentage calculations
                b_total_spend = normalized_df['Spend'].sum()
                b_total_sales = normalized_df['Sales'].sum()
                mt_b = normalized_df.groupby(match_type_col).apply(lambda x: kpi_agg(x, b_total_spend, b_total_sales), include_groups=False).reset_index()
                expected_match_types = [
                    "Exact", "Phrase", "Broad", "Auto", "Product Target", "Category Targeting",
                    "Remarketing - Branded", "Remarketing - Competitor"
                ]
                mt_b = mt_b.set_index(match_type_col)
                mt_b = mt_b.reindex(expected_match_types, fill_value=0).reset_index().rename(columns={"index": match_type_col})
                mt_b_fmt = format_agg_table(mt_b, index_col=match_type_col)
                # Calculate average ACoS if needed
                use_avg_acos = st.session_state.client_config.get('goals', {}).get('use_avg_acos_branded', False)
                avg_acos = None
                if branded_target is None and use_avg_acos:
                    # Calculate ACoS properly as (total spend / total sales) * 100
                    total_spend = mt_b['Spend'].sum() if 'Spend' in mt_b.columns else 0
                    total_sales = mt_b['Sales'].sum() if 'Sales' in mt_b.columns else 0
                
                    if total_sales > 0 and total_spend > 0:
                        avg_acos = (total_spend / total_sales) * 100
                        avg_acos = round(avg_acos, 1)
                    else:
                        avg_acos = None
            
                # Display the target being used
                target_to_use = None
                if branded_target is not None:
                    target_to_use = float(branded_target)
                    pass
                elif avg_acos is not None and use_avg_acos:
                    target_to_use = float(avg_acos)
                    st.caption(f"Using Average ACoS as Target: {target_to_use}% (no explicit target set)")
                else:
                    pass
                
                # Initialize sorting state if not exists
                if 'branded_targets_sort_by' not in st.session_state:
                    st.session_state.branded_targets_sort_by = None
                if 'branded_targets_sort_ascending' not in st.session_state:
                    st.session_state.branded_targets_sort_ascending = False
            
                # Apply sorting if specified
                if st.session_state.branded_targets_sort_by is not None:
                    mt_b_fmt = mt_b_fmt.sort_values(
                        by=st.session_state.branded_targets_sort_by,
                        ascending=st.session_state.branded_targets_sort_ascending
                    )
            
                # Create a custom column config based on the actual columns in the dataframe
                custom_column_config = {}
            
                # Add Match Type column
                custom_column_config[match_type_col] = st.column_config.TextColumn(label=match_type_col)
            
                # Add currency columns with dollar formatting
                for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                    if col in mt_b_fmt.columns:
                        # Convert to numeric first
                        mt_b_fmt[col] = pd.to_numeric(mt_b_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
            
                # Add percentage columns
                for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                    if col in mt_b_fmt.columns:
                        # Convert to numeric first (as decimal, not percentage)
                        mt_b_fmt[col] = pd.to_numeric(mt_b_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
            
                # Add ROAS as decimal
                if 'ROAS' in mt_b_fmt.columns:
                    mt_b_fmt['ROAS'] = pd.to_numeric(mt_b_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                    custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
            
                # Add integer columns with comma formatting
                for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                    if col in mt_b_fmt.columns:
                        mt_b_fmt[col] = pd.to_numeric(mt_b_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
            
                # Create a copy for numeric processing for styling
                numeric_df = mt_b_fmt.copy()
            
                # Convert to numeric for styling
                for col in numeric_df.columns:
                    if col != match_type_col:
                        numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
            
                # Create formatting dictionary
                fmt_dict = {}
                for col in numeric_df.columns:
                    if col == match_type_col:
                        continue
                    elif col == 'ROAS':
                        fmt_dict[col] = lambda x: f"{x:.2f}"
                    elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    elif col in ['CPC', 'AOV', 'CPA']:
                        fmt_dict[col] = lambda x: f"${x:.2f}"
                    elif col in ['Spend', 'Sales', 'Ad Sales']:
                        fmt_dict[col] = lambda x: f"${x:,.2f}"
                    else:
                        fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
            
                # Style the dataframe
                styled_df = numeric_df.style.format(fmt_dict)
            
                # Apply color gradients to percentage columns
                if '% of Spend' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                if '% of Ad Sales' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                # Apply ACoS styling if target is available
                if target_to_use is not None:
                    # Log the target value for debugging
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f"[Branded Targets Display] Using ACoS target: {target_to_use}")
                    # Use the toggle value from client config for 'use_avg_as_fallback'
                    use_avg_fallback = st.session_state.client_config.get('goals', {}).get('use_avg_acos_branded', False)
                    styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', target_to_use, use_avg_fallback)
            
                # Display the styled dataframe
                st.dataframe(styled_df, use_container_width=True, hide_index=True)
            
                # Display row count
                st.caption(f"Total Rows: {len(mt_b_fmt)}")

            else:
                st.info("No Branded targeting data by Match Type.")

        # Non-Branded
        with match_tabs[2]:
            if not non_branded_targets_df.empty and match_type_col in non_branded_targets_df.columns:
                # Normalize match types before grouping
                normalized_df = normalize_match_types(non_branded_targets_df)
                normalized_df = split_sd_product_target_remarketing(normalized_df, branded_asins)
                # Calculate account totals for percentage calculations
                nb_total_spend = normalized_df['Spend'].sum()
                nb_total_sales = normalized_df['Sales'].sum()
                mt_nb = normalized_df.groupby(match_type_col).apply(lambda x: kpi_agg(x, nb_total_spend, nb_total_sales), include_groups=False).reset_index()
                expected_match_types = [
                    "Exact", "Phrase", "Broad", "Auto", "Product Target", "Category Targeting",
                    "Remarketing - Branded", "Remarketing - Competitor"
                ]
                mt_nb = mt_nb.set_index(match_type_col)
                mt_nb = mt_nb.reindex(expected_match_types, fill_value=0).reset_index().rename(columns={"index": match_type_col})
                mt_nb_fmt = format_agg_table(mt_nb, index_col=match_type_col)
                # Calculate average ACoS if needed
                use_avg_acos = st.session_state.client_config.get('goals', {}).get('use_avg_acos_nonbranded', False)
                avg_acos = None
                if non_branded_target is None and use_avg_acos:
                    # Calculate ACoS properly as (total spend / total sales) * 100
                    total_spend = mt_nb['Spend'].sum() if 'Spend' in mt_nb.columns else 0
                    total_sales = mt_nb['Sales'].sum() if 'Sales' in mt_nb.columns else 0
                
                    if total_sales > 0 and total_spend > 0:
                        avg_acos = (total_spend / total_sales) * 100
                        avg_acos = round(avg_acos, 1)
                    else:
                        avg_acos = None
            
                # Display the target being used
                target_to_use = None
                if non_branded_target is not None:
                    target_to_use = float(non_branded_target)
                    pass
                elif avg_acos is not None and use_avg_acos:
                    target_to_use = float(avg_acos)
                    st.caption(f"Using Average ACoS as Target: {target_to_use}% (no explicit target set)")
                else:
                    pass
                
                # Initialize sorting state if not exists
                if 'non_branded_targets_sort_by' not in st.session_state:
                    st.session_state.non_branded_targets_sort_by = None
                if 'non_branded_targets_sort_ascending' not in st.session_state:
                    st.session_state.non_branded_targets_sort_ascending = False
            
                # Apply sorting if specified
                if st.session_state.non_branded_targets_sort_by is not None:
                    mt_nb_fmt = mt_nb_fmt.sort_values(
                        by=st.session_state.non_branded_targets_sort_by,
                        ascending=st.session_state.non_branded_targets_sort_ascending
                    )
                
                try:
                    # Create a custom column config based on the actual columns in the dataframe
                    custom_column_config = {}
                
                    # Add Match Type column
                    custom_column_config[match_type_col] = st.column_config.TextColumn(label=match_type_col)
                
                    # Add currency columns with dollar formatting
                    for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                        if col in mt_nb_fmt.columns:
                            # Convert to numeric first
                            mt_nb_fmt[col] = pd.to_numeric(mt_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                            custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
                
                    # Add percentage columns
                    for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        if col in mt_nb_fmt.columns:
                            # Convert to numeric first (as decimal, not percentage)
                            mt_nb_fmt[col] = pd.to_numeric(mt_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                            custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
                
                    # Add ROAS as decimal
                    if 'ROAS' in mt_nb_fmt.columns:
                        mt_nb_fmt['ROAS'] = pd.to_numeric(mt_nb_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
                
                    # Add integer columns with comma formatting
                    for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                        if col in mt_nb_fmt.columns:
                            mt_nb_fmt[col] = pd.to_numeric(mt_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                            custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
                
                    # Create a copy for numeric processing for styling
                    numeric_df = mt_nb_fmt.copy()
                
                    # Convert to numeric for styling
                    for col in numeric_df.columns:
                        if col != match_type_col:
                            numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
                
                    # Create formatting dictionary
                    fmt_dict = {}
                    for col in numeric_df.columns:
                        if col == match_type_col:
                            continue
                        elif col == 'ROAS':
                            fmt_dict[col] = lambda x: f"{x:.2f}"
                        elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                            fmt_dict[col] = lambda x: f"{x:.2f}%"
                        elif col in ['CPC', 'AOV', 'CPA']:
                            fmt_dict[col] = lambda x: f"${x:.2f}"
                        elif col in ['Spend', 'Sales', 'Ad Sales']:
                            fmt_dict[col] = lambda x: f"${x:,.2f}"
                        else:
                            fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
                
                    # Style the dataframe
                    styled_df = numeric_df.style.format(fmt_dict)
                
                    # Apply color gradients to percentage columns
                    if '% of Spend' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                    if '% of Ad Sales' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
                
                    # Apply ACoS styling if target is available
                    if target_to_use is not None:
                        # Log the target value for debugging
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f"[Non-Branded Targets Display] Using ACoS target: {target_to_use}")
                        # Use the toggle value from client config for 'use_avg_as_fallback'
                        use_avg_fallback = st.session_state.client_config.get('goals', {}).get('use_avg_acos_nonbranded', False)
                        styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', target_to_use, use_avg_fallback)
                
                    # Display the styled dataframe
                    st.dataframe(styled_df, use_container_width=True, hide_index=True)
                
                    # Display row count
                    st.caption(f"Total Rows: {len(mt_nb_fmt)}")
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append('[Non-Branded Targets Display] Successfully displayed Non-Branded Targeting table.')
                except Exception as e:
                    import traceback
                    tb = traceback.format_exc()
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f"[Non-Branded Targets Display Error] {e}\n{tb}")
            else:
                st.info("No Non-Branded targeting data by Match Type.")

            # --- Pie Charts for Targeting by Match Type (All, Non-Branded, Branded) ---
            def display_match_type_pies(df, label, debug_key):
                if not df.empty and match_type_col in df.columns:
                    # Removed header text as requested
                    total_spend = df['Spend'].sum()
                    total_sales = df['Ad Sales'].sum() if 'Ad Sales' in df.columns else df['Sales'].sum() if 'Sales' in df.columns else 0

                    # Remove match types with 0 value from pie charts for all tabs
                    filtered_df = df.copy()
                    # Remove rows where both Spend and Sales/Ad Sales are 0
                    sales_col = 'Ad Sales' if 'Ad Sales' in filtered_df.columns else 'Sales'
                    filtered_df = filtered_df[(filtered_df['Spend'] > 0) & (filtered_df[sales_col] > 0)]

                    # Create a consistent color mapping for match types
                    # This ensures the same match type always gets the same color across all charts
                    match_types = filtered_df[match_type_col].unique()

                    # Define a fixed color mapping for common match types
                    color_mapping = {
                        'Product Target': '#66C2A5',  # Teal
                        'Exact': '#FFCC66',          # Yellow
                        'Broad': '#FC8D62',          # Orange
                        'Auto': '#8DA0CB',           # Blue
                        'Phrase': '#E78AC3',         # Pink
                        'Category Targeting': '#A6D854',  # Green
                        'Remarketing - Branded': '#FFD92F',  # Gold
                        'Remarketing - Competitor': '#E5C494',  # Tan
                    }

                    # Create a color sequence based on the match types in this dataset
                    colors = []
                    for match_type in match_types:
                        if match_type in color_mapping:
                            colors.append(color_mapping[match_type])
                        else:
                            # Fallback to a default color if not in mapping
                            colors.append('#B3B3B3')  # Gray

                    col1, col2 = st.columns(2)
                    with col1:
                        fig_spend = px.pie(
                            filtered_df,
                            names=match_type_col,
                            values='Spend',
                            title='% of Total Spend by Match Type',
                            color=match_type_col,
                            color_discrete_map=color_mapping
                        )
                        fig_spend.update_traces(textinfo='percent+label', pull=[0.05]*len(filtered_df))
                        st.plotly_chart(fig_spend, use_container_width=True, key=f"{label}_spend_pie")
                    with col2:
                        fig_sales = px.pie(
                            filtered_df,
                            names=match_type_col,
                            values='Ad Sales' if 'Ad Sales' in filtered_df.columns else 'Sales',
                            title='% of Total Ad Sales by Match Type',
                            color=match_type_col,
                            color_discrete_map=color_mapping
                        )
                        fig_sales.update_traces(textinfo='percent+label', pull=[0.05]*len(filtered_df))
                        st.plotly_chart(fig_sales, use_container_width=True, key=f"{label}_sales_pie")
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[{debug_key}] Displayed pie charts for {label} Match Type.')

            # Pie charts for each tab
            with match_tabs[0]:  # All tab
                if 'mt_all' in locals():
                    display_match_type_pies(mt_all, 'All', 'All Match Type Charts')
            with match_tabs[1]:  # Branded tab
                if 'mt_b' in locals():
                    display_match_type_pies(mt_b, 'Branded', 'Branded Match Type Charts')
            with match_tabs[2]:  # Non-Branded tab
                if 'mt_nb' in locals():
                    display_match_type_pies(mt_nb, 'Non-Branded', 'Non-Branded Match Type Charts')

            # --- 2. Ad Type Aggregation ---
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<div style='margin-top:30px;'></div>", unsafe_allow_html=True)
        st.markdown('#### Targeting by Ad Type')
    
        # Extract product groups from campaign names
        product_groups_from_campaigns = set()
    
        # Initialize session state for product group filter if not exists
        if 'adtype_product_group_filter' not in st.session_state:
            st.session_state.adtype_product_group_filter = []
        if 'adtype_filter_active' not in st.session_state:
            st.session_state.adtype_filter_active = False
        
        # Extract product groups from campaign names in bulk data
        if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
            for sheet_name, df in st.session_state.bulk_data.items():
                # Look for Campaign Name column in different formats
                campaign_col = None
                for col in df.columns:
                    if col in ['Campaign Name (Informational Only)', 'Campaign Name']:
                        campaign_col = col
                        break
            
                if campaign_col and not df.empty:
                    # Extract product groups from campaign names using client configuration
                    if st.session_state.get('client_config') and 'campaign_tags_data' in st.session_state.client_config:
                        for campaign_name in df[campaign_col].dropna().unique():
                            # Check if this campaign is in the client config
                            campaign_key = campaign_name.strip().upper()
                            if campaign_key in st.session_state.client_config['campaign_tags_data']:
                                product_group = st.session_state.client_config['campaign_tags_data'][campaign_key].get('tag_1', '') or 'Untagged Group'
                                if product_group and product_group.strip():
                                    product_groups_from_campaigns.add(product_group)
    
        # Add product groups from client configuration as well
        if st.session_state.get('client_config') and 'campaign_tags_data' in st.session_state.client_config:
            for campaign_info in st.session_state.client_config['campaign_tags_data'].values():
                product_group = campaign_info.get('tag_1', '') or 'Untagged Group'
                if product_group and product_group.strip():
                    product_groups_from_campaigns.add(product_group)
    
        # Sort product groups for consistent display
        product_groups_from_campaigns = sorted(list(product_groups_from_campaigns))
    
        # Create filter row with product group dropdown
        filter_col1, filter_col2 = st.columns([0.3, 0.7])
        with filter_col1:
            if product_groups_from_campaigns:
                selected_product_groups = st.multiselect(
                    "Filter by Product Group(s):",
                    options=product_groups_from_campaigns,
                    key="adtype_product_group_filter"
                )
                st.session_state.adtype_filter_active = len(selected_product_groups) > 0
    
        # Create tabs for All, Branded, Non-Branded
        adtype_tabs = st.tabs(["All", "Branded", "Non-Branded"])
    
        # Define the expected ad types for consistent display
        expected_ad_types = ["Sponsored Products", "Sponsored Brands", "Sponsored Display"]
    
        # Function to create and display the ad type table and charts for the selected tab
        def display_ad_type_tab(tab_index, tab_name, df):
            with adtype_tabs[tab_index]:
                if 'Product' in df.columns:
                    # Calculate totals for percentage calculations
                    total_spend = df['Spend'].sum() if 'Spend' in df.columns else 0
                    total_sales = df['Sales'].sum() if 'Sales' in df.columns else 0
                
                    # Aggregate data by Product
                    ad_df = df.groupby('Product').apply(lambda x: kpi_agg(x, total_spend, total_sales), include_groups=False).reset_index() if not df.empty else pd.DataFrame(columns=['Product'])
                
                    # Debug the dataframe structure
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f"[Ad Type Debug] DataFrame before reindexing: {ad_df.shape}, Columns: {list(ad_df.columns)}")
                        if not ad_df.empty and 'Product' in ad_df.columns:
                            st.session_state.debug_messages.append(f"[Ad Type Debug] Product values: {ad_df['Product'].tolist()}")
                
                    # Create a fresh DataFrame with all expected ad types if empty
                    if ad_df.empty:
                        # Create a DataFrame with all expected ad types and zero values for all metrics
                        ad_df = pd.DataFrame({
                            'Product': expected_ad_types,
                            'Spend': [0, 0, 0],
                            'Ad Sales': [0, 0, 0],
                            '% of Spend': [0, 0, 0],
                            '% of Ad Sales': [0, 0, 0],
                            'ACoS': [0, 0, 0],
                            'ROAS': [0, 0, 0],
                            'CPC': [0, 0, 0],
                            'CVR': [0, 0, 0],
                            'CTR': [0, 0, 0],
                            'AOV': [0, 0, 0],
                            'CPA': [0, 0, 0],
                            'Impressions': [0, 0, 0],
                            'Clicks': [0, 0, 0],
                            'Orders': [0, 0, 0],
                            'Units Sold': [0, 0, 0]
                        })
                    else:
                        # Check if we have all expected ad types
                        existing_products = set(ad_df['Product'].tolist()) if 'Product' in ad_df.columns else set()
                        missing_products = set(expected_ad_types) - existing_products
                    
                        # If we're missing any ad types, add them with zero values
                        if missing_products:
                            # Get column names from existing DataFrame
                            columns = ad_df.columns.tolist()
                        
                            # Create rows for missing products
                            for product in missing_products:
                                new_row = {col: 0 for col in columns}
                                new_row['Product'] = product
                                ad_df = pd.concat([ad_df, pd.DataFrame([new_row])], ignore_index=True)
                    
                        # Sort to ensure consistent order
                        ad_df = ad_df.sort_values('Product', key=lambda x: pd.Categorical(
                            x, categories=expected_ad_types, ordered=True
                        )).reset_index(drop=True)
                    ad_df_fmt = format_agg_table(ad_df, index_col='Product')
                
                    # Create a custom column config based on the actual columns in the dataframe
                    custom_column_config = {}
                
                    # Add Product column
                    custom_column_config['Product'] = st.column_config.TextColumn(label="Product")
                
                    # Add currency columns with dollar formatting
                    for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                        if col in ad_df_fmt.columns:
                            # Convert to numeric first
                            ad_df_fmt[col] = pd.to_numeric(ad_df_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                            custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
                
                    # Add percentage columns
                    for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        if col in ad_df_fmt.columns:
                            # Convert to numeric first (as decimal, not percentage)
                            ad_df_fmt[col] = pd.to_numeric(ad_df_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                            custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
                
                    # Add ROAS as decimal
                    if 'ROAS' in ad_df_fmt.columns:
                        ad_df_fmt['ROAS'] = pd.to_numeric(ad_df_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
                
                    # Add integer columns with comma formatting
                    for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                        if col in ad_df_fmt.columns:
                            ad_df_fmt[col] = pd.to_numeric(ad_df_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                            custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
                
                    # ACoS target display
                    # Use the toggle value from client config for 'use_avg_as_fallback'
                    use_avg_fallback = goals.get('use_avg_acos_account', False)
                    account_target = goals.get('account_wide_acos')
                
                    # Create a copy for numeric processing
                    numeric_df = ad_df_fmt.copy()
                
                    # Convert formatted values to numeric for proper sorting
                    for col in numeric_df.columns:
                        if col not in ['Product']:
                            numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
                
                    # Create formatting dictionary
                    fmt_dict = {}
                    for col in numeric_df.columns:
                        if col == 'Product':
                            continue
                        elif col in ['ACoS', 'TACoS', 'CVR', 'CTR']:
                            fmt_dict[col] = lambda x: f"{x:.2f}%"
                        elif col == 'ROAS':
                            fmt_dict[col] = lambda x: f"{x:.2f}"
                        elif col in ['CPC', 'AOV', 'CPA']:
                            fmt_dict[col] = lambda x: f"${x:.2f}"
                        elif col in ['Spend', 'Sales', 'Ad Sales']:
                            fmt_dict[col] = lambda x: f"${x:,.2f}"
                        elif col in ['% of Spend', '% of Ad Sales']:
                            fmt_dict[col] = lambda x: f"{x:.2f}%"
                        else:
                            fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
                
                    # Style the dataframe
                    styled_df = numeric_df.style.format(fmt_dict)
                
                    # Apply color gradients to percentage columns
                    if '% of Spend' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                    if '% of Ad Sales' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
                
                    # Apply ACoS styling if target is available
                    if account_target is not None:
                        # Apply ACoS styling to the ACoS column only
                        acos_col_idx = numeric_df.columns.get_loc('ACoS') if 'ACoS' in numeric_df.columns else None
                        if acos_col_idx is not None:
                            styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', account_target, use_avg_fallback)
                
                    # Display the dataframe with sorting enabled
                    st.dataframe(styled_df, use_container_width=True, hide_index=True)
                
                    # Add bar charts
                    if not df.empty and 'Product' in df.columns:
                        # Add filter indicator if filter is active
                        if st.session_state.adtype_filter_active:
                            st.caption(f"Filtered by Product Group: {', '.join(st.session_state.adtype_product_group_filter)}")
                    
                        col1, col2 = st.columns(2)
                    
                        with col1:
                            # Spend chart
                            # Calculate percentages of total spend
                            total_spend = ad_df['Spend'].sum()
                            ad_df['Spend_Pct'] = ad_df['Spend'] / total_spend * 100 if total_spend > 0 else 0
                        
                            # Create custom text with dollar amount and percentage
                            ad_df['Spend_Text'] = ad_df.apply(
                                lambda row: f"${row['Spend']:,.2f} ({row['Spend_Pct']:.1f}%)", 
                                axis=1
                            )
                        
                            fig_spend = px.bar(
                                ad_df, 
                                x='Product', 
                                y='Spend',
                                title='Spend by Ad Type',
                                color_discrete_sequence=['#1f77b4'],  # Blue color for spend charts
                                text='Spend_Text'  # Use our custom text column
                            )
                            fig_spend.update_layout(
                                xaxis_title='Ad Type',
                                yaxis_title='Spend',
                                height=500,
                                margin=dict(l=50, r=50, t=80, b=80),
                                autosize=True
                            )
                            fig_spend.update_traces(textposition='outside')
                            # Ensure y-axis has enough room for labels
                            fig_spend.update_yaxes(automargin=True, tickformat='$,.0f')
                            st.plotly_chart(fig_spend, use_container_width=True, key=f"adtype_spend_chart_{tab_name}_{tab_index}")
                        
                        with col2:
                            # Ad Sales chart
                            # Calculate percentages of total sales
                            total_sales = ad_df['Ad Sales'].sum()
                            ad_df['Sales_Pct'] = ad_df['Ad Sales'] / total_sales * 100 if total_sales > 0 else 0
                        
                            # Create custom text with dollar amount and percentage
                            ad_df['Sales_Text'] = ad_df.apply(
                                lambda row: f"${row['Ad Sales']:,.2f} ({row['Sales_Pct']:.1f}%)", 
                                axis=1
                            )
                        
                            fig_sales = px.bar(
                                ad_df, 
                                x='Product', 
                                y='Ad Sales',
                                title='Ad Sales by Ad Type',
                                color_discrete_sequence=['#10b981'],  # Green color for sales charts
                                text='Sales_Text'  # Use our custom text column
                            )
                            fig_sales.update_layout(
                                xaxis_title='Ad Type',
                                yaxis_title='Sales ($)',
                                height=500,
                                margin=dict(l=50, r=50, t=80, b=80),
                                autosize=True
                            )
                            fig_sales.update_traces(textposition='outside')
                            fig_sales.update_yaxes(automargin=True, tickformat='$,.0f')
                            st.plotly_chart(fig_sales, use_container_width=True, key=f"adtype_sales_chart_{tab_name}_{tab_index}")
                else:
                    st.info(f"No {tab_name} targeting data by Ad Type (missing 'Product' column).")
    
        # Helper to infer ad type if not present
        def infer_ad_type(df):
            if 'Product' in df.columns and df['Product'].notna().any() and (df['Product'] != '').any():
                return df
            
            # Try to infer from Sheet Source or Campaign Type
            df = df.copy()
        
            # First, check if we can infer from Sheet Source
            if 'Sheet Source' in df.columns:
                def _adtype_from_sheet(row):
                    s = str(row['Sheet Source']).lower()
                    if 'sponsored products' in s:
                        return 'Sponsored Products'
                    elif 'sponsored brands' in s:
                        return 'Sponsored Brands'
                    elif 'sponsored display' in s:
                        return 'Sponsored Display'
                    return 'Unknown'
                df['Product'] = df.apply(_adtype_from_sheet, axis=1)
        
            # If we still don't have valid Product values, try to infer from Campaign Type
            if 'Product' not in df.columns or not df['Product'].notna().any() or (df['Product'] == '').all() or (df['Product'] == 'Unknown').all():
                if 'Campaign Type' in df.columns:
                    def _adtype_from_campaign_type(row):
                        ct = str(row['Campaign Type']).lower()
                        if 'product' in ct or 'sp' in ct or 'sponsored product' in ct:
                            return 'Sponsored Products'
                        elif 'brand' in ct or 'sb' in ct or 'sponsored brand' in ct:
                            return 'Sponsored Brands'
                        elif 'display' in ct or 'sd' in ct or 'sponsored display' in ct:
                            return 'Sponsored Display'
                        return 'Unknown'
                    df['Product'] = df.apply(_adtype_from_campaign_type, axis=1)
        
            # Last resort: try to infer from Campaign Name
            if 'Product' not in df.columns or not df['Product'].notna().any() or (df['Product'] == '').all() or (df['Product'] == 'Unknown').all():
                campaign_col = None
                for col in df.columns:
                    if col in ['Campaign Name (Informational Only)', 'Campaign Name', 'Campaign']:
                        campaign_col = col
                        break
                    
                if campaign_col:
                    def _adtype_from_campaign(row):
                        campaign = str(row[campaign_col]).lower()
                        if 'sp' in campaign.split() or 'sp|' in campaign or '| sp' in campaign or 'sponsored product' in campaign:
                            return 'Sponsored Products'
                        elif 'sb' in campaign.split() or 'sb|' in campaign or '| sb' in campaign or 'sponsored brand' in campaign:
                            return 'Sponsored Brands'
                        elif 'sd' in campaign.split() or 'sd|' in campaign or '| sd' in campaign or 'sponsored display' in campaign:
                            return 'Sponsored Display'
                        return 'Unknown'
                    df['Product'] = df.apply(_adtype_from_campaign, axis=1)
                
            if 'debug_messages' in st.session_state and not df.empty:
                product_counts = df['Product'].value_counts().to_dict()
                st.session_state.debug_messages.append(f"[Ad Type Inference] Product column distribution: {product_counts}")
            
            return df
        
        # Process data outside of tabs to avoid duplication
        # First normalize match types, then infer ad type
        all_df = pd.concat([branded_targets_df, non_branded_targets_df], ignore_index=True)
        normalized_df = normalize_match_types(all_df)
        # Guarantee 'Product' column exists
        if 'Product' not in normalized_df.columns:
            normalized_df['Product'] = ''
        all_ad = infer_ad_type(normalized_df)
    
        # Create separate dataframes for branded and non-branded ads
        b_normalized_df = normalize_match_types(branded_targets_df)
        nb_normalized_df = normalize_match_types(non_branded_targets_df)
    
        # Ensure 'Product' column exists in both dataframes
        if 'Product' not in b_normalized_df.columns:
            b_normalized_df['Product'] = ''
        if 'Product' not in nb_normalized_df.columns:
            nb_normalized_df['Product'] = ''
        
        # Create ad type dataframes
        b_ad = infer_ad_type(b_normalized_df)
        nb_ad = infer_ad_type(nb_normalized_df)
    
        # Debug the product distribution
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append(f"[Ad Type Debug] All Ad Types: {all_ad['Product'].unique().tolist() if 'Product' in all_ad.columns else 'No Product column'}")
            st.session_state.debug_messages.append(f"[Ad Type Debug] Branded Ad Types: {b_ad['Product'].unique().tolist() if 'Product' in b_ad.columns else 'No Product column'}")
            st.session_state.debug_messages.append(f"[Ad Type Debug] Non-Branded Ad Types: {nb_ad['Product'].unique().tolist() if 'Product' in nb_ad.columns else 'No Product column'}")
    
        # Force inclusion of all expected ad types in each dataframe
        # For all ads
        for ad_type in expected_ad_types:
            if 'Product' not in all_ad.columns or ad_type not in all_ad['Product'].unique():
                # Create a dummy row with the missing ad type
                dummy_row = {col: 0 for col in all_ad.columns} if not all_ad.empty else {'Spend': 0, 'Sales': 0}
                dummy_row['Product'] = ad_type
                all_ad = pd.concat([all_ad, pd.DataFrame([dummy_row])], ignore_index=True)
    
        # For branded ads
        for ad_type in expected_ad_types:
            if 'Product' not in b_ad.columns or ad_type not in b_ad['Product'].unique():
                # Create a dummy row with the missing ad type
                dummy_row = {col: 0 for col in b_ad.columns} if not b_ad.empty else {'Spend': 0, 'Sales': 0}
                dummy_row['Product'] = ad_type
                b_ad = pd.concat([b_ad, pd.DataFrame([dummy_row])], ignore_index=True)
    
        # For non-branded ads
        for ad_type in expected_ad_types:
            if 'Product' not in nb_ad.columns or ad_type not in nb_ad['Product'].unique():
                # Create a dummy row with the missing ad type
                dummy_row = {col: 0 for col in nb_ad.columns} if not nb_ad.empty else {'Spend': 0, 'Sales': 0}
                dummy_row['Product'] = ad_type
                nb_ad = pd.concat([nb_ad, pd.DataFrame([dummy_row])], ignore_index=True)
    
        # Apply product group filter if active
        if st.session_state.adtype_filter_active and len(st.session_state.adtype_product_group_filter) > 0:
            # Find campaign column
            campaign_col = None
            for col in all_ad.columns:
                if col in ['Campaign Name (Informational Only)', 'Campaign Name', 'Campaign']:
                    campaign_col = col
                    break
        
            if campaign_col:
                # Create a filtered version of the dataframe based on product groups
                filtered_all_ad = all_ad.copy()
                filtered_b_ad = b_ad.copy()
                filtered_nb_ad = nb_ad.copy()
            
                # Get list of campaigns that match the selected product groups
                matching_campaigns = set()
            
                for campaign_name, info in st.session_state.client_config.get('campaign_tags_data', {}).items():
                    product_group = info.get('tag_1', '') or 'Untagged Group'
                    if product_group in st.session_state.adtype_product_group_filter:
                        matching_campaigns.add(campaign_name.upper())
            
                # Apply filtering only if we found matching campaigns
                if matching_campaigns:
                    # Filter the All dataframe
                    if campaign_col in filtered_all_ad.columns:
                        filtered_all_ad = filtered_all_ad[filtered_all_ad[campaign_col].astype(str).str.upper().isin(matching_campaigns)]
                
                    # Filter the Branded dataframe
                    if campaign_col in filtered_b_ad.columns:
                        filtered_b_ad = filtered_b_ad[filtered_b_ad[campaign_col].astype(str).str.upper().isin(matching_campaigns)]
                
                    # Filter the Non-Branded dataframe
                    if campaign_col in filtered_nb_ad.columns:
                        filtered_nb_ad = filtered_nb_ad[filtered_nb_ad[campaign_col].astype(str).str.upper().isin(matching_campaigns)]
            
                # Use the filtered dataframes only if they're not empty
                all_ad = filtered_all_ad if not filtered_all_ad.empty else all_ad
                b_ad = filtered_b_ad if not filtered_b_ad.empty else b_ad
                nb_ad = filtered_nb_ad if not filtered_nb_ad.empty else nb_ad
            
                # Add debug message if no matching rows
                if all_ad.empty and 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f"[Product Group Filter] No campaigns found matching selected product groups: {', '.join(st.session_state.adtype_product_group_filter)}")
    
        # Display each tab with its corresponding data
        display_ad_type_tab(0, "All", all_ad)
        display_ad_type_tab(1, "Branded", b_ad)
        display_ad_type_tab(2, "Non-Branded", nb_ad)
    
        # Display filter indicator if filter is active
        if st.session_state.adtype_filter_active:
            st.caption(f"Filtered by Product Group: {', '.join(st.session_state.adtype_product_group_filter)}")
        # Function to create and display the ad type table and charts for the selected tab
        def display_ad_type_data(tab_name):
            # Get the appropriate dataframe based on the selected tab
            df = ad_type_data[tab_name]
        
            if 'Product' in df.columns:
                # Calculate totals for percentage calculations
                total_spend = df['Spend'].sum() if 'Spend' in df.columns else 0
                total_sales = df['Sales'].sum() if 'Sales' in df.columns else 0
            
                # Aggregate data by Product
                ad_df = df.groupby('Product').apply(lambda x: kpi_agg(x, total_spend, total_sales), include_groups=False).reset_index() if not df.empty else pd.DataFrame(columns=['Product'])
                ad_df = ad_df.set_index('Product') if not ad_df.empty else pd.DataFrame(index=expected_ad_types)
                ad_df = ad_df.reindex(expected_ad_types, fill_value=0).reset_index().rename(columns={"index": 'Product'})
                ad_df_fmt = format_agg_table(ad_df, index_col='Product')
            
                # Create a custom column config based on the actual columns in the dataframe
                custom_column_config = {}
            
                # Add Product column
                custom_column_config['Product'] = st.column_config.TextColumn(label="Product")
            
                # Add currency columns with dollar formatting
                for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                    if col in ad_all_fmt.columns:
                        # Convert to numeric first
                        ad_all_fmt[col] = pd.to_numeric(ad_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
            
                # Add percentage columns
                for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                    if col in ad_all_fmt.columns:
                        # Convert to numeric first (as decimal, not percentage)
                        ad_all_fmt[col] = pd.to_numeric(ad_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
            
                # Add ROAS as decimal
                if 'ROAS' in ad_all_fmt.columns:
                    ad_all_fmt['ROAS'] = pd.to_numeric(ad_all_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                    custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
            
                # Add integer columns with comma formatting
                for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                    if col in ad_all_fmt.columns:
                        ad_all_fmt[col] = pd.to_numeric(ad_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
            
                # ACoS target display removed
                # Use the toggle value from client config for 'use_avg_as_fallback'
                use_avg_fallback = goals.get('use_avg_acos_account', False)
                account_target = goals.get('account_wide_acos')
            
                # Create a copy for numeric processing
                numeric_df = ad_all_fmt.copy()
            
                # Convert formatted values to numeric for proper sorting
                for col in numeric_df.columns:
                    if col not in ['Product']:
                        numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
            
                # Create formatting dictionary
                fmt_dict = {}
                for col in numeric_df.columns:
                    if col == 'Product':
                        continue
                    elif col in ['ACoS', 'TACoS', 'CVR', 'CTR']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    elif col == 'ROAS':
                        fmt_dict[col] = lambda x: f"{x:.2f}"
                    elif col in ['CPC', 'AOV', 'CPA']:
                        fmt_dict[col] = lambda x: f"${x:.2f}"
                    elif col in ['Spend', 'Sales', 'Ad Sales']:
                        fmt_dict[col] = lambda x: f"${x:,.2f}"
                    elif col in ['% of Spend', '% of Ad Sales']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    else:
                        fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
            
                # Style the dataframe
                styled_df = numeric_df.style.format(fmt_dict)
            
                # Apply color gradients to percentage columns
                if '% of Spend' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                if '% of Ad Sales' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                # Apply ACoS styling if target is available
                if account_target is not None:
                    # Apply ACoS styling to the ACoS column only
                    acos_col_idx = numeric_df.columns.get_loc('ACoS') if 'ACoS' in numeric_df.columns else None
                    if acos_col_idx is not None:
                        styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', account_target, use_avg_fallback)
            
                # Display the dataframe with sorting enabled
                st.dataframe(styled_df, use_container_width=True, hide_index=True)
            else:
                st.info("No targeting data by Ad Type (missing 'Product' column).")
        
            # Add bar charts for All Ad Type
            if not all_ad.empty and 'Product' in all_ad.columns:
                # Add filter indicator if filter is active
                if st.session_state.adtype_filter_active:
                    st.caption(f"Filtered by Product Group: {st.session_state.adtype_product_group_filter}")
                # Removed header text as requested
                col1, col2 = st.columns(2)
            
                with col1:
                    # Spend chart
                    # Calculate percentages of total spend
                    total_spend = ad_all['Spend'].sum()
                    ad_all['Spend_Pct'] = ad_all['Spend'] / total_spend * 100 if total_spend > 0 else 0
                
                    # Create custom text with dollar amount and percentage
                    ad_all['Spend_Text'] = ad_all.apply(
                        lambda row: f"${row['Spend']:,.2f} ({row['Spend_Pct']:.1f}%)", 
                        axis=1
                    )
                
                    fig_spend = px.bar(
                        ad_all, 
                        x='Product', 
                        y='Spend',
                        title='Spend by Ad Type',
                        color_discrete_sequence=['#1f77b4'],  # Blue color for spend charts
                        text='Spend_Text'  # Use our custom text column
                    )
                    fig_spend.update_layout(
                        xaxis_title='Ad Type',
                        yaxis_title='Spend',
                        height=500,
                        margin=dict(l=50, r=50, t=80, b=80),
                        autosize=True
                    )
                    fig_spend.update_traces(textposition='outside')
                    # Ensure y-axis has enough room for labels
                    fig_spend.update_yaxes(automargin=True, tickformat='$,.0f')
                    st.plotly_chart(fig_spend, use_container_width=True)
                
                with col2:
                    # Ad Sales chart
                    # Calculate percentages of total sales
                    total_sales = ad_all['Ad Sales'].sum()
                    ad_all['Sales_Pct'] = ad_all['Ad Sales'] / total_sales * 100 if total_sales > 0 else 0
                
                    # Create custom text with dollar amount and percentage
                    ad_all['Sales_Text'] = ad_all.apply(
                        lambda row: f"${row['Ad Sales']:,.2f} ({row['Sales_Pct']:.1f}%)", 
                        axis=1
                    )
                
                    fig_sales = px.bar(
                        ad_all, 
                        x='Product', 
                        y='Ad Sales',
                        title='Ad Sales by Ad Type',
                        color_discrete_sequence=['#10b981'],  # Green color for sales charts
                        text='Sales_Text'  # Use our custom text column
                    )
                    fig_sales.update_layout(
                        xaxis_title='Ad Type',
                        yaxis_title='Sales ($)',
                        height=500,
                        margin=dict(l=50, r=50, t=80, b=80),
                        autosize=True
                    )
                    fig_sales.update_traces(textposition='outside')
                    fig_sales.update_yaxes(automargin=True, tickformat='$,.0f')
                    st.plotly_chart(fig_sales, use_container_width=True)
            
                # Calculate account totals for percentage calculations
                nb_ad_total_spend = nb_ad['Spend'].sum() if 'Spend' in nb_ad.columns else 0
                nb_ad_total_sales = nb_ad['Sales'].sum() if 'Sales' in nb_ad.columns else 0
                ad_nb = nb_ad.groupby('Product').apply(lambda x: kpi_agg(x, nb_ad_total_spend, nb_ad_total_sales), include_groups=False).reset_index() if not nb_ad.empty else pd.DataFrame(columns=['Product'])
                ad_nb = ad_nb.set_index('Product') if not ad_nb.empty else pd.DataFrame(index=expected_ad_types)
                ad_nb = ad_nb.reindex(expected_ad_types, fill_value=0).reset_index().rename(columns={"index": 'Product'})
                ad_nb_fmt = format_agg_table(ad_nb, index_col='Product')
            
                # Create a custom column config based on the actual columns in the dataframe
                custom_column_config = {}
            
                # Add Product column
                custom_column_config['Product'] = st.column_config.TextColumn(label="Product")
            
                # Add currency columns with dollar formatting
                for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                    if col in ad_nb_fmt.columns:
                        # Convert to numeric first
                        ad_nb_fmt[col] = pd.to_numeric(ad_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
            
                # Add percentage columns
                for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                    if col in ad_nb_fmt.columns:
                        # Convert to numeric first (as decimal, not percentage)
                        ad_nb_fmt[col] = pd.to_numeric(ad_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
            
                # Add ROAS as decimal
                if 'ROAS' in ad_nb_fmt.columns:
                    ad_nb_fmt['ROAS'] = pd.to_numeric(ad_nb_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                    custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
            
                # Add integer columns with comma formatting
                for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                    if col in ad_nb_fmt.columns:
                        ad_nb_fmt[col] = pd.to_numeric(ad_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
            
                # Create a copy for numeric processing
                numeric_df = ad_nb_fmt.copy()
            
                # Convert formatted values to numeric for proper sorting
                for col in numeric_df.columns:
                    if col not in ['Product']:
                        numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
            
                # Create formatting dictionary
                fmt_dict = {}
                for col in numeric_df.columns:
                    if col == 'Product':
                        continue
                    elif col == 'ROAS':
                        fmt_dict[col] = lambda x: f"{x:.2f}"
                    elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    elif col in ['CPC', 'AOV', 'CPA']:
                        fmt_dict[col] = lambda x: f"${x:.2f}"
                    elif col in ['Spend', 'Sales', 'Ad Sales']:
                        fmt_dict[col] = lambda x: f"${x:,.2f}"
                    else:
                        fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
            
                # Style the dataframe
                styled_df = numeric_df.style.format(fmt_dict)
            
                # Apply color gradients to percentage columns
                if '% of Spend' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                if '% of Ad Sales' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                # Apply ACoS styling if target is available
                use_avg_fallback = goals.get('use_avg_acos_nonbranded', False)
                non_branded_target = goals.get('non_branded_acos')
            
                if non_branded_target is not None:
                    # Apply ACoS styling to the ACoS column only
                    acos_col_idx = numeric_df.columns.get_loc('ACoS') if 'ACoS' in numeric_df.columns else None
                    if acos_col_idx is not None:
                        styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', non_branded_target, use_avg_fallback)
            
                # Display the dataframe with sorting enabled
                st.dataframe(styled_df, use_container_width=True, hide_index=True)
            else:
                st.info("No Non-Branded targeting data by Ad Type (missing 'Product' column).")
        
            # Add bar charts for Non-Branded Ad Type
            if not nb_ad.empty and 'Product' in nb_ad.columns:
                # Add filter indicator if filter is active
                if st.session_state.adtype_filter_active:
                    st.caption(f"Filtered by Product Group: {st.session_state.adtype_product_group_filter}")
                # Removed header text as requested
                col1, col2 = st.columns(2)
            
                with col1:
                    # Spend chart
                    # Calculate percentages of total spend
                    total_spend = ad_nb['Spend'].sum()
                    ad_nb['Spend_Pct'] = ad_nb['Spend'] / total_spend * 100 if total_spend > 0 else 0
                
                    # Create custom text with dollar amount and percentage
                    ad_nb['Spend_Text'] = ad_nb.apply(
                        lambda row: f"${row['Spend']:,.2f} ({row['Spend_Pct']:.1f}%)", 
                        axis=1
                    )
                
                    fig_spend = px.bar(
                        ad_nb, 
                        x='Product', 
                        y='Spend',
                        title='Spend by Ad Type',
                        color_discrete_sequence=['#1f77b4'],  # Blue color for spend charts
                        text='Spend_Text'  # Use our custom text column
                    )
                    fig_spend.update_layout(
                        xaxis_title='Ad Type',
                        yaxis_title='Spend ($)',
                        height=500,
                        margin=dict(l=50, r=50, t=80, b=80),
                        autosize=True
                    )
                    fig_spend.update_traces(textposition='outside')
                    # Ensure y-axis has enough room for labels
                    fig_spend.update_yaxes(automargin=True, tickformat='$,.0f')
                    st.plotly_chart(fig_spend, use_container_width=True)
                
                with col2:
                    # Ad Sales chart
                    # Calculate percentages of total sales
                    total_sales = ad_nb['Ad Sales'].sum()
                    ad_nb['Sales_Pct'] = ad_nb['Ad Sales'] / total_sales * 100 if total_sales > 0 else 0
                
                    # Create custom text with dollar amount and percentage
                    ad_nb['Sales_Text'] = ad_nb.apply(
                        lambda row: f"${row['Ad Sales']:,.2f} ({row['Sales_Pct']:.1f}%)", 
                        axis=1
                    )
                
                    fig_sales = px.bar(
                        ad_nb, 
                        x='Product', 
                        y='Ad Sales',
                        title='Ad Sales by Ad Type',
                        color_discrete_sequence=['#10b981'],  # Green color for sales charts
                        text='Sales_Text'  # Use our custom text column
                    )
                    fig_sales.update_layout(
                        xaxis_title='Ad Type',
                        yaxis_title='Sales ($)',
                        height=500,
                        margin=dict(l=50, r=50, t=80, b=80),
                        autosize=True
                    )
                    fig_sales.update_traces(textposition='outside')
                    # Ensure y-axis has enough room for labels
                    fig_sales.update_yaxes(automargin=True, tickformat='$,.0f')
                    st.plotly_chart(fig_sales, use_container_width=True)

        # --- 3. Combined Ad Type & Match Type Pivot Table ---
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<div style='margin-top:30px;'></div>", unsafe_allow_html=True)
        st.markdown('#### Targeting by Ad Type & Match Type')
    
        # Get product groups from client configuration for filtering
        product_groups = set()
        if st.session_state.get('client_config') and 'branded_asins_data' in st.session_state.client_config:
            for asin_info in st.session_state.client_config['branded_asins_data'].values():
                product_group = asin_info.get('product_group', '')
                if product_group and product_group.strip():
                    product_groups.add(product_group)
    
        # Add campaign product groups as well
        if st.session_state.get('client_config') and 'campaign_tags_data' in st.session_state.client_config:
            for campaign_info in st.session_state.client_config['campaign_tags_data'].values():
                product_group = campaign_info.get('tag_1', '') or 'Untagged Group'
                if product_group and product_group.strip():
                    product_groups.add(product_group)
    
        product_groups = sorted(list(product_groups))

        # Initialize session state variables if they don't exist
        if 'targeting_product_group_filter2' not in st.session_state:
            st.session_state.targeting_product_group_filter2 = []
        if 'targeting_filter_active2' not in st.session_state:
            st.session_state.targeting_filter_active2 = False
        
        # Initialize debug variables for product group filtering
        if 'debug_targeting_filter' not in st.session_state:
            st.session_state.debug_targeting_filter = {}
    
        # Store current filter state for debugging
        st.session_state.debug_targeting_filter['active'] = st.session_state.get('targeting_filter_active2', False)
        st.session_state.debug_targeting_filter['selected_groups'] = st.session_state.get('targeting_product_group_filter2', [])
    
        # Get product groups from campaign tagging data
        campaign_tagging_product_groups = set()
        if 'client_config' in st.session_state and 'campaign_tags_data' in st.session_state.client_config:
            for campaign_data in st.session_state.client_config['campaign_tags_data'].values():
                if 'tag_1' in campaign_data and campaign_data['tag_1']:  # tag_1 is the Product Group in Campaign Tagging
                    campaign_tagging_product_groups.add(campaign_data['tag_1'])
            # Add Untagged Group as a filter option for campaigns that could be untagged
            if st.session_state.client_config["campaign_tags_data"]:
                campaign_tagging_product_groups.add("Untagged Group")
    
        campaign_tagging_product_groups = sorted(list(campaign_tagging_product_groups))
    
        # Only show the filter if we have product groups from campaign tagging
        if campaign_tagging_product_groups:
            # Create the multiselect widget with a callback to update session state
            def update_product_group_filter():
                # Synchronize the widget value with the session state variable
                st.session_state.targeting_product_group_filter2 = st.session_state.targeting_product_group_filter2_widget
                # Update the filter active state
                st.session_state.targeting_filter_active2 = len(st.session_state.targeting_product_group_filter2) > 0
                # Add debug information
                if 'debug_targeting_filter' not in st.session_state:
                    st.session_state.debug_targeting_filter = {}
                st.session_state.debug_targeting_filter['widget_callback'] = {
                    'widget_value': st.session_state.targeting_product_group_filter2_widget,
                    'session_state_value': st.session_state.targeting_product_group_filter2,
                    'filter_active': st.session_state.targeting_filter_active2,
                    'timestamp': datetime.now().strftime('%H:%M:%S')
                }
        
            # Create the multiselect widget with the callback
            selected_groups = st.multiselect(
                "Filter by Product Group(s)",
                options=campaign_tagging_product_groups,
                key="targeting_product_group_filter2_widget",
                on_change=update_product_group_filter
            )
        
            # Ensure session state is updated immediately for first render
            if st.session_state.targeting_product_group_filter2 != st.session_state.targeting_product_group_filter2_widget:
                st.session_state.targeting_product_group_filter2 = st.session_state.targeting_product_group_filter2_widget
                st.session_state.targeting_filter_active2 = len(st.session_state.targeting_product_group_filter2) > 0
        else:
            # No product groups in campaign tagging, so hide the filter completely
            st.session_state.targeting_product_group_filter2 = []
            st.session_state.targeting_filter_active2 = False
    
        # Create tabs
        combined_tabs = st.tabs(["All", "Branded", "Non-Branded"])

        # Function to create combined Ad Type & Match Type column
        def create_combined_column(df):
            if df.empty:
                return df
            
            df = df.copy()
        
            # Define match_type_col within the function to avoid global variable issues
            match_type_col = 'Match Type' if 'Match Type' in df.columns else 'Target Type'
        
            # Ensure we have both columns
            if 'Product' not in df.columns:
                df = infer_ad_type(df)
        
            if match_type_col not in df.columns:
                # If we still don't have a match type column, add a default one
                df[match_type_col] = 'Unknown'
            
            # Add product group information if available
            # Only populate if there are actually product groups defined in Campaign Tagging
            if 'Campaign' in df.columns and st.session_state.get('client_config') and 'campaign_tags_data' in st.session_state.client_config:
                # Standardize campaign names for consistent matching
                def standardize_campaign_name(name):
                    return str(name).strip().lower()
                
                # Get campaign tags data with standardized keys
                campaign_tags_data = {standardize_campaign_name(k): v for k, v in st.session_state.client_config['campaign_tags_data'].items()}
            
                # Check if there are any product groups defined
                has_product_groups = any(v.get('tag_1', '') for v in st.session_state.client_config['campaign_tags_data'].values())
            
                # Apply product group mapping with standardized campaign names
                if has_product_groups:  # Only if there are product groups defined
                    df['Product Group'] = df['Campaign'].apply(
                        lambda x: campaign_tags_data.get(standardize_campaign_name(x), {}).get('tag_1', '') or 'Untagged Group'
                    )
                else:
                    df['Product Group'] = 'Untagged Group'  # Use 'Untagged Group' if no product groups defined
        
            # Create the combined column with special handling for different ad types
            def combine_adtype_matchtype(row):
                ad_type = row.get('Product', 'Unknown')
                match_type = row.get(match_type_col, 'Unknown')
            
                # Handle Sponsored Products
                if ad_type == 'Sponsored Products':
                    if match_type in ['Exact', 'Phrase', 'Broad']:
                        return f"{ad_type} - {match_type}"
                    elif match_type == 'Auto':
                        return f"{ad_type} - Auto"
                    elif match_type == 'Product Target':
                        return f"{ad_type} - Product Target"
                    elif match_type == 'Category Targeting':
                        return f"{ad_type} - Category Target"
            
                # Handle Sponsored Brands
                elif ad_type == 'Sponsored Brands':
                    if match_type in ['Exact', 'Phrase', 'Broad']:
                        return f"{ad_type} - {match_type}"
                    elif match_type == 'Product Target':
                        return f"{ad_type} - Product Target"
                    elif match_type == 'Category Targeting':
                        return f"{ad_type} - Category Target"
            
                # Handle Sponsored Display
                elif ad_type == 'Sponsored Display':
                    if match_type == 'Product Target':
                        return f"{ad_type} - Product Target"
                    elif match_type == 'Category Targeting':
                        return f"{ad_type} - Category Target"
                    elif match_type == 'Remarketing - Branded':
                        return f"{ad_type} - Remarketing - Branded"
                    elif match_type == 'Remarketing - Competitor':
                        return f"{ad_type} - Remarketing - Competitor"
            
                # Default fallback
                return f"{ad_type} - {match_type}"
        
            df['Ad Type & Match Type'] = df.apply(combine_adtype_matchtype, axis=1)
            return df
            
        # All Combined
        with combined_tabs[0]:
            # First, ensure we have the product group information in both dataframes
            b_df = branded_targets_df.copy()
            nb_df = non_branded_targets_df.copy()
        
            # Standardize campaign names for consistent matching
            def standardize_campaign_name(name):
                return str(name).strip().lower()
            
            # Get campaign tags data with standardized keys
            campaign_tags_data = {}
            has_product_groups = False
            if st.session_state.get('client_config') and 'campaign_tags_data' in st.session_state.client_config:
                campaign_tags_data = {standardize_campaign_name(k): v for k, v in st.session_state.client_config['campaign_tags_data'].items()}
                # Check if there are any product groups defined
                has_product_groups = any(v.get('tag_1', '') for v in st.session_state.client_config['campaign_tags_data'].values())
        
            # Add product group to branded dataframe
            # Only populate if there are actually product groups defined in Campaign Tagging
            if 'Campaign' in b_df.columns:
                if has_product_groups:  # Only if there are product groups defined
                    b_df['Product Group'] = b_df['Campaign'].apply(
                        lambda x: campaign_tags_data.get(standardize_campaign_name(x), {}).get('tag_1', '') or 'Untagged Group'
                    )
                else:
                    b_df['Product Group'] = 'Untagged Group'  # Use 'Untagged Group' if no product groups defined
            
            # Add product group to non-branded dataframe
            if 'Campaign' in nb_df.columns:
                if has_product_groups:  # Only if there are product groups defined
                    nb_df['Product Group'] = nb_df['Campaign'].apply(
                        lambda x: campaign_tags_data.get(standardize_campaign_name(x), {}).get('tag_1', '') or 'Untagged Group'
                    )
                else:
                    nb_df['Product Group'] = 'Untagged Group'  # Use 'Untagged Group' if no product groups defined
            
            # Apply product group filtering if active
            if st.session_state.get('targeting_filter_active2', False) and len(st.session_state.targeting_product_group_filter2) > 0:
                # Convert all product groups to strings for consistent comparison
                selected_groups = [str(pg) for pg in st.session_state.targeting_product_group_filter2]
            
                # Store original row counts for debugging
                b_df_original_count = len(b_df) if not b_df.empty else 0
                nb_df_original_count = len(nb_df) if not nb_df.empty else 0
            
                # Debug information before filtering
                st.session_state.debug_targeting_filter['before_filtering'] = {
                    'branded_rows': b_df_original_count,
                    'nonbranded_rows': nb_df_original_count,
                    'branded_product_groups': b_df['Product Group'].unique().tolist() if 'Product Group' in b_df.columns and not b_df.empty else [],
                    'nonbranded_product_groups': nb_df['Product Group'].unique().tolist() if 'Product Group' in nb_df.columns and not nb_df.empty else []
                }
            
                # Filter branded dataframe
                if 'Product Group' in b_df.columns:
                    b_df = b_df[b_df['Product Group'].astype(str).isin(selected_groups)]
                
                # Filter non-branded dataframe
                if 'Product Group' in nb_df.columns:
                    nb_df = nb_df[nb_df['Product Group'].astype(str).isin(selected_groups)]
            
                # Store filtered row counts for debugging
                b_df_filtered_count = len(b_df) if not b_df.empty else 0
                nb_df_filtered_count = len(nb_df) if not nb_df.empty else 0
            
                # Debug information after filtering
                st.session_state.debug_targeting_filter['after_filtering'] = {
                    'branded_rows': b_df_filtered_count,
                    'nonbranded_rows': nb_df_filtered_count,
                    'branded_product_groups': b_df['Product Group'].unique().tolist() if 'Product Group' in b_df.columns and not b_df.empty else [],
                    'nonbranded_product_groups': nb_df['Product Group'].unique().tolist() if 'Product Group' in nb_df.columns and not b_df.empty else [],
                    'rows_removed_branded': b_df_original_count - b_df_filtered_count,
                    'rows_removed_nonbranded': nb_df_original_count - nb_df_filtered_count
                }
                
                # Store filtered dataframes in session state for use in Sankey diagrams
                st.session_state.filtered_branded_targets_df = b_df
                st.session_state.filtered_non_branded_targets_df = nb_df
            
                # Combine filtered dataframes
                all_df = pd.concat([b_df, nb_df], ignore_index=True)
            
                # Add debug caption to show active filter
                st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.targeting_product_group_filter2)}")
            else:
                # Use original dataframes if no filter is active
                all_df = pd.concat([b_df, nb_df], ignore_index=True)
            
                # Reset filtered dataframes in session state
                st.session_state.filtered_branded_targets_df = b_df
                st.session_state.filtered_non_branded_targets_df = nb_df
        
            # Process the data for display
            normalized_df = normalize_match_types(all_df)
        
            # Ensure required columns exist
            if 'Product' not in normalized_df.columns:
                normalized_df['Product'] = ''
            if match_type_col not in normalized_df.columns:
                normalized_df[match_type_col] = ''
        
            # Create the combined column for display
            all_combined = create_combined_column(infer_ad_type(normalized_df))
        
            # Debug information if needed
            if 'debug' in st.session_state and st.session_state.debug:
                st.write(f"Selected product groups: {st.session_state.get('targeting_product_group_filter2', [])}")
                if 'Product Group' in all_combined.columns:
                    st.write(f"Available product groups in data: {all_combined['Product Group'].unique()}")
                    st.write(f"Data types - Selected: {type(st.session_state.targeting_product_group_filter2[0]) if st.session_state.targeting_product_group_filter2 else 'None'}, In DataFrame: {all_combined['Product Group'].dtype}")
                else:
                    st.warning("No 'Product Group' column found in the data")
        
            expected_adtype_matchtypes = [
                "Sponsored Products - Exact", "Sponsored Products - Phrase", "Sponsored Products - Broad", "Sponsored Products - Auto", "Sponsored Products - Product Target", "Sponsored Products - Category Target",
                "Sponsored Brands - Exact", "Sponsored Brands - Phrase", "Sponsored Brands - Broad", "Sponsored Brands - Product Target", "Sponsored Brands - Category Target",
                "Sponsored Display - Product Target", "Sponsored Display - Category Target",
                "Sponsored Display - Remarketing - Branded", "Sponsored Display - Remarketing - Competitor"
            ]
            if 'Ad Type & Match Type' in all_combined.columns:
                all_combined_total_spend = all_combined['Spend'].sum() if not all_combined.empty else 0
                all_combined_total_sales = all_combined['Sales'].sum() if not all_combined.empty else 0
                combined_all = all_combined.groupby('Ad Type & Match Type').apply(lambda x: kpi_agg(x, all_combined_total_spend, all_combined_total_sales), include_groups=False).reset_index() if not all_combined.empty else pd.DataFrame(columns=['Ad Type & Match Type'])
                combined_all = combined_all.set_index('Ad Type & Match Type') if not combined_all.empty else pd.DataFrame(index=expected_adtype_matchtypes)
                combined_all = combined_all.reindex(expected_adtype_matchtypes, fill_value=0).reset_index().rename(columns={"index": 'Ad Type & Match Type'})
                combined_all_fmt = format_agg_table(combined_all, index_col='Ad Type & Match Type')
            
                # Create a custom column config based on the actual columns in the dataframe
                custom_column_config = {}
            
                # Add Ad Type & Match Type column
                custom_column_config['Ad Type & Match Type'] = st.column_config.TextColumn(label="Ad Type & Match Type")
            
                # Add currency columns with dollar formatting
                for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                    if col in combined_all_fmt.columns:
                        # Convert to numeric first
                        combined_all_fmt[col] = pd.to_numeric(combined_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
            
                # Add percentage columns
                for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                    if col in combined_all_fmt.columns:
                        # Convert to numeric first (as decimal, not percentage)
                        combined_all_fmt[col] = pd.to_numeric(combined_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
            
                # Add ROAS as decimal
                if 'ROAS' in combined_all_fmt.columns:
                    combined_all_fmt['ROAS'] = pd.to_numeric(combined_all_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                    custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
            
                # Add integer columns with comma formatting
                for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                    if col in combined_all_fmt.columns:
                        combined_all_fmt[col] = pd.to_numeric(combined_all_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
            
                # ACoS target display removed
                # Use the toggle value from client config for 'use_avg_as_fallback'
                use_avg_fallback = goals.get('use_avg_acos_account', False)
                account_target = goals.get('account_wide_acos')
            
                # Create a copy for numeric processing
                numeric_df = combined_all_fmt.copy()
            
                # Convert formatted values to numeric for proper sorting
                for col in numeric_df.columns:
                    if col not in ['Ad Type & Match Type']:
                        numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
            
                # Create formatting dictionary
                fmt_dict = {}
                for col in numeric_df.columns:
                    if col == 'Ad Type & Match Type':
                        continue
                    elif col == 'ROAS':
                        fmt_dict[col] = lambda x: f"{x:.2f}"
                    elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    elif col in ['CPC', 'AOV', 'CPA']:
                        fmt_dict[col] = lambda x: f"${x:.2f}"
                    elif col in ['Spend', 'Sales', 'Ad Sales']:
                        fmt_dict[col] = lambda x: f"${x:,.2f}"
                    else:
                        fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
            
                # Style the dataframe
                styled_df = numeric_df.style.format(fmt_dict)
            
                # Apply color gradients to percentage columns
                if '% of Spend' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                if '% of Ad Sales' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                # Apply ACoS styling if target is available
                if account_target is not None:
                    # Apply ACoS styling to the ACoS column only
                    acos_col_idx = numeric_df.columns.get_loc('ACoS') if 'ACoS' in numeric_df.columns else None
                    if acos_col_idx is not None:
                        styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', account_target, use_avg_fallback)
            
                # Display the dataframe with sorting enabled
                st.dataframe(styled_df, use_container_width=True, hide_index=True)
            else:
                st.info("No targeting data by Ad Type & Match Type (missing 'Ad Type & Match Type' column).")

        # Branded Combined
        with combined_tabs[1]:
            # Use the filtered branded dataframe from the "All" tab
            if 'filtered_branded_targets_df' in st.session_state:
                b_df = st.session_state.filtered_branded_targets_df
            else:
                b_df = branded_targets_df.copy()
            
            # Show filter status if active
            if st.session_state.get('targeting_filter_active2', False) and len(st.session_state.targeting_product_group_filter2) > 0:
                st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.targeting_product_group_filter2)}")
            
            # Process the data for display
            normalized_df = normalize_match_types(b_df)
        
            # Ensure required columns exist
            if 'Product' not in normalized_df.columns:
                normalized_df['Product'] = ''
            if match_type_col not in normalized_df.columns:
                normalized_df[match_type_col] = ''
            
            # Create the combined column for display
            b_combined = create_combined_column(infer_ad_type(normalized_df))
        
            expected_adtype_matchtypes = [
                "Sponsored Products - Exact", "Sponsored Products - Phrase", "Sponsored Products - Broad", "Sponsored Products - Auto", "Sponsored Products - Product Target", "Sponsored Products - Category Target",
                "Sponsored Brands - Exact", "Sponsored Brands - Phrase", "Sponsored Brands - Broad", "Sponsored Brands - Product Target", "Sponsored Brands - Category Target",
                "Sponsored Display - Product Target", "Sponsored Display - Category Target",
                "Sponsored Display - Remarketing - Branded", "Sponsored Display - Remarketing - Competitor"
            ]
            if 'Ad Type & Match Type' in b_combined.columns:
                b_combined_total_spend = b_combined['Spend'].sum() if not b_combined.empty else 0
                b_combined_total_sales = b_combined['Sales'].sum() if not b_combined.empty else 0
                combined_b = b_combined.groupby('Ad Type & Match Type').apply(lambda x: kpi_agg(x, b_combined_total_spend, b_combined_total_sales), include_groups=False).reset_index() if not b_combined.empty else pd.DataFrame(columns=['Ad Type & Match Type'])
                combined_b = combined_b.set_index('Ad Type & Match Type') if not combined_b.empty else pd.DataFrame(index=expected_adtype_matchtypes)
                combined_b = combined_b.reindex(expected_adtype_matchtypes, fill_value=0).reset_index().rename(columns={"index": 'Ad Type & Match Type'})
                combined_b_fmt = format_agg_table(combined_b, index_col='Ad Type & Match Type')
            
                # Create a custom column config based on the actual columns in the dataframe
                custom_column_config = {}
            
                # Add Ad Type & Match Type column
                custom_column_config['Ad Type & Match Type'] = st.column_config.TextColumn(label="Ad Type & Match Type")
            
                # Add currency columns with dollar formatting
                for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                    if col in combined_b_fmt.columns:
                        # Convert to numeric first
                        combined_b_fmt[col] = pd.to_numeric(combined_b_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
            
                # Add percentage columns
                for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                    if col in combined_b_fmt.columns:
                        # Convert to numeric first (as decimal, not percentage)
                        combined_b_fmt[col] = pd.to_numeric(combined_b_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
            
                # Add ROAS as decimal
                if 'ROAS' in combined_b_fmt.columns:
                    combined_b_fmt['ROAS'] = pd.to_numeric(combined_b_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                    custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
            
                # Add integer columns with comma formatting
                for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                    if col in combined_b_fmt.columns:
                        combined_b_fmt[col] = pd.to_numeric(combined_b_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
            
                # ACoS target display removed
                # Use the toggle value from client config for 'use_avg_as_fallback'
                use_avg_fallback = goals.get('use_avg_acos_branded', False)
            
                # Create a copy for numeric processing
                numeric_df = combined_b_fmt.copy()
            
                # Convert formatted values to numeric for proper sorting
                for col in numeric_df.columns:
                    if col not in ['Ad Type & Match Type']:
                        numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
            
                # Create formatting dictionary
                fmt_dict = {}
                for col in numeric_df.columns:
                    if col == 'Ad Type & Match Type':
                        continue
                    elif col == 'ROAS':
                        fmt_dict[col] = lambda x: f"{x:.2f}"
                    elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    elif col in ['CPC', 'AOV', 'CPA']:
                        fmt_dict[col] = lambda x: f"${x:.2f}"
                    elif col in ['Spend', 'Sales', 'Ad Sales']:
                        fmt_dict[col] = lambda x: f"${x:,.2f}"
                    else:
                        fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
            
                # Style the dataframe
                styled_df = numeric_df.style.format(fmt_dict)
            
                # Apply color gradients to percentage columns
                if '% of Spend' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                if '% of Ad Sales' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                # Apply ACoS styling if target is available
                if branded_target is not None:
                    # Apply ACoS styling to the ACoS column only
                    acos_col_idx = numeric_df.columns.get_loc('ACoS') if 'ACoS' in numeric_df.columns else None
                    if acos_col_idx is not None:
                        styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', branded_target, use_avg_fallback)
            
                # Display the dataframe with sorting enabled
                st.dataframe(styled_df, use_container_width=True, hide_index=True)
            else:
                st.info("No Branded targeting data by Ad Type & Match Type (missing 'Ad Type & Match Type' column).")

        # Non-Branded Combined
        with combined_tabs[2]:
            # Use the filtered non-branded dataframe from the "All" tab
            if 'filtered_non_branded_targets_df' in st.session_state:
                nb_df = st.session_state.filtered_non_branded_targets_df
            else:
                nb_df = non_branded_targets_df.copy()
            
            # Show filter status if active
            if st.session_state.get('targeting_filter_active2', False) and len(st.session_state.targeting_product_group_filter2) > 0:
                st.caption(f"Filtered by Product Group(s): {', '.join(st.session_state.targeting_product_group_filter2)}")
            
            # Process the data for display
            normalized_df = normalize_match_types(nb_df)
        
            # Ensure required columns exist
            if 'Product' not in normalized_df.columns:
                normalized_df['Product'] = ''
            if match_type_col not in normalized_df.columns:
                normalized_df[match_type_col] = ''
            
            # Create the combined column for display
            nb_combined = create_combined_column(infer_ad_type(normalized_df))
        
            if 'Ad Type & Match Type' in nb_combined.columns:
                # Calculate account totals for percentage calculations
                nb_combined_total_spend = nb_combined['Spend'].sum() if not nb_combined.empty else 0
                nb_combined_total_sales = nb_combined['Sales'].sum() if not nb_combined.empty else 0
                combined_nb = nb_combined.groupby('Ad Type & Match Type').apply(lambda x: kpi_agg(x, nb_combined_total_spend, nb_combined_total_sales), include_groups=False).reset_index() if not nb_combined.empty else pd.DataFrame(columns=['Ad Type & Match Type'])
                expected_adtype_matchtypes = [
                    "Sponsored Products - Exact", "Sponsored Products - Phrase", "Sponsored Products - Broad", "Sponsored Products - Auto", "Sponsored Products - Product Target", "Sponsored Products - Category Target",
                    "Sponsored Brands - Exact", "Sponsored Brands - Phrase", "Sponsored Brands - Broad", "Sponsored Brands - Product Target", "Sponsored Brands - Category Target",
                    "Sponsored Display - Product Target", "Sponsored Display - Category Target",
                    "Sponsored Display - Remarketing - Branded", "Sponsored Display - Remarketing - Competitor"
                ]
                combined_nb = combined_nb.set_index('Ad Type & Match Type') if not combined_nb.empty else pd.DataFrame(index=expected_adtype_matchtypes)
                combined_nb = combined_nb.reindex(expected_adtype_matchtypes, fill_value=0).reset_index().rename(columns={"index": 'Ad Type & Match Type'})
                combined_nb_fmt = format_agg_table(combined_nb, index_col='Ad Type & Match Type')
            
                # Create a custom column config based on the actual columns in the dataframe
                custom_column_config = {}
            
                # Add Ad Type & Match Type column
                custom_column_config['Ad Type & Match Type'] = st.column_config.TextColumn(label="Ad Type & Match Type")
            
                # Add currency columns with dollar formatting
                for col in ['Spend', 'Ad Sales', 'CPC', 'AOV', 'CPA']:
                    if col in combined_nb_fmt.columns:
                        # Convert to numeric first
                        combined_nb_fmt[col] = pd.to_numeric(combined_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="dollar")
            
                # Add percentage columns
                for col in ['ACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                    if col in combined_nb_fmt.columns:
                        # Convert to numeric first (as decimal, not percentage)
                        combined_nb_fmt[col] = pd.to_numeric(combined_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="%.2f%%")
            
                # Add ROAS as decimal
                if 'ROAS' in combined_nb_fmt.columns:
                    combined_nb_fmt['ROAS'] = pd.to_numeric(combined_nb_fmt['ROAS'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0)
                    custom_column_config['ROAS'] = st.column_config.NumberColumn(label="ROAS", format="%.2f")
            
                # Add integer columns with comma formatting
                for col in ['Impressions', 'Clicks', 'Orders', 'Units Sold']:
                    if col in combined_nb_fmt.columns:
                        combined_nb_fmt[col] = pd.to_numeric(combined_nb_fmt[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce').fillna(0).astype(int)
                        custom_column_config[col] = st.column_config.NumberColumn(label=col, format="localized")
            
                # ACoS target display removed
                # Use the toggle value from client config for 'use_avg_as_fallback'
                use_avg_fallback = goals.get('use_avg_acos_nonbranded', False)
            
                # Create a copy for numeric processing
                numeric_df = combined_nb_fmt.copy()
            
                # Convert formatted values to numeric for proper sorting
                for col in numeric_df.columns:
                    if col not in ['Ad Type & Match Type']:
                        numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce')
            
                # Create formatting dictionary
                fmt_dict = {}
                for col in numeric_df.columns:
                    if col == 'Ad Type & Match Type':
                        continue
                    elif col == 'ROAS':
                        fmt_dict[col] = lambda x: f"{x:.2f}"
                    elif col in ['ACoS', 'TACoS', 'CVR', 'CTR', '% of Spend', '% of Ad Sales']:
                        fmt_dict[col] = lambda x: f"{x:.2f}%"
                    elif col in ['CPC', 'AOV', 'CPA']:
                        fmt_dict[col] = lambda x: f"${x:.2f}"
                    elif col in ['Spend', 'Sales', 'Ad Sales']:
                        fmt_dict[col] = lambda x: f"${x:,.2f}"
                    else:
                        fmt_dict[col] = lambda x: f"{x:,.0f}" if pd.notnull(x) else "0"
            
                # Style the dataframe
                styled_df = numeric_df.style.format(fmt_dict)
            
                # Apply color gradients to percentage columns
                if '% of Spend' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                if '% of Ad Sales' in numeric_df.columns:
                    styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100) 
                                                        if not pd.isna(v) else '' 
                                                        for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                # Apply ACoS styling if target is available
                if non_branded_target is not None:
                    # Apply ACoS styling to the ACoS column only
                    acos_col_idx = numeric_df.columns.get_loc('ACoS') if 'ACoS' in numeric_df.columns else None
                    if acos_col_idx is not None:
                        styled_df = apply_acos_styling(styled_df, numeric_df, 'ACoS', non_branded_target, use_avg_fallback)
            
                # Display the dataframe with sorting enabled
                st.dataframe(styled_df, use_container_width=True, hide_index=True)
            else:
                st.info("No Non-Branded targeting data by Ad Type & Match Type (missing 'Ad Type & Match Type' column).")

        # --- Ad Spend/Sales Flow Sankey Diagram ---
    
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<div style='margin-top:30px;'></div>", unsafe_allow_html=True)
    
        # Create tabs for Ad Spend and Ad Sales flows
        flow_tabs = st.tabs(["Ad Spend Flow", "Ad Sales Flow"])
    
        def create_ad_spend_sankey_from_targeting_data():
            """
            Create a Sankey diagram showing the flow of ad spend from Branded/Non-Branded to Ad Type to Match Type
            using the existing targeting data from the 'Targeting by Ad Type & Match Type' table.
        
            Returns:
                Plotly figure object for the Sankey diagram
            """
            # Use the filtered dataframes from the 'Targeting by Ad Type & Match Type' section above
            if 'filtered_branded_targets_df' in st.session_state and 'filtered_non_branded_targets_df' in st.session_state:
                branded_targets_df = st.session_state.filtered_branded_targets_df
                non_branded_targets_df = st.session_state.filtered_non_branded_targets_df
            else:
                # Fallback to original dataframes if filtered ones aren't available
                if not ('branded_targets_df' in locals() or 'branded_targets_df' in globals()) or \
                   not ('non_branded_targets_df' in locals() or 'non_branded_targets_df' in globals()):
                    return None
            
            # Product group filtering is already applied in the filtered dataframes above
            product_group_filter_active = st.session_state.get('targeting_filter_active2', False)
            selected_product_groups = st.session_state.get('targeting_product_group_filter2', [])
            
            # Extract ad types and match types from the combined data
            ad_types = ['Sponsored Products', 'Sponsored Brands', 'Sponsored Display']
        
            # Simplify match types for better visualization - consolidate keyword match types
            match_types = ['Keywords', 'Auto', 'Product Target', 'Category Target', 'Remarketing']
        
            # Create nodes for both branded and non-branded flows
            # Format: "[Branded/Non-Branded] [Ad Type/Match Type]"
            nodes = []
        
            # Add Branded and Non-Branded nodes
            nodes.append('Branded')
            nodes.append('Non-Branded')
        
            # Add Ad Type nodes for both Branded and Non-Branded
            branded_ad_types = [f'Branded {ad_type}' for ad_type in ad_types]
            non_branded_ad_types = [f'Non-Branded {ad_type}' for ad_type in ad_types]
            nodes.extend(branded_ad_types)
            nodes.extend(non_branded_ad_types)
        
            # Add Match Type nodes for both Branded and Non-Branded
            branded_match_types = [f'Branded {match_type}' for match_type in match_types]
            non_branded_match_types = [f'Non-Branded {match_type}' for match_type in match_types]
            nodes.extend(branded_match_types)
            nodes.extend(non_branded_match_types)
        
            # Initialize data structures for the Sankey diagram
            sources = []
            targets = []
            values = []
        
            # Define a function to consolidate match types
            def consolidate_match_type(match_type):
                if match_type in ['Exact', 'Phrase', 'Broad']:  # Consolidate keyword match types
                    return 'Keywords'
                elif match_type == 'Auto':
                    return 'Auto'
                elif 'Product' in match_type:
                    return 'Product Target'
                elif 'Category' in match_type:
                    return 'Category Target'
                elif 'Remarketing' in match_type:
                    return 'Remarketing'
                else:
                    return 'Other'
        
            # Process branded targets (filtering already applied in the dataframe)
            if not branded_targets_df.empty:
                b_df = branded_targets_df.copy()
            
                # Extract ad type from each row
                if 'Product' not in b_df.columns:
                    b_df = infer_ad_type(b_df)
                
                # Extract match type from each row
                match_type_col = 'Match Type' if 'Match Type' in b_df.columns else 'Target Type'
                if match_type_col not in b_df.columns:
                    b_df[match_type_col] = 'Unknown'
                
                # Apply the match type consolidation
                b_df['Consolidated Match Type'] = b_df[match_type_col].apply(consolidate_match_type)
    # Layer 1: Branded -> Branded Ad Types
                for ad_type in ad_types:
                    branded_ad_type = f'Branded {ad_type}'
                    ad_type_spend = b_df[b_df['Product'] == ad_type]['Spend'].sum()
                    if ad_type_spend > 0:
                        sources.append(nodes.index('Branded'))
                        targets.append(nodes.index(branded_ad_type))
                        values.append(ad_type_spend)
                    
                # Layer 2: Branded Ad Types -> Branded Match Types
                for ad_type in ad_types:
                    branded_ad_type = f'Branded {ad_type}'
                    ad_type_df = b_df[b_df['Product'] == ad_type]
                
                    for match_type in match_types:
                        branded_match_type = f'Branded {match_type}'
                        match_spend = ad_type_df[ad_type_df['Consolidated Match Type'] == match_type]['Spend'].sum()
                        if match_spend > 0:
                            sources.append(nodes.index(branded_ad_type))
                            targets.append(nodes.index(branded_match_type))
                            values.append(match_spend)
        
            # Process non-branded targets (filtering already applied in the dataframe)
            if not non_branded_targets_df.empty:
                nb_df = non_branded_targets_df.copy()
            
                # Extract ad type from each row
                if 'Product' not in nb_df.columns:
                    nb_df = infer_ad_type(nb_df)
                
                # Extract match type from each row
                match_type_col = 'Match Type' if 'Match Type' in nb_df.columns else 'Target Type'
                if match_type_col not in nb_df.columns:
                    nb_df[match_type_col] = 'Unknown'
                
                # Apply the match type consolidation
                nb_df['Consolidated Match Type'] = nb_df[match_type_col].apply(consolidate_match_type)
    # Layer 1: Non-Branded -> Non-Branded Ad Types
                for ad_type in ad_types:
                    non_branded_ad_type = f'Non-Branded {ad_type}'
                    ad_type_spend = nb_df[nb_df['Product'] == ad_type]['Spend'].sum()
                    if ad_type_spend > 0:
                        sources.append(nodes.index('Non-Branded'))
                        targets.append(nodes.index(non_branded_ad_type))
                        values.append(ad_type_spend)
                    
                # Layer 2: Non-Branded Ad Types -> Non-Branded Match Types
                for ad_type in ad_types:
                    non_branded_ad_type = f'Non-Branded {ad_type}'
                    ad_type_df = nb_df[nb_df['Product'] == ad_type]
                
                    for match_type in match_types:
                        non_branded_match_type = f'Non-Branded {match_type}'
                        match_spend = ad_type_df[ad_type_df['Consolidated Match Type'] == match_type]['Spend'].sum()
                        if match_spend > 0:
                            sources.append(nodes.index(non_branded_ad_type))
                            targets.append(nodes.index(non_branded_match_type))
                            values.append(match_spend)
        
            # Create the Sankey diagram
            if not values:  # If no values, return None
                return None
            
            # Define color scheme for nodes
            node_colors = []
            for node in nodes:
                if node == 'Branded':
                    node_colors.append('#1f77b4')  # Blue
                elif node == 'Non-Branded':
                    node_colors.append('#ff7f0e')  # Orange
                elif node.startswith('Branded Sponsored Products'):
                    node_colors.append('#2ca02c')  # Green
                elif node.startswith('Branded Sponsored Brands'):
                    node_colors.append('#9467bd')  # Purple
                elif node.startswith('Branded Sponsored Display'):
                    node_colors.append('#8c564b')  # Brown
                elif node.startswith('Non-Branded Sponsored Products'):
                    node_colors.append('#2ca02c')  # Green (lighter shade)
                elif node.startswith('Non-Branded Sponsored Brands'):
                    node_colors.append('#9467bd')  # Purple (lighter shade)
                elif node.startswith('Non-Branded Sponsored Display'):
                    node_colors.append('#8c564b')  # Brown (lighter shade)
                elif 'Keywords' in node:
                    node_colors.append('#e377c2')  # Pink
                elif 'Auto' in node:
                    node_colors.append('#17becf')  # Cyan
                elif 'Product Target' in node:
                    node_colors.append('#d62728')  # Red
                elif 'Category Target' in node:
                    node_colors.append('#ff9896')  # Light red
                elif 'Remarketing' in node:
                    node_colors.append('#aec7e8')  # Light blue
                else:
                    node_colors.append('#7f7f7f')  # Gray
            
            fig = go.Figure(data=[go.Sankey(
                arrangement='snap',  # Better node arrangement
                node=dict(
                    pad=20,  # More padding between nodes
                    thickness=25,  # Thicker nodes
                    line=dict(color='black', width=0.5),
                    label=nodes,
                    color=node_colors
                ),
                link=dict(
                    source=sources,
                    target=targets,
                    value=values,
                    hovertemplate='<b>%{source.label} → %{target.label}</b><br>Spend: $%{value:,.2f}<extra></extra>',
                    color='rgba(100, 100, 100, 0.2)'  # Slightly visible link color
                )
            )])
        
            # Update layout for better appearance
            fig.update_layout(
                title=dict(
                    text='Ad Spend Flow by Branded/Non-Branded, Ad Type, and Match Type',
                    font=dict(size=16, color='#333333'),
                    x=0.5,  # Center the title
                    y=0.98  # Position at the top
                ),
                font=dict(family='Arial, sans-serif', size=13),
                height=700,  # Taller for better visibility
                margin=dict(l=20, r=20, t=60, b=20),
                paper_bgcolor='rgba(0,0,0,0)',  # Transparent background
                plot_bgcolor='rgba(0,0,0,0)'  # Transparent plot area
            )
        
            return fig
    
        # Create the Ad Sales Flow Sankey function
        def create_ad_sales_sankey_from_targeting_data():
            """
            Create a Sankey diagram showing the flow of ad sales from Branded/Non-Branded to Ad Type to Match Type
            using the existing targeting data from the 'Targeting by Ad Type & Match Type' table.
        
            Returns:
                Plotly figure object for the Sankey diagram
            """
            # Use the filtered dataframes from the 'Targeting by Ad Type & Match Type' section above
            if 'filtered_branded_targets_df' in st.session_state and 'filtered_non_branded_targets_df' in st.session_state:
                branded_targets_df = st.session_state.filtered_branded_targets_df
                non_branded_targets_df = st.session_state.filtered_non_branded_targets_df
            else:
                # Fallback to original dataframes if filtered ones aren't available
                if not ('branded_targets_df' in locals() or 'branded_targets_df' in globals()) or \
                   not ('non_branded_targets_df' in locals() or 'non_branded_targets_df' in globals()):
                    return None
            
            # Product group filtering is already applied in the filtered dataframes above
            product_group_filter_active = st.session_state.get('targeting_filter_active2', False)
            selected_product_groups = st.session_state.get('targeting_product_group_filter2', [])
        
            # Store filter state for debugging
            if 'debug_targeting_filter' not in st.session_state:
                st.session_state.debug_targeting_filter = {}
            st.session_state.debug_targeting_filter['ad_sales_sankey'] = {
                'filter_active': product_group_filter_active,
                'selected_groups': selected_product_groups
            }
            
            # Extract ad types and match types from the combined data
            ad_types = ['Sponsored Products', 'Sponsored Brands', 'Sponsored Display']
        
            # Simplify match types for better visualization - consolidate keyword match types
            match_types = ['Keywords', 'Auto', 'Product Target', 'Category Target', 'Remarketing']
        
            # Create nodes for both branded and non-branded flows
            # Format: "[Branded/Non-Branded] [Ad Type/Match Type]"
            nodes = []
        
            # Add Branded and Non-Branded nodes
            nodes.append('Branded')
            nodes.append('Non-Branded')
        
            # Add Ad Type nodes for both Branded and Non-Branded
            branded_ad_types = [f'Branded {ad_type}' for ad_type in ad_types]
            non_branded_ad_types = [f'Non-Branded {ad_type}' for ad_type in ad_types]
            nodes.extend(branded_ad_types)
            nodes.extend(non_branded_ad_types)
        
            # Add Match Type nodes for both Branded and Non-Branded
            branded_match_types = [f'Branded {match_type}' for match_type in match_types]
            non_branded_match_types = [f'Non-Branded {match_type}' for match_type in match_types]
            nodes.extend(branded_match_types)
            nodes.extend(non_branded_match_types)
        
            # Initialize data structures for the Sankey diagram
            sources = []
            targets = []
            values = []
        
            # Define a function to consolidate match types
            def consolidate_match_type(match_type):
                if match_type in ['Exact', 'Phrase', 'Broad']:  # Consolidate keyword match types
                    return 'Keywords'
                elif match_type == 'Auto':
                    return 'Auto'
                elif 'Product' in match_type:
                    return 'Product Target'
                elif 'Category' in match_type:
                    return 'Category Target'
                elif 'Remarketing' in match_type:
                    return 'Remarketing'
                else:
                    return 'Other'
        
            # Get the appropriate sales column based on attribution setting for Sponsored Display
            def get_sales_column(df):
                """Helper function to determine which sales column to use based on data availability and attribution setting"""
                # Check if we're dealing with Sponsored Display data and user has selected Views & Clicks attribution
                is_sponsored_display = False
                if 'Product' in df.columns:
                    is_sponsored_display = df['Product'].astype(str).str.contains('Sponsored Display', case=False).any()
                elif 'Campaign Type' in df.columns:
                    is_sponsored_display = df['Campaign Type'].astype(str).str.contains('Sponsored Display', case=False).any()
            
                # --- SALES ATTRIBUTION CONSISTENCY: Always respect st.session_state.sd_attribution_choice for sales columns ---
                if is_sponsored_display and 'sd_attribution_choice' in st.session_state and \
                   st.session_state.sd_attribution_choice == 'Sales (Views & Clicks)':
                    # For Sponsored Display with Views & Clicks attribution
                    for col in ['Sales (Views & Clicks)', 'Total Sales (Views & Clicks)']:
                        if col in df.columns:
                            return col
            
                # Default sales columns in order of preference
                for col in ['Sales', 'Total Sales', '7 Day Total Sales']:
                    if col in df.columns:
                        return col
            
                # If no sales column found
                return None
        
            # Process branded targets (filtering already applied in the dataframe)
            if not branded_targets_df.empty:
                b_df = branded_targets_df.copy()
            
                # Extract ad type from each row
                if 'Product' not in b_df.columns:
                    b_df = infer_ad_type(b_df)
                
                # Extract match type from each row
                match_type_col = 'Match Type' if 'Match Type' in b_df.columns else 'Target Type'
                if match_type_col not in b_df.columns:
                    b_df[match_type_col] = 'Unknown'
                
                # Apply the match type consolidation
                b_df['Consolidated Match Type'] = b_df[match_type_col].apply(consolidate_match_type)
            
                # Get the appropriate sales column
                sales_column = get_sales_column(b_df)
                
                # Layer 1: Branded -> Branded Ad Types
                for ad_type in ad_types:
                    branded_ad_type = f'Branded {ad_type}'
                    ad_type_df = b_df[b_df['Product'] == ad_type]
                    ad_type_sales = ad_type_df[sales_column].sum() if sales_column in ad_type_df.columns else 0
                    if ad_type_sales > 0:
                        sources.append(nodes.index('Branded'))
                        targets.append(nodes.index(branded_ad_type))
                        values.append(ad_type_sales)
                    
                # Layer 2: Branded Ad Types -> Branded Match Types
                for ad_type in ad_types:
                    branded_ad_type = f'Branded {ad_type}'
                    ad_type_df = b_df[b_df['Product'] == ad_type]
                
                    for match_type in match_types:
                        branded_match_type = f'Branded {match_type}'
                        match_df = ad_type_df[ad_type_df['Consolidated Match Type'] == match_type]
                        match_sales = match_df[sales_column].sum() if sales_column in match_df.columns else 0
                        if match_sales > 0:
                            sources.append(nodes.index(branded_ad_type))
                            targets.append(nodes.index(branded_match_type))
                            values.append(match_sales)
        
            # Process non-branded targets (filtering already applied in the dataframe)
            if not non_branded_targets_df.empty:
                nb_df = non_branded_targets_df.copy()
            
                # Extract ad type from each row
                if 'Product' not in nb_df.columns:
                    nb_df = infer_ad_type(nb_df)
                
                # Extract match type from each row
                match_type_col = 'Match Type' if 'Match Type' in nb_df.columns else 'Target Type'
                if match_type_col not in nb_df.columns:
                    nb_df[match_type_col] = 'Unknown'
                
                # Apply the match type consolidation
                nb_df['Consolidated Match Type'] = nb_df[match_type_col].apply(consolidate_match_type)
            
                # Get the appropriate sales column
                sales_column = get_sales_column(nb_df)
                
                # Layer 1: Non-Branded -> Non-Branded Ad Types
                for ad_type in ad_types:
                    non_branded_ad_type = f'Non-Branded {ad_type}'
                    ad_type_df = nb_df[nb_df['Product'] == ad_type]
                    ad_type_sales = ad_type_df[sales_column].sum() if sales_column in ad_type_df.columns else 0
                    if ad_type_sales > 0:
                        sources.append(nodes.index('Non-Branded'))
                        targets.append(nodes.index(non_branded_ad_type))
                        values.append(ad_type_sales)
                    
                # Layer 2: Non-Branded Ad Types -> Non-Branded Match Types
                for ad_type in ad_types:
                    non_branded_ad_type = f'Non-Branded {ad_type}'
                    ad_type_df = nb_df[nb_df['Product'] == ad_type]
                
                    for match_type in match_types:
                        non_branded_match_type = f'Non-Branded {match_type}'
                        match_df = ad_type_df[ad_type_df['Consolidated Match Type'] == match_type]
                        match_sales = match_df[sales_column].sum() if sales_column in match_df.columns else 0
                        if match_sales > 0:
                            sources.append(nodes.index(non_branded_ad_type))
                            targets.append(nodes.index(non_branded_match_type))
                            values.append(match_sales)
        
            # Create the Sankey diagram
            if not values:  # If no values, return None
                return None
            
            # Define color scheme for nodes
            node_colors = []
            for node in nodes:
                if node == 'Branded':
                    node_colors.append('#1f77b4')  # Blue
                elif node == 'Non-Branded':
                    node_colors.append('#ff7f0e')  # Orange
                elif node.startswith('Branded Sponsored Products'):
                    node_colors.append('#2ca02c')  # Green
                elif node.startswith('Branded Sponsored Brands'):
                    node_colors.append('#9467bd')  # Purple
                elif node.startswith('Branded Sponsored Display'):
                    node_colors.append('#8c564b')  # Brown
                elif node.startswith('Non-Branded Sponsored Products'):
                    node_colors.append('#2ca02c')  # Green (lighter shade)
                elif node.startswith('Non-Branded Sponsored Brands'):
                    node_colors.append('#9467bd')  # Purple (lighter shade)
                elif node.startswith('Non-Branded Sponsored Display'):
                    node_colors.append('#8c564b')  # Brown (lighter shade)
                elif 'Keywords' in node:
                    node_colors.append('#e377c2')  # Pink
                elif 'Auto' in node:
                    node_colors.append('#17becf')  # Cyan
                elif 'Product Target' in node:
                    node_colors.append('#d62728')  # Red
                elif 'Category Target' in node:
                    node_colors.append('#ff9896')  # Light red
                elif 'Remarketing' in node:
                    node_colors.append('#aec7e8')  # Light blue
                else:
                    node_colors.append('#7f7f7f')  # Gray
            
            fig = go.Figure(data=[go.Sankey(
                arrangement='snap',  # Better node arrangement
                node=dict(
                    pad=20,  # More padding between nodes
                    thickness=25,  # Thicker nodes
                    line=dict(color='black', width=0.5),
                    label=nodes,
                    color=node_colors
                ),
                link=dict(
                    source=sources,
                    target=targets,
                    value=values,
                    hovertemplate='<b>%{source.label} → %{target.label}</b><br>Sales: $%{value:,.2f}<extra></extra>',
                    color='rgba(100, 100, 100, 0.2)'  # Slightly visible link color
                )
            )])
        
            # Update layout for better appearance
            fig.update_layout(
                title=dict(
                    text='Ad Sales Flow by Branded/Non-Branded, Ad Type, and Match Type',
                    font=dict(size=16, color='#333333'),
                    x=0.5,  # Center the title
                    y=0.98  # Position at the top
                ),
                font=dict(family='Arial, sans-serif', size=13),
                height=700,  # Taller for better visibility
                margin=dict(l=20, r=20, t=60, b=20),
                paper_bgcolor='rgba(0,0,0,0)',  # Transparent background
                plot_bgcolor='rgba(0,0,0,0)'  # Transparent plot area
            )
        
            return fig
    
        # Create product group filter for Sankey diagrams
        # Removed duplicate filter
    
        # Create and display the Sankey diagrams in their respective tabs
        with flow_tabs[0]:  # Ad Spend Flow tab
            sankey_spend_fig = create_ad_spend_sankey_from_targeting_data()
            if sankey_spend_fig:
                st.plotly_chart(sankey_spend_fig, use_container_width=True)
            else:
                st.info('Not enough data to create the Ad Spend Flow diagram.')
    
        with flow_tabs[1]:  # Ad Sales Flow tab
            sankey_sales_fig = create_ad_sales_sankey_from_targeting_data()
            if sankey_sales_fig:
                st.plotly_chart(sankey_sales_fig, use_container_width=True)
            else:
                st.info('Not enough data to create the Ad Sales Flow diagram.')
    
        # --- Product Analysis Section ---
        st.markdown("<div id='product-analysis' class='section-anchor'></div>", unsafe_allow_html=True)
        st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
        st.markdown("<span class='main-section-header dashboard-section'>Product Analysis</span>", unsafe_allow_html=True)
        st.markdown("<div style='margin-bottom:1.2rem;'></div>", unsafe_allow_html=True)

        # Create a row with a subtle help icon and tooltip
        col1, col2 = st.columns([0.98, 0.02])
        with col1:
            st.markdown('#### Performance by ASIN')
        with col2:
            st.markdown("""<div title="Product-Level metrics do not include SB data due to ambiguous attribution. Some products may have higher Ad Sales than Total Sales if a click on the ad led to a Brand Halo purchase on a variated product.">ℹ️</div>""", unsafe_allow_html=True)
    
        # Add a spinner while ASIN data is being processed
        with st.spinner("Processing data..."):
            # Prepare and cache column lookups
            bulk_data = st.session_state.get('bulk_data', {})
            if bulk_data is None:
                bulk_data = {}
            bulk_dfs = [df for df in bulk_data.values() if isinstance(df, pd.DataFrame)]
            combined_bulk_df = pd.concat(bulk_dfs, ignore_index=True) if bulk_dfs else None
            sales_df = st.session_state.get('sales_report_data')
            branded_asins_data = st.session_state.client_config.get('branded_asins_data', {}) if st.session_state.get('client_config') else {}

            # Caching possible columns for efficiency
            if isinstance(combined_bulk_df, pd.DataFrame):
                asin_columns_cache = [col for col in combined_bulk_df.columns if 'asin' in col.lower()]
                sales_columns_cache = [col for col in combined_bulk_df.columns if col.lower() == 'sales']
                sd_sales_cols_cache = [col for col in combined_bulk_df.columns if 'sales (views & clicks)' in col.lower()]
            else:
                asin_columns_cache, sales_columns_cache, sd_sales_cols_cache = [], [], []

            # Caching sales report columns
            if isinstance(sales_df, pd.DataFrame):
                sales_report_asin_cols = [col for col in sales_df.columns if 'asin' in col.lower()]
                sales_report_title_cols = [col for col in sales_df.columns if 'title' in col.lower() or 'product name' in col.lower() or 'item name' in col.lower()]
            else:
                sales_report_asin_cols, sales_report_title_cols = [], []

            # Initialize variables
            asin_perf_records = []
            # Get bulk file data to extract ad metrics
            bulk_dfs = []
            for sheet_name, df in bulk_data.items():
                if isinstance(df, pd.DataFrame):
                    bulk_dfs.append(df)
                    st.session_state.debug_messages.append(f"[Product Analysis] Including sheet '{sheet_name}' with {len(df)} rows")
        
            # Combine all bulk data sheets
            combined_bulk_df = pd.concat(bulk_dfs, ignore_index=True) if bulk_dfs else None
        
            if combined_bulk_df is not None:
                st.session_state.debug_messages.append(f"[Product Analysis] Combined bulk data has {len(combined_bulk_df)} total rows")
                if 'ASIN' in combined_bulk_df.columns:
                    asin_count = combined_bulk_df['ASIN'].dropna().nunique()
                    st.session_state.debug_messages.append(f"[Product Analysis] Found {asin_count} unique ASINs in combined data")
                if 'Entity' in combined_bulk_df.columns:
                    entity_counts = combined_bulk_df['Entity'].value_counts().to_dict()
                    st.session_state.debug_messages.append(f"[Product Analysis] Entity distribution: {entity_counts}")
            else:
                st.session_state.debug_messages.append("[Product Analysis] No combined bulk data available")
        
            # Get sales report data for Total Sales
            sales_df = st.session_state.get('sales_report_data')
        
            # Find total sales column in sales report
            total_sales_col = None
            if isinstance(sales_df, pd.DataFrame):
                # Define the helper function for finding columns
                def find_col_pattern(df_cols, patterns, case_sensitive=False):
                    """Finds the first matching column name from a list."""
                    # First try exact matches
                    for pattern in patterns:
                        if pattern in df_cols:
                            return pattern
                
                    # Then try case-insensitive if allowed
                    if not case_sensitive:
                        df_cols_lower = [col.lower() for col in df_cols]
                        for pattern in patterns:
                            pattern_lower = pattern.lower()
                            if pattern_lower in df_cols_lower:
                                idx = df_cols_lower.index(pattern_lower)
                                return df_cols[idx]  # Return original case
                    
                    # Finally try partial matches
                    for pattern in patterns:
                        pattern_lower = pattern.lower()
                        for col in df_cols:
                            if pattern_lower in col.lower():
                                return col
                
                    # If no match found
                    return None
            
                # Use user-selected Total Sales metric if available, otherwise fall back to default search
                if 'selected_total_sales_metric' in st.session_state and st.session_state.selected_total_sales_metric in sales_df.columns:
                    total_sales_col = st.session_state.selected_total_sales_metric
                else:
                    total_sales_col = find_col_pattern(sales_df.columns, ['Total Sales'])
            else:
                total_sales_col = None
        
            # Calculate total spend and sales for percentage calculations
            total_spend = 0
            total_ad_sales = 0
            total_sales = 0
        
            # Track all ASINs we'll process
            all_asins_to_process = set()
        
            # First, collect all ASINs from the sales report
            if isinstance(sales_df, pd.DataFrame) and 'ASIN' in sales_df.columns:
                sales_asins = sales_df['ASIN'].astype(str).str.strip().unique()
                all_asins_to_process.update(sales_asins)
        
            # Also add ASINs from branded_asins_data configuration
            if branded_asins_data:
                all_asins_to_process.update(branded_asins_data.keys())
        
            if isinstance(combined_bulk_df, pd.DataFrame):

                # We'll handle sales column selection at the row level based on Product type and attribution choice
                # Here we just need to calculate the totals for percentage calculations
            
                # Add debug info about bulk file
                if isinstance(combined_bulk_df, pd.DataFrame):
                    asin_columns_in_bulk = [col for col in combined_bulk_df.columns if 'asin' in col.lower()]
                
                    # Show sample of ASINs in bulk file
                    for col in asin_columns_in_bulk:
                        unique_asins = combined_bulk_df[col].dropna().astype(str).str.upper().unique()
                        sample_asins = list(unique_asins)[:10]  # Show first 10 for brevity
            # First, identify which ASINs actually appear in the bulk file
            asins_in_bulk_file = set()
            asin_columns = []  # Initialize to prevent NameError
            if isinstance(combined_bulk_df, pd.DataFrame):
                # Check all possible ASIN columns
                asin_columns = [col for col in combined_bulk_df.columns if 'asin' in col.lower()]
                for col in asin_columns:
                    # Get all unique ASINs from this column
                    asins = combined_bulk_df[col].astype(str).str.lower().unique()
                    asins_in_bulk_file.update(asins)
        
            # Log the count of ASINs found in bulk file
        
        # Now process all ASINs from both sales report and branded_asins_data
            processed_asins = set()  # Keep track of ASINs we've already processed
        
            # First process ASINs from branded_asins_data to get product info
            for asin, info in branded_asins_data.items():
                if asin in processed_asins:
                    continue
                
                processed_asins.add(asin)
            
                # Add this ASIN to the performance records
                asin_row = {}
                # Set columns in the requested order
                asin_row['Product Group'] = info.get('product_group', '') or 'Untagged Group'
                asin_row['ASIN'] = asin
                asin_row['Product Title'] = info.get('product_title', '')
            
                # Initialize metrics
                asin_row['Spend'] = 0
                asin_row['Ad Sales'] = 0
                asin_row['Total Sales'] = 0
                asin_row['% of Spend'] = 0
                asin_row['% of Ad Sales'] = 0
                asin_row['% of Total Sales'] = 0
                asin_row['ACoS'] = 0
                asin_row['TACoS'] = 0
                asin_row['Clicks'] = 0
                asin_row['Orders'] = 0
            
                # Process this ASIN directly without the nested function call
                # Pull ad metrics from bulk file if available
                if isinstance(combined_bulk_df, pd.DataFrame):
                    # Look for this ASIN in the bulk file
                    asin_bulk_rows = pd.DataFrame(columns=combined_bulk_df.columns)
                    asin_lower = asin.lower()
                
                    # Only look in 'ASIN' or 'ASIN (informational only)' columns with case-insensitive exact match
                    # and filter for 'Product' column being 'Sponsored Products' or 'Sponsored Display' and 'Entity' column being 'Product Ad'
                    asin_columns_local = [col for col in combined_bulk_df.columns if 'asin' in col.lower()]
                    valid_asin_cols = [col for col in asin_columns_local if col.lower() in ['asin', 'asin (informational only)']]
                
                    # First check if we have the required columns for filtering
                    if 'Entity' in combined_bulk_df.columns and 'Product' in combined_bulk_df.columns:
                        for col in valid_asin_cols:
                            # Only use exact match with specified filtering criteria
                            filtered_matches = combined_bulk_df[
                                (combined_bulk_df[col].astype(str).str.lower() == asin_lower) & 
                                (combined_bulk_df['Entity'].astype(str).str.strip().str.lower().isin(['product ad', 'product ads'])) & 
                                (combined_bulk_df['Product'].astype(str).isin(['Sponsored Products', 'Sponsored Display']))
                            ]
                        
                            if not filtered_matches.empty:
                                asin_bulk_rows = filtered_matches
                                st.session_state.debug_messages.append(f"[Product Analysis] Found {len(filtered_matches)} rows for ASIN {asin} in column {col}")
                                break
                    
                        if not asin_bulk_rows.empty:
                            # Sum up spend for this ASIN
                            if 'Spend' in asin_bulk_rows.columns:
                                asin_row['Spend'] = asin_bulk_rows['Spend'].sum()
                        
                            # Sum up clicks and orders for this ASIN
                            if 'Clicks' in asin_bulk_rows.columns:
                                asin_row['Clicks'] = asin_bulk_rows['Clicks'].sum()
                        
                            if 'Orders' in asin_bulk_rows.columns:
                                asin_row['Orders'] = asin_bulk_rows['Orders'].sum()
                        
                            # Get ad sales using the appropriate column based on attribution setting
                            # For Sponsored Display rows, use 'Sales (Views & Clicks)' if that attribution is selected
                            sd_rows = asin_bulk_rows[asin_bulk_rows['Product'] == 'Sponsored Display']
                            non_sd_rows = asin_bulk_rows[asin_bulk_rows['Product'] != 'Sponsored Display']
                        
                            # Calculate total ad sales by handling SD and non-SD rows separately
                            total_ad_sales = 0
                        
                            # --- SALES ATTRIBUTION CONSISTENCY: Always respect st.session_state.sd_attribution_choice for sales columns ---
                            # For Sponsored Display rows, check attribution preference
                            if not sd_rows.empty:
                                sd_sales_col = None
                                if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)":
                                    # First try exact match for 'Sales (Views & Clicks)'
                                    if 'Sales (Views & Clicks)' in sd_rows.columns:
                                        sd_sales_col = 'Sales (Views & Clicks)'
                                    # Then try case-insensitive match
                                    else:
                                        sd_sales_cols = [col for col in sd_rows.columns if 'sales (views & clicks)' in col.lower()]
                                        if sd_sales_cols:
                                            sd_sales_col = sd_sales_cols[0]
                            
                                # If no Views & Clicks column found or not selected, fall back to regular sales column
                                if not sd_sales_col:
                                    # First try exact match
                                    if 'Sales' in sd_rows.columns:
                                        sd_sales_col = 'Sales'
                                    # Then try case-insensitive match
                                    else:
                                        sales_cols = [col for col in sd_rows.columns if col.lower() == 'sales']
                                        if sales_cols:
                                            sd_sales_col = sales_cols[0]
                            
                                if sd_sales_col and sd_sales_col in sd_rows.columns:
                                    sd_sales_value = sd_rows[sd_sales_col].sum()
                                    total_ad_sales += sd_sales_value
                        
                            # For non-SD rows, use regular sales column
                            if not non_sd_rows.empty:
                                non_sd_sales_col = None
                                # Look for Sales with exact case-insensitive match
                                sales_cols = [col for col in non_sd_rows.columns if col.lower() == 'sales']
                                if sales_cols:
                                    non_sd_sales_col = sales_cols[0]
                            
                                if non_sd_sales_col and non_sd_sales_col in non_sd_rows.columns:
                                    non_sd_sales_value = non_sd_rows[non_sd_sales_col].sum()
                                    total_ad_sales += non_sd_sales_value
                        
                            asin_row['Ad Sales'] = total_ad_sales
            
                # Pull total sales from sales report if available
                if isinstance(sales_df, pd.DataFrame):
                    # Try to find the ASIN in the sales report with case-insensitive matching
                    if 'ASIN' in sales_df.columns:
                        # Convert both to strings and lowercase for comparison
                        sales_asins = sales_df['ASIN'].astype(str).str.lower()
                        current_asin = asin.lower()
                    
                        # Find matching rows
                        matching_rows = sales_df[sales_asins == current_asin]
                    
                        # If no exact match, try contains
                        if matching_rows.empty:
                            matching_rows = sales_df[sales_asins.str.contains(current_asin, na=False)]
                    
                        if not matching_rows.empty and total_sales_col and total_sales_col in matching_rows.columns:
                            asin_row['Total Sales'] = matching_rows[total_sales_col].sum()
            
                # Calculate ACoS and TACoS
                asin_row['ACoS'] = (asin_row['Spend'] / asin_row['Ad Sales'] * 100) if asin_row['Ad Sales'] > 0 else 0
                asin_row['TACoS'] = (asin_row['Spend'] / asin_row['Total Sales'] * 100) if asin_row['Total Sales'] > 0 else 0
            
                # Add the processed ASIN row to our records
                asin_perf_records.append(asin_row)
        
            # Track unassigned ASINs for debugging
            unassigned_asins = []
        
            # Now process any remaining ASINs from the sales report that weren't in branded_asins_data
            if isinstance(sales_df, pd.DataFrame):
                # Check for ASIN columns with different possible names
                asin_column = None
                possible_asin_columns = ['ASIN', '(Child) ASIN', 'child asin', 'asin', '(Parent) ASIN', 'parent asin', 'sku']
                for col_name in possible_asin_columns:
                    if col_name in sales_df.columns:
                        asin_column = col_name
                        break
            
                # Also check for case-insensitive matches
                if asin_column is None:
                    for col in sales_df.columns:
                        col_lower = str(col).lower().strip()
                        if any(name.lower() in col_lower for name in possible_asin_columns):
                            asin_column = col
                            break
            
                if asin_column is not None:
                    # Check for Title column with different possible names
                    title_column = None
                    possible_title_columns = ['Title', 'Product Title', 'title', 'product name', 'item name']
                
                    for col_name in possible_title_columns:
                        if col_name in sales_df.columns:
                            title_column = col_name
                            break
                
                    # Also check for case-insensitive matches
                    if title_column is None:
                        for col in sales_df.columns:
                            col_lower = str(col).lower().strip()
                            if any(name.lower() in col_lower for name in possible_title_columns):
                                title_column = col
                                break
                
                    # Dump all ASINs for debugging
                    all_asins_in_sales = set(sales_df[asin_column].astype(str).unique())
                    valid_asins = {asin for asin in all_asins_in_sales if asin and asin.lower() != 'nan'}
                    existing_branded_asins = set(str(asin).upper() for asin in branded_asins_data.keys())
                    potential_new_asins = valid_asins - existing_branded_asins
                
                    if potential_new_asins:
                        pass
                    
                    # Process each unique ASIN
                    for asin in sales_df[asin_column].astype(str).unique():
                        if asin in processed_asins or not asin or asin.lower() == 'nan':
                            continue
                        
                        processed_asins.add(asin)
                    
                        # Add to unassigned ASINs list for debugging
                        unassigned_asins.append(asin)
                    
                        # Create a new row for this ASIN
                        asin_row = {}
                        asin_row['Product Group'] = 'Untagged Group'  # Default group for ASINs not in branded_asins_data
                        asin_row['ASIN'] = asin
                    
                        # Try to get product title from sales report if available
                        if title_column is not None:
                            matching_rows = sales_df[sales_df[asin_column].astype(str) == asin]
                            if not matching_rows.empty:
                                asin_row['Product Title'] = matching_rows[title_column].iloc[0]
                            else:
                                asin_row['Product Title'] = f"Unknown Product ({asin})"
                        else:
                            asin_row['Product Title'] = f"Unknown Product ({asin})"
                    
                        # Initialize metrics
                        asin_row['Spend'] = 0
                        asin_row['Ad Sales'] = 0
                        asin_row['Total Sales'] = 0
                        asin_row['% of Spend'] = 0
                        asin_row['% of Ad Sales'] = 0
                        asin_row['% of Total Sales'] = 0
                        asin_row['ACoS'] = 0
                        asin_row['TACoS'] = 0
                        asin_row['Clicks'] = 0
                        asin_row['Orders'] = 0
                    
                        # Process ad metrics and sales data for this ASIN
                        # Pull ad metrics from bulk file if available
                        if isinstance(combined_bulk_df, pd.DataFrame):
                            # Look for this ASIN in the bulk file
                            asin_bulk_rows = pd.DataFrame(columns=combined_bulk_df.columns)
                            asin_lower = asin.lower()
                        
                            # Only look in 'ASIN' or 'ASIN (informational only)' columns with case-insensitive exact match
                            # and filter for 'Product' column being 'Sponsored Products' or 'Sponsored Display' and 'Entity' column being 'Product Ad'
                            asin_columns_local = [col for col in combined_bulk_df.columns if 'asin' in col.lower()]
                            valid_asin_cols = [col for col in asin_columns_local if col.lower() in ['asin', 'asin (informational only)']]
                        
                            # First check if we have the required columns for filtering
                            if 'Entity' in combined_bulk_df.columns and 'Product' in combined_bulk_df.columns:
                                for col in valid_asin_cols:
                                    # Only use exact match with specified filtering criteria
                                    filtered_matches = combined_bulk_df[
                                        (combined_bulk_df[col].astype(str).str.lower() == asin_lower) & 
                                        (combined_bulk_df['Entity'].astype(str).str.strip().str.lower().isin(['product ad', 'product ads'])) & 
                                        (combined_bulk_df['Product'].astype(str).isin(['Sponsored Products', 'Sponsored Display']))
                                    ]
                                
                                    if not filtered_matches.empty:
                                        asin_bulk_rows = filtered_matches
                                        break
                            
                                if not asin_bulk_rows.empty:
                                    # Sum up spend for this ASIN
                                    if 'Spend' in asin_bulk_rows.columns:
                                        asin_row['Spend'] = asin_bulk_rows['Spend'].sum()
                                
                                    # Sum up clicks and orders for this ASIN
                                    if 'Clicks' in asin_bulk_rows.columns:
                                        asin_row['Clicks'] = asin_bulk_rows['Clicks'].sum()
                                
                                    if 'Orders' in asin_bulk_rows.columns:
                                        asin_row['Orders'] = asin_bulk_rows['Orders'].sum()
                                
                                    # Get ad sales using the appropriate column based on attribution setting
                                    # For Sponsored Display rows, use 'Sales (Views & Clicks)' if that attribution is selected
                                    sd_rows = asin_bulk_rows[asin_bulk_rows['Product'] == 'Sponsored Display']
                                    non_sd_rows = asin_bulk_rows[asin_bulk_rows['Product'] != 'Sponsored Display']
                                
                                    # Calculate total ad sales by handling SD and non-SD rows separately
                                    total_ad_sales = 0
                                
                                    # For Sponsored Display rows, check attribution preference
                                    if not sd_rows.empty:
                                        sd_sales_col = None
                                        if 'sd_attribution_choice' in st.session_state and st.session_state.sd_attribution_choice == "Sales (Views & Clicks)":
                                            # First try exact match for 'Sales (Views & Clicks)'
                                            if 'Sales (Views & Clicks)' in sd_rows.columns:
                                                sd_sales_col = 'Sales (Views & Clicks)'
                                            # Then try case-insensitive match
                                            else:
                                                sd_sales_cols = [col for col in sd_rows.columns if 'sales (views & clicks)' in col.lower()]
                                                if sd_sales_cols:
                                                    sd_sales_col = sd_sales_cols[0]
                                    
                                        # If no Views & Clicks column found or not selected, fall back to regular sales column
                                        if not sd_sales_col:
                                            # First try exact match
                                            if 'Sales' in sd_rows.columns:
                                                sd_sales_col = 'Sales'
                                            # Then try case-insensitive match
                                            else:
                                                sales_cols = [col for col in sd_rows.columns if col.lower() == 'sales']
                                                if sales_cols:
                                                    sd_sales_col = sales_cols[0]
                                    
                                        if sd_sales_col and sd_sales_col in sd_rows.columns:
                                            sd_sales_value = sd_rows[sd_sales_col].sum()
                                            total_ad_sales += sd_sales_value
                                
                                    # For non-SD rows, use regular sales column
                                    if not non_sd_rows.empty:
                                        non_sd_sales_col = None
                                        # Look for Sales with exact case-insensitive match
                                        sales_cols = [col for col in non_sd_rows.columns if col.lower() == 'sales']
                                        if sales_cols:
                                            non_sd_sales_col = sales_cols[0]
                                    
                                        if non_sd_sales_col and non_sd_sales_col in non_sd_rows.columns:
                                            non_sd_sales_value = non_sd_rows[non_sd_sales_col].sum()
                                            total_ad_sales += non_sd_sales_value
                                
                                    asin_row['Ad Sales'] = total_ad_sales
                    
                        # Pull total sales from sales report if available
                        if isinstance(sales_df, pd.DataFrame):
                            # Try to find the ASIN in the sales report with case-insensitive matching
                            if 'ASIN' in sales_df.columns:
                                # Convert both to strings and lowercase for comparison
                                sales_asins = sales_df['ASIN'].astype(str).str.lower()
                                current_asin = asin.lower()
                            
                                # Find matching rows
                                matching_rows = sales_df[sales_asins == current_asin]
                            
                                # If no exact match, try contains
                                if matching_rows.empty:
                                    matching_rows = sales_df[sales_asins.str.contains(current_asin, na=False)]
                            
                                if not matching_rows.empty and total_sales_col and total_sales_col in matching_rows.columns:
                                    asin_row['Total Sales'] = matching_rows[total_sales_col].sum()
                    
                        # Calculate ACoS and TACoS
                        asin_row['ACoS'] = (asin_row['Spend'] / asin_row['Ad Sales'] * 100) if asin_row['Ad Sales'] > 0 else 0
                        asin_row['TACoS'] = (asin_row['Spend'] / asin_row['Total Sales'] * 100) if asin_row['Total Sales'] > 0 else 0
                    
                        asin_perf_records.append(asin_row)
        
            # Log how many ASINs were processed
        
            # Log unassigned ASINs
            if unassigned_asins:
                
                    # Prepare titles for unassigned ASINs
                    unassigned_asins_titles = {}
                    for asin in unassigned_asins:
                        if title_column is not None and asin_column is not None:
                            matching_rows = sales_df[sales_df[asin_column].astype(str) == asin]
                            if not matching_rows.empty:
                                unassigned_asins_titles[asin] = matching_rows[title_column].iloc[0]
                            else:
                                unassigned_asins_titles[asin] = f"Unknown Product ({asin})"
                        else:
                            unassigned_asins_titles[asin] = f"Unknown Product ({asin})"
                
                    # Store in session state for the Client Settings Center to use
                    st.session_state.new_sales_asins = unassigned_asins
                    st.session_state.new_sales_asins_titles = unassigned_asins_titles
                    st.session_state.show_new_sales_asins_prompt = True
        
            # Create the DataFrame from the collected records
            asin_perf_df = pd.DataFrame(asin_perf_records)
        
            # Store the ASIN performance data in the session state so it can be accessed by other sections
            st.session_state.asin_perf_df = asin_perf_df
            if not asin_perf_df.empty:
                # --- Filters ---
                col1, col2, col3 = st.columns(3)
                with col1:
                    filter_title = st.text_input("Filter by Product Title", "", key="asin_filter_title")
                with col2:
                    filter_asin = st.text_input("Filter by ASIN", "", key="asin_filter_asin")
                with col3:
                    # --- Product Group Multiselect ---
                    # Gather all unique product groups from the DataFrame
                    product_groups = sorted([g for g in asin_perf_df['Product Group'].dropna().unique() if g])
                
                    # Initialize all session state variables if they don't exist
                    if 'asin_product_group_filter' not in st.session_state:
                        st.session_state.asin_product_group_filter = []
                    if 'asin_filter_active' not in st.session_state:
                        st.session_state.asin_filter_active = False
                
                    # Define a callback function to update related session state variables
                    def update_asin_filter_state():
                        # Update filter active state based on current selection
                        st.session_state.asin_filter_active = len(st.session_state.asin_product_group_filter) > 0
                
                    # Always show the multiselect, but disable it if no product groups
                    if product_groups:
                        # Avoid Streamlit warning by only passing 'default' if session state is not already set
                        if 'asin_product_group_filter' in st.session_state and st.session_state.asin_product_group_filter:
                            st.multiselect(
                                "Filter by Product Group(s)",
                                options=product_groups,
                                key="asin_product_group_filter",
                                on_change=update_asin_filter_state
                            )
                        else:
                            st.multiselect(
                                "Filter by Product Group(s)",
                                options=product_groups,
                                key="asin_product_group_filter",
                                on_change=update_asin_filter_state
                            )
                        # The callback will handle updating session state
                        filter_group = st.session_state.asin_product_group_filter
                    else:
                        st.multiselect(
                            "Filter by Product Group(s) (Add product groups in Client Settings)",
                            options=[],
                            disabled=True,
                            key="asin_product_group_filter_disabled"
                        )
                        # Reset filter state safely
                        if st.session_state.asin_product_group_filter:
                            st.session_state.asin_product_group_filter = []
                            st.session_state.asin_filter_active = False
                        filter_group = []
            
                filtered_df = asin_perf_df.copy()
                if filter_title:
                    filtered_df = filtered_df[filtered_df['Product Title'].str.contains(filter_title, case=False, na=False)]
                if filter_group:
                    filtered_df = filtered_df[filtered_df['Product Group'].isin(filter_group)]
                if filter_asin:
                    filtered_df = filtered_df[filtered_df['ASIN'].str.contains(filter_asin, case=False, na=False)]
            
                # --- Totals Row ---
                global_total_spend = asin_perf_df['Spend'].sum() if 'Spend' in asin_perf_df.columns else 0
                global_total_ad_sales = asin_perf_df['Ad Sales'].sum() if 'Ad Sales' in asin_perf_df.columns else 0
                global_total_sales = asin_perf_df['Total Sales'].sum() if 'Total Sales' in asin_perf_df.columns else 0
            
                # Calculate percentages for each row
                if global_total_spend > 0:
                    filtered_df['% of Spend'] = (filtered_df['Spend'] / global_total_spend * 100).round(2)
                if global_total_ad_sales > 0:
                    filtered_df['% of Ad Sales'] = (filtered_df['Ad Sales'] / global_total_ad_sales * 100).round(2)
                if global_total_sales > 0:
                    filtered_df['% of Total Sales'] = (filtered_df['Total Sales'] / global_total_sales * 100).round(2)
            
                # Add debug info about totals
            
                # --- Totals Row ---
                if not filtered_df.empty:
                    # Removed 'Found In Bulk' column as per user request
                
                    # Default sort will be applied when displaying the dataframe
                
                    # Add debug info about the dataframe
                    top_asins = filtered_df.head(5)['ASIN'].tolist()
                
                                # Add info about untagged ASINs in the filtered dataframe
                untagged_in_filtered = filtered_df[filtered_df['Product Group'] == 'Untagged Group']
                if True:  # Always display table, regardless of untagged ASINs
                    untagged_count = len(untagged_in_filtered)
                    untagged_spend = untagged_in_filtered['Spend'].sum()
                    untagged_sales = untagged_in_filtered['Ad Sales'].sum()
                
                    # Calculate filtered totals for numeric values before formatting
                    filtered_total_spend = filtered_df['Spend'].sum() if 'Spend' in filtered_df.columns else 0
                    filtered_total_ad_sales = filtered_df['Ad Sales'].sum() if 'Ad Sales' in filtered_df.columns else 0
                    filtered_total_sales = filtered_df['Total Sales'].sum() if 'Total Sales' in filtered_df.columns else 0
                    filtered_total_clicks = filtered_df['Clicks'].sum() if 'Clicks' in filtered_df.columns else 0
                
                    # Calculate global totals from the original dataframe (before filtering)
                    global_total_spend = asin_perf_df['Spend'].sum() if 'Spend' in asin_perf_df.columns else 0
                    global_total_ad_sales = asin_perf_df['Ad Sales'].sum() if 'Ad Sales' in asin_perf_df.columns else 0
                    global_total_sales = asin_perf_df['Total Sales'].sum() if 'Total Sales' in asin_perf_df.columns else 0
                
                    # Now calculate percentages for each row based on filtered totals
                    if filtered_total_spend > 0:
                        filtered_df['% of Spend'] = filtered_df['Spend'].apply(lambda x: (x / filtered_total_spend * 100) if filtered_total_spend > 0 else 0)
                    if filtered_total_ad_sales > 0:
                        filtered_df['% of Ad Sales'] = filtered_df['Ad Sales'].apply(lambda x: (x / filtered_total_ad_sales * 100) if filtered_total_ad_sales > 0 else 0)
                    if filtered_total_sales > 0:
                        filtered_df['% of Total Sales'] = filtered_df['Total Sales'].apply(lambda x: (x / filtered_total_sales * 100) if filtered_total_sales > 0 else 0)
                
                    # No pagination - display all rows
                    paged_df = filtered_df.copy()

                    # Format numeric columns for display (on paged_df only)
                    display_df = paged_df.copy()

                    # Remove 'Clicks' and 'Orders', add CVR and AOV
                    for col in ['Clicks', 'Orders']:
                        if col in display_df.columns:
                            display_df = display_df.drop(columns=[col])

                    # Calculate CVR (Orders/Clicks) and AOV (Ad Sales/Orders)
                    clicks = paged_df['Clicks'] if 'Clicks' in paged_df.columns else 0
                    orders = paged_df['Orders'] if 'Orders' in paged_df.columns else 0
                    ad_sales = paged_df['Ad Sales'] if 'Ad Sales' in paged_df.columns else 0

                    # Make sure all are numeric
                    clicks = pd.to_numeric(clicks, errors='coerce').fillna(0)
                    orders = pd.to_numeric(orders, errors='coerce').fillna(0)
                    ad_sales = pd.to_numeric(ad_sales, errors='coerce').fillna(0)

                    # Add CVR and AOV columns
                    display_df['CVR'] = (orders / clicks * 100).replace([np.inf, -np.inf], 0).fillna(0)
                    display_df['AOV'] = (ad_sales / orders).replace([np.inf, -np.inf], 0).fillna(0)

                    money_cols = ['Spend', 'Ad Sales', 'Total Sales', 'AOV']
                    pct_cols = ['% of Spend', '% of Ad Sales', '% of Total Sales', 'ACoS', 'TACoS', 'CVR']

                    # Remove 'Found in Bulk' column if it exists
                    if 'Found In Bulk' in display_df.columns:
                        display_df = display_df.drop(columns=['Found In Bulk'])
                
                    # Remove Product Group column if no product groups are defined in Branded ASINs
                    has_product_groups = False
                    if 'client_config' in st.session_state and 'branded_asins_data' in st.session_state.client_config:
                        # Check if any ASIN has a product group defined
                        has_product_groups = any(info.get('product_group', '') for info in st.session_state.client_config['branded_asins_data'].values())
                
                    if not has_product_groups and 'Product Group' in display_df.columns:
                        display_df = display_df.drop(columns=['Product Group'])

                    # Ensure all columns are numeric for proper sorting
                    for col in money_cols:
                        if col in display_df.columns:
                            display_df[col] = pd.to_numeric(display_df[col], errors='coerce').fillna(0)
                    for col in pct_cols:
                        if col in display_df.columns:
                            display_df[col] = pd.to_numeric(display_df[col], errors='coerce').fillna(0)

                    # Calculate ACoS and TACoS for filtered totals
                    filtered_acos = (filtered_total_spend / filtered_total_ad_sales * 100) if filtered_total_ad_sales > 0 else 0
                    filtered_tacos = (filtered_total_spend / filtered_total_sales * 100) if filtered_total_sales > 0 else 0

                    # Create totals row with proper formatting
                    # Calculate totals for CVR and AOV (global, not just current page)
                    global_clicks = asin_perf_df['Clicks'] if 'Clicks' in asin_perf_df.columns else 0
                    global_orders = asin_perf_df['Orders'] if 'Orders' in asin_perf_df.columns else 0
                    global_ad_sales = asin_perf_df['Ad Sales'] if 'Ad Sales' in asin_perf_df.columns else 0
                    global_clicks = pd.to_numeric(global_clicks, errors='coerce').fillna(0)
                    global_orders = pd.to_numeric(global_orders, errors='coerce').fillna(0)
                    global_ad_sales = pd.to_numeric(global_ad_sales, errors='coerce').fillna(0)
                    global_cvr = (global_orders.sum() / global_clicks.sum() * 100) if global_clicks.sum() > 0 else 0
                    global_aov = (global_ad_sales.sum() / global_orders.sum()) if global_orders.sum() > 0 else 0

                    # Calculate CPC (Cost Per Click)
                    filtered_cpc = (filtered_total_spend / filtered_total_clicks) if filtered_total_clicks > 0 else 0

                    # Calculate percentage of filtered vs total for the totals row
                    filtered_spend_pct = (filtered_total_spend / global_total_spend * 100) if global_total_spend > 0 else 0
                    filtered_ad_sales_pct = (filtered_total_ad_sales / global_total_ad_sales * 100) if global_total_ad_sales > 0 else 0
                    filtered_total_sales_pct = (filtered_total_sales / global_total_sales * 100) if global_total_sales > 0 else 0

                    totals = {
                        'ASIN': 'Total',
                        'Spend': f"${filtered_total_spend:,.2f}",
                        'Ad Sales': f"${filtered_total_ad_sales:,.2f}",
                        'Total Sales': f"${filtered_total_sales:,.2f}",
                        '% of Spend': f"{filtered_spend_pct:.2f}%",
                        '% of Ad Sales': f"{filtered_ad_sales_pct:.2f}%",
                        '% of Total Sales': f"{filtered_total_sales_pct:.2f}%",
                        'ACoS': f"{filtered_acos:.2f}%",
                        'TACoS': f"{filtered_tacos:.2f}%",
                        'CVR': f"{global_cvr:.2f}%",
                        'AOV': f"${global_aov:,.2f}",
                        'CPC': f"${filtered_cpc:.2f}"
                    }
                
                
                    # Create the total row as a separate DataFrame
                    total_row = pd.DataFrame([totals])
                
                    # Display the totals row in a separate table with ACoS conditional formatting
                    account_wide_acos = None
                    if 'client_config' in st.session_state:
                        goals = st.session_state.client_config.get('goals', {})
                        account_wide_acos = goals.get('account_wide_acos', None)
                    style_acos(total_row, account_wide_acos)

                    # Using global color gradient functions defined at the top of the file

                    # Create a dictionary for formatting
                    fmt_dict = {
                        'Spend': lambda x: f"${x:,.2f}",
                        'Ad Sales': lambda x: f"${x:,.2f}",
                        'Total Sales': lambda x: f"${x:,.2f}",
                        'AOV': lambda x: f"${x:,.2f}",
                        'CPC': lambda x: f"${x:,.2f}",
                        '% of Spend': lambda x: f"{x:.2f}%",
                        '% of Ad Sales': lambda x: f"{x:.2f}%",
                        '% of Total Sales': lambda x: f"{x:.2f}%",
                        'ACoS': lambda x: f"{x:.2f}%",
                        'TACoS': lambda x: f"{x:.2f}%",
                        'CVR': lambda x: f"{x:.2f}%"
                    }
                
                    # Convert string-formatted values back to numeric for proper sorting
                    numeric_df = display_df.copy()
                    for col in money_cols:
                        if col in numeric_df.columns:
                            numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')
                    for col in pct_cols:
                        if col in numeric_df.columns:
                            numeric_df[col] = pd.to_numeric(numeric_df[col].astype(str).str.replace('%', ''), errors='coerce')
                
                    # Sort by Total Sales in descending order
                    numeric_df = numeric_df.sort_values(by='Total Sales', ascending=False)
                
                    styled_df = numeric_df.style.format(fmt_dict)
                
                    # Apply styling to each column individually to ensure colors are independent - same approach as Product Group table
                    # For Performance by ASIN table, use a scale_max of 40%
                    if '% of Spend' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_blue(v, 0, 100, scale_max=40) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
                    if '% of Ad Sales' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100, scale_max=40) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
                    if '% of Total Sales' in numeric_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_green(v, 0, 100, scale_max=40) 
                                                            if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Total Sales' else [''] * len(x), axis=0)
                
                    # Display the dataframe with sorting enabled
                    st.dataframe(styled_df, use_container_width=True, hide_index=True)

                    # Display row count at the bottom
                    st.caption(f"Total Rows: {len(filtered_df)}")

                    # Add extra spacing above the ASIN Allocation Chart
                    st.markdown("<br><br>", unsafe_allow_html=True)
                    # Create a stacked bar chart to visualize Spend, Ad Sales, and Total Sales by ASIN
                    st.markdown("##### ASIN Allocation Chart")
                
                    # Create tabs for different visualization types
                    asin_viz_tabs = st.tabs(["% Values", "$ Values", "Bubble Chart", "Donut Chart"])
                
                    # Initialize common variables with default values
                    if 'asin_viz_sort_by' not in st.session_state:
                        st.session_state.asin_viz_sort_by = "Total Sales"
                    if 'asin_viz_count' not in st.session_state:
                        st.session_state.asin_viz_count = 10
                    if 'asin_title_length' not in st.session_state:
                        st.session_state.asin_title_length = 45
                
                    # Prepare base data for visualization
                    base_chart_df = filtered_df.copy()
                
                    # Ensure all values are numeric
                    for col in ['Spend', 'Ad Sales', 'Total Sales', 'ACoS', 'TACoS']:
                        if col in base_chart_df.columns:
                            base_chart_df[col] = pd.to_numeric(base_chart_df[col].astype(str).str.replace('$', '').str.replace('%', '').str.replace(',', ''), errors='coerce').fillna(0)
                
                    # Create shortened labels for ASINs with customizable length
                    def format_product_title(asin, title, max_length):
                        # If title is too long, truncate and add ellipsis
                        if len(title) > max_length:
                            truncated_title = title[:max_length] + '...'
                        else:
                            truncated_title = title
                    
                        # Format with ASIN in bold
                        return f"{asin} - {truncated_title}"
                
                    # Always use stacked mode
                    barmode = 'stack'
                
                    # Custom color scheme that works well in dark mode
                    custom_colors = {
                        'Spend': '#EA4335',      # Red for Spend
                        'Ad Sales': '#4285F4',  # Blue for Ad Sales
                        'Total Sales': '#34A853' # Green for Total Sales
                    }
                
                    # Percentage Values Tab (now first tab)
                    with asin_viz_tabs[0]:
                        # Add chart controls specific to % Values tab
                        with st.expander("Chart Display Options", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                sort_by_pct = st.selectbox(
                                    "Sort ASINs by:",
                                    options=["Total Sales", "Spend", "Ad Sales"],
                                    index=0,
                                    key="asin_viz_sort_by_pct"
                                )
                                # Update the session state for other tabs to use
                                st.session_state.asin_viz_sort_by = sort_by_pct
                            with col2:
                                display_count_pct = st.selectbox(
                                    "Number of ASINs to display:",
                                    options=[5, 10, 15, 20],
                                    index=1,
                                    key="asin_viz_count_pct"
                                )
                                # Update the session state for other tabs to use
                                st.session_state.asin_viz_count = display_count_pct
                        
                            # Title length control
                            title_length_pct = st.slider(
                                "Product title length:",
                                min_value=20,
                                max_value=150,
                                value=45,
                                step=5,
                                key="asin_title_length_pct"
                            )
                            # Update the session state for other tabs to use
                            st.session_state.asin_title_length = title_length_pct
                    
                        # Use the values from this tab's controls
                        sort_by = sort_by_pct
                        display_count = display_count_pct
                        title_length = title_length_pct
                    
                        # Create a copy of the data for this tab
                        chart_df = base_chart_df.copy()
                    
                        # Sort based on user selection
                        if sort_by in chart_df.columns:
                            # Always sort descending for Spend, Total Sales, Ad Sales
                            ascending = False
                            chart_df = chart_df.sort_values(by=sort_by, ascending=ascending).head(display_count)
                        else:
                            # Default sort by Total Sales
                            chart_df = chart_df.sort_values(by='Total Sales', ascending=False).head(display_count)
                    
                        # Apply formatting with user-selected length
                        chart_df['label'] = chart_df.apply(
                            lambda row: format_product_title(
                                row['ASIN'], 
                                row['Product Title'], 
                                title_length
                            ),
                            axis=1
                        )
                        # Create percentage data
                        pct_df = chart_df.copy()
                    
                        # Calculate percentages based on ALL ASINs, not just displayed ones
                        # Use the global totals from the original filtered_df (before limiting to display_count)
                        total_spend_all = filtered_df['Spend'].sum()
                        total_ad_sales_all = filtered_df['Ad Sales'].sum()
                        total_sales_all = filtered_df['Total Sales'].sum()
                    
                        pct_df['Spend %'] = np.where(total_spend_all > 0, (pct_df['Spend'] / total_spend_all * 100).round(1), 0.0)
                        pct_df['Ad Sales %'] = np.where(total_ad_sales_all > 0, (pct_df['Ad Sales'] / total_ad_sales_all * 100).round(1), 0.0)
                        pct_df['Total Sales %'] = np.where(total_sales_all > 0, (pct_df['Total Sales'] / total_sales_all * 100).round(1), 0.0)
                        # Fill any remaining NaNs in % columns just in case
                        pct_df[['Spend %', 'Ad Sales %', 'Total Sales %']] = pct_df[['Spend %', 'Ad Sales %', 'Total Sales %']].fillna(0.0)
                    
                        # Set fixed label position
                        if 'label_position' not in st.session_state:
                            st.session_state.label_position = 'outside'
                    
                        # Create the % values chart - horizontal orientation with enhanced styling
                        fig_pct = px.bar(
                            pct_df,
                            y='label',  # Now y-axis has the labels
                            x=['Spend %', 'Ad Sales %', 'Total Sales %'],  # Now x-axis has the values
                            title=f'Top {display_count} ASINs by {sort_by} (% of All ASINs)',
                            labels={'label': 'ASIN', 'value': 'Percentage (%)', 'variable': 'Metric'},
                            height=600,  # Increased height for better readability
                            barmode=barmode,
                            orientation='h',  # Horizontal bars
                            color_discrete_map={
                                'Spend %': '#EA4335',  # Red for Spend
                                'Ad Sales %': '#4285F4',  # Blue for Ad Sales
                                'Total Sales %': '#34A853'  # Green for Total Sales
                            },
                            text_auto=False,  # We will set text manually to avoid NaN%
                            template='plotly_dark'  # Use a dark theme for better visual appeal
                        )
                        # Ensure bar text always shows a value, never NaN
                        for metric in ['Spend %', 'Ad Sales %', 'Total Sales %']:
                            fig_pct.for_each_trace(lambda trace: trace.update(text=[f'{v:.1f}%' if not pd.isna(v) and v > 0 else '0.0%' for v in trace.x]) if trace.name == metric else None)
                    
                        # Determine font size based on number of ASINs displayed
                        y_axis_font_size = 14 if display_count <= 10 else 11
                    
                        # Improve layout for horizontal chart with enhanced styling
                        fig_pct.update_layout(
                            xaxis=dict(
                                title=dict(text='Percentage (%)', font=dict(size=14, family="Arial, sans-serif")),
                                tickformat='.1f',
                                ticksuffix='%',
                                gridcolor='rgba(255,255,255,0.1)',
                                showgrid=True,
                                zeroline=True,
                                tickfont=dict(family="Arial, sans-serif")
                            ),
                            yaxis=dict(
                                title='',
                                automargin=True,  # Ensure there's enough space for labels
                                tickfont=dict(size=y_axis_font_size, family="Arial, sans-serif"),
                                gridcolor='rgba(0,0,0,0)'  # No horizontal grid lines
                            ),
                            legend=dict(
                                title='',
                                orientation='h',
                                yanchor='bottom',
                                y=1.02,
                                xanchor='right',
                                x=1,
                                bgcolor='rgba(0,0,0,0.5)',
                                bordercolor='rgba(255,255,255,0.3)',
                                font=dict(family="Arial, sans-serif", size=12)
                            ),
                            margin=dict(l=40, r=40, t=70, b=100),
                            hovermode='closest',
                            plot_bgcolor='rgba(0,0,0,0)',  # Transparent background
                            paper_bgcolor='rgba(0,0,0,0)',  # Transparent paper
                            title=dict(
                                text=f'Top {display_count} ASINs by {sort_by} (% of All ASINs)',
                                font=dict(size=16, family="Arial, sans-serif")
                            ),
                            hoverlabel=dict(
                                bgcolor='rgba(0,0,0,0.8)',
                                font_size=12,
                                font=dict(family="Arial, sans-serif", color='white')
                            )
                        )
                    
                        # Determine text size based on number of ASINs displayed
                        bar_text_size = 14 if display_count <= 10 else 11
                    
                        # Improve text display on bars with fixed position
                        fig_pct.update_traces(
                            textposition='outside',  # Fixed to outside position
                            textfont=dict(size=bar_text_size, family="Arial, sans-serif", color="white"),
                            hovertemplate='<b>%{y}</b><br>' +
                                         '%{x:.1f}% of total<br>' +
                                         '<extra></extra>',
                            texttemplate='%{text}',  # Use the custom text we defined above
                            selector=dict(type='bar'),
                            opacity=0.9,  # Slight transparency for better aesthetics
                            marker=dict(line=dict(width=0.5, color='rgba(255,255,255,0.2)'))  # Add subtle borders
                        )
                    
                        # No reference lines needed for stacked mode
                    
                        # Display the chart
                        st.plotly_chart(fig_pct, use_container_width=True)
                
                    # Dollar Values Tab (now second tab)
                    with asin_viz_tabs[1]:
                        # Add chart controls specific to $ Values tab
                        with st.expander("Chart Display Options", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                # Get index of current sort_by value in options list
                                sort_options = ["Total Sales", "Spend", "Ad Sales"]
                                current_sort_index = sort_options.index(st.session_state.asin_viz_sort_by) if st.session_state.asin_viz_sort_by in sort_options else 0
                            
                                sort_by_dollar = st.selectbox(
                                    "Sort ASINs by:",
                                    options=sort_options,
                                    index=current_sort_index,
                                    key="asin_viz_sort_by_dollar"
                                )
                                # Update the session state for other tabs to use
                                st.session_state.asin_viz_sort_by = sort_by_dollar
                            with col2:
                                # Get index of current display count in options list
                                count_options = [5, 10, 15, 20]
                                current_count_index = count_options.index(st.session_state.asin_viz_count) if st.session_state.asin_viz_count in count_options else 1
                            
                                display_count_dollar = st.selectbox(
                                    "Number of ASINs to display:",
                                    options=count_options,
                                    index=current_count_index,
                                    key="asin_viz_count_dollar"
                                )
                                # Update the session state for other tabs to use
                                st.session_state.asin_viz_count = display_count_dollar
                        
                            # Title length control
                            title_length_dollar = st.slider(
                                "Product title length:",
                                min_value=20,
                                max_value=150,
                                value=st.session_state.asin_title_length,
                                step=5,
                                key="asin_title_length_dollar"
                            )
                            # Update the session state for other tabs to use
                            st.session_state.asin_title_length = title_length_dollar
                    
                        # Use the values from this tab's controls
                        sort_by = sort_by_dollar
                        display_count = display_count_dollar
                        title_length = title_length_dollar
                    
                        # Create a copy of the data for this tab
                        chart_df = base_chart_df.copy()
                    
                        # Sort based on user selection
                        if sort_by in chart_df.columns:
                            # Always sort descending for Spend, Total Sales, Ad Sales
                            ascending = False
                            chart_df = chart_df.sort_values(by=sort_by, ascending=ascending).head(display_count)
                        else:
                            # Default sort by Total Sales
                            chart_df = chart_df.sort_values(by='Total Sales', ascending=False).head(display_count)
                    
                        # Apply formatting with user-selected length
                        chart_df['label'] = chart_df.apply(
                            lambda row: format_product_title(
                                row['ASIN'], 
                                row['Product Title'], 
                                title_length
                            ),
                            axis=1
                        )
                        # Create the $ values chart - horizontal orientation
                        fig_dollars = px.bar(
                            chart_df,
                            y='label',  # Now y-axis has the labels
                            x=['Spend', 'Ad Sales', 'Total Sales'],  # Now x-axis has the values
                            title=f'Top {display_count} ASINs by {sort_by} ($)',
                            labels={'label': 'ASIN', 'value': 'Amount ($)', 'variable': 'Metric'},
                            height=600,  # Increased height for better readability
                            barmode=barmode,
                            orientation='h',  # Horizontal bars
                            color_discrete_map=custom_colors,
                            text_auto=False  # We'll set custom text formatting
                        )
                    
                        # Determine font size based on number of ASINs displayed
                        y_axis_font_size = 14 if display_count <= 10 else 10
                    
                        # Improve layout for horizontal chart
                        fig_dollars.update_layout(
                            xaxis=dict(
                                title=dict(text='Amount ($)', font=dict(size=14, family="Arial, sans-serif")),
                                tickformat='$,.0f',
                                gridcolor='rgba(255,255,255,0.1)',
                                showgrid=True,
                                zeroline=True,
                                zerolinecolor='rgba(255,255,255,0.3)'
                            ),
                            yaxis=dict(
                                title='',
                                automargin=True,  # Ensure there's enough space for labels
                                tickfont=dict(size=y_axis_font_size, family="Arial, sans-serif"),
                                gridcolor='rgba(0,0,0,0)'  # No horizontal grid lines
                            ),
                            legend=dict(
                                title='',
                                orientation='h',
                                yanchor='bottom',
                                y=1.02,
                                xanchor='right',
                                x=1,
                                bgcolor='rgba(0,0,0,0.5)',
                                bordercolor='rgba(255,255,255,0.3)',
                                font=dict(family="Arial, sans-serif", size=12)
                            ),
                            margin=dict(l=40, r=40, t=60, b=100),
                            hovermode='closest',
                            plot_bgcolor='rgba(0,0,0,0)',  # Transparent background
                            paper_bgcolor='rgba(0,0,0,0)',  # Transparent paper
                            template='plotly_dark',  # Use a dark theme for better visual appeal
                            hoverlabel=dict(
                                bgcolor='rgba(0,0,0,0.8)',
                                font_size=12,
                                font=dict(family="Arial, sans-serif", color='white')
                            )
                        )
                    
                        # Determine text size based on number of ASINs displayed
                        bar_text_size = 13 if display_count <= 10 else 10
                    
                        # Custom text formatting for dollar values
                        for i, metric in enumerate(['Spend', 'Ad Sales', 'Total Sales']):
                            # Format dollar values with appropriate scaling
                            def format_currency(value):
                                if value >= 1000000:  # $1M+
                                    return f'${value/1000000:.1f}M'
                                elif value >= 1000:   # $1K+
                                    return f'${value/1000:.0f}K'
                                else:
                                    return f'${value:.0f}'
                        
                            # Apply custom text to each trace
                            fig_dollars.data[i].text = [format_currency(val) if val > 0 else '' for val in fig_dollars.data[i].x]
                    
                        # Improve text display on bars
                        fig_dollars.update_traces(
                            textposition='outside',
                            textfont=dict(size=bar_text_size, family="Arial, sans-serif", color="white"),
                            hovertemplate='<b>%{y}</b><br>' +
                                         '%{fullData.name}: $%{x:,.2f}<br>' +
                                         '<extra></extra>',
                            selector=dict(type='bar'),
                            opacity=0.9,  # Slight transparency for better aesthetics
                            marker=dict(line=dict(width=0.5, color='rgba(255,255,255,0.2)'))  # Add subtle borders
                        )
                    
                        # No reference lines needed for stacked mode
                    
                        # Display the chart
                        st.plotly_chart(fig_dollars, use_container_width=True)
                
                    # Bubble Chart Visualization Tab
                    with asin_viz_tabs[2]:
                        # Add chart controls specific to Bubble Chart tab
                        with st.expander("Chart Display Options", expanded=False):
                            # Only show Bubble Chart specific controls
                            st.markdown("### Bubble Chart Axes")
                            col1, col2 = st.columns(2)
                            with col1:
                                x_metric = st.selectbox(
                                    "X-Axis Metric:",
                                    options=["Spend", "ACoS", "ROAS", "CTR", "CVR", "Ad Sales"],
                                    index=0,  # Spend as default
                                    key="bubble_x_metric"
                                )
                            with col2:
                                y_metric = st.selectbox(
                                    "Y-Axis Metric:",
                                    options=["Total Sales", "Ad Sales", "ACoS", "ROAS", "CTR", "CVR"],
                                    index=0,  # Total Sales as default
                                    key="bubble_y_metric"
                                )
                        
                            # Best-fit line options
                            st.markdown("### Best-Fit Line Options")
                            col3, col4 = st.columns(2)
                            with col3:
                                show_best_fit = st.checkbox(
                                    "Show Best-Fit Line",
                                    value=True,
                                    key="show_best_fit_line",
                                    help="Add a trend line to show the relationship between the selected metrics"
                                )
                            with col4:
                                if show_best_fit:
                                    best_fit_scope = st.selectbox(
                                        "Best-Fit Data Scope:",
                                        options=["Current filtered data", "All account data"],
                                        index=0,  # Current filtered data as default
                                        key="best_fit_scope",
                                        help="Choose whether to calculate the trend line based on current filters/pivot or all data in the account"
                                    )
                                else:
                                    # Set default when not showing best fit line
                                    best_fit_scope = "Current filtered data"
                    
                        # Use the values from the session state
                        sort_by = st.session_state.asin_viz_sort_by
                        display_count = st.session_state.asin_viz_count
                        title_length = st.session_state.asin_title_length
                    
                        # Values are now taken from session state
                    
                        # Create a copy of the data for this tab
                        chart_df = base_chart_df.copy()
                    
                        # Sort based on user selection
                        if sort_by in chart_df.columns:
                            # Always sort descending for Spend, Total Sales, Ad Sales
                            ascending = False
                            chart_df = chart_df.sort_values(by=sort_by, ascending=ascending).head(display_count)
                        else:
                            # Default sort by Total Sales
                            chart_df = chart_df.sort_values(by='Total Sales', ascending=False).head(display_count)
                    
                        # Apply formatting with user-selected length
                        chart_df['label'] = chart_df.apply(
                            lambda row: format_product_title(
                                row['ASIN'], 
                                row['Product Title'], 
                                title_length
                            ),
                            axis=1
                        )
                        # Create a copy of the data for bubble chart
                        bubble_df = chart_df.copy()
                    
                        # Add percentage columns for hover information
                        bubble_df['Spend %'] = np.where(total_spend_all > 0, (bubble_df['Spend'] / total_spend_all * 100).round(1), 0.0)
                        bubble_df['Ad Sales %'] = np.where(total_ad_sales_all > 0, (bubble_df['Ad Sales'] / total_ad_sales_all * 100).round(1), 0.0)
                        bubble_df['Total Sales %'] = np.where(total_sales_all > 0, (bubble_df['Total Sales'] / total_sales_all * 100).round(1), 0.0)
                    
                        # Ensure numeric values for all metrics
                        for col in ['ACoS', 'ROAS', 'CTR', 'CVR']:
                            if col in bubble_df.columns:
                                bubble_df[col] = pd.to_numeric(bubble_df[col].astype(str).str.replace('%', '').str.replace('x', '').str.replace(',', ''), errors='coerce').fillna(0)
                    
                        # Axis metrics are now selected in the Chart Display Options expander
                    
                        # Create hover text with comprehensive metrics
                        def create_hover_text(row):
                            hover_text = f"<b>{row['ASIN']}</b><br>"
                            hover_text += f"{row['Product Title'][:50]}{'...' if len(row['Product Title']) > 50 else ''}<br><br>"
                            hover_text += f"<b>Total Sales:</b> ${row['Total Sales']:,.2f} ({row['Total Sales %']:.1f}%)<br>"
                            hover_text += f"<b>Ad Sales:</b> ${row['Ad Sales']:,.2f} ({row['Ad Sales %']:.1f}%)<br>"
                            hover_text += f"<b>Spend:</b> ${row['Spend']:,.2f} ({row['Spend %']:.1f}%)<br>"
                        
                            if 'ACoS' in row and not pd.isna(row['ACoS']):
                                hover_text += f"<b>ACoS:</b> {row['ACoS']:.1f}%<br>"
                            if 'ROAS' in row and not pd.isna(row['ROAS']):
                                hover_text += f"<b>ROAS:</b> {row['ROAS']:.1f}x<br>"
                            if 'CTR' in row and not pd.isna(row['CTR']):
                                hover_text += f"<b>CTR:</b> {row['CTR']:.2f}%<br>"
                            if 'CVR' in row and not pd.isna(row['CVR']):
                                hover_text += f"<b>CVR:</b> {row['CVR']:.2f}%<br>"
                        
                            return hover_text
                    
                        bubble_df['hover_text'] = bubble_df.apply(create_hover_text, axis=1)
                    
                        # Calculate and add best-fit line if requested
                        best_fit_line_data = None
                        if show_best_fit and len(bubble_df) > 2:
                            try:
                                # Determine which dataset to use for best-fit calculation
                                if best_fit_scope == "All account data":
                                    # Use all base_chart_df data (before limiting to display_count)
                                    bestfit_df = base_chart_df.copy()
                                else:
                                    # Use only the currently filtered/displayed data
                                    bestfit_df = bubble_df.copy()
                            
                                # Ensure numeric values for best-fit calculation
                                for col in ['ACoS', 'ROAS', 'CTR', 'CVR']:
                                    if col in bestfit_df.columns:
                                        bestfit_df[col] = pd.to_numeric(bestfit_df[col].astype(str).str.replace('%', '').str.replace('x', '').str.replace(',', ''), errors='coerce').fillna(0)
                            
                                # Clean data for best-fit calculation (remove NaN and infinite values)
                                bestfit_clean = bestfit_df[[x_metric, y_metric]].dropna()
                                bestfit_clean = bestfit_clean[np.isfinite(bestfit_clean[x_metric]) & np.isfinite(bestfit_clean[y_metric])]
                            
                                if len(bestfit_clean) > 2:
                                    # Calculate linear regression
                                    X = bestfit_clean[x_metric].values.reshape(-1, 1)
                                    y = bestfit_clean[y_metric].values
                                
                                    model = LinearRegression()
                                    model.fit(X, y)
                                
                                    # Generate line points
                                    x_min, x_max = bestfit_clean[x_metric].min(), bestfit_clean[x_metric].max()
                                    x_line = np.linspace(x_min, x_max, 100)
                                    y_line = model.predict(x_line.reshape(-1, 1))
                                
                                    # Calculate R-squared
                                    r_squared = model.score(X, y)
                                
                                    # Store best-fit line data
                                    best_fit_line_data = {
                                        'x': x_line,
                                        'y': y_line,
                                        'r_squared': r_squared,
                                        'slope': model.coef_[0],
                                        'intercept': model.intercept_,
                                        'data_scope': best_fit_scope,
                                        'n_points': len(bestfit_clean)
                                    }
                            except Exception as e:
                                st.warning(f"Could not calculate best-fit line: {str(e)}")
                                best_fit_line_data = None
                    
                        # Create the bubble chart
                        fig_bubble = px.scatter(
                            bubble_df,
                            x=x_metric,
                            y=y_metric,
                            size="Ad Sales",  # Bubble size represents Ad Sales
                            color="ACoS" if "ACoS" in bubble_df.columns else "Total Sales",  # Color represents ACoS if available
                            hover_name="ASIN",
                            text="ASIN",
                            size_max=60,
                            color_continuous_scale="RdYlGn_r" if "ACoS" in bubble_df.columns else "Viridis",  # Red-Yellow-Green reversed for ACoS
                            title=f'ASIN Performance: {y_metric} vs {x_metric}',
                            height=600,
                            template='plotly_dark'
                        )
                    
                        # Format hover text
                        fig_bubble.update_traces(
                            hovertemplate='%{customdata}<extra></extra>',
                            customdata=bubble_df['hover_text'],
                            textposition='top center',
                            textfont=dict(family="Arial, sans-serif", size=10, color="white"),
                            marker=dict(opacity=0.8, line=dict(width=1, color='white'))
                        )
                    
                        # Update layout
                        x_suffix = '%' if x_metric in ['ACoS', 'CTR', 'CVR'] else 'x' if x_metric == 'ROAS' else ''
                        y_suffix = '%' if y_metric in ['ACoS', 'CTR', 'CVR'] else 'x' if y_metric == 'ROAS' else ''
                    
                        fig_bubble.update_layout(
                            xaxis=dict(
                                title=dict(text=f"{x_metric} {x_suffix}", font=dict(size=14, family="Arial, sans-serif")),
                                ticksuffix=x_suffix,
                                gridcolor='rgba(255,255,255,0.1)',
                                zeroline=True,
                                zerolinecolor='rgba(255,255,255,0.3)'
                            ),
                            yaxis=dict(
                                title=dict(text=f"{y_metric} {y_suffix}", font=dict(size=14, family="Arial, sans-serif")),
                                ticksuffix=y_suffix if y_suffix else '',
                                tickprefix='$' if y_metric in ['Total Sales', 'Ad Sales', 'Spend'] else '',
                                gridcolor='rgba(255,255,255,0.1)',
                                zeroline=True,
                                zerolinecolor='rgba(255,255,255,0.3)'
                            ),
                            coloraxis_colorbar=dict(
                                title="ACoS" if "ACoS" in bubble_df.columns else "Total Sales",
                                ticksuffix="%" if "ACoS" in bubble_df.columns else "",
                                tickprefix="" if "ACoS" in bubble_df.columns else "$"
                            ),
                            margin=dict(l=40, r=40, t=60, b=40),
                            legend=dict(orientation='h'),
                            hoverlabel=dict(
                                bgcolor='rgba(0,0,0,0.8)',
                                font_size=12,
                                font=dict(family="Arial, sans-serif", color='white')
                            )
                        )
                    
                        # Add best-fit line to the chart if calculated
                        if best_fit_line_data is not None:
                            # Add the best-fit line to the figure
                            fig_bubble.add_trace(go.Scatter(
                                x=best_fit_line_data['x'],
                                y=best_fit_line_data['y'],
                                mode='lines',
                                name=f'Best-Fit Line (R² = {best_fit_line_data["r_squared"]:.3f})',
                                line=dict(
                                    color='rgba(255, 255, 0, 0.8)',  # Yellow line
                                    width=2,
                                    dash='dash'
                                ),
                                hovertemplate=f'<b>Best-Fit Line</b><br>' +
                                             f'R² = {best_fit_line_data["r_squared"]:.3f}<br>' +
                                             f'Slope = {best_fit_line_data["slope"]:.2e}<br>' +
                                             f'Data: {best_fit_line_data["data_scope"]}<br>' +
                                             f'Points: {best_fit_line_data["n_points"]}<br>' +
                                             f'{x_metric}: %{{x}}<br>' +
                                             f'{y_metric}: %{{y}}<extra></extra>',
                                showlegend=True
                            ))
                        
                            # Update layout to show legend if best-fit line is displayed
                            fig_bubble.update_layout(
                                showlegend=True,
                                legend=dict(
                                    orientation='h',
                                    yanchor='bottom',
                                    y=1.02,
                                    xanchor='right',
                                    x=1,
                                    bgcolor='rgba(0,0,0,0.5)',
                                    bordercolor='rgba(255,255,255,0.2)',
                                    borderwidth=1
                                )
                            )
                    
                        # Display the bubble chart
                        st.plotly_chart(fig_bubble, use_container_width=True)
                    
                        # Display best-fit line statistics if available
                        if best_fit_line_data is not None:
                            with st.expander("📊 Best-Fit Line Statistics", expanded=False):
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("R-squared", f"{best_fit_line_data['r_squared']:.3f}")
                                with col2:
                                    st.metric("Slope", f"{best_fit_line_data['slope']:.2e}")
                                with col3:
                                    st.metric("Data Points", f"{best_fit_line_data['n_points']:,}")
                                with col4:
                                    st.metric("Data Scope", best_fit_line_data['data_scope'])
                            
                                # Interpretation text
                                r_squared = best_fit_line_data['r_squared']
                                if r_squared >= 0.7:
                                    interpretation = "Strong positive correlation"
                                elif r_squared >= 0.5:
                                    interpretation = "Moderate positive correlation"
                                elif r_squared >= 0.3:
                                    interpretation = "Weak positive correlation"
                                else:
                                    interpretation = "Very weak or no correlation"
                            
                                st.info(f"**Interpretation:** {interpretation} between {x_metric} and {y_metric}")
                    
                        # Add some spacing after the chart
                        st.markdown("<div style='margin-top:1rem;'></div>", unsafe_allow_html=True)
                
                    # Donut Chart Visualization Tab
                    with asin_viz_tabs[3]:
                        # Add chart controls specific to Donut Chart tab
                        with st.expander("Chart Display Options", expanded=False):
                            # Only show Donut Chart specific options
                            st.markdown("### Donut Chart Options")
                            donut_size = st.slider(
                                "Donut hole size:",
                                min_value=0.3,
                                max_value=0.8,
                                value=0.6,
                                step=0.05,
                                key="donut_hole_size"
                            )
                        
                            text_position = st.radio(
                                "Label position:",
                                options=["outside", "inside", "auto"],
                                index=0,
                                key="donut_text_position",
                                horizontal=True
                            )
                    
                        # Use the values from the session state
                        sort_by = st.session_state.asin_viz_sort_by
                        display_count = st.session_state.asin_viz_count
                        title_length = st.session_state.asin_title_length
                    
                        # Values are now taken from session state
                    
                        # Create a copy of the data for this tab
                        chart_df = base_chart_df.copy()
                    
                        # Sort based on user selection
                        if sort_by in chart_df.columns:
                            # Always sort descending for Spend, Total Sales, Ad Sales
                            ascending = False
                            chart_df = chart_df.sort_values(by=sort_by, ascending=ascending).head(display_count)
                        else:
                            # Default sort by Total Sales
                            chart_df = chart_df.sort_values(by='Total Sales', ascending=False).head(display_count)
                    
                        # Apply formatting with user-selected length
                        chart_df['label'] = chart_df.apply(
                            lambda row: format_product_title(
                                row['ASIN'], 
                                row['Product Title'], 
                                title_length
                            ),
                            axis=1
                        )
                        # Create a copy of the data for donut charts
                        donut_df = chart_df.copy()
                    
                        # Calculate percentages for each metric
                        donut_df['Spend %'] = np.where(total_spend_all > 0, (donut_df['Spend'] / total_spend_all * 100).round(1), 0.0)
                        donut_df['Ad Sales %'] = np.where(total_ad_sales_all > 0, (donut_df['Ad Sales'] / total_ad_sales_all * 100).round(1), 0.0)
                        donut_df['Total Sales %'] = np.where(total_sales_all > 0, (donut_df['Total Sales'] / total_sales_all * 100).round(1), 0.0)
                    
                        # No 'Others' category as requested
                    
                        # Create three columns for the three donut charts
                        col1, col2, col3 = st.columns(3)
                    
                        # Helper function to create donut charts
                        def create_donut_chart(df, values, title, color_sequence):
                            # Filter out zero values
                            df_filtered = df[df[values] > 0].copy()
                        
                            if len(df_filtered) == 0:
                                return None
                        
                            # Create donut chart
                            fig = go.Figure()
                        
                            # Create custom hover text with more information
                            hover_texts = []
                            for idx, row in df_filtered.iterrows():
                                asin = row['ASIN']
                                product_title = row['Product Title'] if 'Product Title' in row else ''
                                value = row[values]
                                spend = row['Spend'] if 'Spend' in row else 0
                                ad_sales = row['Ad Sales'] if 'Ad Sales' in row else 0
                                total_sales = row['Total Sales'] if 'Total Sales' in row else 0
                                acos = round((spend / ad_sales * 100), 1) if ad_sales > 0 else 0
                            
                                hover_text = f"<b>{asin}</b><br>"
                                if product_title:
                                    hover_text += f"{product_title[:50]}{'...' if len(product_title) > 50 else ''}<br>"
                            
                                # Only add metrics that aren't the current chart's value metric
                                if values != 'Spend':
                                    hover_text += f"<b>Spend:</b> ${spend:,.2f}<br>"
                                if values != 'Ad Sales':
                                    hover_text += f"<b>Ad Sales:</b> ${ad_sales:,.2f}<br>"
                                if values != 'Total Sales':
                                    hover_text += f"<b>Total Sales:</b> ${total_sales:,.2f}<br>"
                                
                                hover_text += f"<b>ACoS:</b> {acos}%<br>"
                            
                                hover_texts.append(hover_text)
                        
                            # Add the donut trace
                            fig.add_trace(go.Pie(
                                labels=df_filtered['ASIN'],
                                values=df_filtered[values],
                                hole=st.session_state.get('donut_hole_size', 0.6),
                                textinfo='label+percent',
                                textposition=st.session_state.get('donut_text_position', 'outside'),
                                texttemplate='%{label}<br>%{percent}',
                                hovertemplate='%{label}<br>%{percent}<br>%{value:$,.2f}<br>%{customdata}<extra></extra>',
                                customdata=hover_texts,
                                marker=dict(
                                    colors=color_sequence,
                                    line=dict(color='rgba(255,255,255,0.2)', width=1)
                                ),
                                sort=False,
                                direction='clockwise',
                                rotation=90
                            ))
                        
                            # Update layout with significantly increased top margin
                            fig.update_layout(
                                title=dict(
                                    text=title,
                                    font=dict(size=16, family="Arial, sans-serif"),
                                    y=0.98  # Move title even higher up
                                ),
                                margin=dict(t=120, b=20, l=20, r=20),  # Significantly increased top margin
                                showlegend=False,
                                height=450,  # Increased height to accommodate labels
                                template='plotly_dark',
                                plot_bgcolor='rgba(0,0,0,0)',
                                paper_bgcolor='rgba(0,0,0,0)',
                                hoverlabel=dict(
                                    bgcolor='rgba(0,0,0,0.8)',
                                    font_size=12,
                                    font=dict(family="Arial, sans-serif", color='white')
                                )
                            )
                        
                            # Add center text with total value
                            total_value = df_filtered[values].sum()
                            value_text = f'${total_value:,.0f}'
                        
                            # Add annotation in the center
                            fig.add_annotation(
                                text=f"<b>{value_text}</b>",
                                font=dict(size=16, family="Arial, sans-serif"),
                                showarrow=False,
                                x=0.5,
                                y=0.5
                            )
                        
                            return fig
                    
                        # Create color sequences for each chart - Consistent themed gradients (Red, Blue, Green)
                        spend_colors = ['#D32F2F', '#E53935', '#F44336', '#EF5350', '#E57373', '#FFCDD2', '#FFEBEE', '#FFF5F5'][:display_count+1]
                        ad_sales_colors = ['#1976D2', '#1E88E5', '#2196F3', '#42A5F5', '#64B5F6', '#BBDEFB', '#E3F2FD', '#F3F9FF'][:display_count+1]
                        total_sales_colors = ['#388E3C', '#43A047', '#4CAF50', '#66BB6A', '#81C784', '#C8E6C9', '#E8F5E8', '#F1F8E9'][:display_count+1]
                    
                        # Create and display the three donut charts
                        with col1:
                            spend_donut = create_donut_chart(donut_df, 'Spend', 'Ad Spend Distribution', spend_colors)
                            if spend_donut:
                                st.plotly_chart(spend_donut, use_container_width=True)
                    
                        with col2:
                            ad_sales_donut = create_donut_chart(donut_df, 'Ad Sales', 'Ad Sales Distribution', ad_sales_colors)
                            if ad_sales_donut:
                                st.plotly_chart(ad_sales_donut, use_container_width=True)
                    
                        with col3:
                            total_sales_donut = create_donut_chart(donut_df, 'Total Sales', 'Total Sales Distribution', total_sales_colors)
                            if total_sales_donut:
                                st.plotly_chart(total_sales_donut, use_container_width=True)
                    
                        # Add some spacing after the charts
                        st.markdown("<div style='margin-top:1rem;'></div>", unsafe_allow_html=True)
                
                    # Space for better visual separation between sections
                    st.markdown("<div style='margin-top:2rem;'></div>", unsafe_allow_html=True)

        # --- Performance by Parent ASIN Section ---
        # Check if Parent ASIN data exists in the sales report
        has_parent_asin_data = False
        parent_asin_relationships = {}
        
        if isinstance(sales_df, pd.DataFrame) and 'Parent ASIN' in sales_df.columns:
            # Filter out empty/null Parent ASIN values
            parent_asin_data = sales_df[sales_df['Parent ASIN'].notna() & 
                                      (sales_df['Parent ASIN'].astype(str).str.strip() != '') &
                                      (sales_df['Parent ASIN'].astype(str).str.strip() != 'nan')].copy()
            
            if not parent_asin_data.empty:
                has_parent_asin_data = True
                
                # Build parent-child relationships
                for _, row in parent_asin_data.iterrows():
                    parent_asin = str(row['Parent ASIN']).strip()
                    child_asin = str(row['ASIN']).strip()
                    
                    if parent_asin not in parent_asin_relationships:
                        parent_asin_relationships[parent_asin] = {
                            'children': [],
                            'parent_title': parent_asin  # Default to ASIN if no title
                        }
                    
                    parent_asin_relationships[parent_asin]['children'].append({
                        'asin': child_asin,
                        'title': str(row.get('Title', child_asin))
                    })
                    
                st.session_state.debug_messages.append(f"[Parent ASIN] Found {len(parent_asin_relationships)} Parent ASINs with children")

        if has_parent_asin_data and len(filtered_df) > 0:
            st.markdown("##### Performance by Parent ASIN")
            
            # Create Parent ASIN performance data for table display
            parent_asin_table_data = []
            
            for parent_asin, relationship_data in parent_asin_relationships.items():
                # Initialize parent ASIN record
                parent_summary = {
                    'Type': 'Parent',
                    'ASIN': parent_asin,
                    'Parent ASIN': parent_asin,
                    'Product Group': '',  # Will be set based on children
                    'Product Title': relationship_data['parent_title'],
                    'Child Count': len(relationship_data['children']),
                    'Spend': 0,
                    'Ad Sales': 0,
                    'Total Sales': 0,
                    'Clicks': 0,
                    'Orders': 0,
                    'ACoS': 0,
                    'TACoS': 0,
                    '% of Spend': 0,
                    '% of Ad Sales': 0,
                    '% of Total Sales': 0
                }
                
                # Aggregate metrics from all child ASINs
                child_records = []
                for child_info in relationship_data['children']:
                    child_asin = child_info['asin']
                    child_title = child_info['title']
                    
                    # Find this child ASIN in the filtered performance data
                    child_perf = filtered_df[filtered_df['ASIN'] == child_asin]
                    
                    if not child_perf.empty:
                        child_data = child_perf.iloc[0]
                        
                        # Add to parent totals
                        parent_summary['Spend'] += child_data.get('Spend', 0)
                        parent_summary['Ad Sales'] += child_data.get('Ad Sales', 0)
                        parent_summary['Total Sales'] += child_data.get('Total Sales', 0)
                        parent_summary['Clicks'] += child_data.get('Clicks', 0)
                        parent_summary['Orders'] += child_data.get('Orders', 0)
                        
                        # Get product group for this child ASIN
                        child_product_group = 'Untagged Group'  # Default
                        if (st.session_state.client_config and 
                            'branded_asins_data' in st.session_state.client_config and 
                            child_asin in st.session_state.client_config['branded_asins_data']):
                            asin_info = st.session_state.client_config['branded_asins_data'][child_asin]
                            if 'product_group' in asin_info and asin_info['product_group'].strip():
                                child_product_group = asin_info['product_group'].strip()
                        
                        # Create child record
                        child_record = {
                            'Type': 'Child',
                            'ASIN': child_asin,
                            'Parent ASIN': parent_asin,
                            'Product Group': child_product_group,
                            'Product Title': child_title,
                            'Child Count': 0,  # Use 0 instead of empty string to fix Arrow serialization
                            'Spend': child_data.get('Spend', 0),
                            'Ad Sales': child_data.get('Ad Sales', 0),
                            'Total Sales': child_data.get('Total Sales', 0),
                            'Clicks': child_data.get('Clicks', 0),
                            'Orders': child_data.get('Orders', 0)
                        }
                        
                        # Calculate child-level metrics
                        if child_record['Ad Sales'] > 0:
                            child_record['ACoS'] = (child_record['Spend'] / child_record['Ad Sales'] * 100)
                        else:
                            child_record['ACoS'] = 0
                            
                        if child_record['Total Sales'] > 0:
                            child_record['TACoS'] = (child_record['Spend'] / child_record['Total Sales'] * 100)
                        else:
                            child_record['TACoS'] = 0
                        
                        # Calculate CPC, CVR, and AOV for child
                        if child_record['Clicks'] > 0:
                            child_record['CPC'] = child_record['Spend'] / child_record['Clicks']
                            child_record['CVR'] = (child_record['Orders'] / child_record['Clicks'] * 100)
                        else:
                            child_record['CPC'] = 0
                            child_record['CVR'] = 0
                            
                        if child_record['Orders'] > 0:
                            child_record['AOV'] = child_record['Ad Sales'] / child_record['Orders']
                        else:
                            child_record['AOV'] = 0
                        
                        child_records.append(child_record)
                
                # Determine parent product group based on children
                child_product_groups = [record['Product Group'] for record in child_records if record['Product Group'] != 'Untagged Group']
                unique_groups = list(set(child_product_groups))
                
                if len(unique_groups) == 1:
                    # All children have the same product group
                    parent_summary['Product Group'] = unique_groups[0]
                elif len(unique_groups) > 1:
                    # Children have different product groups - leave parent blank
                    parent_summary['Product Group'] = ''
                else:
                    # All children are untagged
                    parent_summary['Product Group'] = 'Untagged Group'
                
                # Calculate parent-level metrics
                if parent_summary['Ad Sales'] > 0:
                    parent_summary['ACoS'] = (parent_summary['Spend'] / parent_summary['Ad Sales'] * 100)
                else:
                    parent_summary['ACoS'] = 0
                    
                if parent_summary['Total Sales'] > 0:
                    parent_summary['TACoS'] = (parent_summary['Spend'] / parent_summary['Total Sales'] * 100)
                else:
                    parent_summary['TACoS'] = 0
                
                # Calculate CPC, CVR, and AOV for parent
                if parent_summary['Clicks'] > 0:
                    parent_summary['CPC'] = parent_summary['Spend'] / parent_summary['Clicks']
                    parent_summary['CVR'] = (parent_summary['Orders'] / parent_summary['Clicks'] * 100)
                else:
                    parent_summary['CPC'] = 0
                    parent_summary['CVR'] = 0
                    
                if parent_summary['Orders'] > 0:
                    parent_summary['AOV'] = parent_summary['Ad Sales'] / parent_summary['Orders']
                else:
                    parent_summary['AOV'] = 0
                
                # Add parent record followed by its children
                parent_asin_table_data.append(parent_summary)
                parent_asin_table_data.extend(child_records)
            
            # Create DataFrame for the table
            parent_asin_df = pd.DataFrame(parent_asin_table_data)
            
            # Check if there are any meaningful product groups defined (excluding 'Untagged Group')
            has_product_groups = False
            if (st.session_state.client_config and 
                'branded_asins_data' in st.session_state.client_config):
                for asin_info in st.session_state.client_config['branded_asins_data'].values():
                    if ('product_group' in asin_info and 
                        asin_info['product_group'].strip() and 
                        asin_info['product_group'].strip() != 'Untagged Group'):
                        has_product_groups = True
                        break
            
            # Calculate percentage metrics after creating the full dataframe
            col1, col2 = st.columns([0.5, 0.5])
            with col1:
                sort_options = {
                    'Parent ASIN (A-Z)': ('Parent ASIN', True),
                    'Spend (High to Low)': ('Spend', False),
                    'Spend (Low to High)': ('Spend', True),
                    'Ad Sales (High to Low)': ('Ad Sales', False),
                    'Ad Sales (Low to High)': ('Ad Sales', True),
                    'ACoS (High to Low)': ('ACoS', False),
                    'ACoS (Low to High)': ('ACoS', True),
                    'Total Sales (High to Low)': ('Total Sales', False),
                    'Total Sales (Low to High)': ('Total Sales', True)
                }
                
                selected_sort = st.selectbox(
                    "Sort By:",
                    options=list(sort_options.keys()),
                    index=1  # Default to Spend (High to Low)
                )
                
                sort_column, ascending = sort_options[selected_sort]
            
            with col2:
                show_detailed_columns = st.checkbox("Show detailed columns", value=False, key="parent_table_detailed")
            
            # Calculate percentage metrics: Parents relative to all Parents, Children relative to all Children
            all_parents_df = parent_asin_df[parent_asin_df['Type'] == 'Parent']
            all_children_df = parent_asin_df[parent_asin_df['Type'] == 'Child']
            
            all_parents_spend = all_parents_df['Spend'].sum()
            all_parents_ad_sales = all_parents_df['Ad Sales'].sum()
            all_parents_total_sales = all_parents_df['Total Sales'].sum()
            
            all_children_spend = all_children_df['Spend'].sum()
            all_children_ad_sales = all_children_df['Ad Sales'].sum()
            all_children_total_sales = all_children_df['Total Sales'].sum()
            
            for idx, row in parent_asin_df.iterrows():
                if row['Type'] == 'Parent':
                    # Parents relative to all other parents
                    if all_parents_spend > 0:
                        parent_asin_df.at[idx, '% of Spend'] = (row['Spend'] / all_parents_spend * 100)
                    if all_parents_ad_sales > 0:
                        parent_asin_df.at[idx, '% of Ad Sales'] = (row['Ad Sales'] / all_parents_ad_sales * 100)
                    if all_parents_total_sales > 0:
                        parent_asin_df.at[idx, '% of Total Sales'] = (row['Total Sales'] / all_parents_total_sales * 100)
                else:
                    # Children relative to all other children
                    if all_children_spend > 0:
                        parent_asin_df.at[idx, '% of Spend'] = (row['Spend'] / all_children_spend * 100)
                    if all_children_ad_sales > 0:
                        parent_asin_df.at[idx, '% of Ad Sales'] = (row['Ad Sales'] / all_children_ad_sales * 100)
                    if all_children_total_sales > 0:
                        parent_asin_df.at[idx, '% of Total Sales'] = (row['Total Sales'] / all_children_total_sales * 100)
            
            # Sort the dataframe while maintaining parent-child grouping
            if sort_column == 'Parent ASIN':
                # For Parent ASIN sorting, sort by the parent ASIN column
                parent_asin_df_sorted = parent_asin_df.sort_values(['Parent ASIN', 'Type'], ascending=[ascending, False])
            else:
                # For other metrics, sort parent groups by the metric, but keep children with their parents
                parent_groups = []
                
                # Group by Parent ASIN
                for parent_asin in parent_asin_df[parent_asin_df['Type'] == 'Parent']['Parent ASIN'].unique():
                    parent_group = parent_asin_df[parent_asin_df['Parent ASIN'] == parent_asin].copy()
                    parent_groups.append(parent_group)
                
                # Sort parent groups by the selected metric (using parent row values)
                parent_groups.sort(
                    key=lambda x: x[x['Type'] == 'Parent'][sort_column].iloc[0] if not x[x['Type'] == 'Parent'].empty else 0,
                    reverse=not ascending
                )
                
                # Concatenate sorted groups
                parent_asin_df_sorted = pd.concat(parent_groups, ignore_index=True)
            
            # Display columns based on detailed view setting
            if show_detailed_columns:
                if has_product_groups:
                    display_columns = ['Type', 'ASIN', 'Product Group', 'Product Title', 'Child Count', 'Spend', 'Ad Sales', 'Total Sales', 
                                     'ACoS', 'TACoS', '% of Spend', '% of Ad Sales', '% of Total Sales', 'CPC', 'CVR', 'AOV']
                else:
                    display_columns = ['Type', 'ASIN', 'Product Title', 'Child Count', 'Spend', 'Ad Sales', 'Total Sales', 
                                     'ACoS', 'TACoS', '% of Spend', '% of Ad Sales', '% of Total Sales', 'CPC', 'CVR', 'AOV']
            else:
                if has_product_groups:
                    display_columns = ['Type', 'ASIN', 'Product Group', 'Product Title', 'Child Count', 'Spend', 'Ad Sales', 'Total Sales', 'ACoS']
                else:
                    display_columns = ['Type', 'ASIN', 'Product Title', 'Child Count', 'Spend', 'Ad Sales', 'Total Sales', 'ACoS']
            
            # Format the display dataframe
            display_df = parent_asin_df_sorted[display_columns].copy()
            
            # Format currency columns
            currency_cols = ['Spend', 'Ad Sales', 'Total Sales', 'CPC', 'AOV']
            for col in currency_cols:
                if col in display_df.columns:
                    display_df[col] = display_df[col].apply(lambda x: f'${x:,.2f}' if pd.notna(x) and x != 0 else '$0.00')
            
            # Format percentage columns
            percentage_cols = ['ACoS', 'TACoS', '% of Spend', '% of Ad Sales', '% of Total Sales', 'CVR']
            for col in percentage_cols:
                if col in display_df.columns:
                    display_df[col] = display_df[col].apply(lambda x: f'{x:.1f}%' if pd.notna(x) else '0.0%')
            
            # Format Child Count column to show empty for child rows
            if 'Child Count' in display_df.columns:
                # First ensure the column is properly typed, then format for display
                display_df['Child Count'] = display_df.apply(
                    lambda row: str(int(row['Child Count'])) if row['Type'] == 'Parent' and row['Child Count'] > 0 else '',
                    axis=1
                )
                # Convert to string type to avoid Arrow serialization issues
                display_df['Child Count'] = display_df['Child Count'].astype(str)
            
            # Don't truncate product titles - let column width handle it
            
            # Style the dataframe with conditional formatting
            def highlight_parent_child_rows(row):
                if row['Type'] == 'Parent':
                    # Parent rows - darker background, bold text
                    return ['background-color: rgba(70, 70, 70, 0.8); font-weight: bold; color: white'] * len(row)
                else:
                    # Child rows - lighter background
                    return ['background-color: rgba(40, 40, 40, 0.4); color: #e0e0e0'] * len(row)
            
            # Apply styling and create the table
            styled_df = display_df.style.apply(highlight_parent_child_rows, axis=1)
            
            # Display the scrollable table
            st.dataframe(
                styled_df,
                use_container_width=True,
                hide_index=True,
                height=600,  # Fixed height to make it scrollable
                column_config={
                    "Type": st.column_config.TextColumn("Type", width="small"),
                    "ASIN": st.column_config.TextColumn("ASIN", width="medium"),
                    "Product Group": st.column_config.TextColumn("Product Group", width="medium"),
                    "Product Title": st.column_config.TextColumn("Product Title", width="large"),
                    "Child Count": st.column_config.TextColumn("Children", width="small"),
                    "Spend": st.column_config.TextColumn("Spend", width="small"),
                    "Ad Sales": st.column_config.TextColumn("Ad Sales", width="small"),
                    "Total Sales": st.column_config.TextColumn("Total Sales", width="small"),
                    "ACoS": st.column_config.TextColumn("ACoS", width="small"),
                }
            )
            
            # Summary statistics
            st.markdown("---")
            parent_df = parent_asin_df[parent_asin_df['Type'] == 'Parent'].copy()
            child_df = parent_asin_df[parent_asin_df['Type'] == 'Child'].copy()
            total_parents = len(parent_df)
            total_children = len(child_df)
            
            # Display metrics in a 2x1 grid
            summary_col1, summary_col2 = st.columns(2)
            with summary_col1:
                st.metric("Total Parent ASINs", total_parents)
            with summary_col2:
                st.metric("Total Child ASINs", total_children)
                
            # Add spacing
            st.markdown("<div style='margin-top:2rem;'></div>", unsafe_allow_html=True)

        else:
            st.info("No ASIN performance data available. Please ensure you have uploaded both bulk campaign data and sales report data, and that your bulk data contains Product Ad records in the Entity column.")
        # --- Performance by Product Group ---
    # Only show on the Advertising Audit page
    if st.session_state.current_page == "advertising_audit":
        # Only show if there are product groups defined in the client settings
        show_product_group = False

        # Check if there are any product groups defined in client settings
        if st.session_state.client_config and 'branded_asins_data' in st.session_state.client_config:
            # Check if any ASINs have a non-empty product_group value in the client settings
            has_product_groups = any(info.get('product_group', '').strip() != '' 
                                   for info in st.session_state.client_config['branded_asins_data'].values())
    
            # Only proceed if product groups are defined AND we have data to display
            if has_product_groups and 'asin_perf_df' in st.session_state and st.session_state.asin_perf_df is not None and 'Product Group' in st.session_state.asin_perf_df.columns:
                # Verify we have actual product group values in the data (not just empty strings)
                show_product_group = st.session_state.asin_perf_df['Product Group'].astype(str).str.strip().replace('', pd.NA).dropna().any()
        
                # Add debug message about product groups
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f"[Product Groups] Found defined product groups in client settings: {has_product_groups}")
                    st.session_state.debug_messages.append(f"[Product Groups] Found non-empty product groups in data: {show_product_group}")

        if show_product_group:
            st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
            st.markdown("<span class='main-section-header dashboard-section'>Performance by Product Group</span>", unsafe_allow_html=True)
            st.markdown("<div style='margin-bottom:1.2rem;'></div>", unsafe_allow_html=True)

            # Debug information about available columns
            # Aggregate required columns
            agg_dict = {}
            if 'ASIN' in st.session_state.asin_perf_df.columns:
                agg_dict['ASIN'] = 'count'
            for col in ['Spend', 'Ad Sales', 'Total Sales', 'Clicks', 'Orders']:
                if col in st.session_state.asin_perf_df.columns:
                    agg_dict[col] = 'sum'

            if agg_dict:
                # First, create a copy of the dataframe with consistent handling of untagged items
                temp_df = st.session_state.asin_perf_df.copy()
        
                # Replace empty or NaN product group values with 'Untagged Group'
                # Also replace 'Unassigned' with 'Untagged Group' for consistency
                temp_df['Product Group'] = temp_df['Product Group'].fillna('').astype(str)
                temp_df.loc[temp_df['Product Group'].str.strip() == '', 'Product Group'] = 'Untagged Group'
                temp_df.loc[temp_df['Product Group'] == 'Unassigned', 'Product Group'] = 'Untagged Group'
        
                # Now group by the updated Product Group column
                group_perf_df = temp_df.groupby('Product Group').agg(agg_dict)
                if 'ASIN' in group_perf_df.columns:
                    group_perf_df = group_perf_df.rename(columns={'ASIN': 'ASIN Count'})
                group_perf_df = group_perf_df.reset_index()

                # Product Group Filter Section
                available_product_groups = sorted(group_perf_df['Product Group'].unique())
        
                if 'selected_product_groups' not in st.session_state:
                    st.session_state.selected_product_groups = []
        
                # Create two-column layout for filters
                filter_col1, filter_col2 = st.columns([1, 2])
        
                with filter_col1:
                    # Add checkbox for combining SB Campaign data with ASIN data
                    combine_sb_data = st.checkbox(
                        "Combine SB Campaign-Level Product Groups with ASIN Product Groups?",
                        value=True,
                        help="When enabled, aggregates Sponsored Brands campaign data with ASIN data for matching Product Groups"
                    )
        
                with filter_col2:
                    # Smaller product group filter
                    selected_groups = st.multiselect(
                        "Filter by Product Group(s)",
                        options=available_product_groups,
                        default=st.session_state.selected_product_groups,
                        key="product_group_multiselect",
                        placeholder="Choose an option"
                    )
                    st.session_state.selected_product_groups = selected_groups
        
                # --- Combine SB Campaign Data with ASIN Data if enabled ---
                if combine_sb_data:
                    # Get SB campaign performance data
                    try:
                        sb_campaign_df = get_campaign_performance_data(st.session_state.bulk_data, st.session_state.client_config)
                
                        if not sb_campaign_df.empty:
                            # Filter for Sponsored Brands campaigns only
                            sb_data = sb_campaign_df[sb_campaign_df['Ad Type'] == 'SB'].copy()
                    
                            if not sb_data.empty:
                                # Group SB data by Product Group and aggregate
                                sb_agg_dict = {
                                    'Spend': 'sum',
                                    'Ad Sales': 'sum',
                                    'Clicks': 'sum',
                                    'Orders': 'sum'
                                }
                        
                                sb_grouped = sb_data.groupby('Product Group').agg(sb_agg_dict).reset_index()
                        
                                # Combine with existing ASIN data
                                combined_data = []
                        
                                # Process each Product Group
                                all_product_groups = set(group_perf_df['Product Group'].unique()) | set(sb_grouped['Product Group'].unique())
                        
                                for pg in all_product_groups:
                                    # Get ASIN data for this product group
                                    asin_data = group_perf_df[group_perf_df['Product Group'] == pg]
                                    sb_data_pg = sb_grouped[sb_grouped['Product Group'] == pg]
                            
                                    # Combine the data
                                    combined_row = {'Product Group': pg}
                            
                                    # Add metrics from ASIN data
                                    if not asin_data.empty:
                                        asin_row = asin_data.iloc[0]
                                        combined_row['Spend'] = asin_row.get('Spend', 0)
                                        combined_row['Ad Sales'] = asin_row.get('Ad Sales', 0)
                                        combined_row['Total Sales'] = asin_row.get('Total Sales', 0)
                                        combined_row['Clicks'] = asin_row.get('Clicks', 0)
                                        combined_row['Orders'] = asin_row.get('Orders', 0)
                                        combined_row['ASIN Count'] = asin_row.get('ASIN Count', 0)
                                    else:
                                        # Initialize with zeros
                                        combined_row.update({
                                            'Spend': 0, 'Ad Sales': 0, 'Total Sales': 0,
                                            'Clicks': 0, 'Orders': 0, 'ASIN Count': 0
                                        })
                            
                                    # Add SB campaign data
                                    if not sb_data_pg.empty:
                                        sb_row = sb_data_pg.iloc[0]
                                        combined_row['Spend'] += sb_row.get('Spend', 0)
                                        combined_row['Ad Sales'] += sb_row.get('Ad Sales', 0)
                                        # Note: SB campaigns don't have Total Sales in campaign reports
                                        combined_row['Clicks'] += sb_row.get('Clicks', 0)
                                        combined_row['Orders'] += sb_row.get('Orders', 0)
                            
                                    combined_data.append(combined_row)
                        
                                # Create new combined DataFrame
                                group_perf_df = pd.DataFrame(combined_data)
                        
                                # Update available product groups for the filter
                                available_product_groups = sorted(group_perf_df['Product Group'].unique())
                        
                        
                    except Exception as e:
                        st.warning(f"Could not combine SB campaign data: {str(e)}")
        
                # Calculate totals for percent columns (from the entire unfiltered dataset)
                total_spend_all = group_perf_df['Spend'].sum() if 'Spend' in group_perf_df.columns else 0
                total_ad_sales_all = group_perf_df['Ad Sales'].sum() if 'Ad Sales' in group_perf_df.columns else 0
                total_total_sales_all = group_perf_df['Total Sales'].sum() if 'Total Sales' in group_perf_df.columns else 0
        
                # Filter data based on selection
                if selected_groups:
                    filtered_group_perf_df = group_perf_df[group_perf_df['Product Group'].isin(selected_groups)].copy()
                    filtered_temp_df = temp_df[temp_df['Product Group'].isin(selected_groups)].copy()
                    st.caption(f"Filtered by Product Group(s): {', '.join(selected_groups)}")
                else:
                    # No filter applied - show all data
                    filtered_group_perf_df = group_perf_df.copy()
                    filtered_temp_df = temp_df.copy()
        
                # Calculate metrics for the filtered data
                if len(filtered_group_perf_df) > 0:
                    # Calculate totals for filtered data
                    filtered_spend = filtered_group_perf_df['Spend'].sum() if 'Spend' in filtered_group_perf_df.columns else 0
                    filtered_ad_sales = filtered_group_perf_df['Ad Sales'].sum() if 'Ad Sales' in filtered_group_perf_df.columns else 0
                    filtered_total_sales = filtered_group_perf_df['Total Sales'].sum() if 'Total Sales' in filtered_group_perf_df.columns else 0
                    filtered_clicks = filtered_group_perf_df['Clicks'].sum() if 'Clicks' in filtered_group_perf_df.columns else 0
                    filtered_orders = filtered_group_perf_df['Orders'].sum() if 'Orders' in filtered_group_perf_df.columns else 0
            
                    # Calculate calculated columns for filtered data
                    filtered_group_perf_df['% of Spend'] = filtered_group_perf_df['Spend'] / total_spend_all if total_spend_all else 0
                    filtered_group_perf_df['% of Ad Sales'] = filtered_group_perf_df['Ad Sales'] / total_ad_sales_all if total_ad_sales_all else 0
                    filtered_group_perf_df['% of Total Sales'] = filtered_group_perf_df['Total Sales'] / total_total_sales_all if total_total_sales_all else 0
                    filtered_group_perf_df['ACoS'] = filtered_group_perf_df['Spend'] / filtered_group_perf_df['Ad Sales'] if 'Ad Sales' in filtered_group_perf_df.columns else np.nan
                    filtered_group_perf_df['ROAS'] = filtered_group_perf_df['Ad Sales'] / filtered_group_perf_df['Spend'] if 'Spend' in filtered_group_perf_df.columns else np.nan
                    filtered_group_perf_df['TACoS'] = filtered_group_perf_df['Spend'] / filtered_group_perf_df['Total Sales'] if 'Total Sales' in filtered_group_perf_df.columns else np.nan
                    filtered_group_perf_df['Ad Sales % of Total'] = filtered_group_perf_df['Ad Sales'] / filtered_group_perf_df['Total Sales'] if 'Total Sales' in filtered_group_perf_df.columns else np.nan
                    filtered_group_perf_df['CPC'] = filtered_group_perf_df['Spend'] / filtered_group_perf_df['Clicks'] if 'Clicks' in filtered_group_perf_df.columns else np.nan
                    filtered_group_perf_df['CVR'] = filtered_group_perf_df['Orders'] / filtered_group_perf_df['Clicks'] if ('Orders' in filtered_group_perf_df.columns and 'Clicks' in filtered_group_perf_df.columns) else np.nan
                    filtered_group_perf_df['AOV'] = filtered_group_perf_df['Total Sales'] / filtered_group_perf_df['Orders'] if 'Orders' in filtered_group_perf_df.columns else np.nan

                    # Calculate metrics for totals row
                    total_spend_pct = filtered_spend / total_spend_all if total_spend_all > 0 else 0
                    total_ad_sales_pct = filtered_ad_sales / total_ad_sales_all if total_ad_sales_all > 0 else 0
                    total_total_sales_pct = filtered_total_sales / total_total_sales_all if total_total_sales_all > 0 else 0
                    total_acos = filtered_spend / filtered_ad_sales if filtered_ad_sales > 0 else 0
                    total_roas = filtered_ad_sales / filtered_spend if filtered_spend > 0 else 0
                    total_tacos = filtered_spend / filtered_total_sales if filtered_total_sales > 0 else 0
                    total_cpc = filtered_spend / filtered_clicks if filtered_clicks > 0 else 0
                    total_cvr = filtered_orders / filtered_clicks if filtered_clicks > 0 else 0
                    total_aov = filtered_total_sales / filtered_orders if filtered_orders > 0 else 0

                    # Create totals row
                    totals_data = {
                        'Product Group': 'Total',
                        'Spend': filtered_spend,
                        'Ad Sales': filtered_ad_sales,
                        'Total Sales': filtered_total_sales,
                        '% of Spend': total_spend_pct,
                        '% of Ad Sales': total_ad_sales_pct,
                        '% of Total Sales': total_total_sales_pct,
                        'ACoS': total_acos,
                        'ROAS': total_roas,
                        'TACoS': total_tacos,
                        'CPC': total_cpc,
                        'CVR': total_cvr,
                        'AOV': total_aov,
                        'Ad Sales % of Total': filtered_ad_sales / filtered_total_sales if filtered_total_sales > 0 else 0
                    }
            
                    # Add ASIN Count if available
                    if 'ASIN Count' in filtered_group_perf_df.columns:
                        totals_data['ASIN Count'] = filtered_group_perf_df['ASIN Count'].sum()

                    # Create totals row as DataFrame (separate from main data)
                    totals_df = pd.DataFrame([totals_data])
            
                    # Use filtered data for the main table (no totals row)
                    display_df = filtered_group_perf_df.copy()
                else:
                    # No data to display
                    display_df = filtered_group_perf_df.copy()
                    totals_df = pd.DataFrame()

                # Reorder columns as requested
                columns_order = [
                    'Product Group', 'Spend', 'Ad Sales', 'Total Sales',
                    '% of Spend', '% of Ad Sales', '% of Total Sales',
                    'ACoS', 'ROAS', 'TACoS', 'Ad Sales % of Total', 'CPC', 'CVR', 'AOV', 'ASIN Count'
                ]
                # Only include columns that exist
                columns_order = [col for col in columns_order if col in display_df.columns]
                display_df = display_df[columns_order]
        
                if not totals_df.empty:
                    totals_columns_order = [col for col in columns_order if col in totals_df.columns]
                    totals_df = totals_df[totals_columns_order]

                # Sort by 'Ad Sales' in descending order by default (if column exists)
                if len(display_df) > 0 and 'Ad Sales' in display_df.columns:
                    display_df = display_df.sort_values(by='Ad Sales', ascending=False)

                # Replace all None/NaN values with 0 for display
                display_df = display_df.fillna(0)
                if not totals_df.empty:
                    totals_df = totals_df.fillna(0)

                # Formatting
                def currency_fmt(x):
                    return f"${x:,.2f}" if pd.notnull(x) and x != 0 else "$0.00"
                def percent_fmt(x):
                    return f"{x*100:.1f}%" if pd.notnull(x) and x != 0 else "0.0%"
                def ratio_fmt(x):
                    return f"{x:.2f}" if pd.notnull(x) and x != 0 else "0.00"
                def count_fmt(x):
                    return f"{int(x):,}" if pd.notnull(x) and x != 0 else "0"

                fmt_dict = {
                    'Spend': currency_fmt,
                    'Ad Sales': currency_fmt,
                    'Total Sales': currency_fmt,
                    '% of Spend': percent_fmt,
                    '% of Ad Sales': percent_fmt,
                    '% of Total Sales': percent_fmt,
                    'ACoS': percent_fmt,
                    'ROAS': ratio_fmt,
                    'TACoS': percent_fmt,
                    'Ad Sales % of Total': percent_fmt,
                    'CPC': currency_fmt,
                    'CVR': percent_fmt,
                    'AOV': currency_fmt,
                    'ASIN Count': count_fmt,
                }

                # Display the totals row separately (detached from the main table)
                if not totals_df.empty:

                    # Use simple styling to match ASIN section
                    st.dataframe(totals_df.style.format(fmt_dict), use_container_width=True, hide_index=True)
                    st.markdown("<div style='margin-bottom:1rem;'></div>", unsafe_allow_html=True)

                # Display the main data table
                if len(display_df) > 0:

                    styled_df = display_df.style.format(fmt_dict)
            
                    # Apply gradients only if columns exist and have more than one unique value
                    if '% of Spend' in display_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_blue(v*100, 0, 100) if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Spend' else [''] * len(x), axis=0)
            
                    if '% of Ad Sales' in display_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_green(v*100, 0, 100) if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Ad Sales' else [''] * len(x), axis=0)
            
                    if '% of Total Sales' in display_df.columns:
                        styled_df = styled_df.apply(lambda x: [color_gradient_green(v*100, 0, 100) if not pd.isna(v) else '' 
                                                            for v in x] if x.name == '% of Total Sales' else [''] * len(x), axis=0)
            
                    st.dataframe(styled_df, use_container_width=True, hide_index=True)
                else:

                    st.info("No data to display. Please select one or more Product Groups to analyze.")
        
                # --- HORIZONTAL STACKED BAR CHARTS FOR EACH PRODUCT GROUP ---
                # Update chart data to use filtered data
                if len(filtered_group_perf_df) > 0 and all(col in filtered_group_perf_df.columns for col in ['Spend', 'Ad Sales', 'Total Sales']):
            
                    # --- Chart Display Options ---
                    # Count unique product groups for chart filtering
                    unique_groups = filtered_group_perf_df['Product Group'].unique()
                    total_groups = len(unique_groups)
            
                    # Initialize session state for product group display limit
                    if 'product_group_chart_display_limit' not in st.session_state:
                        # Default to 10, including Untagged Group if it exists
                        st.session_state.product_group_chart_display_limit = min(10, total_groups)
            
                    # Show Chart Display Options only if there are more than 10 unique product groups
                    if total_groups > 10:
                        with st.expander("Chart Display Options", expanded=False):
                            # Create options for the dropdown
                            options = list(range(5, total_groups + 1, 5))  # 5, 10, 15, 20, etc.
                            if 10 not in options:
                                options.append(10)
                            options.append(total_groups)  # Add "All" option
                            options = sorted(set(options))  # Remove duplicates and sort
                    
                            # Create labels for the dropdown
                            option_labels = []
                            for opt in options[:-1]:  # All except the last one
                                option_labels.append(f"Top {opt} Groups")
                            option_labels.append("All Groups")  # Label for the last option
                    
                            # Create the selectbox
                            selected_index = st.selectbox(
                                "Number of Product Groups to Display in Charts:",
                                range(len(options)),
                                format_func=lambda x: option_labels[x],
                                index=options.index(st.session_state.product_group_chart_display_limit) if st.session_state.product_group_chart_display_limit in options else 1,  # Default to "Top 10 Groups"
                                key="product_group_chart_display_selectbox"
                            )
                    
                            # Update session state with selected value
                            st.session_state.product_group_chart_display_limit = options[selected_index]
            
                    # Apply the filtering based on the selected limit for charts only
                    chart_display_df = filtered_group_perf_df.copy()
                    if st.session_state.product_group_chart_display_limit < total_groups:
                        # For charts, include Untagged Group as part of the limit
                        # Sort by Ad Sales and take top N groups (including Untagged if it's in top N)
                        chart_display_df = chart_display_df.sort_values(by='Ad Sales', ascending=False)
                        chart_display_df = chart_display_df.head(st.session_state.product_group_chart_display_limit)
            
                    # Create a copy of the dataframe with only the columns we need for the charts
                    chart_df = chart_display_df[['Product Group', 'Spend', 'Ad Sales', 'Total Sales']].copy()
            
                    # Calculate the total for each product group to use for percentages
                    chart_df['Total'] = chart_df['Spend'] + chart_df['Ad Sales'] + chart_df['Total Sales']
            
                    # Sort by Total Sales (descending)
                    chart_df = chart_df.sort_values('Total Sales', ascending=False)
            
                    # Create tabs for different view types
                    tab1, tab2, tab3 = st.tabs(["Stacked Bar View", "Percentage View", "Pie Charts"])
            

                    # Function to create the chart with either percentage or dollar values
                    def create_product_group_chart(show_percentages=True, combined_view=False):
                        # Create a figure
                        fig = go.Figure()
                
                        # For each product group, add a trace to the figure
                        y_positions = []
                        annotations = []
            
                        for idx, row in chart_df.iterrows():
                            product_group = row['Product Group']
                            # Skip if product group is empty or null
                            if pd.isna(product_group) or str(product_group).strip() == '':
                                continue
                    
                            y_pos = len(y_positions)
                            y_positions.append(y_pos)
                    
                            # Calculate percentages for each product group's internal distribution
                            spend_pct = row['Spend'] / row['Total'] * 100 if row['Total'] > 0 else 0
                            ad_sales_pct = row['Ad Sales'] / row['Total'] * 100 if row['Total'] > 0 else 0
                            total_sales_pct = row['Total Sales'] / row['Total'] * 100 if row['Total'] > 0 else 0
                
                            if show_percentages:
                                # For percentage view, normalize to 100%
                                x_spend = spend_pct
                                x_ad_sales = ad_sales_pct
                                x_total_sales = total_sales_pct
                        
                                # Format text for percentage view - only show if value is significant
                                spend_text = f"{spend_pct:.0f}%" if spend_pct >= 3 else ""
                                ad_sales_text = f"{ad_sales_pct:.0f}%" if ad_sales_pct >= 3 else ""
                                total_sales_text = f"{total_sales_pct:.0f}%" if total_sales_pct >= 3 else ""
                        
                                # Format hover text with more detailed information
                                spend_hover = f"<b>{product_group}</b><br>Spend: ${row['Spend']:,.2f} ({spend_pct:.1f}%)"
                                ad_sales_hover = f"<b>{product_group}</b><br>Ad Sales: ${row['Ad Sales']:,.2f} ({ad_sales_pct:.1f}%)"
                                total_sales_hover = f"<b>{product_group}</b><br>Total Sales: ${row['Total Sales']:,.2f} ({total_sales_pct:.1f}%)"
                        
                                # Set tick format for axis
                                tick_format = ',.0f'
                                tick_suffix = '%'
                                tick_prefix = ''
                            else:
                                # For dollar view, use actual values
                                x_spend = row['Spend']
                                x_ad_sales = row['Ad Sales']
                                x_total_sales = row['Total Sales']
                        
                                # Format text for dollar view - only show if value is significant
                                min_value_for_label = max(row['Total Sales'] * 0.03, 1000)  # At least 3% of total or $1000
                                spend_text = f"${row['Spend']:,.0f}" if row['Spend'] >= min_value_for_label else ""
                                ad_sales_text = f"${row['Ad Sales']:,.0f}" if row['Ad Sales'] >= min_value_for_label else ""
                                total_sales_text = f"${row['Total Sales']:,.0f}" if row['Total Sales'] >= min_value_for_label else ""
                        
                                # Format hover text with more detailed information
                                spend_hover = f"<b>{product_group}</b><br>Spend: ${row['Spend']:,.2f} ({spend_pct:.1f}%)"
                                ad_sales_hover = f"<b>{product_group}</b><br>Ad Sales: ${row['Ad Sales']:,.2f} ({ad_sales_pct:.1f}%)"
                                total_sales_hover = f"<b>{product_group}</b><br>Total Sales: ${row['Total Sales']:,.2f} ({total_sales_pct:.1f}%)"
                        
                                # Set tick format for axis
                                tick_format = ',.0f'
                                tick_suffix = ''
                                tick_prefix = '$'
                
                            # Add the stacked bar segments with improved styling
                            # Spend bar (red)
                            fig.add_trace(go.Bar(
                                x=[x_spend],
                                y=[y_pos],
                                orientation='h',
                                name='Spend',
                                marker_color='rgba(239, 68, 68, 0.9)',  # Bright red with slight transparency
                                marker_line=dict(width=1, color='rgba(255,255,255,0.3)'),
                                text=[spend_text],
                                textposition='inside',
                                insidetextanchor='middle',
                                textfont=dict(color='#fff', size=13, family='Inter, Arial, sans-serif', weight='bold'),
                                showlegend=idx==0,  # Only show in legend for first row
                                hoverinfo='text',
                                hovertext=spend_hover,
                                width=0.75,
                                opacity=0.95
                            ))
                    
                            # Ad Sales bar (blue)
                            fig.add_trace(go.Bar(
                                x=[x_ad_sales],
                                y=[y_pos],
                                orientation='h',
                                name='Ad Sales',
                                marker_color='rgba(59, 130, 246, 0.9)',  # Bright blue with slight transparency
                                marker_line=dict(width=1, color='rgba(255,255,255,0.3)'),
                                text=[ad_sales_text],
                                textposition='inside',
                                insidetextanchor='middle',
                                textfont=dict(color='#fff', size=13, family='Inter, Arial, sans-serif', weight='bold'),
                                showlegend=idx==0,  # Only show in legend for first row
                                hoverinfo='text',
                                hovertext=ad_sales_hover,
                                width=0.75,
                                opacity=0.95
                            ))
                    
                            # Total Sales bar (green)
                            fig.add_trace(go.Bar(
                                x=[x_total_sales],
                                y=[y_pos],
                                orientation='h',
                                name='Total Sales',
                                marker_color='rgba(34, 197, 94, 0.9)',  # Bright green with slight transparency
                                marker_line=dict(width=1, color='rgba(255,255,255,0.3)'),
                                text=[total_sales_text],
                                textposition='inside',
                                insidetextanchor='middle',
                                textfont=dict(color='#fff', size=13, family='Inter, Arial, sans-serif', weight='bold'),
                                showlegend=idx==0,  # Only show in legend for first row
                                hoverinfo='text',
                                hovertext=total_sales_hover,
                                width=0.75,
                                opacity=0.95
                            ))
                    
                        # Create a list of product group names for y-axis labels
                        product_group_labels = [chart_df.iloc[y_positions.index(pos)]['Product Group'] for pos in y_positions]
                
                        # Calculate dynamic height based on number of product groups
                        chart_height = max(350, 55 * (len(y_positions) + 1))  # Increased height per row for better spacing
                
                        # Determine chart title based on view type
                        if combined_view:
                            chart_title = '<b>Product Group Allocation (Combined View)</b>'
                        else:
                            chart_title = '<b>Product Group Allocation (% of Total)</b>' if show_percentages else '<b>Product Group Allocation ($)</b>'
                
                        # Update the layout with enhanced dark mode aesthetic
                        fig.update_layout(
                            barmode='stack',
                            height=chart_height,
                            margin=dict(l=200, r=40, t=70, b=50),  # Adjusted margins for better layout
                            yaxis=dict(
                                showticklabels=True,
                                ticktext=product_group_labels,
                                tickvals=y_positions,
                                tickfont=dict(size=13, color='#ffffff', family='Inter, Arial, sans-serif'),
                                showgrid=False,
                                zeroline=False,
                                domain=[0, 0.95],
                                title='',
                                ticklabelposition='outside'
                            ),
                            xaxis=dict(
                                title='',
                                showgrid=True,
                                gridcolor='rgba(255,255,255,0.15)',  # Slightly more visible grid lines
                                zeroline=False,
                                tickprefix=tick_prefix,
                                ticksuffix=tick_suffix,
                                tickformat=tick_format,
                                color='#ffffff',
                                tickfont=dict(size=12),
                                range=[0, 105] if show_percentages else None,  # Slightly wider range for better spacing
                                showline=True,
                                linecolor='rgba(255,255,255,0.3)',
                                mirror=True  # Add top axis line for better framing
                            ),
                            legend=dict(
                                orientation='h',
                                yanchor='bottom',
                                y=1.02,
                                xanchor='right',
                                x=1.0,  # Right-aligned legend
                                bgcolor='rgba(30,30,30,0.7)',  # Darker, more visible background
                                bordercolor='rgba(255,255,255,0.3)',
                                borderwidth=1,
                                font=dict(color='#ffffff', size=12, family='Inter, Arial, sans-serif'),
                                traceorder='reversed'  # Reverse order to match visual stacking (Spend, Ad Sales, Total Sales)
                            ),
                            legend_traceorder='reversed',
                            annotations=annotations,
                            plot_bgcolor='rgba(17,17,17,0.3)',  # Very subtle dark background
                            paper_bgcolor='rgba(0,0,0,0)',
                            bargap=0.4,  # Larger gap for better separation between product groups
                            font=dict(color='#ffffff', family='Inter, Arial, sans-serif'),
                            title=dict(
                                text=chart_title,
                                font=dict(size=18, color='#ffffff', family='Inter, Arial, sans-serif'),
                                x=0.0,
                                xanchor='left',
                                y=0.98,  # Position title slightly higher
                                yanchor='top'
                            ),
                            hoverlabel=dict(
                                bgcolor='rgba(50,50,50,0.9)',  # Dark hover label background
                                bordercolor='rgba(255,255,255,0.3)',
                                font=dict(family='Inter, Arial, sans-serif', size=13, color='white')
                            ),
                            hovermode='closest',
                            uniformtext=dict(minsize=10, mode='hide')  # Hide text that doesn't fit
                        )
                
                        return fig
            
                    # Function to create the combined view chart showing both dollar values and percentages
                    def create_combined_view_chart():
                        # Create a figure
                        fig = go.Figure()
                
                        # For each product group, add a trace to the figure
                        y_positions = []
                        annotations = []
                
                        # Get total spend across all ASINs for percentage calculations
                        total_spend = chart_df['Spend'].sum()
                        total_ad_sales = chart_df['Ad Sales'].sum()
                        total_sales = chart_df['Total Sales'].sum()
                
                        for idx, row in chart_df.iterrows():
                            product_group = row['Product Group']
                            # Skip if product group is empty or null
                            if pd.isna(product_group) or str(product_group).strip() == '':
                                continue
                    
                            y_pos = len(y_positions)
                            y_positions.append(y_pos)
                    
                            # Calculate percentages of total for each metric
                            spend_pct = row['Spend'] / total_spend * 100 if total_spend > 0 else 0
                            ad_sales_pct = row['Ad Sales'] / total_ad_sales * 100 if total_ad_sales > 0 else 0
                            total_sales_pct = row['Total Sales'] / total_sales * 100 if total_sales > 0 else 0
                    
                            # Use actual dollar values
                            x_spend = row['Spend']
                            x_ad_sales = row['Ad Sales']
                            x_total_sales = row['Total Sales']
                    
                            # Format text to show both dollar value and percentage
                            min_value_for_label = max(row['Total Sales'] * 0.03, 1000)  # At least 3% of total or $1000
                    
                            spend_text = f"${row['Spend']:,.0f} ({spend_pct:.1f}%)" if row['Spend'] >= min_value_for_label else ""
                            ad_sales_text = f"${row['Ad Sales']:,.0f} ({ad_sales_pct:.1f}%)" if row['Ad Sales'] >= min_value_for_label else ""
                            total_sales_text = f"${row['Total Sales']:,.0f} ({total_sales_pct:.1f}%)" if row['Total Sales'] >= min_value_for_label else ""
                    
                            # Format hover text with detailed information
                            spend_hover = f"<b>{product_group}</b><br>Spend: ${row['Spend']:,.2f} ({spend_pct:.1f}%)"
                            ad_sales_hover = f"<b>{product_group}</b><br>Ad Sales: ${row['Ad Sales']:,.2f} ({ad_sales_pct:.1f}%)"
                            total_sales_hover = f"<b>{product_group}</b><br>Total Sales: ${row['Total Sales']:,.2f} ({total_sales_pct:.1f}%)"
                    
                            # Set tick format for axis
                            tick_format = ',.0f'
                            tick_suffix = ''
                            tick_prefix = '$'
                    
                            # Add the stacked bar segments with improved styling
                            # Spend bar (red)
                            fig.add_trace(go.Bar(
                                x=[x_spend],
                                y=[y_pos],
                                orientation='h',
                                name='Spend',
                                marker_color='rgba(239, 68, 68, 0.9)',  # Bright red with slight transparency
                                marker_line=dict(width=1, color='rgba(255,255,255,0.3)'),
                                text=[spend_text],
                                textposition='inside',
                                insidetextanchor='middle',
                                textfont=dict(color='#fff', size=13, family='Inter, Arial, sans-serif', weight='bold'),
                                showlegend=idx==0,  # Only show in legend for first row
                                hoverinfo='text',
                                hovertext=spend_hover,
                                width=0.75,
                                opacity=0.95
                            ))
                    
                            # Ad Sales bar (blue)
                            fig.add_trace(go.Bar(
                                x=[x_ad_sales],
                                y=[y_pos],
                                orientation='h',
                                name='Ad Sales',
                                marker_color='rgba(59, 130, 246, 0.9)',  # Bright blue with slight transparency
                                marker_line=dict(width=1, color='rgba(255,255,255,0.3)'),
                                text=[ad_sales_text],
                                textposition='inside',
                                insidetextanchor='middle',
                                textfont=dict(color='#fff', size=13, family='Inter, Arial, sans-serif', weight='bold'),
                                showlegend=idx==0,  # Only show in legend for first row
                                hoverinfo='text',
                                hovertext=ad_sales_hover,
                                width=0.75,
                                opacity=0.95
                            ))
                    
                            # Total Sales bar (green)
                            fig.add_trace(go.Bar(
                                x=[x_total_sales],
                                y=[y_pos],
                                orientation='h',
                                name='Total Sales',
                                marker_color='rgba(34, 197, 94, 0.9)',  # Bright green with slight transparency
                                marker_line=dict(width=1, color='rgba(255,255,255,0.3)'),
                                text=[total_sales_text],
                                textposition='inside',
                                insidetextanchor='middle',
                                textfont=dict(color='#fff', size=13, family='Inter, Arial, sans-serif', weight='bold'),
                                showlegend=idx==0,  # Only show in legend for first row
                                hoverinfo='text',
                                hovertext=total_sales_hover,
                                width=0.75,
                                opacity=0.95
                            ))
                
                        # Create a list of product group names for y-axis labels
                        product_group_labels = [chart_df.iloc[y_positions.index(pos)]['Product Group'] for pos in y_positions]
                
                        # Calculate dynamic height based on number of product groups
                        chart_height = max(350, 55 * (len(y_positions) + 1))  # Increased height per row for better spacing
                
                        # Update the layout with enhanced dark mode aesthetic
                        fig.update_layout(
                            barmode='stack',
                            height=chart_height,
                            margin=dict(l=200, r=40, t=70, b=50),  # Adjusted margins for better layout
                            yaxis=dict(
                                showticklabels=True,
                                ticktext=product_group_labels,
                                tickvals=y_positions,
                                tickfont=dict(size=13, color='#ffffff', family='Inter, Arial, sans-serif'),
                                showgrid=False,
                                zeroline=False,
                                domain=[0, 0.95],
                                title='',
                                ticklabelposition='outside'
                            ),
                            xaxis=dict(
                                title='',
                                showgrid=True,
                                gridcolor='rgba(255,255,255,0.15)',  # Slightly more visible grid lines
                                zeroline=False,
                                tickprefix=tick_prefix,
                                ticksuffix=tick_suffix,
                                tickformat=tick_format,
                                color='#ffffff',
                                tickfont=dict(size=12),
                                showline=True,
                                linecolor='rgba(255,255,255,0.3)',
                                mirror=True  # Add top axis line for better framing
                            ),
                            legend=dict(
                                orientation='h',
                                yanchor='bottom',
                                y=1.02,
                                xanchor='right',
                                x=1.0,  # Right-aligned legend
                                bgcolor='rgba(30,30,30,0.7)',  # Darker, more visible background
                                bordercolor='rgba(255,255,255,0.3)',
                                borderwidth=1,
                                font=dict(color='#ffffff', size=12, family='Inter, Arial, sans-serif'),
                                traceorder='reversed'  # Reverse order to match visual stacking (Spend, Ad Sales, Total Sales)
                            ),
                            legend_traceorder='reversed',
                            annotations=annotations,
                            plot_bgcolor='rgba(17,17,17,0.3)',  # Very subtle dark background
                            paper_bgcolor='rgba(0,0,0,0)',
                            bargap=0.4,  # Larger gap for better separation between product groups
                            font=dict(color='#ffffff', family='Inter, Arial, sans-serif'),
                            title=dict(
                                text='<b>Product Group Allocation (Stacked Bar View)</b>',
                                font=dict(size=18, color='#ffffff', family='Inter, Arial, sans-serif'),
                                x=0.0,
                                xanchor='left',
                                y=0.98,  # Position title slightly higher
                                yanchor='top'
                            ),
                            hoverlabel=dict(
                                bgcolor='rgba(50,50,50,0.9)',  # Dark hover label background
                                bordercolor='rgba(255,255,255,0.3)',
                                font=dict(family='Inter, Arial, sans-serif', size=13, color='white')
                            ),
                            hovermode='closest',
                            uniformtext=dict(minsize=10, mode='hide')  # Hide text that doesn't fit
                        )
                
                        return fig
            
                    # Display the charts in their respective tabs
                    with tab1:  # Stacked Bar View (default)
                        combined_fig = create_combined_view_chart()
                        st.plotly_chart(combined_fig, use_container_width=True)
            
                    with tab2:  # Percentage View
                        percentage_fig = create_product_group_chart(show_percentages=True)
                        st.plotly_chart(percentage_fig, use_container_width=True)
            
                    with tab3:  # Pie Charts
                        import plotly.express as px
                        import plotly.graph_objects as go
                        from plotly.subplots import make_subplots
                        
                        # Define consistent color palette for product groups
                        product_group_colors = [
                            '#FF6B6B',  # Coral Red
                            '#4A90E2',  # Blue  
                            '#50C878',  # Emerald Green
                            '#FF9F43',  # Orange
                            '#9B59B6',  # Purple
                            '#1ABC9C',  # Teal
                            '#F39C12',  # Golden Yellow
                            '#E74C3C',  # Red
                            '#3498DB',  # Light Blue
                            '#2ECC71',  # Green
                            '#E67E22',  # Dark Orange
                            '#8E44AD',  # Dark Purple
                            '#16A085',  # Dark Teal
                            '#F1C40F',  # Yellow
                            '#C0392B',  # Dark Red
                            '#2980B9',  # Dark Blue
                            '#27AE60',  # Dark Green
                            '#D35400',  # Pumpkin
                            '#7D3C98',  # Violet
                            '#138D75'   # Dark Cyan
                        ]
                        
                        # Create consistent color mapping for product groups
                        unique_groups = chart_df['Product Group'].unique()
                        color_mapping = {}
                        for i, group in enumerate(unique_groups):
                            color_mapping[group] = product_group_colors[i % len(product_group_colors)]
                        
                        pie_columns = [
                            ("Spend", "Ad Spend by Product Group"),
                            ("Ad Sales", "Ad Sales by Product Group"),
                            ("Total Sales", "Total Sales by Product Group")
                        ]
                        
                        # Create tabs including the new "All" tab
                        pie_tabs = st.tabs(["All", "Ad Spend", "Ad Sales", "Total Sales"])
                        
                        # Function to create individual pie chart
                        def create_pie_chart(col, title, chart_data):
                            # Filter out zero values
                            filtered_data = chart_data[chart_data[col] > 0].copy()
                            if len(filtered_data) == 0:
                                return None
                                
                            # Create colors list based on the product groups in this chart
                            colors = [color_mapping[group] for group in filtered_data['Product Group']]
                            
                            fig = px.pie(
                                filtered_data,
                                names="Product Group",
                                values=col,
                                title=title,
                                color_discrete_sequence=colors
                            )
                            fig.update_traces(
                                textinfo='percent+label',
                                pull=[0.05]*len(filtered_data),
                                marker=dict(line=dict(color='#222', width=1)),
                                textfont_color='white',
                                insidetextorientation='auto'
                            )
                            fig.update_layout(
                                template='plotly_dark',
                                height=500,
                                margin=dict(t=80, b=20, l=20, r=20),
                                legend_title_text='Product Group',
                                legend=dict(
                                    font=dict(color='#fff', size=12),
                                    bgcolor='rgba(30,30,30,0.7)',
                                    bordercolor='rgba(255,255,255,0.3)',
                                    borderwidth=1
                                ),
                                title=dict(
                                    font=dict(size=18, color='#fff'),
                                    x=0.5
                                ),
                                hoverlabel=dict(
                                    bgcolor='rgba(0,0,0,0.8)',
                                    font_size=12,
                                    font=dict(color='white')
                                )
                            )
                            return fig
                        # "All" tab - shows all three charts side by side
                        with pie_tabs[0]:
                            st.markdown("### Compare All Metrics")
                            # Create 3 columns for the charts
                            col1, col2, col3 = st.columns(3)
                            
                            # Function to create pie chart without legend
                            def create_pie_chart_no_legend(col, title, chart_data):
                                # Filter out zero values
                                filtered_data = chart_data[chart_data[col] > 0].copy()
                                if len(filtered_data) == 0:
                                    return None
                                    
                                # Create colors list based on the product groups in this chart
                                colors = [color_mapping[group] for group in filtered_data['Product Group']]
                                
                                fig = px.pie(
                                    filtered_data,
                                    names="Product Group",
                                    values=col,
                                    title=title,
                                    color_discrete_sequence=colors
                                )
                                fig.update_traces(
                                    textinfo='percent+label',
                                    pull=[0.05]*len(filtered_data),
                                    marker=dict(line=dict(color='#222', width=1)),
                                    textfont_color='white',
                                    insidetextorientation='auto',
                                    showlegend=False  # Hide individual legends
                                )
                                fig.update_layout(
                                    template='plotly_dark',
                                    height=400,
                                    margin=dict(t=80, b=20, l=20, r=20),
                                    title=dict(
                                        font=dict(size=16, color='#fff'),
                                        x=0.5
                                    ),
                                    hoverlabel=dict(
                                        bgcolor='rgba(0,0,0,0.8)',
                                        font_size=12,
                                        font=dict(color='white')
                                    )
                                )
                                return fig
                            
                            with col1:
                                spend_fig = create_pie_chart_no_legend("Spend", "Ad Spend by Product Group", chart_df)
                                if spend_fig:
                                    st.plotly_chart(spend_fig, use_container_width=True)
                                else:
                                    st.info("No spend data to display")
                            
                            with col2:
                                ad_sales_fig = create_pie_chart_no_legend("Ad Sales", "Ad Sales by Product Group", chart_df)
                                if ad_sales_fig:
                                    st.plotly_chart(ad_sales_fig, use_container_width=True)
                                else:
                                    st.info("No ad sales data to display")
                            
                            with col3:
                                total_sales_fig = create_pie_chart_no_legend("Total Sales", "Total Sales by Product Group", chart_df)
                                if total_sales_fig:
                                    st.plotly_chart(total_sales_fig, use_container_width=True)
                                else:
                                    st.info("No total sales data to display")
                            
                        for i, (col, title) in enumerate(pie_columns):
                            with pie_tabs[i + 1]:  # +1 because "All" tab is first
                                fig = create_pie_chart(col, title, chart_df)
                                if fig:
                                    st.plotly_chart(fig, use_container_width=True)
                                else:
                                    st.info(f"No {col.lower()} data to display")             
                elif len(filtered_group_perf_df) > 0:
                    missing_cols = [col for col in ['Spend', 'Ad Sales', 'Total Sales'] if col not in filtered_group_perf_df.columns]
                    st.info(f"Cannot display charts: Missing required columns {', '.join(missing_cols)}")
                elif not selected_groups:
                    st.info("Please select at least one Product Group to view charts.")
            else:
                st.warning("No metrics available for Product Group aggregation")
            # Debug info for Product Analysis
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append('[INFO] Displayed Product Analysis section')
            

        # Only show the 'Select or create a client' message if no client is selected
        elif not st.session_state.client_config:
            st.info("Select or create a client in the sidebar to get started.")

        # Initialize session state variables if they don't exist
        if 'settings_updated' not in st.session_state:
            st.session_state.settings_updated = False
    
        if 'new_branded_asins' not in st.session_state:
            st.session_state.new_branded_asins = []
    
        if 'new_sales_asins' not in st.session_state:
            st.session_state.new_sales_asins = []
    
        if 'new_sales_asins_titles' not in st.session_state:
            st.session_state.new_sales_asins_titles = {}
    
        if 'show_new_sales_asins_prompt' not in st.session_state:
            st.session_state.show_new_sales_asins_prompt = False

# --- Run the App ---
# (No explicit run needed here, Streamlit handles it)

# --- Performance by Placement Section ---
# Only show on the Advertising Audit page and only if NOT using Companion Exports
if st.session_state.current_page == "advertising_audit" and not st.session_state.get('is_companion_data', False):
    # --- Initialize session state for Placement Product Group filter ---
    if 'placement_product_group_filter' not in st.session_state:
        st.session_state.placement_product_group_filter = []
    if 'placement_product_group_filter_active' not in st.session_state:
        st.session_state.placement_product_group_filter_active = False

    available_placement_pgs = []
    PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT = 'tag_1' # As per memory 1c171cfc-a998-4b55-aeb3-6ef5088e1e87
    CAMPAIGN_NAME_COL_IN_TAGS_FOR_PLACEMENT = 'Campaign Name' # Common name in campaign_tags_df
    CAMPAIGN_NAME_COL_IN_BULK_FOR_PLACEMENT = 'Campaign Name (Informational only)' # Correct column name in bulk files (lowercase 'only')

    # Create campaign_tags_df from campaign_tags_data if it doesn't exist
    campaign_tags_df = None
    if (st.session_state.get('client_config') and 
        'campaign_tags_data' in st.session_state.client_config and 
        st.session_state.client_config['campaign_tags_data']):
        
        # Convert campaign_tags_data to DataFrame
        data = []
        for campaign_name, info in st.session_state.client_config['campaign_tags_data'].items():
            data.append({
                'Campaign Name': campaign_name,
                'Campaign Type': info.get('campaign_type', ''),
                'tag_1': info.get('tag_1', ''),
                'tag_2': info.get('tag_2', ''),
                'tag_3': info.get('tag_3', '')
            })
        
        if data:
            campaign_tags_df = pd.DataFrame(data)
            # Store in session state for use in the filter logic below
            st.session_state.campaign_tags_df = campaign_tags_df

    if campaign_tags_df is not None and not campaign_tags_df.empty:
        if PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT in campaign_tags_df.columns:
            # Get unique product groups, excluding empty/null values and blank strings
            all_product_groups = campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT].dropna().unique().tolist()
            # Filter out empty strings and whitespace-only strings
            available_placement_pgs = sorted([pg for pg in all_product_groups if pg and str(pg).strip()])
            
            # Check if there are any campaigns with empty/null product groups
            has_untagged = campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT].isna().any() or \
                          (campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT] == '').any() or \
                          campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT].astype(str).str.strip().eq('').any()
            
            # Add 'Untagged Group' option if there are campaigns without product group tags
            if has_untagged:
                available_placement_pgs.append('Untagged Group')
        else:
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f"[WARNING] Product group column '{PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT}' not found in campaign_tags_df for Placement filter.")

    # --- Performance by Placement ---
    st.markdown("<hr style='height:2px;border-width:0;color:gold;background-color:gold;margin-top:25px;margin-bottom:15px;margin-left:10px;margin-right:10px'>", unsafe_allow_html=True)
    st.markdown("<span class='main-section-header dashboard-section'>Performance by Placement</span>", unsafe_allow_html=True)

    # --- Product Group Filter for Placement ---
    if available_placement_pgs:
        prev_selection_placement = list(st.session_state.placement_product_group_filter) # Make a copy

        selected_pgs_placement = st.multiselect(
            "Filter by Product Group(s):",
            options=available_placement_pgs,
            key='placement_pg_multiselect_key' # Unique key
        )
        current_placement_pg_filter_active = bool(selected_pgs_placement)

        # If selection or active status changed, update session state and rerun
        if sorted(prev_selection_placement) != sorted(selected_pgs_placement) or \
           st.session_state.placement_product_group_filter_active != current_placement_pg_filter_active:
            st.session_state.placement_product_group_filter = selected_pgs_placement
            st.session_state.placement_product_group_filter_active = current_placement_pg_filter_active
            st.rerun()
    elif st.session_state.placement_product_group_filter_active: # If no PGs available but filter was active, deactivate
        st.session_state.placement_product_group_filter = []
        st.session_state.placement_product_group_filter_active = False
        st.rerun()

    
    # Add debug messages to track execution
    if 'debug_messages' in st.session_state:
        st.session_state.debug_messages.append('[INFO] Starting Performance by Placement section')
    
    # Check if bulk data exists
    if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
        # Add debug message
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append('[INFO] Bulk data found for placement analysis')
        
        # Initialize variables
        has_bidding_adjustment = False
        placement_data = pd.DataFrame()
        entity_columns_found = []
        bidding_adjustment_counts = {}
        
        # Initialize debug tracking for placement filtering
        if 'placement_filter_debug' not in st.session_state:
            st.session_state.placement_filter_debug = {}
    
        # Examine each sheet in the bulk data
        for sheet_name, df in st.session_state.bulk_data.items():
            if isinstance(df, pd.DataFrame) and not df.empty:
                # Initialize debug info for this sheet
                st.session_state.placement_filter_debug[sheet_name] = {
                    'original_rows': len(df),
                    'campaigns_found': 0,
                    'filtered_rows': 0,
                    'bidding_adjustment_rows': 0
                }
                
                # --- Apply Product Group Filter to current sheet df ---
                if st.session_state.get('placement_product_group_filter_active', False) and st.session_state.placement_product_group_filter:
                    if 'campaign_tags_df' in st.session_state and st.session_state.campaign_tags_df is not None and not st.session_state.campaign_tags_df.empty and \
                       CAMPAIGN_NAME_COL_IN_TAGS_FOR_PLACEMENT in st.session_state.campaign_tags_df.columns and \
                       PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT in st.session_state.campaign_tags_df.columns:
                        
                        # Check for campaign column using case-insensitive matching
                        bulk_campaign_col = None
                        for col in df.columns:
                            if col.lower() == CAMPAIGN_NAME_COL_IN_BULK_FOR_PLACEMENT.lower():
                                bulk_campaign_col = col
                                break
                        
                        if bulk_campaign_col is None:
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[WARNING] Campaign column '{CAMPAIGN_NAME_COL_IN_BULK_FOR_PLACEMENT}' not found in sheet '{sheet_name}' for Placement Product Group filtering.")
                        else:
                            # Get campaigns that match the selected product groups
                            campaigns_for_selected_pgs = []
                            
                            # Handle regular product groups
                            regular_pgs = [pg for pg in st.session_state.placement_product_group_filter if pg != 'Untagged Group']
                            if regular_pgs:
                                tagged_campaigns = st.session_state.campaign_tags_df[
                                    st.session_state.campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT].isin(regular_pgs)
                                ][CAMPAIGN_NAME_COL_IN_TAGS_FOR_PLACEMENT].unique().tolist()
                                campaigns_for_selected_pgs.extend(tagged_campaigns)
                            
                            # Handle 'Untagged Group' selection
                            if 'Untagged Group' in st.session_state.placement_product_group_filter:
                                untagged_campaigns = st.session_state.campaign_tags_df[
                                    (st.session_state.campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT].isna()) |
                                    (st.session_state.campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT] == '') |
                                    (st.session_state.campaign_tags_df[PRODUCT_GROUP_COLUMN_NAME_FOR_PLACEMENT].astype(str).str.strip() == '')
                                ][CAMPAIGN_NAME_COL_IN_TAGS_FOR_PLACEMENT].unique().tolist()
                                campaigns_for_selected_pgs.extend(untagged_campaigns)
                            
                            # Remove duplicates and convert to list
                            campaigns_for_selected_pgs = list(set(campaigns_for_selected_pgs))

                            st.session_state.placement_filter_debug[sheet_name]['campaigns_found'] = len(campaigns_for_selected_pgs)
                            
                            # Add detailed debugging for campaign matching
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f"[DEBUG] Sheet '{sheet_name}' - Selected Product Groups: {st.session_state.placement_product_group_filter}")
                                st.session_state.debug_messages.append(f"[DEBUG] Sheet '{sheet_name}' - Campaigns from tags matching PGs: {campaigns_for_selected_pgs[:5]}...")  # Show first 5
                                
                                # Show sample campaigns from the bulk file
                                if bulk_campaign_col:
                                    bulk_campaigns = df[bulk_campaign_col].dropna().unique()[:5].tolist()
                                    st.session_state.debug_messages.append(f"[DEBUG] Sheet '{sheet_name}' - Sample campaigns in bulk file (using column '{bulk_campaign_col}'): {bulk_campaigns}")
                                    
                                    # Check for case-insensitive matches
                                    campaigns_lower = [c.lower() for c in campaigns_for_selected_pgs]
                                    bulk_campaigns_lower = df[bulk_campaign_col].str.lower().dropna().unique()
                                    matches = [c for c in bulk_campaigns_lower if c in campaigns_lower]
                                    st.session_state.debug_messages.append(f"[DEBUG] Sheet '{sheet_name}' - Case-insensitive campaign matches found: {len(matches)} - {matches[:3]}...")
                                else:
                                    st.session_state.debug_messages.append(f"[DEBUG] Sheet '{sheet_name}' - No campaign column matching '{CAMPAIGN_NAME_COL_IN_BULK_FOR_PLACEMENT}' found (case-insensitive)")

                            if campaigns_for_selected_pgs:
                                df_original_shape = df.shape
                                # Apply case-insensitive filtering using the found column
                                campaigns_for_selected_pgs_lower = [camp.lower() for camp in campaigns_for_selected_pgs]
                                df_campaign_col_lower = df[bulk_campaign_col].str.lower()
                                df = df[df_campaign_col_lower.isin(campaigns_for_selected_pgs_lower)].copy()
                                st.session_state.placement_filter_debug[sheet_name]['filtered_rows'] = len(df)
                                if 'debug_messages' in st.session_state:
                                    st.session_state.debug_messages.append(f"[INFO] Sheet '{sheet_name}' (original shape: {df_original_shape}) filtered by Product Groups for Placement. New shape: {df.shape}. Campaigns found: {len(campaigns_for_selected_pgs)}")
                            else:
                                # No campaigns match the selected product groups, so this sheet will be empty for these PGs
                                df = pd.DataFrame(columns=df.columns) # Make df empty
                                st.session_state.placement_filter_debug[sheet_name]['filtered_rows'] = 0
                                if 'debug_messages' in st.session_state:
                                    st.session_state.debug_messages.append(f"[INFO] No campaigns in sheet '{sheet_name}' match selected Product Groups for Placement. Sheet effectively empty for this filter.")
                    else:
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append("[WARNING] Cannot apply Product Group filter for Placements: campaign_tags_df missing or misconfigured.")
                else:
                    # No filtering applied
                    st.session_state.placement_filter_debug[sheet_name]['filtered_rows'] = len(df)
                
                # If df became empty after filtering, skip to the next sheet
                if df.empty:
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f"[INFO] Sheet '{sheet_name}' is empty after potential Product Group filtering for Placement. Skipping.")
                    continue
                # Check if Entity column exists
                if 'Entity' in df.columns:
                    entity_columns_found.append(sheet_name)
                    
                    # Check for Bidding Adjustment rows - only if Entity column exists
                    bidding_rows = df[df['Entity'].astype(str).str.strip().str.lower() == 'bidding adjustment']
                    bidding_adjustment_counts[sheet_name] = len(bidding_rows)
                    st.session_state.placement_filter_debug[sheet_name]['bidding_adjustment_rows'] = len(bidding_rows)
                else:
                    # Skip this sheet if Entity column doesn't exist
                    bidding_rows = pd.DataFrame()
                    bidding_adjustment_counts[sheet_name] = 0
                    
                    # Debug message for missing Entity column
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[WARNING] No Entity column found in {sheet_name}')
                
                # Initialize bidding_rows as an empty DataFrame if not already defined
                if 'bidding_rows' not in locals():
                    bidding_rows = pd.DataFrame()
                    
                if not bidding_rows.empty:
                    has_bidding_adjustment = True
                    
                    # Debug message for bidding adjustment rows found
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[INFO] Found {len(bidding_rows)} Bidding Adjustment rows in {sheet_name}')
                    
                    # List all columns in the dataframe to help with debugging
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[INFO] Available columns in {sheet_name}: {list(bidding_rows.columns)}')
                    
                    # Check for placement columns with more flexible matching
                    placement_columns = []
                    placement_column_patterns = {
                        'rest of search': 'Placement Rest Of Search',
                        'product page': 'Placement Product Page', 
                        'top': 'Placement Top',
                        'business': 'Placement Amazon Business'
                    }
                    
                    # Debug message to show all available columns
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[INFO] Searching for placement columns in: {list(bidding_rows.columns)}')
                    
                    # First, check if there's a generic 'Placement' column
                    has_generic_placement = False
                    for col in bidding_rows.columns:
                        if col.lower() == 'placement':
                            has_generic_placement = True
                            # Add debug message about finding the generic placement column
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f'[INFO] Found generic Placement column: {col}')
                            
                            # Check unique values in this column
                            unique_values = bidding_rows[col].dropna().unique()
                            if 'debug_messages' in st.session_state:
                                st.session_state.debug_messages.append(f'[INFO] Unique values in Placement column: {unique_values}')
                            
                            # If we have a generic placement column, we'll use it differently
                            # We'll treat each unique value as a separate placement type
                            break
                    
                    # Find columns that match our patterns or use the generic placement column
                    if has_generic_placement:
                        # Use the generic placement column
                        for col in bidding_rows.columns:
                            if col.lower() == 'placement':
                                placement_columns.append(col)
                                break
                    else:
                        # Look for specific placement columns
                        for col in bidding_rows.columns:
                            col_lower = col.lower()
                            # Very flexible matching - just look for 'placement' and any of our patterns
                            if 'placement' in col_lower:
                                for pattern, standard_name in placement_column_patterns.items():
                                    if pattern in col_lower:
                                        placement_columns.append(col)
                                        # Map the actual column name to our standard name for later use
                                        placement_column_patterns[pattern] = col
                                        break
                    
                    # Debug message for placement columns found
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[INFO] Found placement columns: {placement_columns}')
                    
                    # Only proceed if we found at least one placement column
                    if placement_columns:
                        # Select columns we need for analysis
                        needed_columns = ['Campaign', 'Ad Group'] if all(col in bidding_rows.columns for col in ['Campaign', 'Ad Group']) else []
                        needed_columns.extend(placement_columns)
                        
                        # Look for metric columns with flexible matching - expanded patterns for better detection
                        metric_patterns = {
                            'spend': 'Spend',
                            'sales': 'Sales',
                            'click': 'Clicks',
                            'impression click': 'Clicks',  # Add this pattern for better clicks detection
                            'order': 'Orders'
                        }
                        
                        metric_columns = {}
                        for col in bidding_rows.columns:
                            col_lower = col.lower()
                            for pattern, standard_name in metric_patterns.items():
                                if pattern in col_lower:
                                    metric_columns[standard_name] = col
                                    needed_columns.append(col)
                                    break
                        
                        # Debug message for metric columns found
                        if 'debug_messages' in st.session_state:
                            st.session_state.debug_messages.append(f'[INFO] Found metric columns: {metric_columns}')
                        
                        # Filter columns that exist in the dataframe
                        existing_columns = [col for col in needed_columns if col in bidding_rows.columns]
                        
                        if existing_columns:
                            # Append to our placement data
                            if placement_data.empty:
                                placement_data = bidding_rows[existing_columns].copy()
                            else:
                                placement_data = pd.concat([placement_data, bidding_rows[existing_columns]], ignore_index=True)
    
        # Debug summary of what we found
        if 'debug_messages' in st.session_state:
            if entity_columns_found:
                st.session_state.debug_messages.append(f'[INFO] Entity column found in sheets: {entity_columns_found}')
            else:
                st.session_state.debug_messages.append('[WARNING] No Entity column found in any sheet')
                
            st.session_state.debug_messages.append(f'[INFO] Bidding Adjustment counts by sheet: {bidding_adjustment_counts}')
            st.session_state.debug_messages.append(f'[INFO] Final placement data shape: {placement_data.shape if not placement_data.empty else "Empty"}')
            
            # Add debug info for Product Group filtering
            if st.session_state.get('placement_product_group_filter_active', False) and st.session_state.placement_product_group_filter:
                st.session_state.debug_messages.append(f'[INFO] Product Group filter applied for Placement: {st.session_state.placement_product_group_filter}')
                if not placement_data.empty and 'Campaign' in placement_data.columns:
                    unique_campaigns = placement_data['Campaign'].unique()
                    st.session_state.debug_messages.append(f'[INFO] Campaigns in filtered placement data: {unique_campaigns[:10].tolist()}')  # Show first 10
            else:
                st.session_state.debug_messages.append('[INFO] No Product Group filter active for Placement')
        
        # Display information about what we found
        if not has_bidding_adjustment:
            st.info("No 'Bidding Adjustment' rows found in the bulk file. Upload a bulk file with bidding adjustment data to see placement performance.")
        elif placement_data.empty:
            st.info("Found 'Bidding Adjustment' rows but no placement columns were detected. Check that your bulk file contains placement data.")
        else:
            # Prepare data for display
            # Convert numeric columns to proper numeric type
            for col in placement_data.columns:
                # Try to identify numeric columns that might contain our metrics - expanded patterns
                if any(metric in col.lower() for metric in ['spend', 'sales', 'click', 'impression click', 'order']):
                    placement_data[col] = safe_convert_to_numeric(placement_data[col])
                    # Map actual column names to our standard names for metrics
            metric_mapping = {}
            for col in placement_data.columns:
                col_lower = col.lower()
                if 'spend' in col_lower:
                    metric_mapping['Spend'] = col
                elif 'sales' in col_lower:
                    metric_mapping['Sales'] = col
                # Prioritize exact 'clicks' column over 'click-through rate'
                elif col_lower == 'clicks':
                    metric_mapping['Clicks'] = col
                elif 'order' in col_lower:
                    metric_mapping['Orders'] = col
            
            # If we didn't find an exact 'clicks' column, look for alternatives
            if 'Clicks' not in metric_mapping:
                for col in placement_data.columns:
                    col_lower = col.lower()
                    if 'click' in col_lower and 'rate' not in col_lower:
                        metric_mapping['Clicks'] = col
                        break
                
                # If we still don't have clicks but have impressions and CTR, calculate clicks
                if 'Clicks' not in metric_mapping:
                    ctr_col = None
                    impressions_col = None
                    
                    for col in placement_data.columns:
                        col_lower = col.lower()
                        if 'click-through rate' in col_lower or 'ctr' in col_lower:
                            ctr_col = col
                        elif 'impression' in col_lower:
                            impressions_col = col
                    
                    if ctr_col and impressions_col:
                        # Calculate clicks from impressions and CTR
                        placement_data['Calculated Clicks'] = placement_data.apply(
                            lambda row: int(row[impressions_col] * row[ctr_col] / 100) if pd.notnull(row[impressions_col]) and pd.notnull(row[ctr_col]) else 0,
                            axis=1
                        )
                        metric_mapping['Clicks'] = 'Calculated Clicks'
                    
            # Debug message to show all available columns for better diagnostics
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f'[INFO] All columns in placement_data: {list(placement_data.columns)}')
        
            # Debug message for metric mapping
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f'[INFO] Metric mapping: {metric_mapping}')
                
                # Add detailed debug for clicks data
                if 'Clicks' in metric_mapping:
                    clicks_col = metric_mapping['Clicks']
                    if clicks_col in placement_data.columns:
                        st.session_state.debug_messages.append(f'[INFO] Clicks column statistics: Min={placement_data[clicks_col].min()}, Max={placement_data[clicks_col].max()}, Sum={placement_data[clicks_col].sum()}')
                        st.session_state.debug_messages.append(f'[INFO] Sample clicks values: {placement_data[clicks_col].head(5).tolist()}')
            
            # Check if we have the necessary columns to calculate metrics
            has_spend = 'Spend' in metric_mapping
            has_sales = 'Sales' in metric_mapping
            has_clicks = 'Clicks' in metric_mapping
            has_orders = 'Orders' in metric_mapping
        
            # Map placement column patterns to display names
            display_mapping = {
                'rest of search': 'Rest Of Search',
                'product page': 'Product Page',
                'top': 'Top of Search',
                'business': 'B2B Modifier'
            }
        
            # Check if we have a generic placement column
            has_generic_placement = False
            generic_placement_col = None
            for col in placement_data.columns:
                if col.lower() == 'placement':
                    has_generic_placement = True
                    generic_placement_col = col
                    # Add debug message
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[INFO] Using generic Placement column: {col}')
                    break
        
            # Map actual column names to our display names
            placement_mapping = {}
            
            if has_generic_placement:
                # For generic placement column, we'll create a special mapping
                # Get unique values from the placement column
                unique_placements = placement_data[generic_placement_col].dropna().unique()
                
                # Debug message for unique placement values
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f'[INFO] Unique placement values: {unique_placements}')
                
                # Map each unique value to a display name
                # We'll use a case-insensitive matching approach
                for value in unique_placements:
                    if isinstance(value, str):
                        value_lower = value.lower()
                        # Try to match to our standard display names
                        matched = False
                        for pattern, display_name in display_mapping.items():
                            if pattern in value_lower:
                                # This is a special mapping where we map (column, value) to display_name
                                placement_mapping[(generic_placement_col, value)] = display_name
                                matched = True
                                break
                        
                        # If no match found, use the value itself as the display name
                        if not matched:
                            placement_mapping[(generic_placement_col, value)] = value
            else:
                # For specific placement columns, use the original approach
                for col in placement_data.columns:
                    col_lower = col.lower()
                    if 'placement' in col_lower:
                        for pattern, display_name in display_mapping.items():
                            if pattern in col_lower:
                                placement_mapping[col] = display_name
                                break

            # Debug message for placement mapping
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f'[INFO] Placement mapping: {placement_mapping}')
            
            # Debug message to show which metrics were found
            if 'debug_messages' in st.session_state:
                st.session_state.debug_messages.append(f'[INFO] Metrics found: Spend={has_spend}, Sales={has_sales}, Clicks={has_clicks}, Orders={has_orders}')
                
            if has_spend and has_sales and placement_mapping:  # Make clicks and orders optional
                # Create a dictionary to store our placement performance data
                placement_performance = {}
                for display_name in display_mapping.values():
                    # Initialize with zeros for all metrics
                    placement_performance[display_name] = {
                        'Spend': 0, 
                        'Ad Sales': 0, 
                        'Clicks': 0 if has_clicks else None,  # Use None if clicks data not available
                        'Orders': 0 if has_orders else None   # Use None if orders data not available
                    }
            
                # Aggregate data for each placement type
                if has_generic_placement:
                    # For generic placement column, we need to filter by value
                    for (col, value), display_name in placement_mapping.items():
                        # Get rows where the placement column equals this specific value
                        relevant_rows = placement_data[placement_data[col] == value]
                        
                        if not relevant_rows.empty:
                            # Initialize this placement type if it doesn't exist
                            if display_name not in placement_performance:
                                placement_performance[display_name] = {'Spend': 0, 'Ad Sales': 0, 'Clicks': 0 if has_clicks else None, 'Orders': 0 if has_orders else None}
                            
                            # Sum up the metrics for this placement type
                            if has_spend:
                                placement_performance[display_name]['Spend'] = relevant_rows[metric_mapping['Spend']].sum()
                            if has_sales:
                                placement_performance[display_name]['Ad Sales'] = relevant_rows[metric_mapping['Sales']].sum()
                            if has_clicks:
                                placement_performance[display_name]['Clicks'] = relevant_rows[metric_mapping['Clicks']].sum()
                            if has_orders:
                                placement_performance[display_name]['Orders'] = relevant_rows[metric_mapping['Orders']].sum()
                else:
                    # For specific placement columns
                    for db_col, display_name in placement_mapping.items():
                        # Get rows where this placement column is not null
                        relevant_rows = placement_data[placement_data[db_col].notna()]
                        
                        if not relevant_rows.empty:
                            # Sum up the metrics for this placement type
                            if has_spend:
                                placement_performance[display_name]['Spend'] = relevant_rows[metric_mapping['Spend']].sum()
                            if has_sales:
                                placement_performance[display_name]['Ad Sales'] = relevant_rows[metric_mapping['Sales']].sum()
                            if has_clicks:
                                placement_performance[display_name]['Clicks'] = relevant_rows[metric_mapping['Clicks']].sum()
                            if has_orders:
                                placement_performance[display_name]['Orders'] = relevant_rows[metric_mapping['Orders']].sum()
            
                # Create a DataFrame from our performance data
                performance_df = pd.DataFrame.from_dict(placement_performance, orient='index')
                
                # Debug message for performance data
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append(f'[INFO] Created performance dataframe with shape: {performance_df.shape}')
                
                # Calculate derived metrics
                performance_df['ACoS'] = performance_df.apply(
                    lambda row: (row['Spend'] / row['Ad Sales'] * 100) if row['Ad Sales'] > 0 else float('inf'),
                    axis=1
                )
                performance_df['ROAS'] = performance_df.apply(
                    lambda row: (row['Ad Sales'] / row['Spend']) if row['Spend'] > 0 else 0,
                    axis=1
                )
                
                # Only calculate CPC and CVR if we have clicks data
                if has_clicks:
                    # Ensure Clicks are properly populated from the bulk file
                    for placement, data in placement_performance.items():
                        if data['Clicks'] is None or pd.isna(data['Clicks']):
                            # Try to get clicks directly from the relevant rows if available
                            if 'Clicks' in metric_mapping and metric_mapping['Clicks'] in placement_data.columns:
                                if has_generic_placement:
                                    for (col, value), display_name in placement_mapping.items():
                                        if display_name == placement:
                                            relevant_rows = placement_data[placement_data[col] == value]
                                            if not relevant_rows.empty:
                                                data['Clicks'] = relevant_rows[metric_mapping['Clicks']].sum()
                                else:
                                    for db_col, display_name in placement_mapping.items():
                                        if display_name == placement:
                                            relevant_rows = placement_data[placement_data[db_col].notna()]
                                            if not relevant_rows.empty:
                                                data['Clicks'] = relevant_rows[metric_mapping['Clicks']].sum()
                    
                    # Now calculate CPC with the updated clicks data
                    performance_df['CPC'] = performance_df.apply(
                        lambda row: (row['Spend'] / row['Clicks']) if pd.notnull(row['Clicks']) and row['Clicks'] > 0 else None,
                        axis=1
                    )
                    
                    if has_orders:
                        performance_df['CVR'] = performance_df.apply(
                            lambda row: (row['Orders'] / row['Clicks'] * 100) if pd.notnull(row['Clicks']) and pd.notnull(row['Orders']) and row['Clicks'] > 0 else None,
                            axis=1
                        )
                
                # Exclude B2B Modifier from totals calculations (avoid double counting)
                # B2B Modifier can be applied across other placements, so including it would double-count
                totals_df = performance_df[~performance_df.index.isin(['B2B Modifier', 'Amazon Business'])].copy()
                
                # Calculate totals for summary cards (excluding B2B Modifier)
                total_spend = totals_df['Spend'].sum()
                total_ad_sales = totals_df['Ad Sales'].sum()
            
                # Calculate ACoS and ROAS for the totals
                total_acos = (total_spend / total_ad_sales * 100) if total_ad_sales > 0 else float('inf')
                total_roas = (total_ad_sales / total_spend) if total_spend > 0 else 0
                
                # Calculate additional metrics for summary cards
                total_clicks = totals_df['Clicks'].sum() if 'Clicks' in totals_df.columns else 0
                total_orders = totals_df['Orders'].sum() if 'Orders' in totals_df.columns else 0
                total_cpc = (total_spend / total_clicks) if total_clicks and total_clicks > 0 else 0
                total_cvr = (total_orders / total_clicks * 100) if total_clicks and total_clicks > 0 and total_orders else 0
                
                # Display summary cards above the table
                st.markdown("### Placement Performance Summary")
                
                # Create columns for summary cards - 6 cards in 2 rows of 3
                summary_cols_1 = st.columns(3)
                
                with summary_cols_1[0]:
                    st.metric(
                        label="Spend",
                        value=f"${total_spend:,.2f}"
                    )
                
                with summary_cols_1[1]:
                    st.metric(
                        label="Ad Sales", 
                        value=f"${total_ad_sales:,.2f}"
                    )
                
                with summary_cols_1[2]:
                    roas_display = f"{total_roas:.2f}x" if total_roas > 0 else 'N/A'
                    st.metric(
                        label="ROAS",
                        value=roas_display
                    )
                
                # Second row of cards
                summary_cols_2 = st.columns(3)
                
                with summary_cols_2[0]:
                    acos_display = f"{total_acos:.1f}%" if total_acos != float('inf') else 'N/A'
                    st.metric(
                        label="ACoS",
                        value=acos_display
                    )
                
                with summary_cols_2[1]:
                    cpc_display = f"${total_cpc:.2f}" if total_cpc > 0 else 'N/A'
                    st.metric(
                        label="CPC",
                        value=cpc_display
                    )
                
                with summary_cols_2[2]:
                    cvr_display = f"{total_cvr:.1f}%" if total_cvr > 0 else 'N/A'
                    st.metric(
                        label="CVR",
                        value=cvr_display
                    )
                
                st.markdown("---")  # Separator line
                
                # Add percentage columns to the performance dataframe (excluding B2B Modifier from totals)
                # Calculate totals excluding B2B Modifier for percentage calculations
                performance_for_percentages = performance_df[~performance_df.index.isin(['B2B Modifier', 'Amazon Business'])].copy()
                total_spend_for_percentages = performance_for_percentages['Spend'].sum()
                total_ad_sales_for_percentages = performance_for_percentages['Ad Sales'].sum()
                
                # Initialize percentage columns
                performance_df['% of Spend'] = 0.0
                performance_df['% of Ad Sales'] = 0.0
                
                # Calculate percentages only for non-B2B Modifier placements
                for placement in performance_df.index:
                    if placement not in ['B2B Modifier', 'Amazon Business']:
                        if total_spend_for_percentages > 0:
                            performance_df.loc[placement, '% of Spend'] = (performance_df.loc[placement, 'Spend'] / total_spend_for_percentages * 100)
                        if total_ad_sales_for_percentages > 0:
                            performance_df.loc[placement, '% of Ad Sales'] = (performance_df.loc[placement, 'Ad Sales'] / total_ad_sales_for_percentages * 100)
                
                # Make a copy for display formatting
                display_df = performance_df.copy()
                
                # Format the metrics for display with improved handling of missing data
                display_df['Spend'] = display_df['Spend'].apply(lambda x: f"${x:,.2f}")
                display_df['Ad Sales'] = display_df['Ad Sales'].apply(lambda x: f"${x:,.2f}")
                display_df['ACoS'] = display_df['ACoS'].apply(lambda x: f"{x:.2f}%" if x != float('inf') else 'N/A')
                display_df['ROAS'] = display_df['ROAS'].apply(lambda x: f"{x:.2f}" if x > 0 else 'N/A')
                display_df['% of Spend'] = display_df['% of Spend'].apply(lambda x: f"{x:.2f}%")
                display_df['% of Ad Sales'] = display_df['% of Ad Sales'].apply(lambda x: f"{x:.2f}%")
                
                # Only format columns that exist in the dataframe
                if 'CPC' in display_df.columns:
                    display_df['CPC'] = display_df['CPC'].apply(lambda x: f"${x:.2f}" if pd.notnull(x) and x > 0 else 'N/A')
                    
                if 'CVR' in display_df.columns:
                    display_df['CVR'] = display_df['CVR'].apply(lambda x: f"{x:.2f}%" if pd.notnull(x) and x > 0 else 'N/A')
                
                if 'Clicks' in display_df.columns:
                    # Improved clicks display with better null handling
                    display_df['Clicks'] = display_df['Clicks'].apply(
                        lambda x: f"{int(x):,}" if pd.notnull(x) and x != 0 else "0"
                    )
                    # Debug message for clicks data
                    # Add debug message
                    if 'debug_messages' in st.session_state:
                        st.session_state.debug_messages.append(f'[INFO] Clicks data in performance_df: {performance_df["Clicks"].to_dict()}')
                        st.session_state.debug_messages.append(f'[INFO] Clicks column used: {metric_mapping.get("Clicks", "None")}')
                    
                if 'Orders' in display_df.columns:
                    display_df['Orders'] = display_df['Orders'].apply(
                        lambda x: f"{int(x):,}" if pd.notnull(x) else "0"
                    )
                
                # Reorder columns for display - only include columns that exist
                # Put Spend and Ad Sales together, followed by their percentage columns
                base_display_cols = ['Spend', 'Ad Sales', '% of Spend', '% of Ad Sales', 'ACoS', 'ROAS']
                optional_cols = []
                
                # Only include optional columns if they exist in the dataframe
                if 'CPC' in display_df.columns:
                    optional_cols.append('CPC')
                if 'CVR' in display_df.columns:
                    optional_cols.append('CVR')
                if 'Clicks' in display_df.columns:
                    optional_cols.append('Clicks')
                if 'Orders' in display_df.columns:
                    optional_cols.append('Orders')
                    
                display_cols = base_display_cols + optional_cols
                display_df = display_df[display_cols]
                
                # Create a styled dataframe with conditional formatting
                styled_df = display_df.copy()
                
                # Extract numeric values for styling (removing % and $ signs)
                numeric_df = performance_df.copy()
                
                # Apply conditional formatting to percentage columns
                # Create a styler object
                styler = styled_df.style
                
                # Apply blue gradient to % of Spend column
                styler = styler.apply(lambda x: [
                    color_gradient_blue(v, 0, 100) if i != len(x)-1 else ''
                    for i, v in enumerate(numeric_df['% of Spend'])
                ], axis=0, subset=['% of Spend'])
                
                # Apply green gradient to % of Ad Sales column
                styler = styler.apply(lambda x: [
                    color_gradient_green(v, 0, 100) if i != len(x)-1 else ''
                    for i, v in enumerate(numeric_df['% of Ad Sales'])
                ], axis=0, subset=['% of Ad Sales'])
                
                # Display the styled table
                st.dataframe(styler, use_container_width=True)

                # --- Display "Filtered by" message for Placement Product Group filter ---
                if st.session_state.get('placement_product_group_filter_active', False) and st.session_state.placement_product_group_filter:
                    st.markdown(f"<p style='font-size: smaller; text-align: left; margin-top: 10px; margin-bottom: 10px;'>Filtered by Product Group(s): {', '.join(st.session_state.placement_product_group_filter)}</p>", unsafe_allow_html=True)
                
                # Add pie charts for Spend and Ad Sales by Placement
                # Exclude B2B Modifier from pie charts to avoid double counting
                pie_chart_df = performance_df[~performance_df.index.isin(['B2B Modifier', 'Amazon Business'])].copy()
                
                # Only create pie charts if we have at least two placements
                if len(pie_chart_df) >= 2:
                    
                    # Define a consistent color mapping for placements
                    placement_types = pie_chart_df.index.tolist()
                    
                    # Define a fixed color mapping for common placement types
                    color_mapping = {
                        'Rest Of Search': '#42A5F5',  # Blue
                        'Product Page': '#66BB6A',   # Green
                        'Top of Search': '#FFA726',  # Orange
                        'B2B Modifier': '#AB47BC',   # Purple
                        'Amazon Business': '#EF5350' # Red
                    }
                    
                    # Create two columns for the pie charts
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Create pie chart for Spend
                        fig_spend = px.pie(
                            pie_chart_df,
                            names=pie_chart_df.index,
                            values='Spend',
                            title='% of Total Spend by Placement',
                            color=pie_chart_df.index,
                            color_discrete_map=color_mapping
                        )
                        fig_spend.update_traces(textinfo='percent+label', pull=[0.05]*len(pie_chart_df))
                        st.plotly_chart(fig_spend, use_container_width=True, key="placement_spend_chart")
                    
                    with col2:
                        # Create pie chart for Ad Sales
                        fig_sales = px.pie(
                            pie_chart_df,
                            names=pie_chart_df.index,
                            values='Ad Sales',
                            title='% of Total Ad Sales by Placement',
                            color=pie_chart_df.index,
                            color_discrete_map=color_mapping
                        )
                        fig_sales.update_traces(textinfo='percent+label', pull=[0.05]*len(pie_chart_df))
                        st.plotly_chart(fig_sales, use_container_width=True, key="placement_sales_chart")
                
                # Add debug message
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append('[INFO] Successfully displayed Performance by Placement section with summary cards and percentage columns')
            else:
                # Identify what's missing
                missing_metrics = []
                if not has_spend: missing_metrics.append('Spend')
                if not has_sales: missing_metrics.append('Sales')
                if not has_clicks: missing_metrics.append('Clicks')
                if not has_orders: missing_metrics.append('Orders')
                
                if missing_metrics:
                    st.info(f"Cannot display Performance by Placement: Missing required metrics {', '.join(missing_metrics)}")
                elif not placement_mapping:
                    st.info("Cannot display Performance by Placement: No placement columns identified")
                else:
                    st.info("Cannot display Performance by Placement: Insufficient data")
                
                # Show what columns we did find to help with debugging
                st.write("Available columns in the bulk file:")
                if not placement_data.empty:
                    st.write(", ".join(placement_data.columns))
                else:
                    st.write("No relevant data found")
                    
                # Add debug message
                if 'debug_messages' in st.session_state:
                    st.session_state.debug_messages.append('[WARNING] Could not display Performance by Placement due to missing data')
    else:
        st.info("No bulk data available. Upload a bulk file to see placement performance.")
        # Add debug message
        if 'debug_messages' in st.session_state:
            st.session_state.debug_messages.append('[INFO] No bulk data available for placement analysis')


# --- Debugging Information: Always show at the very bottom ---
# Initialize debug messages list if it doesn't exist
if 'debug_messages' not in st.session_state:
    st.session_state.debug_messages = []
    
# Initialize debug flag if it doesn't exist
if 'debug' not in st.session_state:
    st.session_state.debug = False

# Create a safe function to add debug messages that won't crash the app
def add_debug_msg(category, message):
    try:
        full_msg = f"[{category}] {message}"
        if full_msg not in st.session_state.debug_messages:
            st.session_state.debug_messages.append(full_msg)
    except Exception as e:
        # If even adding a debug message fails, at least try to record that
        try:
            st.session_state.debug_messages.append(f"[ERROR] Failed to add debug message: {str(e)}")
        except:
            pass  # At this point we can't do anything else

# Display the debugging information in an expander at the very bottom
with st.expander("Debugging Information", expanded=False):
    if 'debug' in st.session_state and st.session_state.debug:
        st.markdown("### Debug Mode is ON")
        
        # Show session state variables
        st.markdown("#### Session State Variables")
        st.write("Client: ", st.session_state.get('client', 'Not set'))
        st.write("Date Range: ", st.session_state.get('date_range', 'Not set'))
        st.write("Marketplace: ", st.session_state.get('marketplace', 'Not set'))
        
        # Show loaded files
        st.markdown("#### Loaded Files")
        if 'loaded_files' in st.session_state:
            for file_type, files in st.session_state.loaded_files.items():
                st.write(f"{file_type}: {len(files)} file(s)")
                for file in files:
                    st.write(f"  - {file}")
        else:
            st.write("No files loaded yet.")
        
        # Show data processing status
        st.markdown("#### Data Processing Status")
        st.write("Bulk Files Processed: ", st.session_state.get('bulk_files_processed', False))
        st.write("Sales Report Processed: ", st.session_state.get('sales_report_processed', False))
        
        # Show any error messages
        st.markdown("#### Error Messages")
        if 'error_messages' in st.session_state and st.session_state.error_messages:
            for error in st.session_state.error_messages:
                st.error(error)
        else:
            st.write("No errors reported.")
            
        # Show Product Group Filtering Debug Information
        st.markdown("#### Product Group Filtering Debug")
        
        # Add Performance by Placement filter debug information
        st.markdown("**Performance by Placement Filter Debug:**")
        st.write(f"Filter Active: {st.session_state.get('placement_product_group_filter_active', False)}")
        st.write(f"Selected Product Groups: {st.session_state.get('placement_product_group_filter', [])}")
        
        # Campaign tags debugging
        if 'campaign_tags_df' in st.session_state and st.session_state.campaign_tags_df is not None:
            st.write(f"Campaign Tags DataFrame Shape: {st.session_state.campaign_tags_df.shape}")
            if not st.session_state.campaign_tags_df.empty:
                if 'tag_1' in st.session_state.campaign_tags_df.columns:
                    unique_product_groups = st.session_state.campaign_tags_df['tag_1'].dropna().unique()
                    st.write(f"Available Product Groups in Campaign Tags: {unique_product_groups}")
                else:
                    st.write("No 'tag_1' column found in campaign_tags_df")
        else:
            st.write("No campaign_tags_df available")
        
                 # Show placement data processing debug information
        if 'placement_filter_debug' in st.session_state:
            debug_info = st.session_state.placement_filter_debug
            st.markdown("**Placement Data Processing Debug:**")
            for sheet_name, info in debug_info.items():
                st.write(f"Sheet: {sheet_name}")
                st.write(f"  - Original rows: {info.get('original_rows', 'N/A')}")
                st.write(f"  - Filtered rows: {info.get('filtered_rows', 'N/A')}")
                st.write(f"  - Campaigns found: {info.get('campaigns_found', 'N/A')}")
                st.write(f"  - Bidding adjustment rows: {info.get('bidding_adjustment_rows', 'N/A')}")
        
        # Show campaign matching debug details
        st.markdown("**Campaign Matching Details:**")
        if 'campaign_tags_df' in st.session_state and st.session_state.campaign_tags_df is not None:
            # Show sample campaigns from campaign tags for selected product groups
            if st.session_state.get('placement_product_group_filter_active', False) and st.session_state.placement_product_group_filter:
                filtered_tags = st.session_state.campaign_tags_df[
                    st.session_state.campaign_tags_df['tag_1'].isin(st.session_state.placement_product_group_filter)
                ]
                st.write(f"Campaign Tags Matching Selected PGs: {len(filtered_tags)} rows")
                if not filtered_tags.empty and 'Campaign Name' in filtered_tags.columns:
                    sample_campaigns = filtered_tags['Campaign Name'].unique()[:10].tolist()
                    st.write(f"Sample Campaign Names from Tags: {sample_campaigns}")
                    
        # Show bulk file campaign names for comparison  
        if 'bulk_data' in st.session_state and st.session_state.bulk_data:
            st.write("Sample Campaign Names from Bulk Files:")
            for sheet_name, df in st.session_state.bulk_data.items():
                if isinstance(df, pd.DataFrame):
                    # Show all available columns
                    st.write(f"  {sheet_name} columns: {list(df.columns)}")
                    
                    # Look for campaign columns
                    campaign_columns = [col for col in df.columns if 'campaign' in col.lower()]
                    if campaign_columns:
                        st.write(f"  {sheet_name} campaign-related columns: {campaign_columns}")
                        
                        # Try to find the target column using case-insensitive matching
                        target_col = None
                        for col in df.columns:
                            if col.lower() == CAMPAIGN_NAME_COL_IN_BULK_FOR_PLACEMENT.lower():
                                target_col = col
                                break
                        
                        if target_col:
                            sample_bulk_campaigns = df[target_col].dropna().unique()[:5].tolist()
                            st.write(f"  {sheet_name}: {sample_bulk_campaigns} (using '{target_col}' column)")
                        else:
                            # Use the first campaign column found
                            campaign_col = campaign_columns[0]
                            sample_bulk_campaigns = df[campaign_col].dropna().unique()[:5].tolist()
                            st.write(f"  {sheet_name}: {sample_bulk_campaigns} (using '{campaign_col}' column - target column not found)")
                    else:
                        st.write(f"  {sheet_name}: No campaign column found")
                    
        # Show column names comparison
        st.markdown("**Column Names Being Used:**")
        st.write(f"Product Group Column (tags): 'tag_1'")
        st.write(f"Campaign Name Column (tags): 'Campaign Name'") 
        st.write(f"Campaign Column (bulk): 'Campaign Name (Informational only)'")
        
        if 'debug_targeting_filter' in st.session_state:
            debug_info = st.session_state.debug_targeting_filter
            
            st.markdown("**Filter State:**")
            st.write(f"Filter Active: {debug_info.get('active', False)}")
            st.write(f"Selected Groups: {debug_info.get('selected_groups', [])}")
            
            if 'before_filtering' in debug_info and 'after_filtering' in debug_info:
                st.markdown("**Before Filtering:**")
                st.write(f"Branded Rows: {debug_info['before_filtering'].get('branded_rows', 0)}")
                st.write(f"Non-Branded Rows: {debug_info['before_filtering'].get('nonbranded_rows', 0)}")
                st.write(f"Branded Product Groups: {debug_info['before_filtering'].get('branded_product_groups', [])}")
                st.write(f"Non-Branded Product Groups: {debug_info['before_filtering'].get('nonbranded_product_groups', [])}")
                
                st.markdown("**After Filtering:**")
                st.write(f"Branded Rows: {debug_info['after_filtering'].get('branded_rows', 0)}")
                st.write(f"Non-Branded Rows: {debug_info['after_filtering'].get('nonbranded_rows', 0)}")
                st.write(f"Branded Product Groups: {debug_info['after_filtering'].get('branded_product_groups', [])}")
                st.write(f"Non-Branded Product Groups: {debug_info['after_filtering'].get('nonbranded_product_groups', [])}")
                st.write(f"Rows Removed (Branded): {debug_info['after_filtering'].get('rows_removed_branded', 0)}")
                st.write(f"Rows Removed (Non-Branded): {debug_info['after_filtering'].get('rows_removed_nonbranded', 0)}")
            
            # Add Sankey diagram debugging
            st.markdown("**Sankey Diagram Filtering:**")
            if 'ad_spend_sankey' in debug_info:
                st.write(f"Ad Spend Sankey - Filter Active: {debug_info['ad_spend_sankey'].get('filter_active', False)}")
                st.write(f"Ad Spend Sankey - Selected Groups: {debug_info['ad_spend_sankey'].get('selected_groups', [])}")
            
            if 'ad_sales_sankey' in debug_info:
                st.write(f"Ad Sales Sankey - Filter Active: {debug_info['ad_sales_sankey'].get('filter_active', False)}")
                st.write(f"Ad Sales Sankey - Selected Groups: {debug_info['ad_sales_sankey'].get('selected_groups', [])}")
            
            if 'spend_sankey' in debug_info:
                st.write(f"Spend Sankey - Pre-filter Count: {debug_info['spend_sankey'].get('pre_filter_count', 0)}")
                st.write(f"Spend Sankey - Post-filter Count: {debug_info['spend_sankey'].get('post_filter_count', 0)}")
                st.write(f"Spend Sankey - Rows Filtered: {debug_info['spend_sankey'].get('rows_filtered', 0)}")
                st.write(f"Spend Sankey - Selected Groups: {debug_info['spend_sankey'].get('selected_groups', [])}")
                
            # Add a section to show the actual filtered dataframes
            st.markdown("**Filtered DataFrames in Session State:**")
            if 'filtered_branded_targets_df' in st.session_state and 'filtered_non_branded_targets_df' in st.session_state:
                st.write(f"Filtered Branded DataFrame Rows: {len(st.session_state.filtered_branded_targets_df) if not st.session_state.filtered_branded_targets_df.empty else 0}")
                st.write(f"Filtered Non-Branded DataFrame Rows: {len(st.session_state.filtered_non_branded_targets_df) if not st.session_state.filtered_non_branded_targets_df.empty else 0}")
                
                # Show the widget key and session state key to verify they're connected
                st.markdown("**Widget and Session State Keys:**")
                st.write(f"Widget Key: targeting_product_group_filter2_widget")
                st.write(f"Session State Key: targeting_product_group_filter2")
                st.write(f"Widget Value: {st.session_state.get('targeting_product_group_filter2_widget', 'Not set')}")
                st.write(f"Session State Value: {st.session_state.get('targeting_product_group_filter2', [])}")
        else:
            st.write("No product group filtering debug information available.")
    else:
        # Add a button to enable debug mode
        if st.button("Enable Debug Mode"):
            st.session_state.debug = True
            st.rerun()
        st.info("No debugging information available yet. Click 'Enable Debug Mode' to see detailed information.")

    # --- Custom Debug DataFrames for Product Group Filtering ---
    if 'debug_branded_pg_mapping' in st.session_state and st.session_state.debug_branded_pg_mapping is not None:
        st.markdown('#### Branded Product Group Mapping')
        st.dataframe(st.session_state.debug_branded_pg_mapping, use_container_width=True)
    if 'debug_nonbranded_pg_mapping' in st.session_state and st.session_state.debug_nonbranded_pg_mapping is not None:
        st.markdown('#### Non-Branded Product Group Mapping')
        st.dataframe(st.session_state.debug_nonbranded_pg_mapping, use_container_width=True)
    if 'debug_filtered_branded' in st.session_state and st.session_state.debug_filtered_branded is not None:
        st.markdown('#### Filtered Branded Data')
        st.dataframe(st.session_state.debug_filtered_branded, use_container_width=True)
    if 'debug_filtered_nonbranded' in st.session_state and st.session_state.debug_filtered_nonbranded is not None:
        st.markdown('#### Filtered Non-Branded Data')
        st.dataframe(st.session_state.debug_filtered_nonbranded, use_container_width=True)

    st.markdown("- Analyzing all columns for campaign type indicators")
    st.markdown("- Using column structure to determine campaign type when other methods fail")
    
    # Display bulk file structure if available
    if 'bulk_data' in st.session_state and st.session_state.bulk_data:
        st.markdown("#### Bulk File Structure:")
        for sheet_name, df in st.session_state.bulk_data.items():
            if isinstance(df, pd.DataFrame) and not df.empty:
                st.markdown(f"**Sheet: {sheet_name}** ({len(df)} rows, {len(df.columns)} columns)")
                st.markdown("Sample columns: " + ", ".join(list(df.columns)[:10]) + (" ..." if len(df.columns) > 10 else ""))
                
                # Check specifically for Customer Search Term column
                has_search_term = False
                for col in df.columns:
                    if col.lower() == 'search term' or col.lower() == 'customer search term':
                        st.success(f"✅ Found search term column: '{col}' in sheet '{sheet_name}'")
                        has_search_term = True
                        
                        # Show sample values from this column
                        if len(df) > 0:
                            sample_values = df[col].dropna().head(5).tolist()
                            if sample_values:
                                st.markdown("Sample values: " + ", ".join([f"\"{str(val)}\"" for val in sample_values]))
                        break
                
                if not has_search_term:
                    st.warning(f"⚠️ No search term column found in sheet '{sheet_name}'")
                
                # Check for Product column
                if 'Product' in df.columns:
                    product_values = df['Product'].dropna().astype(str).unique()
                    if len(product_values) > 0:
                        st.markdown(f"Product column values: {', '.join(product_values[:5])}" + 
                                   (" ..." if len(product_values) > 5 else ""))
                        
                        # Check if any product values contain sponsored products or brands
                        has_sp = any('sponsored product' in val.lower() for val in product_values)
                        has_sb = any('sponsored brand' in val.lower() for val in product_values)
                        
                        if has_sp:
                            st.success("✅ Found 'Sponsored Products' in Product column")
                        if has_sb:
                            st.success("✅ Found 'Sponsored Brands' in Product column")
                        if not has_sp and not has_sb:
                            st.warning("⚠️ No campaign type indicators found in Product column")
    else:
        st.info("No bulk file data available yet. Upload a bulk file to see details.")

    


# Clear out any duplicate system messages from previous runs
st.session_state.debug_messages = [msg for msg in st.session_state.debug_messages 
                                if not msg.startswith('[SYSTEM]')]

# Add useful system information
add_debug_msg("SYSTEM", f"Dashboard version: 1.0.0")
add_debug_msg("SYSTEM", f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# Add information about loaded data
try:
    if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
        if isinstance(st.session_state.bulk_data, dict):
            bulk_info = []
            for sheet_name, df in st.session_state.bulk_data.items():
                if isinstance(df, pd.DataFrame):
                    bulk_info.append(f"{sheet_name}: {df.shape[0]} rows, {df.shape[1]} columns")
            if bulk_info:
                add_debug_msg("DATA", f"Bulk file sheets: {', '.join(bulk_info)}")
            else:
                add_debug_msg("DATA", "Bulk file loaded but no valid dataframes found")
        else:
            add_debug_msg("DATA", f"Bulk data is not a dictionary: {type(st.session_state.bulk_data).__name__}")
    else:
        add_debug_msg("DATA", "No bulk data loaded")

    if 'sales_report_data' in st.session_state:
        if isinstance(st.session_state.sales_report_data, pd.DataFrame):
            sales_df = st.session_state.sales_report_data
            add_debug_msg("DATA", f"Sales report: {sales_df.shape[0]} rows, {sales_df.shape[1]} columns")
        else:
            add_debug_msg("DATA", f"Sales report data is not a DataFrame: {type(st.session_state.sales_report_data).__name__}")
    else:
        add_debug_msg("DATA", "No sales report data loaded")

    # Add attribution information
    if 'sd_attribution_choice' in st.session_state:
        add_debug_msg("SETTINGS", f"Current attribution model: {st.session_state.sd_attribution_choice}")
    else:
        add_debug_msg("SETTINGS", "No attribution model selected")
            
    # Check for untagged ASINs in the ASIN performance dataframe
    if 'asin_perf_df' in st.session_state and isinstance(st.session_state.asin_perf_df, pd.DataFrame) and not st.session_state.asin_perf_df.empty:
        untagged_df = st.session_state.asin_perf_df[st.session_state.asin_perf_df['Product Group'] == 'Untagged Group']
        if not untagged_df.empty:
            untagged_count = len(untagged_df)
    
    # Check if we have any branded ASINs configured - with proper None checks
    if 'client_config' in st.session_state and st.session_state.client_config is not None:
        if isinstance(st.session_state.client_config, dict) and 'branded_asins_data' in st.session_state.client_config:
            branded_asins_data = st.session_state.client_config.get('branded_asins_data', {})
            if branded_asins_data is not None and isinstance(branded_asins_data, dict):
                branded_asins_count = len(branded_asins_data)
                pass
                
                # Sample a few ASINs to show
                if branded_asins_count > 0:
                    sample_asins = list(branded_asins_data.keys())[:3]
                    pass
            else:
                pass
        else:
            pass
    else:
        pass
    
    # Check bulk file for ASIN columns
    if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
        try:
            if isinstance(st.session_state.bulk_data, dict):
                for sheet_name, df in st.session_state.bulk_data.items():
                    if isinstance(df, pd.DataFrame):
                        # Check for ASIN columns
                        asin_cols = [col for col in df.columns if 'asin' in col.lower()]
                        if asin_cols:
                            pass
                        else:
                            pass
                        
                        # Check for Entity column
                        if 'Entity' in df.columns:
                            entity_values = df['Entity'].value_counts().to_dict()
                            pass
                        else:
                            pass
                        
                        # Check for Product column
                        if 'Product' in df.columns:
                            product_values = df['Product'].value_counts().to_dict()
                            pass
                        else:
                            pass
                        
                        # Check for Sales columns
                        sales_cols = [col for col in df.columns if 'sales' in col.lower()]
            else:
                pass
        except Exception as e:
            import traceback
            tb = traceback.format_exc()
            pass

    # Add client configuration information with proper None checks
    if 'client_config' in st.session_state and st.session_state.client_config is not None:
        try:
            if isinstance(st.session_state.client_config, dict):
                client_name = st.session_state.client_config.get('client_name', 'Unknown')
                
                # Safely get branded terms count
                branded_terms_list = st.session_state.client_config.get('branded_terms', [])
                branded_terms = len(branded_terms_list) if branded_terms_list is not None else 0
                
                # Safely get branded ASINs count
                branded_asins_dict = st.session_state.client_config.get('branded_asins_data', {})
                branded_asins = len(branded_asins_dict) if branded_asins_dict is not None else 0
                
                add_debug_msg("CLIENT", f"Client: {client_name}, {branded_terms} branded terms, {branded_asins} branded ASINs")
            else:
                add_debug_msg("CLIENT", f"client_config is not a dictionary: {type(st.session_state.client_config)}")
        except Exception as e:
            import traceback
            tb = traceback.format_exc()
            add_debug_msg("CLIENT", f"Error processing client config: {str(e)}\n{tb}")
    else:
        add_debug_msg("CLIENT", "No client selected or client_config is None")

    # Add targeting data information
    if 'branded_targets_df' in st.session_state and isinstance(st.session_state.branded_targets_df, pd.DataFrame):
        add_debug_msg("TARGETING", f"Branded targets: {st.session_state.branded_targets_df.shape[0]} rows")
    if 'non_branded_targets_df' in st.session_state and isinstance(st.session_state.non_branded_targets_df, pd.DataFrame):
        add_debug_msg("TARGETING", f"Non-branded targets: {st.session_state.non_branded_targets_df.shape[0]} rows")

except Exception as e:
    import traceback
    tb = traceback.format_exc()
    add_debug_msg("ERROR", f"Error collecting debug information: {str(e)}\n{tb}")

# Only display the audit progress information on the Advertising Audit page
if st.session_state.current_page == "advertising_audit":
    # Initialize audit progress log if not exists
    if 'audit_progress_log' not in st.session_state:
        st.session_state.audit_progress_log = []
    
    # Function to add progress updates
    def add_audit_progress(step, message, status="info"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        st.session_state.audit_progress_log.append({
            "timestamp": timestamp,
            "step": step,
            "message": message,
            "status": status
        })
    
    # Add initial progress updates if none exist
    if not st.session_state.audit_progress_log:
        add_audit_progress("Initialization", "Starting advertising audit process", "info")
        
        # Check for data availability
        if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
            add_audit_progress("Data Loading", "Bulk advertising data found", "success")
        else:
            add_audit_progress("Data Loading", "No bulk advertising data found", "warning")
            
        if 'sales_report_data' in st.session_state and st.session_state.sales_report_data is not None:
            add_audit_progress("Data Loading", "Sales report data found", "success")
        else:
            add_audit_progress("Data Loading", "No sales report data found", "warning")
    
    # Display the audit progress updates
    with st.expander("Audit Process Updates", expanded=False):  # Renamed to match your request
        st.markdown("### Advertising Audit Progress")
        st.markdown("This section shows the step-by-step progress of your advertising data analysis.")
        
        # Create a timeline of audit progress
        st.markdown("#### Analysis Timeline")
        
        # Check if bulk data is loaded
        if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
            campaign_count = 0
            ad_types = set()
            
            # Add progress update for data processing
            if isinstance(st.session_state.bulk_data, dict):
                # Count campaigns across all ad types
                for sheet_name, df in st.session_state.bulk_data.items():
                    if isinstance(df, pd.DataFrame):
                        if 'Campaign Name' in df.columns:
                            unique_campaigns = len(df['Campaign Name'].unique())
                            campaign_count += unique_campaigns
                            add_audit_progress("Data Processing", f"Found {unique_campaigns} campaigns in {sheet_name}", "info")
                        
                        # Extract ad types
                        if 'Product' in df.columns:
                            sheet_ad_types = set([str(t) for t in df['Product'].unique() if pd.notna(t) and str(t).strip() != ''])
                            if sheet_ad_types:
                                ad_types.update(sheet_ad_types)
                                add_audit_progress("Campaign Types", f"Detected {', '.join(sheet_ad_types)} campaigns in {sheet_name}", "info")
            
            # Add summary of data processing
            add_audit_progress("Data Summary", f"Completed analysis of {campaign_count} campaigns across {len(ad_types)} ad types", "success")
            
            # Check for branded terms
            if 'client_config' in st.session_state and st.session_state.client_config:
                branded_terms_list = st.session_state.client_config.get('branded_terms', [])
                if not branded_terms_list and 'branded_keywords' in st.session_state.client_config:
                    branded_terms_list = st.session_state.client_config.get('branded_keywords', [])
                
                branded_terms = len(branded_terms_list) if branded_terms_list else 0
                if branded_terms > 0:
                    add_audit_progress("Branded Analysis", f"Found {branded_terms} branded terms for classification", "success")
                    # Show a sample of branded terms
                    if branded_terms_list:
                        sample_size = min(3, len(branded_terms_list))
                        sample_terms = branded_terms_list[:sample_size]
                        add_audit_progress("Branded Terms", f"Sample terms: {', '.join(sample_terms)}" + (" (and more...)" if branded_terms > sample_size else ""), "info")
                else:
                    add_audit_progress("Branded Analysis", "No branded terms found for classification", "warning")
        else:
            add_audit_progress("Data Check", "No advertising data available for analysis", "warning")
        
        # Display the progress log in a timeline format
        for i, entry in enumerate(st.session_state.audit_progress_log):
            if entry["status"] == "success":
                st.success(f"**{entry['timestamp']} - {entry['step']}**: {entry['message']}")
            elif entry["status"] == "warning":
                st.warning(f"**{entry['timestamp']} - {entry['step']}**: {entry['message']}")
            elif entry["status"] == "error":
                st.error(f"**{entry['timestamp']} - {entry['step']}**: {entry['message']}")
            else:
                st.info(f"**{entry['timestamp']} - {entry['step']}**: {entry['message']}")
        
        # Add a section for current analysis status
        st.markdown("#### Current Analysis Status")
        
        # Display client configuration information
        if 'client_config' in st.session_state and st.session_state.client_config:
            client_name = st.session_state.client_config.get('client_name', 'Unknown')
            st.markdown(f"**Current client:** {client_name}")
            
            # Check for client configuration details
            branded_terms_list = st.session_state.client_config.get('branded_terms', [])
            if not branded_terms_list and 'branded_keywords' in st.session_state.client_config:
                branded_terms_list = st.session_state.client_config.get('branded_keywords', [])
            
            branded_terms = len(branded_terms_list) if branded_terms_list else 0
            branded_asins_data = st.session_state.client_config.get('branded_asins_data', {})
            branded_asins = len(branded_asins_data) if branded_asins_data else 0
            
            # Display branded terms information
            if branded_terms > 0:
                st.success(f"✅ {branded_terms} branded terms configured")
                # Show a sample of branded terms
                if branded_terms_list:
                    sample_size = min(5, len(branded_terms_list))
                    sample_terms = branded_terms_list[:sample_size]
                    st.markdown(f"**Sample terms:** {', '.join(sample_terms)}" + (" (and more...)" if branded_terms > sample_size else ""))
                    add_audit_progress("Branded Terms", f"Using {branded_terms} branded terms for classification", "success")
            else:
                st.warning("⚠️ No branded terms configured")
                add_audit_progress("Branded Terms", "No branded terms found - this may affect branded/non-branded analysis", "warning")
            
            # Display branded ASINs information
            if branded_asins > 0:
                st.success(f"✅ {branded_asins} branded ASINs configured")
                # Show a sample of branded ASINs
                if branded_asins_data:
                    sample_size = min(3, len(branded_asins_data))
                    sample_asins = list(branded_asins_data.keys())[:sample_size]
                    st.markdown(f"**Sample ASINs:** {', '.join(sample_asins)}" + (" (and more...)" if branded_asins > sample_size else ""))
                    add_audit_progress("Branded ASINs", f"Using {branded_asins} branded ASINs for product targeting analysis", "success")
            else:
                st.warning("⚠️ No branded ASINs configured")
                add_audit_progress("Branded ASINs", "No branded ASINs found - this may affect product targeting analysis", "warning")
            
            # Check attribution model and add to progress log
            if 'sd_attribution_choice' in st.session_state:
                attribution_model = st.session_state.sd_attribution_choice
                st.markdown(f"**Attribution model:** {attribution_model}")
                add_audit_progress("Attribution", f"Using '{attribution_model}' attribution model for sales metrics", "info")
                
                # Check if we have Sponsored Display campaigns with Views & Clicks attribution
                if attribution_model == "Sales (Views & Clicks)" and 'bulk_data' in st.session_state:
                    has_sd = False
                    for sheet_name, df in st.session_state.bulk_data.items():
                        if isinstance(df, pd.DataFrame) and 'Product' in df.columns:
                            if 'Sponsored Display' in df['Product'].values:
                                has_sd = True
                                add_audit_progress("Sponsored Display", "Found Sponsored Display campaigns - using Views & Clicks attribution", "success")
                                break
                    
                    if not has_sd:
                        add_audit_progress("Sponsored Display", "Views & Clicks attribution selected, but no Sponsored Display campaigns found", "info")
        else:
            st.warning("⚠️ No client selected")
            add_audit_progress("Client Configuration", "No client selected - please select a client from the sidebar", "warning")
        
        # Show any errors that occurred
        errors = [msg for msg in st.session_state.debug_messages if '[ERROR]' in msg]
        if errors:
            st.markdown("#### Issues Detected")
            for error in errors[-5:]:  # Show only the 5 most recent errors
                st.error(error.replace('[ERROR]', '').strip())
                add_audit_progress("Error Detection", error.replace('[ERROR]', '').strip(), "error")
        
        # Check for targeting data generation status
        if ('branded_targets_df' in st.session_state and st.session_state.get('branded_targets_df') is not None) or \
           ('non_branded_targets_df' in st.session_state and st.session_state.get('non_branded_targets_df') is not None):
            
            # Add targeting data processing to progress log
            if 'branded_targets_df' in st.session_state and isinstance(st.session_state.branded_targets_df, pd.DataFrame):
                branded_count = len(st.session_state.branded_targets_df)
                add_audit_progress("Targeting Analysis", f"Processed {branded_count} branded targeting entries", "success")
            
            if 'non_branded_targets_df' in st.session_state and isinstance(st.session_state.non_branded_targets_df, pd.DataFrame):
                non_branded_count = len(st.session_state.non_branded_targets_df)
                add_audit_progress("Targeting Analysis", f"Processed {non_branded_count} non-branded targeting entries", "success")
            
            add_audit_progress("Analysis Status", "Targeting performance data generated successfully", "success")
        else:
            add_audit_progress("Targeting Analysis", "No targeting performance data generated yet", "info")
        
        # Show next steps and recommendations
        st.markdown("#### Next Steps")
        recommendations = []
        
        if 'bulk_data' in st.session_state and st.session_state.bulk_data is not None:
            # Check if we have targeting data
            if ('branded_targets_df' not in st.session_state or st.session_state.get('branded_targets_df') is None) and \
               ('non_branded_targets_df' not in st.session_state or st.session_state.get('non_branded_targets_df') is None):
                recommendations.append("Generate targeting performance data to analyze branded vs. non-branded performance.")
                add_audit_progress("Recommendation", "Need to generate targeting performance data", "info")
            
            # Check if we have search term data
            has_search_terms = False
            if isinstance(st.session_state.bulk_data, dict):
                for sheet_name, df in st.session_state.bulk_data.items():
                    if 'Search Term' in sheet_name or 'Search Term' in (df.columns if isinstance(df, pd.DataFrame) else []):
                        has_search_terms = True
                        add_audit_progress("Search Terms", "Search term data found in bulk file", "success")
                        break
            
            if not has_search_terms:
                recommendations.append("Include search term reports in your bulk file for keyword performance analysis.")
                add_audit_progress("Recommendation", "Include search term reports for better keyword analysis", "info")
        
        if not recommendations:
            st.success("✅ All data is processed and ready for analysis!")
            add_audit_progress("Analysis Complete", "All data processed successfully and ready for analysis", "success")
        else:
            for i, rec in enumerate(recommendations):
                st.info(f"{i+1}. {rec}")
